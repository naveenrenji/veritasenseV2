Address the specific issue keeping in mind that each time you go up one level you will get more calls because at level one can be automated.  Level you have people that are not the software engineer.  So software developers.  But they have functional knowledge.  When you go to the software developers they cost more to reasons why.  Not Because thats probably the M.  Salad is higher but also because you are disacting them from developing new software making updates.  How they access insult.  So those are TV guidelines.  3.  Level on the customers.  Some other issues recruiting hiding software personnel.  Thats always not easy things to do.  So there are several characteristics that you need to match.  Obviously you need to match technical skills.  So you need to be sure that the people you are hiring is able to do the things that he would be.  Hoshi would be higher for so and thats kind of easy point.  But then you have other skills so well be talking moment about that.  The project team has sort of life cycle so it doesnt stop with the hiding so you need to hire the right people.  Give you an example.  Its an example that they use all the was working in technology company.  was coo and CTO for the company and we hire the team leader.  So one who was in charge to manager the technical team.  So the company was doing ticketing mean our our largest client for the Disney.  We were in Orlando Florida and we managed the the tickets issued by Disney to people like going to their team.  Parks.  Its there are several conditions.  So there is time condition.  That is man issue.  There are customer federalization issues.  So there are many issues seems to be an easy problem ticketing command is ticket not so easy.  So mean we interviewed quite lot of candidates.  We ended up with candidate that was interviewed by several of us so hired him and then after he had all the boxes checked he had the right scale.  So apparently the right motivations and so on.  After few days it started saying wear car keys the rest of the team is wearing shorts.  dont feel comfortable.  How can we do that dont want to give up my targets and said You know what its Florida.  mean people sometimes.  So they come to the office.  In short what can you do And thats the first one and the second one was come to the office very early 37 tops and want to live early.  want to live after but most of the team is saying longer.  mean if you are the team leader you need to be the first to come in the last to leave.  So those are things that are really difficult to detect when you are hiding the person.  So for sure there was probation period and we didnt keep the the person and dont know what is doing now about.  We hire the later on another person.  So this is just to say that there are technical issues technical great so that you can like easily test.  But there are software issues that are more difficult to detect.  So again when you create team there is the formation of the team the development the maintenance is kind of life cycle.  When you build team again you really need to keep in mind.  The people will work in team.  So sometimes is more relevant to have good person doing okay from the technical sent point.  Okay.  But the real team player then having genius who is zo social skill and not team player can you mute yourself please So those are things that you really need to keep in mind Let me skip some of those And we already mentioned that developing the team.  So once you have the team you need to be sure that you keep the team motivated.  You need to be sure that you provide the the right reasons to be engaged and there is no single way to do it because each team is different.  Each person in the team is different and you need to understand what people want.  If you really want to keep the the team sometimes can be just just money sometimes can be challenges sometimes can be the environment the quarrel leaving.  And each time you need to compromise because you cannot give unlimited money.  You cannot say you stay home all the time and you work day so mean you need to compromise.  But the it is like in everything in life.  You need to keep the attention as it is not too much not to little.  So if the attention is to match it will break meaning the teamm member will leave if its too little they will underperform and you will never have your job.  So let me stop for second the sharing.  Yes and let me be sure that everyone is muted because still have some noises Okay.  Now everyone should be muted Alright so let me Go back.  Sorry for the interruption.  So developing team creating new challenges make sure that everybody is on board and stay on board When was managing just to continue with the same example.  So was cause.  You and CTO.  All of the company but the vast majority of my time was being the terrorist dealing with with personal problems.  mean you human beings.  We have issues and sometimes if you are the boss or the one in charge for the team at whatever level it is you need to make sure that you create the the right within the the team and the trusting you as manager or whatever is the role that that you Have.  And then you need to deal with the problems that they may have.  mean sometimes our relational problems.  dont like the people in my team and then that you need to negotiate because you cannot just decide that you are fired.  But you say on board the sometimes hes mother of the type of TV that they are doing so.  And then again you need to compromise some.  Being manager.  Its lot of compromises its its very rare that the solutions are black and white.  So you need to work with that you need to work with people when you work with people you have is like vector or if you have one vector you have one direction.  If you have vectors you have directions and then you need to do sort of resulting vectors all over all of it.  Knowing that you will use something.  So sometimes you cannot motivate people.  You cannot do what some people may ask and then at point there is no way to come back.  So anyway just wanted to give you little bit of highlight on what can be behind the scenes What can be in hiring managing teams maintaining the teams and growing things.  So would be happy to share other experiences if you like but thats something that in my opinion can be useful.  mean we are engineering management down the road or right now you are managing teams and when you have taken your people like you will probably do considering your engineering you may have personality.  So you have technical issues and you have soft issues even issues that could be.  mean more on the personal the relational aspects is interesting.  That when you work in consulting company so he wasnt consulting good portion of my career and when you assemble teams and you assemble teams quite often when you are in consulting because each time you have new Job new new plans or the new Pvd.  With with an existing client you need to assemble the team so you need to send people there to do the job physically or lost easily in remote work.  Times how you you create team.  So so you are consulting company.  You are for profit organization meaning you have.  You will want to create the team that will deliver the best results at the lowest cost possible.  So you may not want to have your superstars involved the all the time.  So you want to have probably one super Sarah and bunch of supporters.  But then how you mix match.  So you need to keep in mind who has the competencies on one side but on the other side you also need to work on the compatibility.  few years ago Price Waterhouse created the an AI to do the matching.  So they mean improve the the existing apps on line database with the additional information Im not decides technical up the soft skills.  So the compatibility the history of companies.  And then they had this system doing the match.  So that seems to be trivial but when you have like like And its or 1000 or projects and you need to have 100.  So 1000 teams project can last longer or short time.  So if its longer time its kind of more manageable actually different problems.  But if you have shorter projects mean you have continuous need of creating team.  and having sort of an expert system.  An AI that will help you.  Its really big deal Alright So that was on something not related to Python.  Lets go back to Python and lets talk about input outputs and dictionaries and tubes.  So its really difficult to to think about any program.  Any code that you can write without having any form of interaction with the outside world.  So far the form of interaction that we used was taking an input from the user.  But most of the time you have files that you read you process you do something and eventually you write the results.  So input output.  Hes an essential portion of writing code in any language.  Most of the time we will use files so that are up text like.  So it can be play in Xc.  File can be Csv.  Comma but did value there is pretty much text but they have the advantage that they can be read as tables in excel where the comma is what is telling excel to that one character is in one column and the character After the comma is in the following column and so on.  So we primarily use txt and Csv files.  But keep in mind that that that dont can handle.  Look pretty much any type of file lets say all up the open source type of files can be handled by python.  Then if you have probably the reformata then you may not have the library call for reading it but then is different problem.  When you open file you will use the def function.  Open so open.  Now well make the file available for the type of operation that you are going to do.  So text file or Csv file its typically sequence of lines.  So each line can be record or can be an item to be processed The open function is called the file handle and is what is used to again start the process of either reading or writing files.  So its like in wordprocessor your file open and then you specify the name of the.  They.  Syntax is whatever is the name of the variable open by name mode.  The mode or modality is either read writer or read writer so those are the options you have when you open file for reading you do not need to specify the mode so the default is our then if you want to write then it will be so.  By name.  That can be variable with the name of the file or can be string with the name like in this case is inbox dot txt so but it could be.  can create value called infile and then over here would have open in file if want to do read only that could be the end.  would be close parenthesis.  So file open.  Thats the case.  Its reading it because its the default.  If you print it you dont print the actual file but you print the pointer to to the file and thats what you have.  Then that yeah mean again file is not the result word you can use it to name the file.  Not that you need to but you can.  So again when you print the the variable or it is the handle on the file you will get only the point that to define not the real content.  Lets do an example.  So you have this file is txt file.  You have one line then you have blank line and another line with other text.  So you open the file in readinger Then for example you initialize account for the number of lines and you start the loop.  So the barrier bowl that will be in the Loopo.  Its called text line and it its it will loop into the file.  So line count.  That will be was will become one and then it will print the line counter.  That would be one and that that the text line and it is the phone line of the file.  And then we go an app and it will be to the second line or is blank.  Third and then the end.  So and thats the outcome.  So is reading.  You dont need to have it.  The handle is the essential to point the file that you are going to use Again.  You can do loops Thats another example.  You can have counter You can get the number of records so you can read the file with file.  Read oops and then with the Len over the read the the this point.  You have the entire file in this value and then that you can print the number of records keeping in mind that that blanks will count as one like in this example define as lines just like you can see here And then because as we know strings and lists can be partitioned somehow you can take piece of it Could you please mute yourself Thank you.  So lets say you have some tweets.  So is that text file with one tweet each line.  So this is via case.  dontloaded the those suites while ago.  Oh You have again file with the all the texts on the of tweets and then thats an example.  How to do it how how to do something.  will explain what is the same thing.  So you open the file again.  You dont need the to have Ara because going to be in read mode then that initializing list containing the words with the hashtag and then stop the loop into the file so the first Hi Duration would be the first one.  This one on the top Then what Im doing is basically the split common will create list out of the string.  So each line.  For example this one will be read as string.  You play to separate the the words need to split the string creating list where each element is ward of the initial string.  So.  And thats what Im doing here.  So split will split the string if nothing is specified in the parentheses will be blank.  So if there is blanket there is space that could be the end of the world.  Then once had the list of all the words Im looping into this list checking if the world is starting with hashtag if the word is starting with dash then will append the word to the list of hashtags if not well continue so at the end of The loop for will analyze everything that is you know the first line that mean at the first round will be the first line.  So in this case at the end of the loop there will be nothing because there is no ward.  The starting with will so it will end this looper.  Well go back next line.  Same thing at the very end.  It will in the variable in the list hashtag.  will have all the wards starting with dash tag and then Im printing the first 10 and thats what got.  So again thats an example just to practice how to use the open and and how to create case.  Somehow you can use.  Continue if you dont see like mean in this case you knew wouldnt make sense its intrinsically true but you can have it so.  If not if it is not starting with from continue meaning.  You just keep.  mean we can.  We could have done that to the previous example.  Thats would skip that again drawing your attention to the split statement.  So you have this.  Variable here.  If you split it with the exclamation marker you will have the first mean you will get list.  The list will have Hello.  Then you have the exclamation market.  That will be the separation item.  Then you have the second one that will start with the space and will continue till the d.  Over cold then the next one will be space and then you have all the rest again.  The default is the blank is the white space and if you do not with exclamation Mark But with the space you will will basically have every single word keeping in mind that is not removing the special characters.  So mean the first word is Hello With exclamation Mark And so on so the punctuation would not be removed.  Lets say have this file here.  So is Csv meaning its commercial separated value.  You but you can open it with the regular text.  Edit or with excel.  So you have John American one Mexican.  Yuan is Greek Jean that is French.  So you open the file.  Then you print nationalities and then you start looping in it.  So you you take the first row.  You split it by the comma meaning the list.  That you will generate will have elements John and America and then you will preint the the second element.  That will be the nationality meaning you have American Mexican Greek and French.  You dont see it.  But at the end of each character there is which line there is special character that is new line.  So when you have new line you have this blank current is the new line the skip line that you have it to remove it.  You want to use strip strip is striping the the the string by all the spaces and all the special characters that are either left or right so if you dont specify anything that means left and right you can specify our or for left or right and at that point we didnt move only from the right or from the left.  If you do that you are basically removing the new line.  That is deal the over each line and you will not have the space that you have here.  So and then you have the nationalities just the way they probably supposed to be writing file.  Is not that much different Is Mmm.  mean instead of is W.  So you write the file with the name of the handle right And then you write whatever you want to do.  You may want to have new line eventually and thats what you have in Python point something you had to close the file with the close statement after writing it with python is not required that generally do it just because Its giving me the end the beginning Internet.  Okay.  will keep that.  Those are some of the links.  So lets talk now about dictionaries and balls.  So we mentioned strings integer.  So floating lists there are more types of variables that you will use one of the at least that we will use lot or significant number of times to build so not that much dictionary.  Yes so so when you have Elisa lists are ordered meaning you create list.  In certain way they are mute.  bowl but unless you change either the order or the content you will say the same for the duration of your program.  So if you have Bcd thats the way you created and you printed you will end time you an end time.  You.  You will get Bcd.  If you go for the third element meaning alphabet you will get see So thats what is is going to say.  This is not the case.  With the addition of this.  So list our collections.  This is kind of recap but this are mutable.  You can change it.  You can get the length of string.  You can generate ranges as list of ranges of numbers.  As list you can do little bit of operations.  You can do again.  Then we already mentioned Max mean some.  Those are all things that you can do.  Once you are sure that the content is nomadical otherwise you would get an error.  You can split the.  So we already saw that last class With tuples.  Things are little bit different from lists.  They are kind of similar meaning.  You have elements inside the the party Ebola.  They They are separated by comma inside can be pretty much anything.  But there are main differences one instead of square brackets.  You have round the brackets regular parentheses.  And they are non mutable meaning.  You cannot change this from to the so if you try to do it you will get an app.  So who both are immutable lists are mutable and thats the main difference.  There are not many cases when you use tuple so sometime you use pulse when you want to be sure that the content would not be changed by your program.  Sometimes we do think so that are changing content or variables.  We may or may not want to do that.  If we want to be sure that is not going to happen instead of list you created to go probably use the Tuples in less than 5.  Or of my code Again.  You can assign it to you can create it but you cannot modify it.  Dictionaries.  So we mentioned that lists and tables are all that dictionaries are an order meaning that when you create addiction its dictionary.  So are kind of different from lists instead of regular parentheses they have con brackets like in this case and that with each element as portions one is the key and one is the value.  So in this case is about population.  The population or U. S. A.  is 318.  Either is 59.  Japan is 27.  So the key is you.  The keys are U. S. A.  Italy and Japan.  The values are 1859 127.  So when you create dictionary you dont really need to keep the order because you will.  Recall the single element by the key they have.  So meeting keeping the order wouldnt you benefit you at all So in day right infinite wisdom they creators uhied on this side that that if its not needed that will not so.  Dictionaries are not order.  Meaning that that you can call an element by calling the key and you will get it.  You can ask for all the keys or the values If you create list and you printed you will not necessarily get the same order because again they are an order so they will print the mean you will print the content but if you created the with the U. S. A.  Italy Japan and you print.  You can get Japan Italy U. S. A.  or any combination.  So again.  Don dont expect the same order because it is not going to be there.  You can access by the key by the position by by by by the key or combination of key value you can add the elements.  So theyre mute.  Ebola you can add the for example Uk equals 64 and when you print it you will get an additional element Obviously the key cannot be mute.  The ball line because otherwise you will lose somehow the relationship key value You can like.  In this example you have Charlie one the 42 Jan 100.  Whatever that would mean.  You do looper you print the the key and you print the value for the key.  Then you have John Andred Charlie one and Fred 42 You can get list of keys values or items meaning both from additionally.  So you can transform dictionary into list.  So in this case transform the mean only the keys the like.  In this case the values or the entire items Hello Skip That Dictionaries are sometimes used as form of data representation because you have key and value.  And this is sort of basic data structure.  Its very basic.  Meaning.  If you have something that is more complex there are better data structures to serve you.  But is possibility.  So thats another example.  So you have amendment.  Its based on that.  This file.  So you have work counter.  You initialize the variable What counter as an empty dictionary and then you start reading the file.  Then you split data meaning you are creating list with all the words.  And then you start out the looper into each line First line second line and so on and then what you want to do.  You want to count the number of times.  Each word is in the 5.  So initially What counter as nothing so utterly work counter work Ewa.  What counter would the last one so and the first round that you will get an error because it is empty so there is no element that that can be addressed at that point You will create work counter world e.  One.  If at this second round or end round the world is there then you will add the one to the account.  So at the end you will print this case the first you will create variable with the first 10 and you will print each line at the time and thats what you would.  So keep in mind that you will use this one in the in class exercise that you will do.  Show.  Counter again.  Its something that we use all the time And those are the usual links to the website for more.  The Python website for more information.  So let me stop sharing for second questions Okay so is 34.  And let me introduce the in class assignment And Share the screen again now Let me go here.  So this in class exercise as part one and part 2.  So you will read the fine name fine name the names that dont txt that will show you what is inside that Thats the file So there are few names and they are mean unique names and they are repeated the multiple times So you read the file you count the how many unique names so that are in the file and print the the result to the screen.  So the name record.  The T.  Times the name Then you will print the name that is used the the most in the file So let me make sure That the file is there Yeah you have it.  Let me stop sharing About that And let let me create the breakout rooms So Im creating breakout rooms.  Each one will have participants.  Once create the rules you would join the rooms you will start working with your team and you will have about 25 min to work on it.  Then will close the room so we will discuss the solution and then will introduce the aside.  Then the next assignment and that will be the end of the class Alright So all the rooms are closed.  Let me resume the recording.  How was it Volunteers who is going to share what you did Again.  There is no judgment and is really useful to share the issues.  You had the solutions you created Come on have one to pick names.  Are they good Okay.  Lets say Rahula What do you do Okay to shy Nicolas Okay.  That was not particularly successful.  So no volunteer.  Alright.  Okay so let me share the screen and let me go.  Yeah right.  So again thats an example.  This case created the mean its kind of similar to what was in one of the slides.  So initialized account counter dictionary as empty.  Then initialized 0.  The A.  Counter for the frequency and initialized to blank that not necessary but to blank the name with the highest frequency.  Then started the loop.  open the file reading one line at the time And then within the line Im removing that the blanks and special characters.  So let them write.  Then Im asking if line the name is an account dictionary.  If yes add one to the value.  Or that key and and then Im asking if the value is greater than the Max frequency and initially it will.  If it is then will update the content of the maximum frequency and then will also use that name as the name that will get the the maximum frequency.  If not the value will be one meaning is the first time is reading that name and and Im moving to the next line.  Once everything is finished it will print the the dictionary mean.  The list of names unique names and then the number recording the most is the name and the end of the quarter.  So if run it Thats what youll have.  Im in printing as it is dictionary is not nice looking.  could have done better but it is getting the results.  So you have dot 31 Luke 15 Leah 54 the name according to Moss is Leah with 54 occurrences.  So you have probably an idea of what those names are about.  Okay.  So will publish this And will also P.  Publish.  The exercise.  And let me talk little bit about the exercise for next week.  This exercise as one level or complexity that we didnt have before.  So before going there let me explain what mean.  With the concept of creating story because what you would do would be to read the files.  So the files will look pretty much like this.  One is about New Year Cdcd bike.  So you had the duration the day stuff.  Then stop stop Stop time and things like that and you will do some calculation on each one of the files creating account for the number of lines counter for lines with customer the counter for the subscriber as user type and then you calculate the percentage of users that Are customers so and you do pretty much the same for the other side.  So the files are not similar.  You did the calculation and then there is part where you have all those numbers so you have the default and from N.  to N.  5.  You have Z.  One z.  and you can compare those.  So you want to check if there are more mean one is related to winter.  One is very easy to spring.  You want to compare it.  There are more riders in winter or in spring and then you want to check if there are more customers than subscribers in one of the and you will print the results in proper way and but you will also write the onepage interpretation the interpretation would be and not narrative Description.  So this is something that we will do lot.  During the discourse the the courts is is not about writing codes but its about using code to extract the value meaning from the data.  So let me share the screen again and this time will do shared sound And let me go here and will share videos with you.  On that data storytelling.  So thats the first one As Im in the midst of applying for Residency right now which we look grammarly has again been lifesaver with my application Theres very significant soft scale gap and data is showing that the gap is greatest in communication skills thats oral skills and written skills.  So its kind of funny that data has proven that were not great communicators yet.  The roles that operate with data are the ones that have the greatest gap in expectations to be good communicator is greater when youre working with data its kind of meta.  So what happens when you learn to communicate well is your data moves from making sense to creating meaning.  And everybody that works in data should learn how to communicate it.  Well.  Good when use the word story.  Im not talking about taking your data and turn it into fairy tale or into fiction.  What Im talking about is these fundamental frameworks that work every time and those frameworks come from story.  So now that we can hook up Fmri machines to the brain were starting to see the science of whats going on in peoples heads.  When theyre listening to stories.  And its profound.  So if you take that brain science and wrap data with these story frameworks and apply the brain is going to respond to you the same way.  The brain responds when story is being told and thats powerful way to communicate Almost every role today is impacted by data.  In fact Pwc study states that 67 of roles are enabled by data.  So that means every career in every career progression is going to be impacted by how you handle that data.  So picture that when you start you learn to explore the data.  Youre just digging around in the data and youre an explorer at the data.  Well once you become an explainer of the data thats really big career leap.  You go from being an individual contributor as an explorer of the data and then you become strategic advisor.  As you learn how to explain it.  Well and sure enough when you explain your ideas in the data well and you take point of view and its true.  You move from strategic advisor even to leader.  So it will impact your career.  It will impact your promotion.  Criteria and you will soon one day be great leader.  Through the data that you use every day And have second one.  Another min or so These have your skills.  You plead the up of the town.  But you also need to know very specifically if you want to create data story your first and most important step is to come up with proper question or hypothesis.  You want to prove or disprove that is sort of the most crucial part where also your specific knowledge as journalist comes in.  If you cover specific beat it will be much easier for you to understand what an interesting question of hypothesis is Next step is is there data to answer that question Thats when most of the ideas you might have had in the first step are going to be shut down because there is simply no data that could help you analyze it.  But if youre lucky and you have good question and you find the data then you can sort of move on to the next part which is prepare the data to be analyzed understand the data and see what variables there are whether there are missing values.  Make sure all the spelling of names is correct and homogeneous and once youre all set with that then you can move on to the next step which is the actual analysis part When we as team work on data stories we usually come up with like lets say to 20 questions we want to ask to our data set.  And we actually really document the question.  And then we do the coding to answer that question.  After that we have have an overview of our main hypotheses and all the sub questions with the possible answers.  The data can give us And then thats the point where we meet with reporter and sit down.  Talk through what we found and see what is most interesting from their perspective to go into an article to talk to experts about auto politicians and to then talk to her in the whole thing into an entire story that maybe features some graphics along with that the Okay so.  hope gave you an idea through those videos.  What mean with the you need to tell story so dont want to see just called the in.  The reporter mean in this case is one page down the road.  It would be longer record.  So.  But want to see your interpretation.  So you use the the code that you will write to create the metrics the elements that you will use to draw conclusions to create story around the the data that that you have.  You dont know.  You dont need to become Jo data journalist or things like that.  But giving just the visuals giving just the tables giving just samples of code or the description of the process.  Thats the most common error that see.  When ask for sorry most of the students instead of giving me story theyre giving me the the process that they use.  dont want the documentation on the software.  want to have what does software gave you Which kind of additional information through the software you extract it from the data.  So thats data storytelling.  Yes cocreated the courts in data storytelling.  That is graduate undergraduate with the College of Arts and thats was doing the data portion and they did the the storytelling.  But mean besides that the there is real need for getting sense out of the data and thats one of the skills that really want you to get in this courts alright so is 21 if you dont have Any question.  Thats the end of the class.  really thank you for being with me.  So long.  And if you have questions so down the road the send me or see you an email and will get back to you as soon as possible.  ft STEVENS lw INSTITUTE of TECHNOLOGY Introduction to EM624 Python clipizzistevens. edu SSE Users . vs.  Programmers Users see Computers as set of tools word processor soreadsheet map todo list etc.  Programmers learn the computer ways and the computer language Programmers have some tools that allow them to build new tools Programmers sometimes write tools for lots of users and sometimes programmers write little helpers for themselves to automate task STEVENS INSTITUTE of TECHNOLOGY of What is Code Software Program sequence of stored instructions It is little piece of our intelligence in the computer It is little piece of our intelligence we can give to others we figure something out and then we encode if and then give It fo someone else to save them the time and energy of figuring If out piece of creative art particularly when we do good job on user experience STEVENS INSTITUTE of TECHNOLOGY computer schema Central Processing Unit Runs the Program The CPU is always wondering what to do next Input Devices Keyboard Mouse Touch Screen Output Devices Screen Soeakers Printer DVD Burner Main Memory Fast small temporary storage lost on reboot aka RAM Secondary Memory Slower large permanent storage lasts until deleted disk drive flash drive STEVENS INSTITUTE of TECHNOLOGY Interpreted vs Compiled Why is Python slow Machine Source Executable source codecode preprocessing processing Compilation Interpreter Source code Intermediate code preprocessing processing Interpretation STEVENS INSTITUTE of TECHNOLOGY cf What is Python Python is multiparadigm highlevel interpreted programming language.  Multiparadigm supports various programming paradigm such as procedural objectoriented and functional programming.  Highlevel easy to write closer to human language than to machine language.  Interpreted the program is executed directly by the interpreter instead of being translated in machine language.  These characteristics granted if popularity in textmining data analysis scientific simulations webscraping and many other scripting tasks.  lis flexibility comes with the cost of lower performance with resoect to other languages Java.  For this reason it cannot be used for highfrequency trading.  STEVENS INSTITUTE of TECHNOLOGY History of Python Guido Van Rossum created the.  first version of Python in 1989.  The current version is Python but for this class we are going to consider Python 2.  The language is named after Monty Python.  This reflects in the use of example variable and function names such as spam eggs bacon and sausage.  At the end of this course you will be Pythonista which is someone who speaks the Python language.  STEVENS INSTITUTE of TECHNOLOGY Installing Python Go to hitpswww. python. orgqdownloadsrelease thon2712 Select the version corresponding to your operating system download it and install it.  Python can be used either through The official Python Integrated DeveLopment Environment IDLE Third part IDEs such as Canopy or PyCharm STEVENS INSTITUTE of TECHNOLOGY First Examples we is the orompt for the user to type myname Francisco commands print myname. upper FRANCISCO print myname.  Llower francisco print 15 examplelist 10 print sumexamplelist Three simple properties of variables Name Type Value Name Type Value integer integer myname string Francisco examplelist list 10 MM STEVENS INSTITUTE of TECHNOLOGY Simple Operations 10 15 10 10 Integer division 10 3. 0 Float division 3333333333 10. 0 Float division 3.  3333333333 4. 0 7. 0 23 Power Modulo STEVENS INSTITUTE of TECHNOLOGY 10 Variable Assignment eggs Assigning an integer meat spam Assigning string breakfast eggs meat coffee Assigning list print breakfast 3spam coffee breakfast Assigning an empty list meat sausage Reassigning variable print breakfast 3sausage coffee STEVENS INSTITUTE of TECHNOLOGY 11 Variable Names lw You can name variables whatever you want as long as the names do not start with number and only use letters numbers and underscores.  Names are case sensitive myName 10bestthings temporaryid fivepeople Savings2016 STEVENS INSTITUTE of TECHNOLOGY 12 atts Variable Names we It is wise To Use descriptive variable names rather than short ones you wont remember what Is after 100 lines of code Good Bad height 1. 87 1. 78 weight 90 kg 90 BMI weight height a2 print Your BMI is BMI print Your BMI is Your BMI is 28. 40550435551067 Your BMI is 28. 40550435551067 Is used for comments they are for humans to read not the computer is the power operator like in Excel STEVENS INSTITUTE of TECHNOLOGY 13 atts Mnemonic Variable Names we Since we can choose our variable names there is bit of best practice We name variables to help us remember what we intend fo store in them mnemonic memory aid This can confuse beginning students because well named variables often sound so good that they must be keywords httpen. wikipedia. orgwikiMnemonic STEVENS INSTITUTE of TECHNOLOGY 14 Interactive versus Script Interactive You type directly to Python one line at time and It resoonds Script You enter sequence of statemenis lines into file using text editor and fell Python to execute the statements in the Tile STEVENS INSTITUTE of TECHNOLOGY 15 Python Scripts Programs Interactive Python Is good for experiments and programs of 34 lines long But most programs are much longer so we type them into file and tell python to run the commands in the file As convention we add . py as the suffix on the end of these files to indicate they contain Python STEVENS INSTITUTE of TECHNOLOGY 14 Useful Links lw hitplearnpythonthehardway. orgbookex33. html httpwww. learnpython. orgenLoops httpswww. codecademy. comcoursespythonbeginneren CXxMGf01cCurricuUlumid4f89dab3d788890003000096 httpsen. wikibooks. orgwikiPythonProgrammingConditionalStatements hitpwww. peachpit. comarticlesarticle. asox p1312792SeqNum3 STEVENS INSTITUTE of TECHNOLOGY 17 ft STEVENS lw INSTITUTE of TECHNOLOGY Ls Introduction to Python meme clipizzistevens. edu SSE Python Components Python has many components similar to other languages Variables Assignment operator Functions Conditionals Comparators Loops Mathematical operators STEVENS INSTITUTE of TECHNOLOGY offs Most Common Builtin Types Numerics int to represent integer numbers float to represent real numbers Sequences str to represent strings of text such as characters or words list to represent lists of elements of any type tuple similar to lists but immutable Mappings dict to store values that can be accessed fast by using certain key.  The keys in dictionary have to be immutable types while values can be of any type.  STEVENS INSTITUTE of TECHNOLOGY Variable Assignment eggs Assigning an integer meat spam Assigning string breakfast eggs meat coffee Assigning list print breakfast 3spam coffee breakfast Assigning an empty list meat sausage Reassigning variable print breakfast 3sausage coffee STEVENS INSTITUTE of TECHNOLOGY Variable Names we You can name variables whatever you want as long as the names do not start with Gd number and only use letters numbers and underscores.  Names are case sensitive myName 10bestthings temporaryid fivepeople Savings016 There are reserved words that you also cannot use and del from not while as elif global or with assert else if pass yield break except import print class exec in raise continue finally is return def ror lambda try httpsdocs. python. org2referencelexicalanalysis. htmlkeywords STEVENS INSTITUTE of TECHNOLOGY tts Mnemonic Variable Names we Since we can choose our variable names there is bit of best practice We name variables to help us remember what we intend fo store in them mnemonic memory aid This can confuse beginning students because well named variables often sound so good that they must be keywords httpen. wikipedia. orgwikiMnemonic STEVENS INSTITUTE of TECHNOLOGY Sl afi Comparison Operators When you compare things you get either True or False Boolean Type.  Basic comparators greater than less than is equal to less than or equal to greater than or equal to is not equal to 10 100 True False 55 44 True somelist 1234 sumsomelist 10 True person Alfredo person. startswitha False person. startswithA True Not exactly comparator but the same idea STEVENS INSTITUTE of TECHNOLOGY Sequential Steps When program Is running It flows from one step to the next.  We as programmers set up paths for the program to follow STEVENS INSTITUTE of TECHNOLOGY Conditionals lw Certain parts of your code can be made to depend on certain conditions.  The indented part of the code is executed only if the condition is True.  if today October 30 print Happy Birthday John elif today June 21 print Happy Birthday Lauren else print Good morning The else provides default response if none of the other conditions match STEVENS INSTITUTE of TECHNOLOGY Conditionals truckweight 10000 1bs bridge capacity 5000 lbs if truckweight bridgecapacity print DO NOT CROSS DO NOT CROSS dayofweek if dayofweek print it is Monday elif dayofweek print it is Tuesday else print it is different day it is different day STEVENS INSTITUTE of TECHNOLOGY 10 Loops Sometimes we want to repeat parts of the code multiple times.  If the number of times is predetermined well use for loop which Is definite if we dont know how many times well use while loop indefinite.  We still might know how many times this will repeat see next example STEVENS INSTITUTE of TECHNOLOGY 11 Loops While loops require conditional When the conditional is False the loop stops countdown 25 while countdown 100 print countdown countdown countdown Be careful not fo make Infinite loops In countdown 12 In while countdown print countdown countdown countdown STEVENS INSTITUTE of TECHNOLOGY 12 Control Statements in Loops Sometimes you want your loop to end early or skid back to the top.  You can use break and continue.  numbers range10 for in numbers print if break STEVENS INSTITUTE of TECHNOLOGY 13 Put it all together What this output does people Mark Alex Laura Amy for person in people if person. startswithA print person. upper How about this age 20 while age 66 age age print age print Retirement STEVENS INSTITUTE of TECHNOLOGY 14 Python Scripts Programs Interactive Python is good for experiments and programs of 34 lines long But most programs are much longer so we type them into file and tell python to run the commands in the file As convention we add . py as the suffix on the end of these Tiles to indicate they contain Python STEVENS INSTITUTE of TECHNOLOGY 45 Whats wrong with these weight 100. 0 if weight 200 print You weigh less than 200lbs scores 22 55 70 if sumscores 100 print The sum of the scores is 100 STEVENS INSTITUTE of TECHNOLOGY cfs Common mistakes lw When dividing if you divide by an integer you get an integer Divide by float to get float In In 10 In print In 10 3. 0 In 11 10 In 12 print ba 3033353555333 Some programs indent with tabs others with soaces.  These dont mix well together Dont confuse and More on floats next time STEVENS INSTITUTE of TECHNOLOGY 17 Useful Links lw httplearnoythonthehardway. orgbookex33. html httowww. learnoython. orgenLoops hitoswww. codecademy. comcourses thonbeginneren CxMGTt01 curriculumid4f89dab3d788890003000096 httpsen. wikibooks. orgwikiPythonProgrammingConditional Statements httowww. oeachpit. comarticlesarticle. asox01312792seqNum3 STEVENS INSTITUTE of TECHNOLOGY 18 ft STEVENS lw INSTITUTE of TECHNOLOGY iy Developing Software Deemeee UII bess lh 6k hd WED BAL ib clipizzistevens. edu SSE Beginning of software Software separated trom the hardware in 1950s emerged as distinct technology became independent product Original programmers recruited from the ranks of hardware engineers and mathematicians used adhoc techniques from their former fields STEVENS INSTITUTE of TECHNOLOGY What are the costs of SW development Roughly 60 are develooment costs 40 are testing costs.  For custom software evolution costs offen exceed development costs Costs vary depending on the type of system being developed and the requirements of system attributes such as performance and system reliability Distribution of costs depends on the develooment model used STEVENS INSTITUTE of TECHNOLOGY Design LargerComplex Programs jw Building something larger requires good software engineering Topdown Start from requirements then identify the pieces to write then write the pieces Bottomup Start building pieces you know test them combine them and keep going until you have your program Debugging Programming is the art of debugging blank sheet of paper Testing Because nothing complicated and man made is flawless Maintenance By far the most expensive part of any program STEVENS INSTITUTE of TECHNOLOGY Waterfall metaphor Used in construction and manufacturing collect the requirements create design follow the design during the entire construction transfer finished product to the user solve residual problems through maintenance Intuitively appealing metaphor good design avoids the expensive late rework waterfall became the dominant paradigm STEVENS INSTITUTE of TECHNOLOGY Waterfall model ie Elaborate upfront activities Most of the legacy systems are still largely based on the waterfall STEVENS INSTITUTE of TECHNOLOGY Advantages Disadvantages Thorough requirements definition Design proven Documentation emphasized Planning details Known quantities Lack of flexibility for change Less opportunity for innovation Test compressed Customer only sees result at end Developer works from static specification not with customer Time lag between design and results STEVENS INSTITUTE of TECHNOLOGY Fact Checks we In 1995 31 of all software projects were cancelled 53 were challenged completed only with great difficulty with large cost or time overruns or substantially reduced functionality only 16 could be called successful Obviously the waterfall metaphor did not solve the problems of software develooment STEVENS INSTITUTE of TECHNOLOGY as What is SW Engineering iw SW engineering Is an engineering discipline concerned with all aspects of SW production starting trom the early stages of system specification through to the maintenance of the system after it has started to be used all aspects of SW production not only the technical processes but also deals with project management development of tools methods and theories to support SW production STEVENS INSTITUTE of TECHNOLOGY Basic Practical Principles iw 1.  Use Open Source Software as much as possible Open and cost effective Media production 2.  Use Industry Standards Again open cost effective 3.  Make GUIls as separate components Easy to simulate allows automated testing STEVENS INSTITUTE of TECHNOLOGY 10 Hi Professor.  152 Hello she you How are you 154 Thank you.  158 am on campus.  159 Oh.  yeah in your office.  201 Yeah.  Yeah.  Yeah yeah.  mean wanted to do the class from home but then had medium things to do and couldnt do it.  205 Hello Christina 222 So its 29.  We will wait another 231 couple of minutes.  239 No problem.  240 29.  Lets wait for 30 to officially start in the class.  300 Okay so now is 30 and we can officially start.  So its April the eleventh.  309 and its 30.  319 This is going to be the last class for this courts when will present something next class will be you presenting your finals.  321 and and that will be the end of the course.  So really hope that it was interesting and useful for you.  341 But we will talk next week about that.  So for up this week we will change things little bit compared to what was originally scheduled and in particular we will have 349 couple of things.  One will be she you presenting portion of the research shes doing with me for our Phd program.  408 Then will.  couple of 425 research is applications that developed.  433 Then would talk briefly about couple of scripts that they want to show to you to see what you could do with the 437 mean that in practical uses all the writing scripts.  Then we will talk about the final.  will present again the template for developing it.  will go through some examples of the final.  449 There are couple in particular that just want to show you.  will not share with you the actual presentation because is one of the topics that you could eventually peak for your final.  509 and then will give you 1015 min to work on an in class assignment that could be little bit different from the usual.  So will ask you to use chat gpt to do some tasks.  525 so it will be fun.  545 Okay.  So lets start with the she you just because dont want to keep her waiting for portion for the entire class.  So once 548 she will finish she can go or she can say obviously but she doesnt need to say.  See you on the floor if you are.  600 Hi Professor thank you and 610 I.  like your course very insightful.  took 24 and 26 Highly recommend for you guys for this for yeah.  613 and the 623 share my screen.  Sure.  Sure.  625 Okay.  628 Can you guys see my screen 633 Mina Shafik Yup okay.  Good.  Thank you.  638 Okay.  647 First of all let me introduce myself.  Im.  Sure you pretty probably you guys have already familiar with me.  My email address.  Actually.  649 Im.  Currently Phd students working with Dr.  Carlo and also the Ta.  For this session.  Today will talk about one of the research we are doing now.  Its about sequence labeling task.  658 Probably you guys are not familiar with what is sequence levy and task but believe after this presentation you can link this task to your normal life 714 in case you are using Chij.  Bt.  Now because this task is related to Ted Bt the Chatbot.  Okay.  So will present to this topic in the following.  725 all the first will explain what his sequence labeling and what have the applications of second.  Slowly then will divide the sequence label into sub tasks and introduce how to do the what the method to do.  Sequence labeling task.  738 So first lets look at what is exactly sequence labeling 757 according to definition sequence labeling task attempts to assign categorical labor 802 label in each member in the sequence.  Actually this is very general definition for sequence labeling because we are doing the natural language processing research.  So in natural language processing.  The sequence is the sentence one 808 and the member in the sequence.  The tokens are the words Probably you guys are not familiar with token thats totally fine.  823 you can trade to the member or as worse the worst in the sentence and the sequence labeling task in an Rp.  Is to assign each word token in the sentence 831 to category based on their meaning or function in the sentence.  844 The goal of sequence lovely is to understand the structure and meaning of the input sequence which is the sentence by classifying the word and all the token according to predefined set of categories.  849 the predefined the set of category.  will.  will explain this part in the following slides probably in the third section the sequence lovely sub tasks.  904 So lets look at the application of sequence level.  And this is why we are doing this An Rp.  Research.  915 The most common application of sequence labeling are the information extraction and the checkbox like a.  G.  924 So in information extraction we first need to know what is information extraction.  Its subfield of an Lp.  Research that focuses on identifying and extracting structure the information from unstructured text that data 933 as well know the machine or the computer cannot read the character of the words exactly.  It can only read worse.  It can only read numeric data.  So 948 we need to transform the raw text the data.  the row row text that data is the the character of the world you are seeing.  Now we need to transfer the real text that data into more structured or machine read by format and through this machine with format to data.  We extract to the head information from the real text that data so through sequence labeling tasks we can do the name the entity recognition and the semantic role liberty.  Actually these tasks are this of the sub tasks belongs to Sequence laby.  You can treat the named the entity and the semantic roles as nun in the sentence all they significant information in the sentence sequence labeling can provide information extraction tasks the name the entity and the semantic rows and event extraction knowledge based construction and the P.  On subtest of information extraction for example through name to entity we can.  We can extract the named entity from the raw text.  and we can do the event tracking through the extracted entities.  Also we can use the extracted name to entity from the raw text data and based on their relationship to construct.  to construct the knowledge base.  And through this knowledge base we can do semantic search.  Ill come all construct.  partly to graph to do the recommendation yeah build recommendation system.  And for this third the subtask of information extraction the question Answer.  Actually this is related to the next application of sequence.  Lively.  will combine these together.  which is the chat box.  The definition of Tbots is software that designed to simulate conversation with him.  He my research if you did not use the custom at the commercial check out to like that inserted in the website to deal with some of the some of your purchase or some of the question you concern.  If you did not use that kind of chat about you.  My heart of Ch.  bt and you may use Chi Gp to do some information retrieval out to just the entertainment.  So this is the use usage of about to do information retrieval virtual assistant entertainment.  Yeah thats for the application for the usage of chat about.  So how how sequence labeling tasks have with about also sequence labeling tasks that can provide the name to entity.  And as part of speech to the Chatbot for example the talk about through the named entity extracted from your text.  The tap out can detect or law or locate the entities such as people organization location dates or product from the raw text.  and once the chat about detect the name the entities in the real text the row text that can be the question you asked in the the tabout can provide accurate and relevant information and provide you customized response to your theory.  Probably if you use travel before you may find that sometimes about can only provide us very channel but and useless information through accurately locate the name.  The entities in the question in your question or to in the customers question the checkout can locate.  They salient information like these entities in this question and to provide more customized response.  Also part of speech can help the tap out to understand the grammar took place.  Structure.  and can help that about to generate more coherent and contextually accurate response.  So this is what sequence labeling have with Chatbot.  So next will introduce month subtas of sequence living.  Ive already mentioned them or in the previous slides.  They are the part of speech hacking them to entity recognition and semantic probably probably for now you still feel little bit confusion.  So lets go step by step.  Part of speech.  Tagging is part of speech is category to which word is assigned to in accordance with its syntactic fe function.  This definition is from the Oxford language in English.  The main part of speech are now pronoun adjective determined verb etc.  and these capitalize the character at the representation of part of speech in our research in actually this representation are widely used in the research field.  and let me with concrete example to illustrate what is part of speech.  for example in this sentence.  But yeah so se shell on the shop.  Our task is to assign each of the elements which is the word in the sentence to its corresponding part of speech.  So both of you announced so the verb se shell.  Another now is interject interaction that is determined sure is another.  Now.  if you are if you want to use data driven method we want to train model to learn the relationship between the part of speech and the world in our sequence.  So this is part of speech tagging next the name to entity.  Recognition is to identify and to characterize the named entities mentioned in the text and extract the entity span with levels.  You may wonder why entity span because sometimes the named entity is not single word.  Its word freeze such as Steve Jobs Steve is an is verb is an entity belongs to person Entity Class jobs is another person is another entity that belongs to an person entity class.  So Steve Jobs is actually the entity span the level format of named the entity are these for actually different to data set has different to predefined the Ca category.  Set.  just risk an example to illustrate the label format in in some larger named entity training data set.  They remember the biggest one has 37 named entities.  So here is just example.  It depends on what training data set you choose.  So then.  me illustrated this concept of through the same sentence in name to entity regulation.  Our task ago has changed.  We want to assign each of the element.  Still each of the elements in the sentence but different function.  The public yeah belongs to person like said.  like explained this is actually this to our entity.  Span mobile.  You is the beginner of the person.  Entity UN is the inside of person entity another part another entity is.  its plans to miss us and sure.  which belongs to the location.  So the and now entities.  So we tacked as now.  So we want to build our we want to build model to learn this relationship between the antitax entity type all the not and today with their corresponding token in the sentence.  So the last task is semantic row labeling.  This task is to like.  and then labels towards our freezes in sentence indicating this meant to grow.  The semantic rules focus on who did what we use subject predicate and object to represent hold it What And we use capitalized as you be to represent subject we capitalized we to represent to practice predicate and capitalize the obj to represent the object.  Actually semantic role is related to the part of speech just mentioned.  Part of speech provided the statement of the syntax representation of each token and semantic role can indicate the relationship between the part of speeches of each world.  So let me still use the same sentence to illustrate this concept.  The for here we concern who did what Who is for you which they are the subject Date What about you He sold his sell.  So what se shell So this is the semantic rose we care about in this sentence.  mobile and so shell.  But you may wonder how about on the show because we do not care who did what to whom wed only care about who did what So on the show.  Now semantic crops we ignore that but we still need to tech them as now.  These are more sub tasks of semantic roles of sequence labeling tasks.  And next will introduce the method to do this tasks we have classic sequence label and the modern sequence label you can understand as traditional sequence labeling way and the modern current more current sequence leveling way for traditional sequence leveling we have to.  There are branches the header mark of model and conditional random field hidden.  Markov model is the head of Markov is one.  Oh.  once it to the parents of one situation only depend on its immediate previous token situation.  So will explain how he the Markov model use the impact of speech.  Lets review what is part of speech little bit.  Its taking sequence of words.  Assign each word part of speech like not verb.  And in this section we need probability matrix.  The first one is called the transition probability.  It doesnt matter.  We do not care what is called.  We care what is calculated.  We.  We want to the proper the conditional probability of we be based on the occurrence of Md.  And we calculate to this probability through the through counting the currents of Md.  And they be divided by the current of Md.  Actually this for this calculation is from human engineer and this whole match may measure the head and Markov model is feature engineering.  Its belong to the traditional aspect.  We actually we did not use this method anymore.  Okay so from the next that is emission probability.  Actually this is likelihood we want to pretty.  We want to the likelihood the conditional probability of the talking well based on its based on its part of speech.  Its Md.  They for we formula we formulated this probability by counting the cocurrence of Md.  And will by dividing by the current of Md.  Actually this probability also from human engineered.  Our goal is to get the probability of the it.  We want to get the probability of each part of speech for this token and we want to get the high is the probability.  So this is.  This is the example of the probability matrix.  Like said these numbers these probabilities are from human engineered so in the traditional way.  They use lot of human labor to calculate the statistic and build the statistic model.  But now we are not doing things in this way were doing the your data driven method.  This method has to branch arm based model and the transformer based model are is designed to sequence analysis but it has some limitations.  So the mens room is to use transformer based model.  and will introduce this very classic Fontaine approach.  So first we divide the sentence into each tokens you can treat the token as word.  So this sentence has an numbers of words and we vectorize this because the machine cannot to read word or tokens.  After vector after vectorization we put the token vector into the model and we fix the previous several layers to maintain the parameter and which one the last several layers in the pretend model and the build dense layer because we are because we are doing the multi class classification.  So we use soft Max.  So actually this is the end to end.  Approach.  We assign each token to one entity.  If the second token is not entity we assign it as 0.  So this is the transformer based all the data driven method to do and you are one of the sequence labeling tasks.  So this is this what want to share with you guys dont know if explain clearly.  If you guys have any questions please let me know.  Thank you all right.  Thanks lot to you.  True Professor.  Should stop Share all dont know if you can stop sharing unless we have some questions on on one particular slide and mentioned you.  You can just retrieve it.  Okay.  So one of the goals all the the presentation that she you gave to us mean the most obvious is to give you an example of of the research that we are doing but the second is to frame the research in broader scope.  So the sequence labeling seems to be very specific deep niche research topic.  But when you do complex things as more details.  Wed really make the difference in the old research.  think.  Last class.  mentioned the fact that that one of the things that that we do in natural language processing basic things is programming.  So you want to put together words with the same semantic meaning system engineering project management school of business Webinar mass destruction.  All of those are the same semantic concept spanning over multiple worlds.  So we we can do it the the way we do.  We did the in the past using sort of brute force.  You take the the words so one next to the other and then you take only the most common and those are the end grams.  Thats possibility.  But if you want to do things the right way then you may want to work on the so forth.  You want to remove the stopports but if you remove the stop for so before doing the programming school of business we never exist.  So you want to remove the so forth.  So.  But after you do the programming and only if the stop for the is either at the beginning or at the end of the end.  So thats an example.  We wrote paper on that wrote script that there is probably 200 lines just for that just for and gramming.  and seems to be very niche problem.  But if you dont solve that then Theola interpretation is not going to be right because you will never know what is going on about the school of business or about the systems engineering.  So you want to have that 250.  Another example is done.  You You want to get some insights on on document.  but documents can be big.  So you have document or several 100 page and the same concept can be scattered in different places in the document.  How do you do that.  So the medal that created was basically deconstruct the document and reconstructed the in visual paragraphs that are semantically coherent.  So what did was basically victorize the document 250 and then create clusters based on the vectors.  So at that point and then going back to the actual world.  So recreated the the document with completely different structure.  Again.  It its very niche problem teeny tiny but without that you dont get results.  So again we just wanted to give you an example of thinking big so chatboard but then digging deep going into one detail and so with.  So if you dont do the right labeling you will never get the information you want that you will never understand.  If you are talking about person or you.  You are talking about the CD.  So thats the name the entity re recognition and then the part of speech the part of speech.  Its particularly tree because the role that the words are playing is changing in time.  If you consider Google Uber so they are nouns.  But we use them as verbs meaning over the years language changed.  So if you use methods that are static so if you use that we use the natural language toolkit natural language toolkit as module doing it the part of speech tagging.  But its based on classification of the names and the other parts that is 20 years old.  and Uber may not be there meaning if you use it Weber as verb we not get it.  and language is changing constantly.  And then there are jargons.  So in everyday life we are using words with.  That is not.  The fish are one.  But if you want to understand what people is saying you need to recreate that so.  And the way you extract those its really gridy gala.  So erez agmoni we are exploring creating network and then applying network metrics to recreate these causality in the sequences of awards meaning in phrases 142.  If you dont do that.  you Dont understand the text.  So for human beings so life is easy because you live in the present time.  You use the words that people around you are using.  You are using them.  Its probably in the same way and you understand each other.  But machines do not have this common sense and thats why we need to dig deep and create those algorithms those methods that can really help us fulfill the the the task that that we have.  So again.  sometimes you can go high level.  But sometimes you need to go deep.  So probably is not even when not is definitely not the deepest point that you can reach in natural language processing.  There are many other things that that are more mean smaller targets but pretty complex.  But thats an example.  See you What what do you think of this type on an analysis Yes Professor actually we think we have another kind of sequence labeling task in the recent days that is prompt to learning.  That is also we design different part of sequence.  And this another story.  Yes ill go with you Professor and dont think our research is trivial.  Its build a.  So its foundation to the top tasks.  Yep.  Okay.  Great thanks again to you.  Okay.  All right.  Okay.  So lets move on with the the other topics we have so want to spend as much time as possible on the final and then sometime on some other example.  So lets lets start with the easy portion of examples all the applications.  So want to share with you couple of researches that we did in recent times.  So let me share the screen and let me go here.  So this project that we call the Greek connect is project that we started.  and yet enough to go pretty much and let me go into presentation model.  Its its its its its its its its its its its yeah on different tasks with the 1400 the people participating all over the world.  One of the tasks was financing sustainable future.  So we created the team.  So the the point of contact Martin Powell was former student.  All the George this who was was the Provost Stevens problems.  Ago E.  And Martin encouraged Georgia to participate.  work with Georgia on couple of Dod projects 250 and he knew that they had some background in in natural language processing.  Can we put together the thing that going to show to you So the problem that we want to.  That we want to to address.  So was how to find projects that can be funded by Siemens financial services.  projects that are in the sustainability area.  So that was the target that that that we had.  So again we won the hackathon and let me go.  Here we use the the room theory that presented the last time.  The room theory is basically knowledge driven approach that is based on analyzing documents using computational representation of the knowledge of the specific domain.  The architecture is basically you create the the corpus collecting documents in this case but related to what Zooms financial services was doing so.  All the documentation on all of past projects the way youre doing things what is the background of the people doing the same job And then we transform the this ere that were computational representation of the of the domain.  then that with the same knowledge you can do multiple things.  So we define the specific tasks on with the keywords and related weights mit ctl.  And so keywords are at basic keywords.  And then all the the synonyms all the misspelling.  And again weights because not all the keywords are created equal.  101.  We dont do an exact match.  But we basically measure the proximity of those keywords with the documents so that we are analyzing.  So then we built webcroller going into the web and getting those projects to be analyzed.  Then using this room theory we had the projects that are potentially of interest for Siemens financial services to be funded.  So then you have those elements and you do some visualization to present the the results.  So we developed basic user interface where you have you can select the target industry.  You have the different documents with caller code for the potential interest they may have and distribution in terms of what are the keywords mean based on the keywords that you provide in the in the benchmark.  The proof of concept was simpler than that.  So W.  Was basically room.  We had relatively small room initially mean for the hackad on we had the 450 documents.  The benchmark was 300.  The words of races mean mean whats can be engrams again.  because we wanted to provide that semantic concept not just the work.  And for the hackad on.  We didnt have the wet roller ready and we collected manually the documents.  Now in the current version we do have crawler and the algorithm for matching.  We are the same of the room theory and we use the some sort of basic graphic visualizations.  So thats basically what you have.  You have all the different benchmarks or keywords and you have the different projects and you have this sort of correlation magic.  So that is telling you what are the projects that are potentially more interesting.  We added that this project 0.  There is sort of control project that was not related with the topic to see if the system was doing his job.  But not.  And then you couldnt have little bit more.  That will be on view for the different mean the intersection between documents and and benchmark and you can visually see what are the projects that are matching.  or better what are the keywords that are matched The the most by the different benchmarks.  So a.  And thats basically it.  We are after the hackaton.  Siemens gave us another.  Here of funding.  We are expanding the the system.  The system again has crawler.  The roller is working fine.  We expanded the the benchmark the corpus.  the crawler so far is dumb crawler.  So its just collecting elements based on keywords that we provide.  And then the system is actually doing the job We are thinking about adding layer all the you know common sense because one of the things that seems to be easy but its its kind of complicated.  You have document that is white paper so its commercial pro document.  It is not request for proposal or an idea of project to be founded for human that would be easy to say.  Its commercial promotion is now the Vla request for funds for machine it is.  Its more complicated.  Machines do not have the common sense so we will use something like chat gpt equivalent to to filter out those projects that are only not projects but they are just commercial products to commercial documents.  Same thing for the location.  So sometimes you have document.  and you have Cds.  You have vitro it.  But actually the the project is going to happen in Nairobi.  So because Siemens financial services is is for use in this case on North America Nairobi would be or no interest for them.  So for human it would be easy just to go through everything and say okay this is not of interest to us.  Again.  We will use lunch language model to do this software pre screening.  That was the mean the the of us the the founding members are still there.  We are thinking about the next stage meaning the Erez Agmoni.  The system is now working mean.  Obviously there is always room for improvement but its delivering results.  150 Siemens wants to continue working with us want to use the system.  So we are thinking about creating company that could be with Stevens inside.  So had conversations with the Provost with the senior Vice provost for research and anthropologists with our general counselor and we are going in the directions when there is sort of the organization in our point of contact move to another company.  So right now the idea of the company is kind of on old.  But before our point of contact left.  mean.  He involved the the Cfo the the CEO or Siemens financial services North America.  That is 20000 people.  Then he seems to be on board.  But again.  The direction is to spin off this activity creating company and then wed see what is going to happen.  So thats an example.  Its not end to end.  But mean it is pretty lets say mature example.  and then of application of something that we discussed.  something completely different.  Let me share this research that we did about probably years ago.  and was join effort with unicef during the pandemic A.  There there was spike in domestic violence and children abuse.  So we we wanted to track that.  We wanted to create some awareness on on the problem.  So we created the a.  joint team with some people from Stevens some people from Unicef.  and thats the Unicef team.  Thats the Stevenss team.  So myself.  The of us are of the main point of contacts when is about analytics in in broad sense is more focus on on resilience and more on data analytics and natural language processing its.  We are of our Phd students both employed.  Now.  Korea is in Bangladesh as senior data scientist and Fernando same thing in data consulting company.  So there is no need to to give you the background on the team.  But just want to go into the project.  So we we wanted to again create the some sort of awareness we for use the on different countries for sure on the Us.  But we wanted to expand little bit.  and that we use the social media to get what people was thinking was doing and trying to map somehow the facts with story Again its all about the storytelling million issues.  Some data may be misleading.  We are talking about topic that is very sensible and sensitive.  and some people its not comfortable discussing those experiences with me.  mean on public records.  And then there is the issue or multilanguages.  So we collected the tweets from 15 different countries.  In those data frames we collected the data from red.  It tweets red.  Its they are very different.  So tweets are are less for use the shorter red.  Its more for use longer.  Wed read it.  You have communities with tweets not so much so.  We use the modeling to represent all of that.  So the first case study is using tweed.  So again there are some advantages.  Its easy to access was so easy to access before you know.  Mask.  Its widely used based on text.  So mean Instagram.  Will it be great but its way much more difficult to process images than text.  and because you have the possibility to comment mean to to side.  There is sort of conversation that can and gone.  Okay.  We collected the the data we and identify the conversation so that we are more related to the topic of our research.  We mapped the results by geography all location and we analyze the results.  So those are our hate speeches in different States before and after.  So before Covid and after Covid.  So that was the increase for this Rito Columbia for example.  So this is hate speech around the world so abusive non abusive.  There.  mean that again as usual.  Swedish are always the best in the world.  But unfortunately what this big and the number of people in Sweden unfortunately is not as much as the people in Indonesia or in Brazil meaning theyre having so much of abuses but compared to non abusive.  its really warring up there.  So then we created sort of an index to measure it.  and that this is the distribution.  So you have an average and and countries that are above over below that similar thing using red.  It so again red.  It is very different from to either.  Its social media but its different animal you have Subreddits subreddits are very focus on given topic.  Mit ctl and so we focus on on abuserelated subreddits abuse survivors abuse survivors of abuse and massive violence.  150.  We determine control group just to have way to create context for the results that that we had.  And again one of the limitations in this case is that the credit is used primarily by the Us.  Meaning you Dont have the same amount of data from other countries that you have with with them.  Thats an example of one on the post collected data analyzing in time expecting topics.  Thats what we did.  Number of newly active users on abuse Re related the Reddit.  So there is definitely spike even just considering the number of users and not the content or what they said.  Then using nda we had that mean.  We kind of manipulated little bit the nda adding labels to the different topics.  So thats basically where those were more related.  So abuse related subred.  Its are among the topics with the highest growth during the lockdown.  So that was something scaring somehow.  So let me skip that.  So those are the topics.  So again we detected the topics.  and we label them and we extracted the keywords that are meaning the the different topics.  and that thats basically for each one of the topics the distribution in time that is giving you an idea of what was going on.  So if you look at the first one thats really growing lot lot mean its its its carries out so 33 more exposure to abusive languages language and cyber bowling on twitter 37 us states so large and increase in tweets containing abusive language.  94 more child abuse on ready during the lockdown 88 more intimate partner abuse re but already during the lockdown.  So those are the facts.  So the paper that we published the following this presentation was highly sided There are more out to to the story.  So the the first one when you write something stay on facts that can really drive attention.  because at that point you will get more exposure.  The sag on the most important.  What we do can really be useful to expose Some situations create or increase awareness.  Some of those researches are not so easy meaning you can.  You may not find them on the New York Times not because they they are not good but but because mean it.  It took us months to develop it.  Jordan is may not have the same the the the actually Ill spend so much time.  But again you can do lot of good or lot of working with data and leveraging on them and presenting them in in the proper way.  So thats something that they wanted to share with you.  Another thing that they want to share with you is few scripts.  So in particular.  of them let me share this screen again.  Let me go here.  So analyzing text is pretty general need.  So she you was mentioning retrieval in in text.  There is genetic term.  It really depends what you want to do with the the text.  What are the information that you want to extract Some of the tasks kind of repetitive.  So we spend some time for for example not analyzing text and extracting the most frequent words the diagrams.  By the way let me stop here for second and let me go into diagrams.  Yesterday was teaching class on visualization course of course 22 with Professor Ramirez pretty much each semester.  We do sort of an exchange of of classes at certain point and at each one of these classes using my my experience in natural language processing and applying that to visualizations and or to network analysis or combination of the one of the students and asked me Why shes also student in my other 24 class.  She asked me why you are asking us to do diagrams.  So whats the use of diagrams.  Well diagrams are an essential component of the or engram so are an essential component of of the conversation.  mentioned that half an hour ago.  so school of business project management information technology.  So all of those are are in Grams diagrams grams or more with the same semantic meaning.  So you dont want to leave the words as individual words but you want to aggregate them creating some sort or representing one single semantic concept.  Once you have that that could be diagram.  It could be engram again web on mass destruction.  There are quite some words but we just one single semantic element.  You want to use them erez agmoni in pretty much all the representations you have.  You want to use them for the word cloud.  The most frequent words even if They are not really words but they are those chunks those semantic elements 150 you want to use.  When you do some topic analysis.  you do Lda as an example of topic for presentation and you want to have business single word or business management as diagram.  So thats the reason why you want to have diagrams because you want to extract from the text not only the words but you want to extract the the concepts the the semantic elements in those who can span across multiple words.  So thats something that mean that you may have the same question that this you have all right.  So this script is kind of genetic script.  Its relatively long 240 and change lines of code.  and he is doing kind of repetitive tasks in IP so is text cleaning Most common words generated in the Engrams doing the core.  And so let me stop here for moment.  Cocorance cocurrence means we mentioned briefly last week means appearing together.  So you have large text and you have some words so that they are appearing together.  So the assumption is that if they are repeating together that means they are related.  So this being related as value because when you have more words that are related then you have set of related topic.  What that will create topic.  So using this call quorance awards across the document is way to analyze the document.  Eventually you can create network out of it with whats the that are related because they are appealing one next to the other Then what is next to the other is to be defined meaning if they are one next to the other mean one following the other then he is diagram.  But if they are in works of distance so degree of separation.  Then you can define the degrees of separation between the words.  That will be that that threshold Obviously the larger is the document and the the smaller is going to be the number of degrees of separation because otherwise you you would have medium words.  and then you may want to count the number of times the words are appearing because if they appear together only once they may not be relevant.  So with those parameters you can create network based on this call quorance.  So and thats why in my script im calculating the coordinates.  Then what cloud some topic modeling and some statistics.  So basically imported the All the different libraries.  Some are for visualization some are for calculation.  This is and very basic cleaning function.  This is to calculate the the most common elements generating the engram sir.  generating this matrix of cocaine.  then generating the work cloud generating the the visualization for the nda model for representing topics.  And then you define whatever is the file you read the software file you mean load the the file files into.  At least you said that the minimal length Sorry about that.  You set the window separation and that was mentioning to you the number of engrams that you want.  How many of mean how big and as should be in Engrams how many of them you want.  and then that some naming number of topics here im generating from the Madrid.  So the Co.  Currents madrics what is in the network analysis Its called the adjacency madrics.  and from that Im.  Generating the the graph and then saving it for future analysis Then.  and from the cleaning get the vocabulary that is the least of unique words and creating the work cloud topic modeling topic modeling more that think needs the vocabulary.  Thats why generated it.  And then basically generating some statistics.  The number of words.  the number of unique words.  So the entropy meaning how diversified is the user awards.  So text with the higher entropy than another means that there are wider variety awards.  So when you run it let me run it.  And so you are going to have the what cloud And thats Why not You have the engrams.  the topics Thats the this that was mentioning.  and there are some graphs.  So this for example.  is the graph im opening it with the her FDA that is being generated.  So when you go into the different so we define for topics.  So when you go on each one on the right side that you have the wars or and Graham.  So you have natural language processing senior business consultant.  So those are engrams.  and this is actually from something different.  But the the the same concept.  You can eventually change the relevance.  Madrid.  So this was for the resume.  Okay let me go to what has been generated in this case.  It is right here.  This is what has been generated in this case.  Sorry about that was not for topics.  And again you have the different topics.  The relevance is all of them.  You have another interesting representation that is this one up.  So was mentioning that that you can generate network out of the awards using the call quor and so and thats basically what its been generated.  So you have the different elements and how they are connected.  So going into it.  you can get sense eventually from that you can do clustering using an algorithm and its called the lobbying community detection.  And you can get more insights.  You can change what is called the gravity meaning how much the notes are attracted either one to the other or to the center.  You can change the what its called the solver that is the visualization.  and then you have the work cloud.  So you have the work cloud.  You have the Mba.  You have the network and you have some statistics.  use that the when we were hiding new people at Ssc.  So wanted to compare those results so and its pretty much the same as the previous one.  Im not keeping in mind that when you have resume most likely the resume is in Pdf.  So had this.  Theres script that was reading Pdf.  And transforming the the Pdf.  Into text is relatively straightforward script using library.  There are several of them is the one that use in this case.  So using this one its basically where got this one.  So so this Lda is related to my resume.  So you have business intelligence.  You have natural language processing step and Cecil of technology.  So the things that you can expect.  So did the something very straightforward.  went to Linkedin.  downloaded the transformed the profile into Pdf.  And then use the Pdf again.  Its just an example.  you can see actually the user.  All the the engrams.  So Stevens is the technology business intelligence natural language processing lab.  In this case senior business consultant principal investigator developing solution.  So you want to have machine learning.  So you want to have those and grabs all right.  So very briefly want to show you couple of finals.  So in particular want to show you this one that is from last year.  and my opinion is one of the best in recent semesters and was for sure the best in that particular semester.  So let me share the screen.  Let me go here.  Its on one of the tasks of the problems that you have as options for this year.  So global migration dynamics.  Joshua Johnson good the table of content.  mean that that was kind of massive 30 page and you would see the quality of the visualizations and the analysis and the conclusions in particular.  So you have introduction research questions data description preparation representation conclusions references appendixes list of figures.  list of Tables abstract.  So why we are doing what we we are doing why this problem is relevant.  Why we are talking about the migration.  So thats the description.  Im not going to spend much time but just want to give you sense of the the way it was done.  Some terminology that is always good because we assume that we are using sometimes.  But everybody knows but not necessarily.  Everybody does so.  Factors push and pool.  so push job opportunities hyp population.  cool availability or regular work.  higher wages education opportunities and so on.  Results questions.  So you want to have questions.  What are the major global migration dynamics and so on.  Data description.  exploratory data analysis.  preparation.  and then some visualization.  So with this one you really see who is going where.  So youll see.  dont know people from Europe North America going to North Africa eventually and so on.  So source destination numbers the range that some from the different regions global migration in terms of immigration immigration self immigration.  meaning from dont know Latin America to Latin America different countries eventually.  and so on.  Thats another interesting one.  So you have going Where From Where So this is sun key diagram created for analyzing flows and this is flow of people.  mean its not fluids but its the same concept.  same thing.  So none want to go into each one conclusions.  So thats mean you want to have something at that because thats your take.  So migration is ongoing and happens from all over to all over.  So they are working side by side.  Somehow.  Obviously.  people in less developed the lower income region are more likely to migrate to more developed and thats something that it is not surprise.  little bit more surprising is people in more developed region so do not always migrate to more developed region but may actually migrate back to less developed regions.  think about the the countries that are growing think about.  mean the typical example is China.  mean.  30 years ago China was an underdeveloped country.  Now its definitely developed country people who migrated from China to us 150 30 years ago or years ago.  Now they may want to go back.  So it it.  Its an inverse migration that is happening anyway so that and then references and some appendix is so thats way to use the the concept of appendix is you dont need to have them another big fun of having lot of tables but mean that its an appendix.  You can use it or you can out.  Okay so really wanted to share with you those very briefly.  Another think that they want to share with you is again at something that they already presented.  But want to be sure that you have it and you consider it in the proper way is data exploration template.  So be sure that you have structure that is somehow similar to this one.  So you want to have the goals you want to cover those faces that are business understanding date understanding data preparation and data representation.  So you want to cover all those phases those can be like in in the document that they represented before as table of content.  You can call them in different ways.  So you dont want to call like in this case data understanding data description thats absolutely fine.  but you need to have those steps so and that for each one you will add the your content.  So you have this.  Use it not necessarily to create presentation that the but as table of content for your final document.  One more thing that want to share with you and then we will spend few minutes playing with the the in class assignment.  probably already share with you little bit.  Let me share the screen now.  So we are now talking about the chat Gpt.  The way you present you prompt you type.  The query will effect heavily the way they bought the will provide the answer.  So this case created the several chats from for different topics.  So this is mixed then have future AI technologies.  So when place query in this chat will have an answer that is different from the answer that could get from another chat.  So the more context you provide for your query the more accurate is going to be your answer.  So use Chat Gpt.  Use it wisely.  So keep in mind that that it is likely that those bots will take out the some of the jobs.  but most likely the jobs that will be lost will be the bottom 10.  So mit ctl and you dont want to be in the bottom 10.  So you need to use the boats.  But now it be replaced by the bolts 150.  So the idea of the next assignment in class you will have just 10 min so no more than that just want you to think in those terms is about.  Let me share again the screen and let me go here.  So this in classics that sizes exercises on chat gpt that calling the the in the rest of the description you want to perform.  One of the following tasks using the Board called the documentation input your code to the both and ask for documentation creating narrative input your results and get narrative from the boat code writing input the the requirements.  So from one of the first assignment and get the Python code.  So im going to share this in class assignment.  You have it.  Okay.  So lets have just 10 min and then we will recombine that.  So will create breakout rooms.  But they are not really necessary but didnt do that.  So im creating breakout rooms with participants each.  They are open to you in less than 10 min.  Okay.  So so we have another 15 s.  10 s.  All right.  So want your input so what is your experience What do you think What did you do What did you get anyone So we had noticed like it needed login.  So we kind of just my group and were just.  was kind of telling narrative about how my team at work actually use Chat Gpt because we were just doing release planning.  and our chief architect actually wondered if it could write description and acceptance criteria for story we wanted done for feature in our Jira and it was shockingly long and like quite accurate to what our goal was for writing the acceptance criteria.  and then like talking as in the English was quite correct as well.  So we actually ended up.  you know taking inspiration from it.  And thought you know in professional setting.  thought that was pretty interesting.  but you use it as these at the very end or you did some modifications.  think our chief architect was like for my own pride.  Im going to change like Im going to add my own tidbits like.  For the most part he did keep it pretty much the same.  Wow okay thats great.  Okay Thank you.  Anyone else.  Yeah.  So Professor this is Kevin at the At our organization level and in in Lockheed we we do block the use of it.  But there there.  Isnt really policy of of using on assigned as supplement to like.  you know for for some some you know textual or verbiage you know assistance.  but found that it.  It is really helpful if you provide the proper questions and sometimes you just have to reformat the question.  It is nice that it has context of your previous submissions.  So thats really cool.  found that really interesting and powerful.  Yeah mean at the very end.  Its sort of next level of so changing them.  So what the search engine is doing It has crawler going into the websites and tang.  and then you have sort of database with the page and tags some.  Then you have your query and is is matching the tags in your query with the tags in the database and giving you the URL.  So thats very straightforward the approach with the those bots.  Instead of having tag you have pattern or pattern so and it is taking the patterns in your query and matching them with patterns in the database it is and then is adding layer of conversation.  The more patents you provide the in your query the more matches will be in this sort of pattern matching that that that you have and thats why its so important to to formulate the questions.  So in the proper way.  It is becoming job but it is called the the Prompt Engineering.  We mentioned that probably last time up.  But the way you formulate the query its really important for the the quality of the answer.  So out of curiosity what they did the just before the class was to fast.  So script this one so saying write documentation for the following code.  And it was just code.  And thats basically what got.  mean that is not something that can use directly.  but consider that this daily support is not specific chat.  If would create something more on the documentation would probably get something better.  But its still giving something.  mean that writing documentation is pain in the neck and most of the people write the code the mean in theory.  You should write code the and documentation at the same time.  The majority of developers dont do that.  So having something that will help you can be helpful.  Anyway.  Its 806.  Does the end of the class Let me know.  Let us know if you have any question on the final.  We we are definitely here to help.  If you want to change at the last minute your project and you have something that you really want to do it.  Thats not problem.  But you need to send me not just the overall genetic idea but more detail the the description all the project you want to do and the data set you are going to use.  Not page paragraphs is absolutely fine but they really need to understand what you have in mind.  So thats basically it.  And again feel free to work in teams.  So thats absolutely fine.  Be sure that you are all working on the same project.  mean.  The main reason why have no problem with this class is because you are professionals.  So yes you are here to get good grade.  But you are here to learn now.  So while in my other 24 are things that different the students may have different goals they may be less mature.  In this class have no problem.  im pretty sure that you know how to do things in broad way.  So again thank you for being with me till and again if you have questions so send me and see you an email and we will get back to you.  By the way just out of curiosity.  We are working on creating sort of Ssc.  Gpt.  And will use the transcripts of my classes as sorts of data that that im going to use for training the bought with those larger language models.  You also have the possibility to do what is called finetuning.  providing couple question answers.  So those would be conceded before using the matching of patterns.  So we are collecting the email from the past few semesters and creating a.  A.  Q.  A.  That we will feed the to the system to do that for extracting a.  Q.  A.  From the email.  We are using combination of our chat Gpt.  And New months.  so the initial Ssc.  Gpt will be on 24 and will be sort of tube or for 24 so just to let you know.  anyway.  So thank you again.  809.  Have good night and see you next week again.  If you have any question let me know.  Next week you will present so we will exchange her emails.  In the meantime you will present your final projects and we will start sort of discussion on that.  So its 32.  000 So changed the the plan because some of you were not sure if if they could 004 making time.  013 the the courts were scheduled to end the this week.  016 but the very end at at Stevens the final of the we last until the beginning of may.  So thought that.  Why dont we use the extra time to do things 022 the best we can so and thats why im giving you an additional week.  039 So hope that you like the idea.  But again if for any reason you want to close it to today thats absolutely fine mean that that if you have your presentation feel free to present it that.  045 and otherwise well be next week.  101 So what do you think 105 any one of you time What do you think 114 Kyle Jonas Yeah.  So mean thought just assumed the presentation was next week because thats when the last module is.  120 So was not ready for this week.  So yeah was happy to see your your message.  Okay Good.  Good good good 126 Christina.  You okay 133 Okay Sorry.  Im.  Actually between computers the computer normally use.  140 We started on me and jumped on my back up.  144 Okay.  148 actually was under the impression that the presentation was done today.  It was due today so was 152 kind of put in pedal the metal to get everything ready with my group for today.  158 Okay we we can go today if you dont.  If you dont mind were were ready.  No no no no no mean a.  As in my email if you prefer to do it today.  Just make sure that you submitted it.  So we dont have 202 spending issue and and just want to be fully transparent with you professor and im not sure it.  It doesnt matter who whos whos fall It is or is it It is fall But on Sunday night.  think saw some instructions posted on Module 13 for how to do the analysis.  219 but regardless think think were fine.  240 just wanted to plan out there that we didnt realize that there was you know additional instructions for module and module 13.  But we we we did started early.  243 just want to to set that straight.  Okay then thats why were ready.  Okay okay go ahead.  Alright.  So ill.  Ill share my screen.  Thank you 254 sure 303 All right lets see.  304 All right.  309 We have live audience today.  You see my screen.  311 Yep.  Okay.  So 315 what what we did Our analysis on was on aviation.  Specifically accidents that occur in the aviation space.  found that really really you know our group found it really interesting.  318 The specifically it was data set where we were able to apply filters to in specific website which ill get into details later.  330 But we were able to partition.  You know the the data set into separate decades and then we performed our analysis month amongst those decades.  Right So our our team is is Elise Christina and and myself Kevin.  340 So this is summary of what we did right.  So the purpose is.  Again we were interested in the aviation accents over time to see how the accent that changed with with heavy focus on on injuries.  354 We decide its best to analyze the data in in the separate decades right Because its large data set right.  And think its started out in like 1960 S.  And I.  It Eventually the data for some reason stopped recording that around 2015.  But 405 our our our analysis was focused between like 19 eighties and 2011.  423 So what we did first is data preparation the aviation data contain.  They have full inconsistencies.  We we clean the data up before performing the analysis.  429 Obviously for the columns of dial that we were interested in.  If it had missing data we would just remove the entire role If there were columns that were not print you know that did not apply to our analysis.  We just left it alone because it provide no value in just removing that.  439 So what we did.  In Our strategy is to partition it as you know discussed into separate decades.  Right So we have one spanning 1979 to 1989 457 1990 to 2000 2000and one to 2011.  So the the reason why we partition this data is so that we can perform our analysis and and see the trends right.  The accent trends.  My team will discuss that later on on on their approach to do that.  508 What we did last was we generate that right We we pl at the data and comparisons between the separate decades that we analyze.  526 and some methods we use identify columns that should be grouped together and identified which comes that we can compare against.  536 So the that we we obtain data from Ntsb aviation query 544 we we left.  We intentionally left the query right country anywhere state anywhere month all and including all accidents right and the injury severity would be fatal 550 that details.  So in this data set we we have good amount of columns right But we we focused on ones that made more sense for analysis.  Specifically events data engine type.  603 far description which is the Federal aviation regulation description if it is present that means that that particular aviation rule is being scrutinized by this.  That organization.  Right Lets say you had an accent and it was related to maybe maintenance or something.  Then there will be a.  You know respective description to to indicate that 616 total fatal injuries serious injuries minor injuries the phase of flight and the weather conditions which is pretty interesting.  We decide to ignore certain ones because theyre very unique per accident like event.  Id investigation type accent number.  639 location country.  Most of them fall under like the United States.  So it didnt really make sense to analyze the others because theres only few that that from from other countries for for whatever reason guess its more flexible out of the United States 657 that are preparation.  So this is just like brief summary of our strategy right We we did the filtering and this our strategy for getting our partitions 710 all right.  We we had like data frame for start date and an end date right between those years right Those years start and start and and start end.  And this is how we stored and returned our new data frame 721 for those those timeframes.  Right Of course we ran to some issues where the data the the date time fields were either empty or had tab space.  So we we had strategy.  We had function to to filter that out.  737 Thats it for me.  Im gonna pass this to 753 Christina.  Shell talk about the the scope of our analysis now 759 all right.  So the 804 broad trends that we looked into were the types of injuries over the decades.  the phase of flight versus the number of accidents.  807 the weather conditions and how they affected the accidents the purpose of the flight.  Theres variety of different reasons why planes are flying so what are they doing and 813 how that affected the trends for accidents The engine type for the airplane itself.  824 And then just generic accident trends over the years.  Kevin you can go the next slide.  829 Okay.  So this is just the data that we looked at.  This is just comparing fatal serious and minor injuries over the decades.  838 The overall trend that we noticed at the highest number tended to be in the 1990 to 2000 category decade that held true for total overall injuries minor injuries and serious injuries.  847 The only one that was little different was fatal.  Injuries actually had higher 900 number in the 1979 to 1989 decade 905 for all categories.  The lowest decade was 2001 to 2011 908 and across each of the decades as well.  The highest injury type was fatal.  914 You know the next have.  923 Alright so this is just the correlation analysis that we ran on the data for each of the decades.  So its actually comparing 926 the types of injuries to each other and seeing the relationship between one type of injury and another in both 1979 to 1989 and 1990 to 2000.  There was all positive correlations between the types of injuries.  933 So as one injury type increase youd expect to see an increase in the other injury types as well.  949 The strongest correlation in both sets of both decades was between serious injuries and minor injuries.  2001 to 2011 was little different.  There was still very small positive correlation between serious injuries and minor injuries.  955 but the other combinations actually saw negative correlations between them so as one increase the other would be expected to decrease which was vastly different than the previous decades.  But the overall turn was actually weakening of the correlation over time between the injury types.  All right Kevin go on the next one.  So in this chart were just comparing the number of accidents that occurred at each phase of flight.  For each of the decades they look kind of similar across the years the top phases of flight for injury.  for accidents im sorry would be cruise maneuvering and take off.  and the lowest were seeing the lowest number of accidents are seen echo around landing standing and taxing across all decades.  All right Kev.  Thank you.  Thank you.  This is got one more at least Takes over an 11 last one.  So for weather conditions we also compared them to face the flight.  So across all decades we saw trend where the highest number of accidents actually occurred in good weather conditions visible.  visible meteorological.  Thats tough word conditions.  So when the pilots actually able to rely on what he can see as opposed to having to rely on the instruments.  and at first we kind of thought that was bit alarming.  Is it something up with the pilots But it actually may be factor of the fact that statistically most flights actually occur in good weather lot of times.  If theres poor weather or visibility flight so we cancel delay.  Theyre not going to take off.  So it may just be factor of the number of flights that actually occur some statistically be more likely to have an accident there that that was actually something.  We said that with another data set might be an interesting comparison to look into.  But across all the decades as well we noticed that in maneuvering was the highest number of accidents that occurred even during good weather.  All right.  im going to pass it over to at least.  Now Yeah go for at least Alright perfect thanks guys.  So now were going into specifically over each decade the purpose of flight.  So we see here there is trending very large percentage which is represented by the purpose of personal flying.  So from 1979 through 2011 this is represented by approximately 50 to greater percentage from that 1979 to 2011 window.  Now.  being factor of you know thinking what is the most common purpose of flight about the time of the sixties is when commercial flights started to become popular and so gradually air travel was less exclusive.  By about the eighties via popularized You know commercial flying experience.  And so into the thousands more people had access to plane travel had the money to also had via the Internet.  You know more of desire to see places that were farther away.  So that is reasoning for that.  50 approximate growing to so much larger to about 70 over the years.  And then the subsequent larger percentages here are represented by in order business unknown purpose and instructional flights.  and so obviously business can be justified by saying that this is necessary means of flight in terms of obviously those who are employing that need to travel for their.  for their work would quantify mass amount of people.  Then we have an unknown reasoning which could be for any very smaller and significant purpose of flying and then instructional flights.  For obviously there are pilots that are in school that would be flying planes where any number of situations could possibly go awry.  So the next slide please Kevin.  So now we move into the engine type of what the plane would have.  So here all decades analyze the engine type with the most injuries would be the reciprocating engine.  Aka piston engine which uses one or more pistons you know convert pressure into rotational motion and rotational source of power.  So over the years we see that this actually grows the use of this engine and it is that the piston engine has become the most popular type of engine to date.  So that is very literal reasoning for this percentage going up.  And so also the reason for this going up is that you know advancements in technology have happened over the years which supports us the use of this type of engine more so over any other type.  so you can go to the next slide.  So now we move into.  They look in the Federal aviation regulations for the far rules.  So these are sets of rules set by the Federal administration to kind of look at this data to see how every regulation was documented over each decade and which rule was under the most scrutiny in terms of looking at accidents that were reported.  So we did notice majority of accidents that were looked at.  Were missing data value regardless of what year we were looking at.  and also the rule that was under the most scrutiny over all decades by the Federal Aviation Association was general aviation.  Aka.  These personal flying instances Some next slide.  Oh youre done.  At least were going to do quick conclusion just to wrap up.  So for over all decades the greatest number of accidents that we saw occurring was during that Vmc.  Period or that visual meter meteor lodge.  Oh my goodness Christine that youre absolutely correct conditions.  So just to reiterate.  That was when the pilot was able to use good visual cues to be able to navigate the aircraft.  and therefore would have you know better sense of surroundings when in flight.  Another trend that happened to occur for all decades was that the most occurring injury type was that of fatal.  And for the if they are data values President present the general aviation category which could mostly categorize that personal and business purposes of flying was scrutinized the most and was therefore put under the most investigation.  And now well open anything up to more questions from everyone.  Okay great.  Thank you.  So have few questions.  So one is more general question.  Why you didnt consider the making model.  Oh yeah so we we explain.  In the report.  There were lot of nick and models to the point where it wasnt.  It was very difficult to to consider.  mean guess it can but it would take lot more effort not sure what value would bring.  but from from what we we try doing.  They They end up having lot of variations making models in the data set.  And guess if you were going to move into the type of plane.  piece of that aspect that we took was being the engine there like being that there were much more succinct data set to look through and you were able to get numbers that put more value toward the analysis.  Yeah its kind of interesting because im former student of mine did the in the 800 project on similar problem.  She hes working think for lock it.  and and then she did the the on the same topic.  So im not saying that they became an expert.  But little bit familiar with the the the topic on your project.  The second question is why you think there are so many less fatal accidents in the last decade can go first.  If yeah can follow up the investments in technology right Maybe the robustness and the design of like the landing gear.  For example Ive seen lot of documentaries because just like it on documentary nerd but they they just made everything better.  Theres more strict regulations more may maybe more maintenance right the panel.  Theres have cousin that works in the maintenance side of of aircraft and think the requirements are more stricter right Just everything overall.  Its just better over the years.  Yeah.  mean that it its quite relevant point because when you do with an analysis like what you did the the the main question is why you are doing it.  Who can benefit from it So when you see those differences in breeding down on why there are such difference.  So it could be an indication mean if it is matter of different regulatory system what are the regulations that that impacted the the most.  and that the second answer think kind of following the first one.  How can reduce even in farther So did did they reach sort of plateau for those changes.  So mean im not at all like criticizing the very good work that that that you did but keep in mind that that you can get some actionable.  So somehow from research like like this one.  and the actionable in this case would be okay.  see reduction.  Let let me better understand why and a.  Is there any margin for improvement So those things could be the next step for the analysis that that that you did not not saying that that is not great but it its really good.  The other question have and thats unfortunately something that is common in mostly analysis that that see the lack of normalization by the size of the population that you are comparing.  So if you dont normalize for number of flights so then the comparison may not be that much relevant.  So either you go in in terms of percentage or you go with the normalization with with the that there is the sort of person that January.  So what do you Because at the certain point you mentioned also the the fact that the numbers can be different because the number of flights in the different periods could be different.  So how did you consider that Ill be honest Professor We do not consider that but thats very good point.  think what youre saying it makes absolute sense.  We should probably do maybe like an approach where we do 1000 from this year 1000 for this decade another 1000 from the second decade another 1000 from the third decade for some type of of way to make it equal comparison.  Yeah.  mean that in any form of normalization would would be fine.  Because mean if you had the percentage that the percentage in sense is the normalization because you have the the the the type of A.  As percentage of the total.  What they are they total is.  and then you can compare them order.  You can normalize using any form of normalization the meeting Max or whatever is the most the the the normalization that that that you pick.  But mean like keep in mind that that thats something that you may want to have for future analysis because otherwise if they feel to to compare.  Thank you.  Thats very good feedback.  appreciate that.  To go back to your second question also about you know why you might have the injuries and accidents that like went down over the years would say to theres definitely besides the less human factors of new technologies.  There is also probably better training and risk mitigation factors with instructing new pilots and teaching like new pilots how to flying.  Also that imagine there is more of demand for pilots and so therefore over greater number of them there is safer flight.  Yeah in the work we did with the with the other student.  We know this the same fact that that accident happened more in clear of sky.  and it it was kind of surprising so she didnt do much of the normalization that would help but because mean if you have all the data that are in clear of sky and few that are with cloud this guy then obviously you will have more on the clear sky cases.  But another consideration that we did was.  and when you go in clear sky condition.  You rely on the equipment.  and the the pilot may pay less attention because there is nothing to be worried about.  and that could be another factor.  Yeah went to note that thats exactly what me and my team were discussing specifically.  Christina was saying.  We can add that to the conclusion how they could be less reliant on technology.  But maybe they should use combination of the technology and the clear skies to make judgment.  So thats another good point.  Yep.  Yep.  Okay sounds great.  You did good.  Youd be very good.  How big was your code then Do you have the code The By the way yeah yeah we have the code.  believe minus the the comments.  The code should be around 350 lines but not Okay So as final conclusion was this courts useful for you Yeah absolutely.  think it.  It forced me to learn python but certainly it.  Its new.  Its new language for me.  And do we learning the different You know various ways to process data and the what What was certainly interesting is the the analysis that we had to do.  never had to do analysis in in this kind of way before so it definitely was new opening experience for me and and of course allowing us to choose topic of our choice for the final was very enjoyable experience.  Thats for me good Christina Elise.  you like before.  They only used Python handful of times for very specific like AI purposes.  but because they were so specific.  kind of lost touch with it quite quickly after ending the assignment.  So certainly feel like actually put you know methods to memory which is for me pretty impressive.  only usually code with like Bash scripting at work.  So think this you know everything culminating together in this project was very useful and made sense to You know how we moved through everything.  Good.  Good.  Yeah.  dont use.  probably havent looked at coding since my underground number of years ago.  So its definitely different than my norm.  was interesting to see different ways of analyzing data.  Im generally in excel person.  So it was interesting to see could find the information in excel but could also do it another way for other purposes.  Okay.  okay.  So mean was not fishing for compliments.  It was just getting your input because mean this this courts is running since quite while change little bit each semester and getting input.  Its really important to me.  So is there any part that you think could could have been different or didnt work Well as you expected the not really not necessarily my head right now.  Not necessarily.  Yeah not not for me.  But was actually curious.  Oh Professor is there any class that incorporates students to contribute to like code repository like collective you know way of developing or working on something or an assignment.  not really.  We have more research projects right now.  As an example Im.  Working with some students on project to create in Ssc.  Chat box based on on larger language model that could be sort of Tudor for students.  and we are going to start with the with this course with the 24 and and then we use the from the classes as data along with the the the teaching material so the slides the readings and all the rest.  All of that.  Well generate code and they code will be available to students as well.  We dont have real repository.  mean that repository for the the the wouldnt make not much sense.  share some parts of code during the the like.  dont know what cloud or cleaning data so that those are either scripts or as nippets.  Its something that they share.  Probably it would be good that to create sort of small gee tab with the all those pieces.  We our students can just go there and get it for the larger scripts or problems.  mean.  they go into research projects and for those we do have repository.  But then the the research projects sometimes have some some restrictions.  We do research properties for the Dod and while at the results are the public the the code the maybe now after.  So thats my experience.  So far.  all right.  So its really interesting that you mentioned the the chat boss because im working on software as service platform.  And were also trying to incorporate.  You know AI into into that as well.  More and more of so to facilitate the whole it help desk that were shooting you know basically automating the the the way we we handle requests some request to be automated to certain degree.  Yeah.  mean that this paradigm of the larger language models it.  Its very interesting because you can have an interaction with the data that is more conversational that is lowering the threshold for people to use it.  We are considering.  mean the model that they developed on on specific knowledge base that is specific one domain as the limitation of not having the the common sense.  So think so.  That seems to be obvious may not be noticed by the system and that its why we want to incorporate the the existing large language models either open AI like or those from hugging face and they have some models that are available for the common sense meaning.  Before going into the analysis that is more domain specific we go to the common sense to eliminate the obvious.  It would be great to have resources enough to have something that is domain specific and big enough like bloom.  But the so Bloomberg had the the actually all the dont know how many years all financial data and publications and they use that to create the the entire model.  We dont have that.  So even with the all the transcripts and all the the material.  It would be tiny tiny fraction compared to what could give the the system real enjoyable interaction.  Yeah its as good as the that you have right.  It is separate project is to use.  mean the large language models have component that is generating language.  The idea is to use the language generation capability of large language model for presenting the results of different model.  So developed my mode lot with the lets say combination lets say generating the data like those that would go in dashboard.  So have quite lot of data and could create dashboard instead of creating the dashboard.  feed the language model and the model will present the results in plain English.  and that could be useful in when you are in critical conditions.  So you are on the bottom field.  You are in intensive care unit.  You are in nuclear plant with an emergency.  So in those cases you you dont really rely much on what you see you are doing something and you want your explanation in English.  So when you have those models so generating the text then the text to speech is nobrainer.  There are medium module for that.  So thats another thing that that we are exploring there so language as an equivalent to the visualization of the next blow something like that.  Yeah Professor have questions.  Thanks for asking some some of my work pose question about language models.  Specifically think theyre concerned about how it would drive.  You know it.  And and is that something were were were you know concerned about or adapting right where where your thoughts on on that is that is that the future is that going to define Well mean we.  We need to set the expectations in the proper way.  We tend to have way too much expectation from technology.  So when the first computers were used there we are people saying the machine side that and has to be through.  But the reality the algorithm that the machine was using and the data that the machine was using.  You know we are not so well done or strong or tested or larger to mean justify the fate.  We are pretty much in the same situation here.  So those models they call them generative models but theyre not generating anything they are generating.  Answers to that are the equivalent of what Google is giving us with the layer of conversation.  So this is to be very intelligent but in reality theyre not erez agmoni creating something like an intelligent mind that could do.  They are as teaching together pieces and presented it 150 in sort of probabilistic way.  If we continue increasing the size of all the models we will be.  mean we we will have both so that are more accurate in analyzing the date than presenting the data.  But there is no generation of new concept new ideas.  and there is no domain.  So we didnt solve the the the problem.  All the the specific knowledge that you can have in that one specific domain.  The yeah If you have it it should be relying on the the the basis of of what it it it knows right to to generate the answers.  Yeah mean if you add the all your knowledge in the aircraft industry and you dump into an open AI.  It will be drop in the ocean meaning the part that it will discover will be sort of deluded in homeopathic way in way that there will be no trace of the specific knowledge.  So what we need to do is to come out with better or more representation of the knowledge that can value the different components so the generic and the specific in the proper way.  And then mean that we will be able to reach the the point that we will have those types of representation working in in proper way most likely.  Yes probably not in the next couple of years but in in the next 10 years probably.  or even years.  At that point it would be interesting because mean.  dont know if already mentioned that im writing book on societal implication of a.  am machine learning.  and am analyzing those issues.  jobs will be destroyed but jobs will be created.  So if you look back to to the past revolutions driven by technology.  the revolution so they did destroy the the entire categories of of jobs.  If you think the the music industry who is buying buying it.  Yes there is little bit but it the marginal business.  So who is buying cassettes Who is buying analogue Music in general.  blockbuster renting Dvds or Cassettes that they are gone or developing teachers printing pictures.  So all of those were big businesses but they are gone even now with the streaming.  mean videos move these.  They they they They they are gone but new industries will come.  So we really need to be very flexible and very open and fast reacting because things will change.  Things are changing very fast.  The major issue that they really see is more on the concentration of that that we see more and more.  If we stay with this paradigm like open AI.  There will be or companies able to create those giant models.  and we will need to use them.  Yeah.  and thats an oligopoly.  but it would be noticeably of the knowledge because we will all use the know that that is collected by them.  So with the chat gpt the vast majority of the data is in English.  That that means that we have large section of the population in the world that is under represented.  So we dont want that there are many changes that we need to do.  The current proof of concept that we are experiencing with with with the open AI and similar to to make it work.  We need to be aware of what what is wrong and try to do our best to work better.  So distributing intelligence is something that is coming up the mean.  In fact we already have it with the mean most of our phones.  They have dedicated components for our machine learning meaning and there is some computing 150 on the machine learning side that is happening in our phone and probably on our smart watches 250.  But we need more than that.  So we need more of distributed computing more of distributed intelligence.  So anyway thats going to be an interesting period though.  Yeah were living an interesting times.  Yup yup Yup yeah.  Im always interested on how how the you know.  Does the the data preparation that cleaning for for their learning models Very very interesting stuff.  My My my last question is so nice exciting is message you and the Ta.  About submitting the file project.  We just need one person to submit.  Everything.  Is that correct Yes yes Yes yes so mean that just just to be sure that they everything will be done in the proper way.  Either one of you would submit or all of you would submit the same thing.  Okay the last.  The last time checked the submission button was not available.  But you know it could be available.  Now.  Yeah okay All right Thank you.  Sure.  mean the the reason why would be more on all of you with submit is because if at the certain point there will be an audit.  dont want someone that checking and normally.  Why those students didnt submit.  so mean we know it but it could look better if you all will submit.  Okay.  And it would make much professor that you that that you who will will will get it.  Thank you Professor for sharing all your insights absolutely absolutely.  So again.  Next week there will be other presentations so feel free to join my opinion.  Its good learning moment because you would see what did the on probably different areas different topics.  So encourage you to join us next week.  Okay Thank you for us sir.  Okay thank you all.  If you dont have question.  So thats the end of this sort of class.  This is very short one.  and appreciated your presentation.  You did great job.  fis STEVENS lw INSTITUTE of TECHNOLOGY is Variable Types and Conversions Repel clipizzistevens. edu SSE hslUui Variable Types In the previous class we said that variables have names types and values There are many types of variables but few that you will come across most offen STEVENS INSTITUTE of TECHNOLOGY Variable Types You will use strings numbers and lists most to start with.  Strings are strings of characters hello goodbye 100 Numbers can be integers ints or floating point numbers int 10. 0 float 5. 5 float SS LULU STEVENS INSTITUTE of TECHNOLOGY cfs Variable Types and Operators Depending on the type of the variable the same operators do different things first John last Smith print first last JohnSmith dollars 1. 0 cents 0. 75 print dollars cents 1. 75 word Hi print word HiHiHiHiHi hourlywage 14. 50 print hourlywage 116. 0 print Hi Traceback most recent call last Type Error can only concatenate str not int to str SS LULU STEVENS INSTITUTE of TECHNOLOGY Which type is variable If you need to know or fest the type of variable you can use Pythons type function name Julia print typename type str height 178 cm print typeheight type int scores 99 80 78 print typescores type list versionno 2. 7 print typeversionno type float height seven feet if typeheight str printI am height tall elif typeheight int printMy height is height else printThere is no information am seven feet tall SS LULU STEVENS INSTITUTE of TECHNOLOGY several Types of Numbers je Numbers have two main types Integers are whole numbers 14 100 401233 Floating Point Numbers have decimal parts 2. 5 0. 0 98. 6 14. 0 There are other number types they are variations on float and integer xx type xx type int Temp 98. 6 typetemp type float type1 type int type1. 0 type float STEVENS INSTITUTE of TECHNOLOGY Type Conversions When you put an integer and floating point in an expression the integer Is implicitly converted to float You can control this with the built in functions int and float print float99 100 0. 99 42 typei type int floati print 42. 0 typef type float print float3 45 2. 5 STEVENS INSTITUTE of TECHNOLOGY Type Conversion lw You can turn numbers into strings and some strings into numbers using the conversion functions int float and str Id In print a5 55555 In 576. 3 In strx In print Number y2 Number 576. 3576. 3 In inta In print bxb 25 In 10 age fifteen In 11 newage intage Traceback most recent call last ValueError invalid literal for int with base 10 fifteen STEVENS INSTITUTE of TECHNOLOGY String Conversions lw You can also use int and float to convert between strings and integers You will get an error if the string does not contain numeric characters aft sval 123 typesval type str print sval Traceback most recent call last File stdin line in module TypeError cannot concatenate str and int ival intsvall typeival type int print ival 124 nsv hello bob niv intnsv Traceback most recent call last File stdin line in module ValueError invalid literal for int STEVENS INSTITUTE of TECHNOLOGY hslUui won PreventingManaging Error Type Conversion When you try to convert info numeric string without ag number inside you will get an error In 10 age fifteen In 11 newage intage Traceback most recent call last ValueError invalid literal for int with base 10 fifteen STEVENS INSTITUTE of TECHNOLOGY 10 User Input lw Wecan instruct name inputWho are you Python to pause print Welcome name and read data from the user using Who are you Carlo the inout function Welcome Carlo The input function returns string STEVENS INSTITUTE of TECHNOLOGY Converting User Input lif we want to read ino inputEurope floor number from the usf intinp print US floor usf User we must convert It from Europe floor string to number US floor UsINg Type conversion function Later we will deal with bad input data STEVENS INSTITUTE of TECHNOLOGY 10 String Operations Some operators apply to strings implies concatenation implies multiple concatenation Python knows when It Is dealing with string or number and behaves appropriately ots we print abc 123 abc123 print Hi HiHIHIHiHI STEVENS INSTITUTE of TECHNOLOGY 14 Lists lw Lists are containers for other types.  For example you can have list of strings list of integers list of floating point numbers and also lists of mixed Types.  The square brackets and are used to define lists Items inside lists elements are separated by commas examplelist 123 abc 2. 0 Fish STEVENS INSTITUTE of TECHNOLOGY 14 ER hlslUri Lists lw You can access elements in list by their position index.  Indices in Python Start at In examplelist 123 abc 2. 0 Fish In print examplelist 123 In print examplelist Fish You can change the elements of list too In 23 examplelist3 Tilapia In 24 print examplelist 123 abc 2. 0 Tilapia STEVENS INSTITUTE of TECHNOLOGY 15 List Indexes and Slicing ye In addition to selecting particular element you can select slice of list In 14 athruh abcdefgh In 15 print athruh3 In 16 print athruh3 Tw 2s hh In 17 print athruh3 hi In 18 print athruh35 You can even count backwards from the end In 19 print athruh1 In 20 print athruh2 ae STEVENS INSTITUTE of TECHNOLOGY 16 Using Lists In examplelist 123 abc 2. 0 Fish You can use the index method of list to find the index of particular value In print examplelist.  indexabc In print examplelist.  index123 Add something to the end of list with append In 25 examplelist.  append 42 In 26 print examplelist 123 abc 2. 0 Tilapia 42 Delete something form list with remove In 27 examplelist.  removeabc In 28 print examplelist 123 2. 0 Tilapia 42 SS rrriSS STEVENS INSTITUTE of TECHNOLOGY 17 Concatenation vs.  append method 123 456 concatenation print 123456 123 456 a. appendb append method print 123456 STEVENS INSTITUTE of TECHNOLOGY 18 Ils an element in list 234 133 42 42 ina True 55 ina False 55 not ina True STEVENS INSTITUTE of TECHNOLOGY 19 Lists are Ordered The order of elements in list does not change unless you change it so they are useful for keeping track of sequential events.  You can also loop through them in order easily.  In 29 schedule Math Gym French History In 30 periods P1 p2 p3 apa In 31 for in 0123 print periods il schedule P1 Math P2 Gym P3 French P4 History STEVENS INSTITUTE of TECHNOLOGY 20 Lists can be sorted 457 246 110 111 a. sort print 110 111 246 457 sopam eggs bacon b. sort print bacon eggs soam STEVENS INSTITUTE of TECHNOLOGY 21 Strings We already know that strings of characters are the data type for words and letters You can loop through iterate slice and select by index the same way you can with lists STEVENS INSTITUTE of TECHNOLOGY 22 String Methods There are several useful methods that strings have upper lower capitalize and title change the capitalization of the string astring HeLlO.  hOw ArE yOu print astring.  lower print astring. upper print astring. title print astring. capitalize hello.  how are you HELLO.  HOW ARE YOU Hello.  How Are You Hello.  how are you startswith is useful too astring HeLlO.  hOw ArE yOu print astring. startswithHe print astring. startswithhe True False There are 30 string methods httpsdocs. python. org2librarystdtypes. htmlstringmethods STEVENS INSTITUTE of TECHNOLOGY 23 String Methods lower or Upper is useful for comparing words Say we want to check If word Is in list original fISH cow DOG cAt word Dog print word in original lowercase x. lower for in original print word.  lower in lowercase STEVENS INSTITUTE of TECHNOLOGY 24 replace Method The replace method lets you replace part of string with something else which is offen useful.  Notice that this doesnt change the original string name Jonathan print name. replacea print name Jonthn Jonathan STEVENS INSTITUTE of TECHNOLOGY 25 won Type Conversion Type conversion can be useful when geiting input from users.  The rawinput function gets input from user as string.  In 13 age rawinputPlease enter your age Please enter your age27 In 14 print In years you will be intage In years you will be 32 The list function will turn string into list too In 36 print listStevens Ss is is STEVENS INSTITUTE of TECHNOLOGY 26 Ly won Some Tips You can use the rangen function to quickly oe Ct ar beagel ee print create list of numbers n1 to loop through Lists can even have other lists as elements mylist two 3three3. 0 4. 0 print mylist2 three The index method will only return the position of the first match In 32 letters Hello In 33 print letters.  index1l SS LULU STEVENS INSTITUTE of TECHNOLOGY 27 .  3hlUui won Conditional Steps sometimes we want to repeat parts of the code multiple times.  If the number of times is predetermined well use for loop which is definite if we dont know how many times well use while loop indefinite.  We still might Know how many times this will repeat see next example SS LULU STEVENS INSTITUTE of TECHNOLOGY 28 Comparison Operators Boolean expressions ask question and produce Yes or No resulf which we use to control program flow Boolean expressions using comparison operators evaluate to True False Yes No Comparison operators look at variables but do not change the variables Python Meaning Less than Less than or Equa Equal to Greater than or Equal Greater than Not equal STEVENS INSTITUTE of TECHNOLOGY 29 Breaking Out of Loop lu The break statement ends the current loop and jumps To the statement immediately following the loop It is like loop test that can happen anywhere in the body of the loop while True line input if line done break print line print Done hello there hello there finished finished done Done STEVENS INSTITUTE of TECHNOLOGY 30 Finishing an Iteration with continue The continue statement ends the current iteration and jumps fo the top of the loop and starts the next iteration while True line input if lineO continue If line done break print line print Donel hello there hello there dont print this print this print this done Done STEVENS INSTITUTE of TECHNOLOGY 34 .  fs Finding the Average in Loop we count sum print Before count sum for value in 41 12 74 15 count count sum sum value print count sum value print After count sum sum count python averageloop. py Before 50 41 62 12 65 139 74 154 15 After 154 25 An average just combines the counting and sum patterns and divides when the loop is done SS LULU STEVENS INSTITUTE of TECHNOLOGY 32 Useful Links we httowww. tutorialspoint. compythonpython variable types. htm httpwww.  informit. comarticlesarticle. aspx p459269 SeqNUM7 httpsdocs. python. org2. 7tutorialdatastructures. html httplearnpythonthehardway. orgbookex32. html STEVENS INSTITUTE of TECHNOLOGY 33 And probably you can reduce the code using functions doing the same thing.  mean some of the plots are the same plot with different data.  Right.  So mean nothing too bad.  But keep in mind that when you have code that is so long if there is something wrong in one of the logical blocks then you need to change each one of them and then things can be different you do.  Think in one but not in the other and then it will become problematic.  So when you have sort of common denominator you change in one place and well take effect to all the times that you will call it.  Great that makes sense.  need to practice little more since were starting off right.  So Ill try and improve on this you know.  Just.  Thank you.  Absolutely.  mean you did good job.  Did you enjoy analyzing the data overall really did it.  This is the data set that made most sense to me and like it.  So it was really.  Oh learned lot by doing this.  So so yes so thank you.  Good good good.  Thank you.  Alright.  Okay.  This is basically concluding our class including our courts.  Shortly we will post the final grades.  If you have issues questions send us an email as soon as possible.  It was good semester as soon as possible.  It was good semester.  really thank you all.  really hope that you learned something that was useful or will be useful for the rest of your professional career.  Studies whatever its going to use that you will have for what you learn.  So again thats been pleasure working with you and if you have any question on the course or something that is related or on the program of your studies or in your professional activities if there is something that you can benefit from on the data side or AI machine learning Nlp feel free to contact me will be super happy to help you.  So we are really here not for the money because Academy is not exactly one of the most highest paid job.  So but because we want to help you.  So we want to be able as much as possible to touch lives to help you to succeed and to mean get the most you can get from.  Okay.  So again we started recording its February the fourth and is 631.  001 This is 624 us.  011 And we have relatively full agenda for the day.  015 So let me go here for second.  So we are right here February 4th.  023 We will talk about variables control.  033 We will talk about testing.  And we will start mean will introduce exercise number two.  038 Before doing that let me go here.  051 And it is new to your cell phone.  055 You will be a.  Okay.  106 So can you mute yourself this All right.  114 Okay.  So.  The assignment that we had asked for.  118 But this week was writer program named Convert the API that will convert the temperature in Celsius into temperature in Fahrenheit.  131 So that was the specs and the specifications for the assignment.  143 And thats basically one of the possible solutions.  152 So again there are million other ways for doing it.  157 So in this case and using is digital we all know that this is not the best way to do it but its the easiest way.  201 So inputting the temperature in Celsius uh then if the user will type down it will go here to print.  212 Thanks for using this tool break meaning is leaving the loop and is leaving the program.  224 If is not done then Im checking if the input is numeric.  230 If its not will print the message and go back.  239 If yes do the calculation on the temperature and will print the and thats the end of it.  244 So run it.  So if the temperature is 12.  255 The equivalent is 53. 6.  And then.  304 Is that mean obviously that was not the only way of doing it.  309 There is also the possibility to use try.  321 Except that is always recommended.  just wanted to use metaphor.  325 We can seriously.  Oh thank you for letting me know.  331 Sorry about that.  All right so let me start all over.  335 My apologies.  Okay.  343 So the program.  So again my apologies.  346 So its basically the same wide through Looper that we did the million other times.  353 So the looper is on what is the temperature insult is asking.  402 mean the input is what is the temperature in Celsius then when finished.  406 So if the input is done then it will print message and it will break.  414 Wed go out of the loop out of the program.  421 If its not done using is digit again is not the best way to do it is the more straightforward but its not the most recommended.  423 But mean try except the would work better.  434 So if it falls meaning is now the digital will print the you need to input the number on the letter.  440 Continue going back and asking again if will pass the test then will do the calculation and will print the results again.  447 Right again.  So if the number is 33.  503 The temperature the 91. 4 in Fahrenheit.  512 And if type then well exit.  515 So is that straight forward 521 So let me stop sharing for second the questions.  524 All right.  So if.  535 No question sir.  Again you can use the right accepter or you can use the is digital.  538 Keeping in mind that if you use is digit and you import name number that is protein pointer it has the decimal 550 but then you will not pass the test and you will get the message input the number on the letter and that will state over you.  603 All right.  So just quick question.  616 Are you all okay with With Python with the environment with Pi Sharma.  623 Its all okay.  Is there any problem It is working fine for you.  636 Are you still debating if you want to use notebook or something else 642 So.  What do you think 650 Well good.  So far so good.  655 Okay.  Thats what want to know.  All right.  658 Okay.  Okay.  702 So thank you for the feedback.  707 Let me share the screen again and let me go now and the PowerPoint.  713 So want to spend just few slides on testing.  722 The slides are more sort of placeholder than something to really describe method or something like that.  730 We mentioned in the first class that when you develop software.  744 You have.  Apart from the maintenance.  So the two main components are the development and the testing.  751 Testing code is really essential.  758 So its close to impossible to write code with certain level of complexity with zero error or the first round.  803 So when you start writing something with certain level of complexity meaning not just three lines 816 but something like 300 lines or 100 lines whatever it is it is very likely that there is bug.  823 So you want to be sure that when you develop your software.  833 You tested that in the proper way.  840 As we said that most of the time you have different people developing and testing.  844 When you develop your goal is to make sure that the program is running and is generating something that seems to be in line with the specs.  850 When you are testing you actually are looking for points of failure.  902 So you want the software the program to fail to break because at that point you did your job and you found something 907 then obviously it could happen that there is no way or most likely this is not going to happen at the first round 918 but it could happen after an aberration.  925 So testing most of the time its really back and forth.  931 So you do the first round you tested you fix something and then once you fix that you realize that there is something else.  936 So you need to make sure that when you are developing the software when you are testing the software you test all the possible options.  945 So even before you write the code you need to have mental view of what the options can be for your program 957 meaning all the different grounds the different branches in you are logical tree that is your program.  The user can go and you want to be sure that you will test each one of them.  So its like having flow chart and testing each branch of the flow chart.  So again its really essential to do proper testing.  There are different schools of testing.  So in this case is bay.  You develop code based on testing.  So you do force flowchart.  You determine all the alternatives that are in your program and you define the data that would drive the program into those branches.  And when you write the code you tested that using those data.  So either you do development that is based on tests or you do something that is more retrofitting the test the software you have but meaning you wrote it and then you tested and you test every single aspect.  But testing its really essential for the development.  Um.  It sometimes is not easy to find airdrops.  Sometimes the airdrops can be logical sometimes can be of different nature.  So let me go for second.  To think its.  Yeah.  Its probably.  Yeah.  Yeah.  So let me go for second to the different types of areas that you can get.  So one error is syntax error.  So for example you had no call on after an for else statement.  So thats syntax said or meaning is an error on the syntax or the language.  So its formal lets say error rather.  In other cases it could be an execution error.  So the syntax is correct.  But you are dont know.  You are adding string with number and you will get an error.  So.  The interpreter will tell you the type of error.  So thats an execution error meaning syntactically its nothing wrong but when applied on will execute the code will generate the error.  Other.  Option is the design error.  Thats the trickiest type of arrow because there is no syntactic error.  There is no execution.  Arora.  But the program is not doing what its supposed to do.  So at that point you really need to go into the code and mean be like the Python interpreter and do each step.  Top from top to bottom left to right all the alternatives and see what is wrong.  What is generally very useful is to insert some temporary print statements for the variables to make sure that the output at that point is like checkpoint.  At that point of the code is exactly what you expect.  You can write the printer and then you can use you can comment the printer when you do not need to again.  And eventually you can remove the numbered sign and have it again.  You bring the variable but the value of the variable that you can print the type of variable.  So sometimes you got an error because instead of having number you have string.  So at that point you may want to type to print the type of variable instead of the content itself.  So generally speaking those check points that you will remove when the code will work fine.  But those check points are what we use the most when we do the debugging.  So you run the program you see that its not generating any error or meaning.  There is no syntax error or no execution.  Arora.  But the results are not what you expected.  So at that point what you do is to place those check points and see whats going on.  So is this variable at this point having the value that expected If not go back and check the way that value has been calculated and then you go back.  So again inserting those check points is really essential when you do the debugging of your code.  So now lets go back to Python and lets talk about the other features that we will use down the road and from next assignment on.  So variable types.  So we so the strings we so the numbers that are that are variable types in Python.  Strings numbers.  Again strings are normally in single or double quotation.  For Biden its pretty much the same numbers can be.  Integers can be floating.  You have operators working with both of their mustering and numbers.  So those are some of the examples.  You can do some of the same operations.  So you can add the strings.  You can divide strings obviously.  But you can add the strings.  When you add the strings you attach one to the other.  There is no space because you are physically taking one string and the other and collapse that is.  But you can do multiplication.  That is like adding in that time when an is the number that multiplier.  You cannot and you can do the same thing with numbers with the result that you expect.  So addition multiplication.  Its obviously not my way.  You cannot mix and match meaning that would be an execution error.  If you add string to number you will get an error.  So mean the interpreter will tell you the type of error that you are getting.  As was mentioning before you can ask python.  What is the type of variable that you are working with So if you have variable name the name and you are.  Hope.  And you assign value to that variable.  If you do print that type the name of the variable you will get that.  What is the type of the variable Meaning this case is string.  In this case it is list.  In this case is an integer and so on.  So those can be useful because sometimes a.  You have one you expect one type but you did something and the result is not the type that you expected.  So at that point you probably need to go back and do something in your logic and change it.  So keep that in mind.  This is something that you may want to consider.  Um.  We mention that there are two main types of numbers integers floating point.  So there are also array.  We will talk about that later on.  Arrays her vectors.  We are the elements of numbers.  But this is something that we will do later on.  For the time being integers and floating points are the two types of numbers that we are going to see them.  As we know because we did two assignments on that you can convert the string into integer and vice versa.  So obviously you need to be sure if you are converting string into integer or numbers either floating or integer.  If you are converting as we know if you are converting string into number and the content of the string is not numeric you will get an error.  So again.  You can mean convert one into another.  You can convert an integer into floating the string into integer or floating thinks that that.  So thats an example.  So you have stringer with the number inside.  This is sort of pseudocode in Python three point something which should have the parentheses.  This is not there.  So in this case you will get no error.  This case you will get no error as well in this case because the content of the string is non numerical.  If you try to do the conversion of the string into number you will get the net.  And we already knew that.  So again be aware of what could be inside.  Again thats another case where you may want to add that eventually in print statement before doing the operation.  If you see that there is something wrong and then you will remove it.  So it is just temporary check point.  So.  Again we know that there are statements like is the jitter that can prevent the error.  We also know that we can use the trai statement that will intercept the error.  And that.  So we talked about the user input.  We use that.  So in Python three point something is just input in two point something was row input.  But what you get is string as.  Meaning that eventually you need to transform the input into number if you want to do operations with that.  Again strings.  You can add the string.  You can multiply string.  Lisa is another data variable type that is very useful.  We will use it quite lot.  It is probably one is not the most common.  Variable type that we use this like the number and the name is sequence of elements within square brackets.  So the elements are separated by comma.  You can have one or you cannot have space before or after.  The comma is not required.  generally use it for better readability but you do not have to.  So the elements inside the the list can be numbers can be string or can be lists.  So you can have nested the list meaning get list of lists and then you need to address those in the proper way since youll be little bit convoluted but is something that is commonly used.  We would do an exercise on that.  Those are examples.  So you have this list with four elements.  So number string an integer string and floating point number and then other string.  So python up for the list for the strings.  Pretty much whatever you think is starting counting from zero.  So the first element of string is the element zero.  So if you want to print the example list the first element that will be zero and you will get one two three three is the fourth element.  And you will get fish.  So lists are mutable meaning you can change the content of the entire list of elements of the list.  In this case replace the the last element from fish to tilapia.  And then when printed will get the instead of the fish that was initially have tilapia or whatever.  So.  If you do print typer for this list you will get this.  So again sometimes when you do you are coding.  You expect list but instead of list you got string.  So meaning that either you do the conversion or there is something wrong in the logic of your program.  And thats where the print type of the variable can help.  Again its sort of temporary checkpoint.  Both lists and strings can be as allies.  So if you consider or if you consider what am.  If you consider this.  Mr.  If you consider this list.  So the fourth element would be if you do.  Three.  Fall.  That means that you start from the fourth element and you go all the way to the end.  So you are at least in the list taking from one certain point that you specify up to the end or you can do vice versa from the beginning to that point or you can just slice from certain point to certain point.  So in this case you are taking from this string that from the fourth element the up to the fifth element meaning you have the fourth and the fifth.  So.  You can do also with the minus sign you can get the last element.  Minus one.  Minus two would be G.  in the last two and a.  And that means you can really do lot of slicing.  Um.  Listen as we said before.  Can be addressed by that number.  And it is two ways method to access the content.  Well let me go back to this one.  Uh.  With up to three you have the and then five means you stop before the five.  So that means is DNA.  So its up to that.  So you can do.  List the name of the list the square brackets one and you will get to ABC but you can do vice versa.  So you can get the index from the value.  In given position.  So in this case that is the reverse of getting the content based on the position so you can get the position based on the content.  So in this case you are doing you are getting one.  And it is the second position calling the content ABC.  With dont know four.  mean you can do the first.  You can do.  Uh thats kind of tricky.  You can add the elements or you can join list.  So with pen there you are adding an element to an existing list.  So you have that this list.  You add the to 2.  You are extending the list with the new value.  Thats particularly useful when you do loop and in each loop you add one element to your list.  So you use and append within the loop adding at each adoration.  One value you can do removal meaning same thing again.  Lists are mutable.  You can change them the way you want.  So you can remove elements.  So you can remove the element calling the value.  Or you can also remove it calling the position.  So what is pre he was mentioning before is that.  Difference between concatenation and appending.  So concatenation you have this list one two three these other lists four five six and you are adding one to the other.  But when you do the concatenation you are concatenating the two lists and the result will be list with all the elements of the fourth.  And all the elements of this is one single list plain simple one place to this concatenation append as you.  So over here is pending an element at the end as last element of the of an existing list.  So if you have the same and lists you are pending to at this point you are appending new element the meaning the entire list as fourth element as an additional element.  So you really need to address the drawing of lists in the proper way.  Concatenation is creating list that is sort of summation of the two lists.  Append is just pending the second list as an element of the existing list.  So in this case you have five elements or six elements with the sixth that is addressed by the number five.  In this case you have four elements where the first three elements are simple numbers and the fourth element is list.  So if you want to address that lets say this value five it will be a.  Three because it is the fourth element to any square bracket that you will.  Right one.  So there are two indexes at that point.  We will go back to that.  You can use that in for list.  So you can mean that could be in brief statement but just to explain how it works you have value and you are asking the interpreter if this value is in the list.  So you just do value lets say 42 in this list here and you will get through 55 is not in list that you will get at folds.  You can do either in or not in.  In this case if you do not in with 55 you will get through.  Obviously again those could be part of an effort statement and you can do different things based on either true or false value.  Police are ordered the scenes to be obvious but not all the variables in Python are ordered.  So when you create the list that order will say so is the order of your creation or the list.  So then you can change it.  Meaning you can add the elements you can remove elements you can rewrite the entire content.  But if you dont do anything called those the order will say the same again.  Seems to be obvious but not all the variables implied on have the same behavior.  And we will go there shortly.  So again if this is the order when you printed that will say exactly the way it is.  So in this case this loop what is doing You have scheduler impedance for in this list of value.  So the first iteration would be zero and will print the periods zero schedule zero.  Meaning you have one map.  The other iteration of the second element you will have to Jim and so on till the end of the list till the number three.  That is the fourth element.  Um.  mentioned before the order will stay the same unless you change it because again these are immutable.  So you can sort of ascending or descending to list if is numerical.  Is either numerical descending on ascending if is alphabetical strings the sort will be by alphabetical order.  The.  The strings.  We know strings so we use strings few times.  So in sense they have similar behavior as this.  So if you have this string here.  You can slice it.  Meaning if you print from a.  Five on meaning ops.  You are printing from deep space on and youll have Morning America.  If you ask for the fourth element that would be this the here.  Uh if you do loop.  Um.  When you loop into string you are looping into each letter.  So when you print you will get something like that.  So and so on.  think certainly we use that with is digital.  They have method to get we.  Additional mean to transform somehow the or to test what is in the string.  So if you have string like this one and you can lower the values in the stringer getting this one you can have all capital with upper you have tidal meaning the capital will be after each space.  You can capitalize meaning the copy.  The letter will be only on the fourth letter of the string you can use.  Start with the meaning you are testing.  You are getting true or false based on if the condition is true.  mean if in this case you have low and start with you are asking basically if the string it is starting with the capital and you will get through.  Biden is sensitive of the capital lot of small letters and that meaning if you ask her small letter you will get false.  There are about 30 medals and you can get them on Python.  Thats because.  So in this case you have word.  That is stronger dog.  You have list and you are asking if this word is in the list and you get false because dog in the string in the list is all capital.  And in the string its only the first letter in cabinet.  If you do loop.  So thats compact way for doing loops.  So in this case the way you read this loop is you have four peaks in the origin of the list that we had.  Meaning is looping in each one of the values in the list.  So the first round will be fish cycle round would be cow and so on and is lowering it and is creating list new list with all the values in that lowercase.  And then when you printed that when you ask if its lowercase you would get true.  You can do replace pretty much like in this you can replace value with another value.  So you have name or replace the original value the new value.  You can replace chunks as well.  You can do conversions when you convert string into list.  You will get list of the characters the single letters if letters or characters in general that are in the string.  Im saying characters because it could be punctuation sign that it could be space could be special character or whatever it was.  So each one will be one element of the list.  We pretty much covered this just one moment driving your attention on this one.  We already mentioned something similar.  So this list is list of lists.  So you have the first element that is number.  The second element is string.  The third element that is list.  And the fourth element that is number.  So when you do when you bring the two meaning the third element that without this one you would get the entire list in the third position.  When you say one that means that on that element you want to have the second element and you will get three.  So thats the way to get the an element that is inside the list.  That is inside the list.  They can be nested as much as you want meaning you can have eventually if instead of three there was another place.  Then you need to have another number in square brackets to address.  Eventually.  What is inside We know that you can do conditional steps.  So conditional steps in list meaning you can have list and then you can loop into the list and getting each one of the values that are in the list.  Again you can do all the comparison that you normally do.  We mentioned breaking out of loops we mention continue.  You can do averages and thats pretty much it.  Okay.  So we finished the uh the slides uh quite early.  So Im stopping sharing for moment.  Just to check if you have any question.  If no question will introduce the inclass assignment.  So let me publish first the content.  So Im publishing.  The script for the previous exercise and.  And publishing.  The slides and the inclass exercise.  All right.  So let me share again the screen.  And let me go here.  So the inclass exercise is actually two exercises.  So one up is ask the user for number depending on whether the number is even or the printout an appropriate message to the user.  Meaning if Id say is to then the message would be the number that you input.  It was an event and so on and you want to print different message if the input is multiple of four.  So if its multiple of four instead of printing.  Its an event that you will print that the number is multiple of four instead of to determine if he is even or all the you would use.  You will divide the number by two and if the reminder is zero that means it is an even number.  But the second would be create program that asks the user to enter the name and age and will print out method that will tell the year when the user will take the hundred and the number of days from today till the first day of their hundredth year or not for the year.  So we dont know the birthday but we are just based on yet.  Okay.  So you have that in your canvas.  So now will create a.  Some break rooms.  So you will.  There would be 11 breakout rooms three four participants per room.  And just to be sure is clear for the first assignments there will be no grading in any way for these inclass exercises.  They are only to be sure that you are practicing languages.  The best way to learn language.  said that medium time.  So sorry for repeating it but its true.  Learning languages are the real key for learning languages.  Either computer languages or spoken languages is to practice.  So you really need to practice lot to be sure that you will be proficient in using it.  So at this point will pull.  All right so Im recording again.  There is no need to submit anything.  As was mentioning before for the fourth class and we are still in the first classes.  So there will be no submission no grading for the class exercises theyve been done only to give you the opportunity to practice little bit more in sort of protect the no judgment no grading environment working with your colleagues.  And thats it based on how the class will go.  can give students the opportunity to get more points and then the inclass exercises.  We get some grading.  It will be mean not much on the quality but more on the fact that you did something or you did not much or anything or you didnt attend to class.  So the real scope is to be sure that you are using the time of the lectures for what they are meaning then in the lectures doing the inclass exercises for practicing.  So mean you are paying quite some money and you want to use all the resources that we are giving to you for the money you are paying.  So anyway.  Lets start with your versions.  Anyone want to present what you did Again there is no judgment.  There is no mapping of.  Yep.  Quite.  could present.  Please somebody else.  Okay.  Cool.  Yep.  Okay.  You want to comment little bit Yeah.  So have defined function call as is number which tests whether it is all number order or not voice.  have tried to plot so that although one point number ago are taken and secondly for negative and positive also its considering your by expanding it whether its complex or not.  And if its not true it will break out of the loop and the invalid statement will be shown.  So secondly have then taken the input and after that if Loop is running poised have checked whether it is all multiple of four or not.  And as it does my role of audit will also be or even number.  And secondly if its not multiple of four but its still even number then additive is shown.  And after that if it neither of them then it will show its an odd number.  So.  Ill just run glass.  So this isnt.  This is our number.  Mm hmm.  The.  It is an even number as well.  little more colorful.  Mm hmm.  And what about if its not number and if its not number For example if would look at cutoff then it would show Im getting an ad off.  just.  Yeah you are getting an error because you defined the function but you didnt use it.  So in line 12 you do or if is number well 930.  Yeah.  But mean if is not the number you will get an error in line 12.  That is what you have in the message.  Mm hmm.  So what will how how will it solves Well mean you need to test before doing the integer.  So you need to.  mean about the normal guess.  Still yeah.  You need to remove from line 12 the ante like this.  Well you dont have the number yet so you cannot test the number.  So so remove the one that you just added.  So this one will go then in line 12 you have space that you want to remove this base before because at this point okay then you want to remove the anti.  Yeah.  And the parentheses at the end.  And at that point it should work.  just testo character.  Yeah yeah yeah.  Now its looking okay.  Thank you so sure that gets awfully not dull competing for startup one input into your name.  And secondly it was the age of the person.  Then to show the persons Adrian when the person returned 100 that will be displayed.  So just run.  But its.  Or whatever you.  So this is the year Paulson moved on.  Mm hmm.  All right.  Okay.  So in both cases you didnt do the loop for uh keep using the tool till the user will type done.  But.  But thats okay.  Right.  mean in the previous exercises we used the the while loop just to be sure that the user can stay in the loop till will type done.  But mean what was not required.  Yeah.  And mean you you the function.  We didnt introduce the function for the rest of the of the students in the class.  Dont worry about the function.  You do not need to use functions yet.  You will use it in two or three classes.  All right.  Okay.  Thanks lot.  Thank you sir.  Mm hmm.  Anyone else You can stop sharing.  Whatever.  Anyone else want to present what to do So tried the first one.  Go ahead.  Yeah.  Murder.  havent heard of that thing with Lego.  If there is input of like.  If there is string as input.  have got that.  Okay.  Go ahead.  You.  It is the program that tried.  So have input now as if thats done or done.  And yeah from Yaron if an integer is less than zero then only natural numbers are allowed.  And please try again.  Message will pop up and continue.  If number is equal to 000 that would not even then continue.  If its less its divided by four and the reminder is zero then the number is multiple of four and hence it is an even number.  Continue again.  Then if the number is divided by two and the remainder is zero then the given number is even others.  Its an hour and we just need you.  Yeah.  So here it is.  Like please insert number if its in negative two or something.  It will only natural numbers that are alert.  And please try again.  If the number is zero then it will show zero is neither or not an even number.  If its multiple of four then it will show this number is multiple foreign hands.  Its even number.  If its an odd number maybe like the spin rate which is an even number.  And if its an R.  And if everything has been.  Okay.  Sounds good.  Yeah.  You didnt check for the nomadic but thats fine.  Yeah.  All right.  Great.  Thanks lot.  Anyone else Professor Paul the second question what want to say to my screen.  Please.  Yeah.  So.  This is worth something.  Okay.  So Anderson.  Actually was trying to locate what would do but still without looking it is working fine.  Just.  Im in the presentation that you are doing.  Its really useful because its giving the other students way of doing things that they may not think that was possible or was useful or you made better or had that.  They also did.  Its good learning way of doing things.  Thank you.  Thank you Professor.  So Professor this is my program.  So on the first to last day was it about his name It is.  And.  And then like here and giving my name.  Mm hmm.  The rest is printed.  So then it will ask me what is the current year 2023 and then the calculation books.  So the 100 is will be under minus is plus the current year.  And here am also saying the remaining days for 400 year and also the remaining year for the hundred.  Thats a.  Thats is simple problem.  Okay.  Sounds good.  So you did the printing in different way.  But thats absolutely fine.  Yeah.  Okay.  So here have used this extreme to call this defined name year 100 as to call this thing.  have used extreme.  Mm hmm.  Mm hmm.  Well if I.  If remove this upstream and run this program then.  Lagos State considered to be the largest.  It will not recognize the name.  So that is given this upstream.  Thats good.  Thats very good.  Okay.  So thanks lot.  And you want to thank you.  Thank you.  Anyone else.  Well mine is relatively simpler but concentrated.  Please.  So this was the first one what just said while true and if it is desert then it will check the multiples or else itll say please and draw numerical value.  Mm hmm.  So youll give it number to say for it says its an even number and multiple of 47.  It says its an odd number.  And if its oh if its letter itll say please and add numerical value.  And itll just look if you enter another.  So itll asking for number.  So that was plus one.  Thats good.  mean you may want to add an exit condition in the loop.  The usual done when you want to exit.  But thats fine.  Okay.  And then for the next one this one was also pretty simple but name id int enter your ID and then took it directly as two doesnt do anything.  So you print you will be hundred in this year and then the number of days you have.  So to.  Yeah.  Yeah.  You need to stop the other one so itll go on the bottom left.  Okay thats fine.  Yeah.  No unfortunately.  Yeah yeah yeah.  Yeah.  Okay.  Yeah.  Okay.  Once again think can just around here.  Yep.  So you and your name.  And then you and do your age.  So it tells you you will do 100 in the year 20 101 and then you have this many days before your hundred year.  Sounds great.  Yeah.  mean the only thing you may want to check if is nomadic or not because if the user will type something that is not nomadic then you will get an article.  Okay.  Thank you.  Yep.  Sure.  All right.  Winona.  What did you do now that you need to present But just want your comments.  Sure.  mean can present both.  Yeah sure.  One second.  Okay.  guess Ill start with the first one.  So mean one of my group members Ive already presented but Ill show what did in case did it little differently.  So this is the first assignment.  First question.  So did print enter number equals integer input and then the conditions were if module learned the module from forgot.  So thank you for that.  If the module two double equals zero print numbers even.  Same thing for for.  If module for equals zero print number is odd.  So if run it.  say by numbers even number is odd.  dont know if did that one right but thats what get.  All right Yeah.  mean there is no.  mean there is connection.  Well mean the condition is intrinsically there because there is no loop.  Okay.  But what is missing is a.  mean that if you look at the code in this case if is multiple its even is even.  But then on line six it shouldnt be.  Its odd but it should be is multiple of four.  Right.  Right.  And then there should be an Elsa that is.  Print.  mean that column.  Before.  Yeah.  You want to delete this piece Hold on sec.  So you held call on that.  And then new line.  After Elsa.  Okay great.  And then that print number is on.  Run it.  All right.  All right.  Okay.  And if you try.  And an odd number.  All right.  You got it.  Thanks.  So there are couple of things.  One you may want to check if the input is really numeric or not.  Mm hmm.  And the second is you may want to check.  You may want to have look just to give the user the possibility to keep using the tool till he or she would say thats enough.  But that is not was not in the requirements.  Yeah.  Did you want me to share the second question.  Confident in this one.  So for the second.  For second one did.  Name equals input.  Hi.  What is your name Age equals integer parentheses input.  What is your age use current year equals integer input.  Whats the current year And then year underscore 100 equals 100 minus age plus current year days.  So 100 equals 365 times 100 minus current year.  And then print name.  You will turn 100 years old and youre 100 F.  Thats days to 100 days.  Now similar to Debbie Rogers you helped me with this one.  think mines little bit different.  Maybe shorter so.  But think.  If run it so.  think it does work.  Yep.  Yeah.  Okay.  Sounds great.  mean the same thing.  It check on being numeric for the input would be appropriate and then the loop eventually to give the user the possibility to keep using the tool.  But mean its minor.  All right.  Thanks lot.  Okay.  So.  Let me share the screen and let me show you.  So this one was the program for checking if the number is on the ribbon and multiple of four.  So again generally speaking you may want to have some comments obviously not in half an hour time as you had.  But when you do when you have more time its always good to.  Add comments because it will increase the readability.  So Lupo on on the requests.  Just to be sure that the user can keep using the tool then getting and testing if its done if done will break after message.  Then have to try.  Except on.  On the first input.  So try getting the integer out of the value that is been imported.  If get an error will print an error message and will go back.  Then am checking for if is multiple of four.  If yes multiple of four.  If not will go here and check if it is multiple to message.  Otherwise its odd.  And when run into.  So if have body for.  Table for 22.  Its even not 33.  Its the.  Uh that can do.  W.  W.  Thats America.  Dun dun.  The other one.  Um.  Same thing.  Some comments same looper asking.  Name.  If done break holds.  Asking The Age.  Transforming an integer if no error.  If there is an error go back read in here those values that Im in that is not great to write values into code but thats just an example.  So you have what is the year today what is the month the day and what is the number of years 200 and then that calculating the centennial birth here printing.  The days same think.  Im printing.  So its little bit more complex because Im also taking into consideration the day and the month but its pretty much the same that some of you already did.  Name whatever it is.  Age or whatever it is.  And then you have all the rest.  And then when you finish ups where was we would look.  All right.  So.  Thats basically it.  will.  Both those two on campus.  Let me go now to the assignment.  So for next week we have an assignment with the two parts.  So the part one its riding.  mean they are both related to the same program.  So the testing and the program are related to the same matter.  That is what the program is going to do.  But you want to do to design the testing.  So designing testing is basically using an approach like this one.  So you will use this doc phyla as sort of template.  So you want to have the goal of the program.  And the goal of the program will be.  From here write program that has loop and so on.  So thats the goal of the program.  What is the testing strategy So the testing strategy is checking each one of the option.  For example using Don to exit the program printing proper statement when the user enter done checking that the password enter is acceptable.  Printing proper statement that when the user enters non acceptable password.  So those are examples of the alternatives that there will be in your program and then you want to have data to go into each one of those elements.  Those are alternatives that youll have.  So if the input is ABC then the output will be the password is too short.  If the input is done the output will be good by things like that.  And you want to be sure that you are checking all the bases where the bases are.  Each one of the options so that your program can go in running.  So the programmer is writer programmer as looper to ground the user for input checking it and printing the proper message until the user it will print done.  That is very generic.  So in this case.  The idea is to enter password and check if the password is meeting the requirements so the user will input password or done when finished and the output will be either password accepted or not accepted or good by.  So the password needs to have minimum length five character maximum length 12 character and then any combination of numerical and alphabetical character either as more or capital letter.  So you will you will prompt so you will to the rules of the game that are daughter.  Please type password with the following characteristics.  Then the user will input the password.  If the user will type done you will print goodbye.  And so then you will check the password.  Meaning you will take the input that you had from number two and you will check if the requirements are meaning meaning minimum length maximum length and combination or maybe going out for alphabetical characters if.  The requirements are okay are met.  Then password accepted.  If not you will print the proper message so they can be.  The password is too short.  The password is too long.  Or that there is.  There are not the numerical values or things that they.  So each one will have separate message if multiple errors of course occur.  Then you can use any of them.  If is accepted then you will print password accepted and thats basically it.  So you need to submit your document your PDF or doc document with the testing and that you will submit and you will submit your program in the pie format.  So thats basically it that its little bit more complex.  Again each assignment will be little bit more complex than the previous one.  Thats the rules of the game and thats the reason why you do not want to fall behind.  Because catching up could be complicated.  So be sure that you are current that you are okay if there is something that is not going right.  Check with me.  Check with the DEA with you.  And we would be happy to help you.  Questions.  As someone questioned the test driven the testing driven part are you essentially explaining what you will be writing in the program or.  didnt didnt understand.  What exactly are we supposed to describe You will describe what will be the.  mean in sense you are describing in plain English what you are doing.  But let me go back to sharing the screen and let me go to the document again.  So you are writing what are every single alternative that you are going to have in your program So basically one alternative is the minimum length.  The requirement for minimum length is not met meaning dont know the password that is for correctness.  And in this case you will have uh so that logic would be the first one would be the testing for the length of the password.  The second that will be testing for the presence of numerical character.  The third that will be testing for the presence of alphabetical character.  And each one will be elements that you will need to test.  You want to be sure that the output would be what you expect.  Meaning if the password is too long and then you need to screen the message the password is too long or is too short.  The password is too short.  And then when you do this sample you need to provide the sample of the password.  So if the input is ABC because the requirement is minimum of five this part is is three characters and the output that will be the password is too short.  ABC is just an example.  Its any of character.  Its combination of characters or numbers that are not up to five.  So.  Its really describing the logic of your program and when and how you will do the testing.  So.  Hello everybody is Wednesday April 20 sixth and its 32 right now in this class is not Br.  Class.  Its kind of office time.  001 So the only thing that want to show you is basically how to proceed.  The with the the last assignment to that size whatever it was and then would be here to 018 get your questions if any if there will be no question that will be the end of the class.  036 So again if you have any question on the final or other things so that are related to the courts so feel free to ask me now or whenever you want.  But now would be good moment for that.  046 So 102 let me start sharing the screen and going to 104 this to the 111 proposed solution.  So the idea was to work on this file.  That is subset of what we normally get from 115 mit ctl and what day for each semester.  We have something like what you have on your screen with the information 150 130 on the individual courses.  So each court so is one line and so kind of sanitize the some of the content distractors.  You will not see the names.  You would see numbers 140 the to 200 corporate courses and there is name of the sponsor.  eliminated that.  But apart from that it its its 100.  What we get from work day 201 you you were required to do some analysis.  So some of the analysis where in the requirements some other maybe something that you want to do on top of what W.  Was asked by the requirements.  218 So let me go into the code and 235 so 241 its obviously heavily relying on on pandas.  So without Pandas so it would take way much more than the current 89 lines of code and mean considering that there are comments that are blank lines.  The code is called the the the pure 243 lines of code that 308 the number could be probably 60.  311 So it is short script doing quite lot of things.  314 So imported the batch of libraries including library for the palate.  So you do not need to do that but it is nice to have call off.  So 321 thats the given palette.  You can in pick another pilot if you like.  337 So because we have chats that are pie shots so that mean that the same apart from the data that and title that that we passed to 342 the the chart created the function called the Create Pie Shop.  358 Not much imagination.  And pass the data structure the the call on that they want to analyze.  So 406 all the shots are based on the enrollment count but its role my account as instructor.  So as program.  So thats 418 the mean the the the name and then passing and then the title that we change.  430 So did my group buy in the in this function so im grouping by 438 whatever is the name of the call on that could be we will not see over the year.  so that will be program or delivery mode.  449 So lets say its programmer.  want to do chat program roll my account.  So im group buying program selecting the the column enrollment count.  501 and then doing the the the summation on the value.  So thats something this nomadic only true that was introduced in the latest version of all the Pandas 516 in the past the nomadic only through was the default.  Now you need to specify.  If you dont do that you will get warning.  529 Nothing that will crash your code.  But if you can avoid it that would be better 539 calculating the percentage because mean with the bouquet you youre gonna just pass the number so.  547 and the the the the library.  We do the calculation with the percentage.  You need to do it kind of manually so and then 558 converting the series into Pandas so data frame because this is required as an input for the pie chart im passing the angle so that calculated using the percentage.  610 and 629 Im using pi 3. 14 631 and and another number.  So 639 to calculate the the angles.  643 So using the library.  647 we adding colors and then creating the source data for the visualization 651 setting the parameters.  Im.  Having the 701 over on the tool tip by group.  704 you will see the results 712 creating the the actual pie shaft.  saving it showing it.  714 And thats what the function is doing.  721 The main program reading the Csv file.  724 You dont need to to do what is in the room 59 728 replacing the not available with 0.  That is no no no not available.  But mean that you never know.  Thats why added it.  If there is no not not available then 735 it would not replace anything.  749 so 751 they do nothing.  But if you dont have it and you have some none available.  Then you may have problem 753 calculating and printing the different metrics.  802 So this is the largest for enrollment 807 Again some of you.  One of you asked me.  812 You have some courses that are on multiple sections like am 24 or that is and dont know if this semester.  816 But lets lets say 12 so there are out 12 so 833 you could have the combination of those giving them more indication of the entire courts and not just the section.  But this was not a.  Was W.  What was asked the by the requirements.  841 so 856 eventually is an additional level of analysis that you can definitely do so we can.  When we talk about 857 the the largest enrollment count per instructor we are counting the the individual sections for the different courses no matter if it is the same course in multiple sections or not.  907 students in graduate courses.  So im reducing and selecting only the part of the data set we are Level is equal.  925 for graduate Same thing for undergraduate corporate.  936 then and for each one.  Im.  Creating additional data structure.  942 then open courses close cis and then 948 im printing then creating the pie shards.  955 So the first one im passing program at the column and the title is Distribution of enrollment by program and the second delivery mode the distribution of all meant by delivery mode and and no processing.  So if run it so those are the shots.  So this is the distribution of enrollment by the delivery mode that you had the over on with the the values.  So and this is distribution of enrollment by program and same thing with the legend that is telling me what the different sections on in terms of printing.  So have the largest enrollment count but court.  So mean it is not the nicest definitely way of presenting the data but is what you need.  So those E.  Ng.  R.  Are cross school courses.  They are undergraduate.  They are some of the first courses that under undergraduate are taking.  They are not only school of systems and enterprises but cross the entire Institute and thats why you have those monuments in terms of numbers.  Ss.  W.  55 but is very popular court.  So and hes on that.  and he is graduate undergraduate when you have the numbering of the course so there is nothing with 5.  That means that that can be both rather than an undergrad right largest enrollment count but structure.  So you have the Id of the instructor.  There is no name.  remove the name and the counter.  Its quite likely that those mean.  Obviously those are the instructors for those courses.  The total number of students in graduate courts is undergraduate courses corporate courses.  But we have quite lot of corporate students so its almost half for the ground as they are all graduate.  How for the grad weight ere.  and little bit more than 900 undergraduates.  Traditionally this school of systems and enterprises has more graduate than undergraduate.  Things are.  know in changing bit so we are having more and more undergraduate.  But Still thats distribution.  The open courses meaning that courts is that they are running and not at capacity.  And those are the courses that running at.  So thats basically it for the and thats pretty much all have to say on my side.  So im not sure that all of you already submitted it.  We are not going to to be too strict in the submission time so we we Obviously if you would submit in week you will get 0.  But but erez agmoni if you submit little bit late thats not major problem and thats the reason why im not publishing the solution yet 101.  So questions Are you working on the final mit ctl And again just as the recap final are due in few days 250 next week.  That will be the presentation of the finals meaning some of you.  of you will be asked to present day jobs.  You will be notified the the day before.  We dont have lot of time so it its kind of trade off if give you less days to complete the final.  Then could give you more days in advance to know who is going to present.  But the very end thought that is better to give you as many days extra as possible to complete the final instead of giving us that.  So when you will develop the document.  Keep in mind that you may be asked the to present it.  You dont need to have powerpoint the regular 10 page 15 page whatever its going to be for for for the fine of would be too short at once.  Lets say saying that plus page for the document that will be enough for the presentation.  So again you dont need to have the Powerpoint.  If you feel more comfortable developing Powerpoint on top of your Pdf.  Or word document.  Thats absolutely fine.  What else During the presentation you will have 10 you can do 12 or you can do 13.  You cannot do 20 min for the presentation.  You cannot do min so be sure that you mean get the into the mindset of doing presentation all around 10 min after the final up after the presentation of the final.  So will have 72 to submit the your final grade.  meaning there will be not much time for any complain that you may have.  So go back to to the grades that you have.  You basically have everything apart from the except size Number the one that presented few minutes ago and the final.  So you and you had the formula to calculate the final grade.  So there shouldnt be that much in terms of surprise for most of you meaning if you have any issue any question ask me now because can do something now if it appropriate it would be way much more difficult if you ask me.  Once posted the final grade.  mean that cannot think about anything else in terms of instruction.  Be sure that you will submit the your document whatever format is the format that you are using and the script we need to run the script.  So we need to make sure that the script is working.  When you will do the presentation you will spend few minutes explaining what you did in terms of writing the script.  So be sure that you are prepared for that.  Thats Basically it questions Ava Hi Professor So as was working through the final had like questions.  Ones like more of general one and then the second is more specific to the problem that chose.  So its the more general one.  First as im like running this script im fine thats taking long time to run.  So was wondering if you had any comments on that like is it okay If the runtime is really long or is there any like workarounds for that.  Well mean there is no generalized the answer for that.  When run my model victorizing tests its run for couple of days.  But mean in that case is lot of calculation.  Its deep learning that are lot.  Its mean TV show neural network with lot of he delay it and it takes long when use another metal the using what is called the shallow neural network meaning with just one hidden layer.  It takes few hours but still is few hours.  It it really depends.  Keep in mind that that sometimes when you dont have very complex calculations so ill go it that you are implementing in your tool.  You may do something to optimize it.  An example.  Now if you do loops into loops so nested loops generally seeking python is not very efficient on that.  If you can transform debt into operations between data structures like what presented for the solution of the the current assignment that that would help lot.  c.  So with C.  think that are faster because its compiled.  So revise little bit the code the try to reduce the the loops as much as possible.  Try to use pandas and data structure in general as much as possible.  Thats the most generalize the answer that that can give you.  Obviously each code that is different.  dont know exactly why you are called the its not as fast as you want and the but generally speaking up that those could be some some of the issues.  Obviously another issue that is quite obvious if you do quite lot of of of writing files.  So we defiance that is lowing down.  so do all the readings and then keep the the the data in memory and then write whatever you need to write at the end and dont do Megan for that because this this is low in down.  Thats probably it.  Its not the case in your case.  Ava Hmm.  Okay that makes sense.  Yeah mean its not hours.  Its more like couple of minutes so guess its not something too much to worry about but ill take look at the loops and try to limit those as much as possible.  Ava Second question.  Ava And yeah so the second question.  So im working on the people migration data and want quick clarification.  On the fourth question asks what are the dynamics by income and geographic region Ava So just wanted to clarify like Are you looking for like one Ava visual that has both income and geographic reach and data on it or like are you looking for separate visuals one about income and one about thats up to you.  It really depends on the type of visualization that that that you are using.  If youre using the the San que diagram and in one of the an example so that presented the the the Sanky diagram wed allow you to give both the ways.  But it may be little bit complex so probably it would be easier to do graphs.  But again its totally up to you.  Ava Okay yeah it was little bit tricky because we only have like the income level and regions for like the destinations of the origin.  So was trying.  Ava But yeah if its okay just to do it.  As to thats great.  Okay.  And then like for each question like mean of course if the first one is just like an overall.  But so are you looking for about like one to visuals per question or how like What do you expect Go beyond the the questions you have.  So the questions are are kind of samples.  So you you want to understand whats going on.  will give you an example.  So yesterday it was the presentation day for the other 24 that that im teaching student what on the mass shooting and she was analyzing both the text and numbers.  So and what she did that was was basically to see what is the distribution in time What what are the States where there is more mass shooting and then on the tech side she collected data from that some news outlets so that they are more on the Conservative side and the news out outlets so that that more on the limit outside.  and then doing some natural language processing she extracted the the diagram.  So the visuals so visuals.  In that case we are.  What Cloud and what she got was something that she didnt really expect that that mean if you think for second its reasonable but may not be the first thing that could come.  E.  C.  The the psychological conditions of the shoe thats not all the other problems.  So thats an example.  mean.  did then ask in this particular case what was the most stress the aspect the of the conversation.  But when you have problem.  You want to drill down and see what are the reasons What is the problem So in those cases you may even use external sources like in our case.  She downloaded the the text from the different news outlets.  So again obviously.  eventually there is no limit.  You can spend months doing.  The analysis in particular.  migration is complicated problem.  But just to be sure that you are not limited to the questions you have.  So the questions are example of questions.  So if you address those thats fine.  If you think that there are other elements that would be more relevant to better understand the problem.  Thats absolutely fine.  You will explain it.  You would say think that this point is more relevant.  and then you you will analyze it.  Ava Okay yeah that definitely makes sense You know.  If something you know sticks out definitely you know.  Try to find some more info on it to go.  mean that dont see this course this assignment as traditional one.  When you have questions you need to provide answers.  You need to use the tools.  So to understand whats going on.  and then your vision is different from mine is different from anyone else.  So use your vision your interests your experience to address the mean to understand the the problem.  Ava Right Okay think that answers my questions.  Thank you so much.  Other questions.  Ive got so think go ahead.  So yeah have have couple of questions on the project but before that will.  wanted to talk about the exercise that you just showed.  So you seem to use bouquet plots mean.  try to do it that way but Ive found it bit challenging so dropped it halfway down and used blockly.  dont know if that is thats absolutely fine.  Its fine.  Okay.  And can relate to that.  Yeah it was.  It was pretty challenging and there was no time.  But yeah okay thats fine.  So yeah coming to the project picked the COVID19 as my project.  So was.  was analyzing the counties data and for that flip codes were already given so it was pretty easy to find the shape file and merge it with that and create to that.  That was easy.  But when was trying to merge the data sets of the Gdp and the counties and the housing units.  It was it was bit challenging to actually create new column and put those flip codes on the columns for Gdp and the housing unit.  So did did it manually so created new column and actually went back to.  downloaded the code file and actually copied it manually.  So dont know if that is that is yeah mean sometimes doing it with the school the way much more complicated than doing it.  The reason was both the excel files format was bit mean they they didnt match quite bit so had to do it manually.  So just to get the High Gdp low Gdp Counties and the corresponding deaths and the cases and yeah such.  And you can explain that in your report to saying did the the with little bit of human contribution not 100 automatic.  And thats absolutely fine.  Okay that thats the only area that just manually inputed stuff.  Actually there was one more.  So wanted to.  So the Gdp was only up till 2018.  If im not mistaken.  Yeah it was only up till 2018 so wanted to see how the like.  wanted to build time series graph so to check how the Gdp was on the 2019 2020 and did it go up Did it go down So at that point wanted to merge the new Gdp file that found and with the with the one that you gave that that was also bit challenging.  So just merge just the United States the top the top level one just to get the general consensus like the General Gdp of the the whole country as whole and for the all years.  So that was also bit of manual.  My.  just to create the one graph just to create the time series.  But that is okay right Yeah.  mean it would be good to do the analysis at the county level because you would see how the Gdp at the county level may have an impact on things related to the Yeah.  So yeah you have dont know less resources meaning less intensive care units and people will die more so just as an example.  But at the very end.  You need to deal with the data you have.  That is true.  So still want to build those graphs but im already up to think 13 or something so dont know if can build report for all the that that makes sense explain the limitations.  So the issues that that you had consider it as sort of the the same criteria that we use when we do the academic publications when you publish your paper is reviewed by Ps.  And they review it a.  And they do it sort of critique all what what is inside.  So when see something like in this case why the analysis is not done at the county level it would make more sense.  So you dont have the time you dont have the the data set.  But you need to explain that.  So you need to say okay it would be good.  know that it would be good to go at that level.  But didnt have the data set that can assist me and didnt have the time and to find another one doing it.  and thats fine.  So you are explaining the the limitations of your will do that.  So didnt do it for the 2019 2020 because just found the data set like days ago.  But for the 2018 the one which you gave.  went down deep down to the country level and from the High Gdp Countries Low Gdp Countries and how they dealt with this in that.  And same with the high housing units countries and low housing units counties and how the cases progressed over there.  So just didnt go above 2018 2019.  So yeah another way to go around mean at the county level it is.  Its unlikely that the Gdp will go to from being very low to being very high.  so you can create categories meaning you.  You can have that will not give you time series for the Gdp.  But it will give you data point in the in the analysis.  So you you can class.  The account is by categories so medium and high.  So and its likely that they will stay like that quarter the remaining year.  So that you dont have data.  Okay that thats fine.  Okay just did it for the low and high.  But yeah could ben it for the medium level.  And yeah yeah.  better story.  Yeah the last question.  So there was another file professor which was think the the total census data of the entire country based on the whole 10 years.  so you dont need to use it.  You dont need to use it.  You can use it.  This data Set the if you think that can be read around.  Oh yeah Ive found one use where just looked at the age group.  mean the total populations of these counties which the the debts were higher and looked at the population and then looked down and looked at the age group of each counties where there were more debts and whether all the people who were likely affected by that.  So thats all that could do with that data.  But if could merge merger with another one it would have been better.  But found it really challenging to.  mean the age is one of those things that we know that is highly correlated with the thats from Covid.  Yeah the Yeah yeah it.  It.  It is pretty much common sense that the older the people are more likely.  Theyre you know to be effective.  But so wanted to do regression analysis.  But couldnt get it.  Get the data sets to merge.  So thats thats where im at right now.  But yeah think that clears my doubts that that thats all have.  Yup alright great.  all right.  Other questions.  Sure.  Question.  Okay.  So that was short.  And again if you have questions from now till the deadline feel free to send me and she you be sure to include she you just to increase the the chances that you will get an answer right away.  and we will be happy to address the issues you may have or the questions you might have.  All right.  So enjoy the rest of the evening and we talk in week if not before so would be on campus tomorrow if you need me most of the time.  But would be available anyway via email.  fis STEVENS lw INSTITUTE of TECHNOLOGY Is Fi it Input Outputs Dictionaries and Tuples clipizzistevens. edu SSE at Files we Offen when you are writing code you will want To access data that is stored in file.  For example Text file . 1xt Comma Separated Values file . csv really just text Tile Too but the extension lets you know the format of the data inside You can use the open function in Python to open file for reading or writing data STEVENS INSTITUTE of TECHNOLOGY File Processing lw text file can be thought of as sequence of lines From steohen. marquarduct. ac. za Sat Jan 16 2008 ReturnPath postmastercollab. sakaiproject. org Date Sat Jan 2008 18 O500To sourcecollab. sakaiproject. orgFrom steohen. marquarduct. ac. zaSubject sakai svn commit r39772 contentbranchesDetalls httosource. sakaiproject. orgviewsvnVviewrev feV39772 httpwww.  py4inf. comcodemboxshort. txt STEVENS INSTITUTE of TECHNOLOGY Opening File lw Before we can read the contents of the file we must tell Python which file we are going to work with and what we will be doing with the file This is done with the open function open returns Tile handle variable used to perform operations on the Tile Kind of like File Open in Word Processor STEVENS INSTITUTE of TECHNOLOGY Using open lw handle opentilename mode returns handle use to manipulate the file filename is string file openmbox. txt mode Is optional and should be if we are planning reading the file and if we are going to write To the file.  httpdocs. python. orglibbuiltinfuncs. hAtml STEVENS INSTITUTE of TECHNOLOGY What is Handle ie file openmbox. txt print file open file mbox. txt mode at Ox1005088b0 Note Since file is not reserved word it can be used as the handle.  STEVENS INSTITUTE of TECHNOLOGY won Simple Example Say we have fext file like this the simple code below gives the output to the right.  test. txt The quick brown fox jumped over the lazy dog.  Goodbye filehandle opentest. txt Linecount for textline in filehandle Linecount linecount print linecount textline The quick brown fox jumped over the lazy dog.  Goodbye STEVENS INSTITUTE of TECHNOLOGY won Simple Example Say we have fext file like this the simple code below gives the output to the right.  eee test. txt The quick brown fox jumped over the lazy dog.  Goodbye filehandle opentest. txt Llinecount for textline in filehandle Linecount Linecount print linecount textline The quick brown fox jumped over the lazy dog.  Goodbye STEVENS INSTITUTE of TECHNOLOGY File Handle as Sequence file handle open for read can be treated as sequence of strings where each line in the file is string in the sequence We can use the for statement to iterate through sequence Remember sequence Is an ordered set STEVENS INSTITUTE of TECHNOLOGY Counting Lines in File iw Open file readonly Use for loop to read each line Count the lines and print out the number of ine Geunh 1aaosds lines file openmbox. txt count for line in file count count print Line Count count Output Line Count 132045 STEVENS INSTITUTE of TECHNOLOGY 10 Reading the Whole File lw We can read the whole file newlines and all into single string.  file openmboxshort. txt inp file. read print leninp 94626 print ino20 From steohen. marquar STEVENS INSTITUTE of TECHNOLOGY 11 Practical Example Say we have fext file with Tweet on each line and we want to extract all the hashtags. . .  Our file looks like this eee tweets. txt jaFlunkie we have etdragonpunch .  even more dank than trump Rand Paul Supposes He Might Support Trump As Nominee After All rssmicro httpst. coohPsEsO9Rf slushstuff Things are looking pretty bleak for him.  Would you vote at all if based Trumpsama won the primary No doubt about it Cruz is good man. Trump or Cruz.  httpst. coiDH9X1ANDs Trump voters too dangerous for kids on Election Day rssmicro httpst. coohPsEs9Rf This is what happens when you attack Trump Each candidate falls bigtime Beware Cruzhttpst. colBZBHIv01I4 hate Donald Trump he is just racist Donald Trump Says His Money Drew Hillary Clinton to His Wedding ABC News httpst. cokjxJuV7r via ABC slone Trump being rude to disabled ties with mob bribing politicians Samp more.  Sounds like NY to me.  AndrewArlink Schu64 leskomike Excellent piece in guardian by KaddieAbdul about humanizing the other even if its Trump supporters httpst. coOnb4Pho2Gy ObamaU2s Failings Are the Reasons for TrumpUs Rise by Victor Davis Hanson httpst. cosmr4e0yy16 via NRO Politics Politics analyst Mike Tyson predicts Trump vs.  Hillary for 2016 UO USA TODAY httpst. coDxsaMItZju Obamas Failings Among The Reasons For Trumps Rise rssmicro httpst. coohPsEs9Rf Behind Cruzs attack on Trumps New York values httpst. couoZyUQPINL via DCExaminer CNN jaketapper realDonaldTrump hate Iran as much as anyone but its about time Trump started to tell the truth The end of TedUs excellent adventure How New York Times bombshell and Donald Trump could finish Cruz rssmicro httpst. coohPsEsQ9Rf This Freedom Kids Trump VIDEO is making the internet GO NUTS httpst. cowq0eQWUb87 Is it just me or is that video of the three little girls from the Trump rally vibe with North Korea in style not to mention substance U. S.  Chamber chief calls Trump politically stupid httpst. coPxTGGhBz0k Clintons Real Bimbo Eruptions vs.  Trumps Alleged Sexism httpst. covDXx8GSOsr American Thinker httpst. copCKoA0g8xi 123 AnnCoulter Trump is right take it to the courts let it be decidedyou have to ask if he believes there isnt problem take this as evidence that GOP billionaires dont really care if Trump wins the nomination httpst. coa0LgkoB3u Donald Trump Campaign Now Clearly Endangering the WellBeing of Children httpst. coeXlcqcVzsD ss31704s cat1012000 LiberatedCit jensan1332 TheLastRefuge2 Funny Trump started with 1M load THEN got 20M from DADDY when he died Im going to respectfully ask trump supporters if they are troubled by white supremacists openly supporting trump and he wont denounce.  Nationaltile TylerDaDragon people are hoping is Donald trump.  Each line is Tweet election debate discussions STEVENS INSTITUTE of TECHNOLOGY 12 Practical Example This is Our code tweetfile opentweets. txtr 10 An empty list that we will save our hashtags to when we find them 11 hashtags 12 13 Loop through each tweet line of file 14 for tweet in tweetfile 15 16 The split method of string splits it into list a7 It splits at spaces by default 18 wordslist tweet. split 19 20 Loop through the words of the tweet 21 for word in wordslist 22 if word. startswith 23 hashtags.  append word 24 25 Print first 10 hashtags 26 for hashtag in hashtags10 27 print hashtag EE STEVENS INSTITUTE of TECHNOLOGY 13 Skipping with continue lw We can conveniently Skip line by using the continue statement fhand openmboxshort. txt for line in fhand line line.  rstrip Skip uninteresting lines if not line. startswithFrom continue Process our interesting line print line STEVENS INSTITUTE of TECHNOLOGY 14 Using in to select lines lu We can look for string anywhere in line as our selection criteria fhand openmboxshort. txt for line in fhand line line. rstrip if not uct. ac. za in line continue print line From steohen. marquarduct. ac. za Sat Jan 16 2008 XAuthenticationWarning set sender to steohen. marquarduct. ac. za using From steohen. marquarduct. dc. za Author steophen. marquarduct. dac. za STEVENS INSTITUTE of TECHNOLOGY 15 split The split method of string can be very useful when reading files.  It will split string into list.  It will solit at every instance of the separator you fell it to.  E. g.  In print Hello My name is Frosty.  Im Cold Who are you. split Hello My name is Frosty.  Im Cold Who are you The default separator is whitespace In print Hello My name is Frosty.  Im Cold Who are you. split Hello My name is Frosty.  Im Cold Who are you STEVENS INSTITUTE of TECHNOLOGY 16 split and CSV Files We know CSV files have data separated by commas names. csv John American JuanMexican IoannisGreek Jean French We can split at the commas to get the information we want peoplefile opennames. csvr print Nationalities for row in peoplefile print row. split Nationalities American Mexican Greek French But why the extra soaces between lines SS LULU STEVENS INSTITUTE of TECHNOLOGY 17 Newlines lw Each line in the . CSV file in all text files has an invisible newline character at the end.  In Python its written as n.  The strip method of string removes all whitespace including newlines from each end of the string.  If we add it to our code peoplefile opennames. csvr print Nationalities .  for row in peoplelife print row.  strip. split Nationalities American Mexican Greek French The print statement starts newline anyway so each output is on its own line SS LULU STEVENS INSTITUTE of TECHNOLOGY 18 Write to File we We can also use the open function with the option for writing ourfile opennewfile. txtw ec50e adios ourfile. writeThe first linen The first line ourfile. writen .  ourfile. writeThe third line Lil la ourfile. close STEVENS INSTITUTE of TECHNOLOGY 19 Some Tips Its good practice to close the file once youre done using It peoplefile opennames. csvr print Nationalities for line in peoplefile print line. strip. split peoplefile. close If youre using Mac and are opening CSV files from PCs use rU rather than just when opening for Universal Newline.  It doesnt hurt to do it always peoplefile opennames. csvrU print Nationalities for line in peoplefile print line. strip. split peoplefile. close SS LULU STEVENS INSTITUTE of TECHNOLOGY 20 Useful Links le hitpwww. pythontorbeginners. comTilesreadingandwritingfilesinpython hitpsdocs. python. org2. 7tutorialinputoutput. Atml STEVENS INSTITUTE of TECHNOLOGY 21 Dictionaries and Tuples We have already seen and used lists Remember that they are ordered collections and you can access elements using their index In alphabet abcd In print alphabet Cc Tuples and dictionaries are other collections that operate in different ways.  STEVENS INSTITUTE of TECHNOLOGY 22 46 Vb oft Lists are like collection we collection allows us to put many values in single variable In acollection we can carry all many values around IN one convenient package friends Joseph Glenn Sally carryon socks shirt oerfume STEVENS INSTITUTE of TECHNOLOGY 23 Looking Inside Lists ie Just like strings we can get at any single element in list Using an Index specified in square brackets STEVENS INSTITUTE of TECHNOLOGY 24 Lists are Mutable Strings are immutable we cannot change the contents of string we must make ad new string to make any change Lists are mutable we can change an element of list using the index operator fruit Banana fruitO Traceback. . . TypeeError. . .  fruit. lower print banana print fruit Banana lotto 14 26 41 63 print lotto 14 26 41 63 lotto2 28 print lotto 14 28 41 63 STEVENS INSTITUTE of TECHNOLOGY 25 Getting the length of List The len function takes list GS paramefter and returns the number of elements in the list Actually len tells us the number of elements of any set or sequence i. e.  such as string. . .  greet Hello Bob print lengreet x1 joe 99 print lenx STEVENS INSTITUTE of TECHNOLOGY 26 Using the range function ie The range function returns list of numbers that range from zero To one less than the parameter Wecan construct an index loop using for and an integer iterator print range friends Joseph Glenn Sally print lenfriends print range lenfriends STEVENS INSTITUTE of TECHNOLOGY 27 Built in Functions and Lists lw There are number of functions built into Python that take lists as parameters Remember the loops we built These are much simpler httpdocs. python. orglibbuiltinfuncs. hAtml af nums 41 12 74 15 print lennums print maxnums 74 print minnums print sumnums 154 print sumnumslennums 25 STEVENS INSTITUTE of TECHNOLOGY 28 Multiple splitting Sometimes we split line one way and then grab one of the pieces of the line and split that piece again From steohen. marquarduct. ac. za Sat Jan 16 2008 words ine. split email words1 pieces email. split print pieces1 STEVENS INSTITUTE of TECHNOLOGY 29 Tuples Tuples act very similarly to lists.  The two main differences are They are defined with parentheses and not square brackets.  They are immutable.  This means you cant change the elements once youve created the tuple.  mytuple print mytuple1 mytuple1 Traceback most recent call last TypeError tuple object does not support item assignment STEVENS INSTITUTE of TECHNOLOGY 30 Tuple assignment le Tuples allow to assign many variables at the same Time.  27 31 Tuple assignment allows to swap values in variables without the use of temporary variable using instead of temp abb temp SS LULU STEVENS INSTITUTE of TECHNOLOGY 31 Dictionaries Dictionaries are very different They are unordered They are made from key value pairs Each value in the dictionary has key associated with it that can be used to look up the value Curly braces and are used and the key is followed by colon and then the value populations USA318 ltaly59 Japan127 STEVENS INSTITUTE of TECHNOLOGY 32 Dictionaries You can add new key value pairs simply by assigning value to new key populations USA318 Italy59 Japan127 print populations Japan127 Italy59 USA318 PopulationsUK 64 print populations Japan127 Italy59 UK64 USA318 As with lists the dictionaries values can be any type even other dictionaries or lists The keys have to be immutable types e. g.  strings ints tuples not lists STEVENS INSTITUTE of TECHNOLOGY 33 ae at Dictionaries we You can add new key value pairs simply by assigning value to ad new key populations USA318 ltaly59 Japan127 print populations Japan127 Italy59 USA318 PopulationsUK 64 print populations Japan127 ltaly59 UK64 USA318 As with lists the dictionaries values can be any type even other dictionaries or lists The keys have to be immutable types e. g.  strings ints tuples not lists STEVENS INSTITUTE of TECHNOLOGY 34 Definite Loops and Dictionaries Even though dictionaries are not stored in order we can write for loop that goes through all the entries in dictionary actually if goes through all of the keys in the dictionary and looks Up the values counts charlie fred 42 jan 100 for key in counts print key countskey jan 100 charlie fred 42 STEVENS INSTITUTE of TECHNOLOGY 35 Retrieving lists of Keys and Values You can get list of keys values or items both from dictionary mydict charlie fred 42 jan 100 print listmydict jan charlie fred print mydict. keys jan charlie fred print mydict. values 100 42 print mydict. items jan 100 charlie fred 42 STEVENS INSTITUTE of TECHNOLOGY 36 oft Dictionary Example We will make use of the try. . .  except construction This will try some code and if an error occurs if will run the code listed under except 10 try print except print There is no variable There is no variable The code tries to print but if doesnt exist so it throws an error so it prints the other statement STEVENS INSTITUTE of TECHNOLOGY 37 .  ge cis Dictionary Example Say we have text file and we want to count how many words there are eee newsstory. txt In the minutes before an EgyptAir flight from Paris to Cairo crashed into the Mediterranean Sea killing all 66 people on board there were rapid and escalating failures in the planes flight control system according to sensor data transmitted by the aircraft to operators on the ground that was published Friday by respected aviation journal.  Ac awiatinon officiale cortead throinh the data which wac noacted nnline hv The We will Read one line at time Split each line into words Try to add to the value of that words dictionary entry If that fails create dictionary entry with value SS LULU STEVENS INSTITUTE of TECHNOLOGY 38 won Dictionary Example The code newsfile opennewsstory. txtr wordcounter for line in newsfile words line. strip. split for word in words try wordcounterword wordcounterword except wordcounterword first10 wordcounter. keys 10 for key in first10 print key wordcounter key STEVENS INSTITUTE of TECHNOLOGY 39 Counter object The same code from the previous example can be rewritten using Counter which is particular type of dictionary used for counting Tally occurrences of words ina list cnt Counter for word in red blue red green blue blue cntword cnt Counterblue red green STEVENS INSTITUTE of TECHNOLOGY 40 Counter object newsfile opennewsstory. txtr wordcounter for line in newsfile words line. strip. split for word in words try wordcounterword wordcounterword except wordcounter word first10 wordcounter. keys 10 for key in first10 print key wordcounter key newsfile opennewsstory. txtr wordcounter Counter for line in newsfile words line. strip. split for word in words wordcounterword first10 wordcounter. keys10 for key in first10 print key wordcounterkey STEVENS INSTITUTE of TECHNOLOGY 41 Useful Links we hitplearnpythonthehardway. orgbookex39. html hitpwww. tutorialsooint. compythonpythondictionary. htm hitpsen. wikibooks. orgwikiPythonProgrammingTuples hitpstackoverflow. comquestions348907 inpythonwhentousea dictionarylistorset STEVENS INSTITUTE of TECHNOLOGY 42 Learn Python The Hard Way Release 2. 0 Zed A.  Shaw June 24 2011 The Hard Way Is Easier Reading and Writing . . . . . . . . . . . . . . . . . .  Attentionto Detail . . . . . . . . . . . . . . . . 0. .  Spotting Differences . . . . . . . . . . . . . . 20. 0.  Do Not CopyPaste . . . . . . . . . . . . . . . . . . 4.  Note On Practice And Persistence . . . . . . . . . .  LICENSE same se ew Hee EE EMME Exercise The Setup MaeOSX se eeit it eee eet ct trameues Windows . .  1. . .  .  ee ee Linux 2. . .  ee Exercise Good First Program What You ShouldSee. . . . . . . . . . 0. . . . . . . .  ExtraCredit . .  2. . .  ee ee Exercise Comments And Pound Characters What You ShouldSee. . . . . . . . . . . . . . . . . .  ExtraCredit . .  2. . .  ee ee ee Exercise Numbers And Math What You ShouldSee. . . . . . . . . . . . . . . . . .  Extra Credit. . .  2. . .  2.  eee Exercise Variables And Names What.  You Should See se eestititaweues ExtraCredit . . .  ee ee CONTENTS aAnb BH WW Ww 17 Le ee 17 Le ee 17 19 Se fee Ghee ss ogame es 20 Se 20 Exercise More Variables And Printing What You Should See. . .  2. . .  2. . .  ee ee Extra Credit 2.  2. . .  ee Exercise Strings And Text What You Should See. . .  2. . .  ee Extra Credit 2.  2.  ee Exercise More Printing What You Should See. . .  2. . .  ee Extra Credit. . .  ee Exercise Printing Printing What You. Should. See.  . . 265 .  ga ow meee tc EM mH ee EE Extra Credit. . .  ee Exercise Printing Printing Printing What YouShould. See asieUeH ete caw RHE EES Extra Credit 2. . .  0.  ee Exercise 10 What Was That What YouSHGuIG. SGE.  os sis tte eee wee ERM BBR ee BetreCGredt .  5.  iw sane eS ts eh HEE MAH EE Exercise 11 Asking Questions What You Should See. . .  2. . .  ee Extra Credit sc ae me eens tb ta ERM BE BHEE EEG Exercise 12 Prompting People What You Should See. . .  2. . .  ee Extfa Grdif.  .  cca mew mit tt REHM MMB wee ee Exercise 13 Parameters Unpacking Variables Hold Up Features Have Another Name . . . . . . . . . . . . . . . . .  What You Should See 26 .  cee eee eet eee ew HE Eee Extra Credit. . .  see eae st ee eB HHEET EER BH HEE EES Exercise 14 Prompting And Passing What You Should See. . .  2. . .  ee Extfa Grdif.  .  cca mew mit tt REHM MMB wee ee Exercise 15 Reading Files What You Should See. . .  2. . .  ee Extra Credit. . .  0.  eee Exercise 16 Reading And Writing Files What You Should See. . .  2. . .  ee 23 24 24 25 26 26 27 27 28 29 29 29 31 31 32 33 34 34 35 36 36 37 34 38 Extra Credit. . .  ee Exercise 17 More Files What You Should See ese8itteeeeeenceeraewaee PRAVCTEO se as km he EE EA lm ae OE wl me Exercise 18 Names Variables Code Functions What You Should S.  .  cee uit tc RM EB HEE ERM Be Extra Credit ei3 st dM RBH EE MARES ws Exercise 19 Functions And Variables What You Should See. . .  2. . .  ee ExtraCHediE cw uees it kM MMH RRO BEEBE Exercise 20 Functions And Files What You Should See. . .  2. . .  ee ee Extra Credit. . .  ee Exercise 21 Functions Can Return Something What You Should See. . .  2. . .  ee et Extra Credit. . .  ee Exercise 22 What Do You Know So Far What Youare Learning . . . . . . . . . . . . . 2.  002002 eee eee Exercise 23 Read Some Code Exercise 24 More Practice What You Should See. . .  2. . .  2. 0. . .  ee ee ee et Extra Credit. . .  ee Exercise 25 Even More Practice What You Should See. . .  2. . .  2. . .  ee ee Extra Credit. . .  ee Exercise 26 Congratulations Take Test Exercise 27 Memorizing Logic The Truth Terms. . .  2. . .  ee The Truth Tables . .  2. . .  2. . .  ee ee Exercise 28 Boolean Practice What You Should See. . .  .  2.  ee ee Extra Credit. . .  ee Exercise 29 What If What You Should See. . .  2. . .  2. 2. . .  ee et 53 54 54 55 56 59 60 60 61 62 62 63 64 64 67 67 69 71 72 72 73 74 75 77 79 80 80 83 85 85 87 88 Extra Credit 2.  ee 88 Exercise 30 Else And If 89 What YouShouldSee sass stage MHA SE ERM Hae ECR MH Bae Te REM 90 Extrared 5s cms ee EAE EO mG Ewa mE Gk Ew wl 90 Exercise 31 Making Decisions 91 What You. SHould. S eens st ctw ee HEE ERB BDH EER BBE HEE Ew 92 Extra Credit cs cee eat CTA RBH EAR HAGE ERR BR Ae TC RRM 93 Exercise 32 Loops And Lists 95 What You Should See. . .  2. . .  ee 96 Extfa Credit.  .  sce eee HE EE EME ERR MEH EEE EH HHS HEE EE aE 97 Exercise 33 While Loops 99 What You Should See. . .  2. . .  ee 100 BXifa Cred.  sc cee mewte MRAP Ee Re em ee ee 100 Exercise 34 Accessing Elements Of Lists 103 Extra Credit. . .  2.  ee eee 104 Exercise 35 Branches and Functions 105 What You.  Should. See. . . 65 tases kw EA ee sd Ee ae 107 Extra Credit. . .  2.  ee 107 Exercise 36 Designing and Debugging 109 RulesFor liStatements asi sia HHS TRAM HHT ERR BR Ae eC RRM 109 Rules For Loops. . .  2. . .  2.  ee 110 Tips For Debugging . . .  2. . .  2. . .  eee 110 Homework. . .  2. 2. . .  ee 110 Exercise 37 Symbol Review 111 Keywords . .  2. . .  ee 111 Data Types 2. . .  eee 112 Stting Escapes Sequences. . .  .  2s cee eee ett eee we ee ewe ee ew eS 113 String Formats see aguas te Ce RM HES TERR HEE ERE MRE RR 113 Operators 2. 2. . .  ee 114 Exercise 38 Reading Code 117 Extfa Credit.  .  sce eee HE EE EME ERR MEH EEE EH HHS HEE EE aE 117 Exercise 39 Doing Things To Lists 119 What You Should See. . .  2. . .  ee 121 EXifa Gredi .  cs cee meet EMRE APE eRe em ee we 121 Exercise 40 Dictionaries Oh Lovely Dictionaries 123 What You Should See. . .  2. . .  ee 125 ExtraCredit .  2. . .  ee 125 Exercise 41 Gothons From Planet Percal 25 127 What You Should See sss e823 eee HH EEE ERT HERE EE RHR Ee ae 132 Extpasremit eae cc em EEE EMM EEG EA eG Em we GG 134 Exercise 42 Gothons Are Getting Classy 135 What You Shoild See. . .  esee8uiitt eee MERE RR RR HB ee 140 Extra Credit 22. 22 se 888Gb EERE EHH REE RB RR EG ae 140 Exercise 43 You Make Game 143 Exercise 44 Evaluating Your Game 145 POMEHOMSOVIE.  cc oi me SEEM EEO ae EE ee eS 145 Class Style.  2. . .  ee 146 Code Style. . .  2.  ee 146 Good Comments . . .  2. . .  .  ce ee 147 Evaluate YourGame .  . e2 888322 ade OH CHEM HEE ERM RMBES TS 147 Exercise 45 IsA HasA Objects and Classes 149 How This Looks InCode . .  2. . .  0.  2.  ee 150 Exercise 46 Project Skeleton 153 Skeleton Contents LinuxOSX . .  0. . .  0.  ee 153 Testing YourSetup . . . .  2. . .  2. 2. . .  2. 2. 2 ee ee 155 Usme The Skel6toh .  .  cum eee ce eww Ee eR we ee we ee 155 Required QUIZ e222 se eR BHE SEER BMH EET EMH HEE EMM BAe se 156 Exercise 47 Automated Testing 157 Writing Test Case.  2. . .  eee 157 Testine GuidGlNES . .  stew ewe HH EEE ESHER EHH EES 159 What You Should See.  .  cc ma ee tm Ee EEA md Em ee 159 Extra Credit .  2. . .  ee 159 Exercise 48 Advanced User Input 161 OurGame Lexicon see e8e3 ib eee RHEE ERT HH REE RH BREE ae 161 What You Should Test 2. 2. . .  .  ee 163 Design Hints 2. . .  2. . .  ee 165 Extra Credit 2. . .  eee 165 Exercise 49 Making Sentences 167 Match And Peek. . .  2. . .  ee 167 The Sentence Grammar. . .  1.  ee 168 WordOn EXceptionS .  see eet ce ieee ee ER ww eee mw ee 170 What. You Should Test .  2. 225883 22 taOHs bce HHH Ee ERM RMBES TS 170 Extra Credit .  2. . .  ee 171 Exercise 50 Your First Website Fixing Errors. . .  ee ee Create Basic Templates. . .  2. . .  ee Extra Credit. . .  2.  ee Exercise 51 Getting Input From Browser How The Web Works . .  2. . .  2. . .  ee How Forms Work . .  2. . .  ee Creatine HTML Fotms 222.  seem eee ee we ee wee ew Creating Layout Template 2. 2 cae eee ee ewe HEE HH BREE eee HS Writing Automated Tests For Forms . . . . . . . . . . . . . 2.  0. 000222 eee ee eee ExtraCredit .  2. . .  Exercise 52 The Start Of Your Web Game Refactoring The Exercise 42 Game. . .  0.  be me ee Sessions And Tracking Users. . .  2. . .  ee ee Creating AnEngine. . . .  2. . .  ee ee Your FinalLbxam 2c eee ct eRe we ee wee ewe Next Steps Advice From An Old Programmer 173 173 174 175 175 176 178 179 179 181 182 184 185 188 189 189 194 195 198 199 201 vi Learn Python The Hard Way Release 2. 0 Welcome to the 2nd Edition of Learn Python the hard way.  You can visit the companion site to the book at httplearnpythonthehardway. org where you can purchase digital downloads and paper versions of the book.  The free HTML version of the book is available at httplearnpythonthehardway. orgbook.  CONTENTS Learn Python The Hard Way Release 2. 0 CONTENTS The Hard Way Is Easier This simple book is meant to get you started in programming.  The title says its the hard way to learn to write code but its actually not.  Its only the hard way because its the way people used to teach things.  With the help of this book you will do the incredibly simple things that all programmers need to do to learn language 1.  Go through each exercise.  2.  Type in each sample exactly.  3.  Make it run.  Thats it.  This will be very difficult at first but stick with it.  If you go through this book and do each exercise for one or two hours night you will have good foundation for moving onto another book.  You might not really learn programming from this book but you will learn the foundation skills you need to start learning the language.  This books job is to teach you the three most essential skills that beginning programmer needs to know Reading and Writing Attention to Detail Spotting Differences.  Reading and Writing It seems stupidly obvious but if you have problem typing you will have problem learning to code.  Especially if you have problem typing the fairly odd characters in source code.  Without this simple skill you will be unable to learn even the most basic things about how software works.  Typing the code samples and getting them to run will help you learn the names of the symbols get familiar with typing them and get you reading the language.  Attention to Detail The one skill that separates bad programmers from good programmers is attention to detail.  In fact its what separates the good from the bad in any profession.  Without paying attention to the tiniest details of Learn Python The Hard Way Release 2. 0 your work you will miss key elements of what you create.  In programming this is how you end up with bugs and difficulttouse systems.  By going through this book and copying each example exactly you will be training your brain to focus on the details of what you are doing as you are doing it.  Spotting Differences very important skill that most programmers develop over time is the ability to visually notice differences between things.  An experienced programmer can take two pieces of code that are slightly different and immediately start pointing out the differences.  Programmers have invented tools to make this even easier but we wont be using any of these.  You first have to train your brain the hard way then you can use the tools.  While you do these exercises typing each one in you will be making mistakes.  Its inevitable even seasoned programmers would make few.  Your job is to compare what you have written to whats required and fix all the differences.  By doing so you will train yourself to notice mistakes bugs and other problems.  Do Not CopyPaste You must type each of these exercises in manually.  If you copy and paste you might as well just not even do them.  The point of these exercises is to train your hands your brain and your mind in how to read write and see code.  If you copypaste you are cheating yourself out of the effectiveness of the lessons.  Note On Practice And Persistence While you are studying programming Im studying how to play guitar.  practice it every day for at least hours day.  play scales chords and arpeggios for an hour at least and then learn music theory ear training songs and anything else can.  Some days study guitar and music for hours because feel like it and its fun.  To me repetitive practice is natural and just how to learn something.  know that to get good at anything you have to practice every day even if suck that day which is often or its difficult.  Keep trying and eventually itll be easier and fun.  As you study this book and continue with programming remember that anything worth doing is difficult at first.  Maybe you are the kind of person who is afraid of failure so you give up at the first sign of difficulty.  Maybe you never learned selfdiscipline so you cant do anything thats boring.  Maybe you were told that you are gifted so you never attempt anything that might make you seem stupid or not prodigy.  Maybe you are competitive and unfairly compare yourself to someone like me whos been programming for 20 years.  The Hard Way Is Easier Learn Python The Hard Way Release 2. 0 Whatever your reason for wanting to quit keep at it.  Force yourself.  If you run into an Extra Credit you cant do or lesson you just do not understand then skip it and come back to it later.  Just keep going because with programming theres this very odd thing that happens.  At first you will not understand anything.  Itll be weird just like with learning any human language.  You will struggle with words and not know what symbols are what and itll all be very confusing.  Then one day BANG your brain will snap and you will suddenly get it.  If you keep doing the exercises and keep trying to understand them you will get it.  You might not be master coder but you will at least understand how programming works.  If you give up you wont ever reach this point.  You will hit the first confusing thing which is everything at first and then stop.  If you keep trying keep typing it in trying to understand it and reading about it you will eventually get it.  But if you go through this whole book and you still do not understand how to code at least you gave it shot.  You can say you tried your best and little more and it didnt work out but at least you tried.  You can be proud of that.  License This book is Copyright 2010 by Zed A.  Shaw.  You are free to distribute this book to anyone you want so long as you do not charge anything for it and it is not altered.  You must give away the book in its entirety or not at all.  This means its alright for you to teach class using the book so long as you arent charging students for the book and you give them the whole book unmodified.  Special Thanks Id like to thank few people who helped with this edition of the book.  First is my editor at Pretty Girl Editing Services who help me edit the book and is just lovely all by herself.  Then theres Greg Newman who did the cover jacket and artwork plus reviewed copies of the book.  His artwork made the book look like real book and didnt mind that totally forgot to give him credit in the first edition.  Id also like to thank Brian Shumate for doing the website landing page and other site design help which need lot of help on.  Finally Id like to thank the hundreds of thousands of people who read the first edition and especially the ones who submitted bug reports and comments to improve the book.  It really made this edition solid and couldnt have done it without all of you.  Thank you.  License Learn Python The Hard Way Release 2. 0 The Hard Way Is Easier Exercise The Setup This exercise has no code.  It is simply the exercise you complete to get your computer setup to run Python.  You should follow these instructions as exactly as possible.  For example Mac OSX computers already have Python so do not install Python or any Python.  Mac OSX To complete this exercise complete the following tasks 1.  2.  NH nn ff Go to httplearnpythonthehardway. orgexerciseO. html with your browser get the gedit text ed itor and install it.  Put gedit your editor in your Dock so you can reach it easily.  Run gedit so we can fix some stupid defaults it has.  Open Preferences from the gedit menu and select the Editor tab.  Change Tab width to4.  Select make sure check mark isin Insert spaces instead of tabs.  Turn on Automatic indentation as well.  Open the View tab and turn on Display line numbers.  .  Find your Terminal program.  Search for it.  You will find it.  .  Put your Terminal in your Dock as well.  .  Run your Terminal program.  It wont look like much.  .  In your Terminal program run python.  You run things in Terminal by just typing their name and hitting RETURN.  .  Hit CTRLD 4D and get out of python.  .  You should be back at prompt similar to what you had before you typed python.  If not find out why.  Learn Python The Hard Way Release 2. 0 9.  Learn how to make directory in the Terminal.  Search online for help.  10.  Learn how to change into directory in the Terminal.  Again search online.  11.  Use your editor to create file in this directory.  You will make the file Save or Save As. . .  and pick this directory.  12.  Go back to Terminal using just the keyboard to switch windows.  Look it up if you cant figure it out.  13.  Back in Terminal see if you can list the directory to see your newly created file.  Search online for how to list directory.  Note If you have problems with gedit which is possible with nonEnglish keyboard layouts then suggest you try Textwrangler found at httpwww. barebones. comproductstextwrangler instead.  OSX What You Should See Heres me doing the above on my computer in Terminal.  Your computer would be different so see if you can figure out all the differences between what did and what you should do.  Last login Sat Apr 24 54 on ttys001 python Python 2. 5. 1 r2863 Feb 2009 12 GCC 4. 0. 1 Apple Inc.  build 5465 on darwin Type help copyright credits or license for more information.  mkdir mystuff cd mystuff mystuff ls . . .  Use Gedit here to edit test. txt. . . .  mystuff ls bests Cxt mystuff Windows Note Contributed by zhmark.  1.  Go to httplearnpythonthehardway. orgwikiExerciseZero with your browser get the gedit text editor and install it.  You do not need to be administrator to do this.  2.  Make sure you can get to gedit easily by putting it on your desktop andor in Quick Launch.  Both options are available during setup.  Exercise The Setup Learn Python The Hard Way Release 2. 0 NH nn fS 12.  13.  Run gedit so we can fix some stupid defaults it has.  Open EditPreferences select the Editor tab.  Change Tab width to4.  Select make sure check mark isin Insert spaces instead of tabs.  Turn on Automatic indentation as well.  Open the View tab turn on Display line numbers.  .  Find your Terminal program.  Its called Command Prompt.  Alternatively just run cmd.  .  Make shortcut to it on your desktop andor Quick Launch for your convenience.  .  Run your Terminal program.  It wont look like much.  .  In your Terminal program run python.  You run things in Terminal by just typing their name and hitting RETURN.  If yourun python andits not therepython is not recognized.  . .  Install it from httppython. orgdownload Make sure you install Python not Python 3.  You may be better off with ActiveState Python especially when you miss Administrative rights .  Hit CTRLZ 4Z Enter and get out of python.  .  You should be back at prompt similar to what you had before you typed python.  If not find out why.  .  Learn how to make directory in the Terminal.  Search online for help.  10.  11.  Learn how to change into directory in the Terminal.  Again search online.  Use your editor to create file in this directory.  Make the file Save or Save As. . .  and pick this directory.  Go back to Terminal using just the keyboard to switch windows.  Look it up if you cant figure it out.  Back in Terminal see if you can list the directory to see your newly created file.  Search online for how to list directory.  Warning Windows is big problem for Python.  Sometimes you install Python and one com puter will have no problems and another computer will be missing important features.  If you have problems please visit httpdocs. python. orgfaqwindows. html Windows Learn Python The Hard Way Release 2. 0 Windows What You Should See CDocuments and Settingsyoupython ActivePython 2. 6. 5. 12 ActiveState Software Inc.  based on Python 2. 6. 5 r2063 Mar 20 2010 52 MSC v. 1500 32 bit Intel on win32 Type help copyright credits or license for more information.  Soe CDocuments and Settingsyoumkdir mystuff CDocuments and Settingsyoucd mystuff Here you would use gedit to make test. txt in mystuff CDocuments and Settingsyoumystuff bunch of unimportant errors if you istalled it as nonadmin ignore them hit Enter CDocuments and Settingsyoumystuffdir Volume in drive is Volume Serial Number is 085C7E02 Directory of CDocuments and Settingsyoumystuff 04. 05. 2010 DIR 04. 05. 2010 DIR 04. 05. 2010 test. txt Files bytes Dirs 14 804 623 360 bytes free CDocuments and Settingsyoumystuff You will probably see very different prompt Python information and other stuff but this is the general idea.  If your system is different let us know at httplearnpythonthehardway. org and we Il fix it.  Linux Linux is varied operating system with bunch of different ways to install software.  Im assuming if you are running Linux then you know how to install packages so here are your instructions 1.  Go to httplearnpythonthehardway. orgwikiExerciseZero with your browser get the gedit text editor and install it.  2.  Make sure you can get to gedit easily by putting it in your window managers menu.  Run gedit so we can fix some stupid defaults it has.  Open Preferences select the Editor tab.  10 Exercise The Setup Learn Python The Hard Way Release 2. 0 Change Tab width to4.  Select make sure check mark isin Insert spaces instead of tabs.  Turn on Automatic indentation as well.  Open the View tab turn on Display line numbers.  .  Find your Terminal program.  It could be called GNOME Terminal Konsole or xterm.  .  Put your Terminal in your Dock as well.  .  Run your Terminal program.  It wont look like much.  nH On HR .  In your Terminal program run python.  You run things in Terminal by just typing their name and hitting RETURN.  If you run python and its not there install it.  Make sure you install Python not Python 3.  7.  Hit CTRLD and get out of python.  8.  You should be back at prompt similar to what you had before you typed python.  If not find out why.  9.  Learn how to make directory in the Terminal.  Search online for help.  10.  Learn how to change into directory in the Terminal.  Again search online.  11.  Use your editor to create file in this directory.  Typically you will make the file Save or Save As. .  and pick this directory.  12.  Go back to Terminal using just the keyboard to switch windows.  Look it up if you cant figure it out.  13.  Back in Terminal see if you can list the directory to see your newly created file.  Search online for how to list directory.  Linux What You Should See python Python 2. 6. 5 r2063 Apr 2010 39 GCC 4. 4. 3 20100316 prerelease on linux2 Type help copyright credits or license for more information.  mkdir mystuff cd mystuff . . .  Use gedit here to edit test. txt . . .  is test . 0xC You will probably see very different prompt Python information and other stuff but this is the general idea.  Linux 11 Learn Python The Hard Way Release 2. 0 Warnings For Beginners You are done with this exercise.  This exercise might be hard for you depending on your familiarity with your computer.  If it is difficult take the time to read and study and get through it because until you can do these very basic things you will find it difficult to get much programming done.  If programmer tells you to use vim or emacs tell them No.  These editors are for when you are better programmer.  All you need right now is an editor that lets you put text into file.  We will use gedit because it is simple and the same on all computers.  Professional programmers use gedit so its good enough for you starting out.  programmer may try to get you to install Python and learn that.  You should tell them When all of the python code on your computer is Python then Ill try to learn it.  That should keep them busy for about 10 years.  programmer will eventually tell you to use Mac OSX or Linux.  If the programmer likes fonts and typography theyll tell you to get Mac OSX computer.  If they like control and have huge beard theyll tell you to install Linux.  Again use whatever computer you have right now that works.  All you need is gedit Terminal and python.  Finally the purpose of this setup is so you can do three things very reliably while you work on the exercises 1.  Write exercises using gedit.  2.  Run the exercises you wrote.  3.  Fix them when they are broken.  4.  Repeat.  Anything else will only confuse you so stick to the plan.  12 Exercise The Setup YA QA WwW Fw HY Exercise Good First Program Remember you should have spent good amount of time in Exercise learning how to install text editor run the text editor run the Terminal and work with both of them.  If you havent done that then do not go on.  You will not have good time.  This is the only time Ill start an exercise with warning that you should not skip or get ahead of yourself.  print Hello World print Hello Again print Jake typing this Print This is fun.  print Sey Printing print Id much rather you not.  print said do not touch this.  Type the above into single file named ex1.  py.  This is important as python works best with files ending in . py.  Warning Do not type the numbers on the far left of these lines.  Those are called line numbers and they are used by programmers to talk about what part of program is wrong.  Python will tell you errors related to these line numbers but you do not type them in.  Then in Terminal run the file by typing python exl. py If you did it right then you should see the same output have below.  If not you have done something wrong.  No the computer is not wrong.  What You Should See python exl. py Hello World Hello Again like typing this.  13 Ww Fk Bw NY Learn Python The Hard Way Release 2. 0 This is fun.  Yay Printing.  Id much rather you not.  said do not touch this.  You may see the name of your directory before the which is fine but if your output is not exactly the same find out why and fix it.  If you have an error it will look like this python exexl. py File exexl. py line print like typing this.  SyntaxError EOL while scanning string literal Its important that you can read these since you will be making many of these mistakes.  Even make many of these mistakes.  Lets look at this linebyline.  1.  Here we ran our command in the terminal to run the ex1.  py script.  2.  Python then tells us that the file ex1. py has an error on line 3.  3.  It then prints this line for us.  .  Then it puts caret character to point at where the problem is.  Notice the missing double quote character 5.  Finally it prints out SyntaxError and tells us something about what might be the error.  Usually these are very cryptic but if you copy that text into search engine you will find someone else whos had that error and you can probably figure out how to fix it.  Extra Credit You will also have Extra Credit.  The Extra Credit contains things you should try to do.  If you cant skip it and come back later.  For this exercise try these things 1.  Make your script print another line.  2.  Make your script print only one of the lines.  3.  Put octothorpe character at the beginning of line.  What did it do Try to find out what this character does.  From now on wont explain how each exercise works unless an exercise is different.  14 Exercise Good First Program Learn Python The Hard Way Release 2. 0 Note An octothorpe is also called pound hash mesh or any number of names.  Pick the one that makes you chill out.  Extra Credit 15 Learn Python The Hard Way Release 2. 0 16 Exercise Good First Program Exercise Comments And Pound Characters Comments are very important in your programs.  They are used to tell you what something does in English and they also are used to disable parts of your program if you need to remove them temporarily.  Heres how you use comments in Python comment this is so you can read your program later.  Anything after the is ignored by python.  print could have code like this.  and the comment after is ignored You can also use comment to disable or comment out piece of code print This wont run.  print This Wii 2iti What You Should See python ex2. py could have code like this.  This will run.  Extra Credit 1.  Find out if you were right about what the character does and make sure you know what its called octothorpe or pound character.  2.  Take your ex2 .  py file and review each line going backwards.  Start at the last line and check each word in reverse against what you should have typed.  17 Learn Python The Hard Way Release 2. 0 3.  Did you find more mistakes Fix them.  4.  Read what you typed above out loud including saying each character by its name.  Did you find more mistakes Fix them.  18 Exercise Comments And Pound Characters Exercise Numbers And Math Every programming language has some kind of way of doing numbers and math.  Do not worry program mers lie frequently about being math geniuses when they really arent.  If they were math geniuses they would be doing math not writing ads and social network games to steal peoples money.  This exercise has lots of math symbols.  Lets name them right away so you know what they are called.  As you type this one in say the names.  When saying them feels boring you can stop saying them.  Here are the names plus minus slash asterisk percent lessthan greaterthan lessthanequal greaterthanequal Notice how the operations are missing After you type in the code for this exercise go back and figure out what each of these does and complete the table.  For example does addition.  print will now count my chickens print Hens 25 30 print Roosters 100 2534 print Now will count the eggs print 3421542146 print Is it true that 72 19 20 21 22 23 Learn Python The Hard Way Release 2. 0 print 342 52 prant What ts 34 27 print Wheat is 72 57 print Oh thats why its False.  print How about some more.  print Is it greater print Is it greater or equal print Is it less or equal What You Should See python ex3. py will now count my chickens Hens 30 Roosters 97 Now will count the eggs Is it true that False What is What is Oh thats why its False.  How about some more.  Is it greater True Is it greater or equal True Is it less or equal False Extra Credit 1.  Above each line use the to write comment to yourself explaining what the line does.  2.  Remember in Exercise when you started python Start python this way again and using the above characters and what you know use python as calculator.  3.  Find something you need to calculate and write new .  py file that does it.  4.  Notice the math seems wrong There are no fractions only whole numbers.  Find out why by researching what floating point number is.  5.  Rewrite ex3. py to use floating point numbers so its more accurate hint 20. 0 is floating point.  20 Exercise Numbers And Math Exercise Variables And Names Now you can print things with print and you can do math.  The next step is to learn about variables.  In programming variable is nothing more than name for something so you can use the name rather than the something as you code.  Programmers use these variable names to make their code read more like English and because they have lousy memories.  If they didnt use good names for things in their software theyd get lost when they tried to read their code again.  If you get stuck with this exercise remember the tricks you have been taught so far of finding differences and focusing on details 1.  Write comment above each line explaining to yourself what it does in English.  2.  Read your .  py file backwards.  3.  Read your .  py file out loud saying even the characters.  cars 100 spaceinacar 4. 0 drivers 30 passengers 90 carsnotdriven cars drivers carsdriven drivers carpoolcapacity carsdriven spaceinacar averagepassengerspercar passengers carsdriven print There are cars cars available.  print There are only drivers drivers available.  print There will be carsnotdriven empty cars today.  print We can transport carpoolcapacity people today.  print We have passengers to carpool today.  print We need to put about averagepassengerspercar in each car.  Note The in spaceinacar is called an underscore character.  Find out how to type it if you do not already know.  We use this character lot to put an imaginary space between words in variable names.  21 Learn Python The Hard Way Release 2. 0 What You Should See python ex4. py There are 100 cars available.  There are only 30 drivers available.  There will be 70 empty cars today.  We can transport 120. 0 people today.  We have 90 to carpool today.  We need to put about in each car.  Extra Credit When wrote this program the first time had mistake and python told me about it like this Traceback most recent call last File ex4. py line in module averagepassengerspercar carpoolcapacity passenger NameError name carpoolcapacity is not defined Explain this error in your own words.  Make sure you use line numbers and explain why.  Heres more extra credit 1.  Explain why the 4. 0 is used instead of just 4.  .  Remember that 4. 0 is floating point number.  Find out what that means.  .  Write comments above each of the variable assignments.  .  Remember is an underscore character.  4.  Make sure you know what is called equals and that its making names for things.  .  Try running python as calculator like you did before and use variable names to do your calcu lations.  Popular variable names are also and 3.  22 Exercise Variables And Names Exercise More Variables And Printing Now well do even more typing of variables and printing them out.  This time well use something called format string.  Every time you put doublequotes around piece of text you have been making string.  string is how you make something that your program might give to human.  You print them save them to files send them to web servers all sorts of things.  Strings are really handy so in this exercise you will learn how to make strings that have variables embed ded in them.  You embed variables inside string by using specialized format sequences and then putting the variables at the end with special syntax that tells Python Hey this is format string put these variables in there.  As usual just type this in even if you do not understand it and make it exactly the same.  myname Zed A.  Shaw myage 35 not lie myheight 74 inches myweight 180 lbs myeyes Blue myteeth White myhair Brown print Lets talk about s.  myname print Hes inches tall.  myheight print Hes pounds heavy.  myweight print Actually thats not too heavy.  print Hes got eyes and hair.  myeyes myhair print His teeth are usually depending on the coffee.  myteeth this line is tricky try to get it exactly right print If add and get d.  myage myheight myweight myage myheight myweight 23 Learn Python The Hard Way Release 2. 0 What You Should See python ex5. py Lets talk about Zed A.  Shaw.  Hes 74 inches tall.  Hes 180 pounds heavy.  Actually thats not too heavy.  Hes got Blue eyes and Brown hair.  His teeth are usually White depending on the coffee.  If add 35 74 and 180 get 289.  Extra Credit 1.  Change all the variables so there isnt the my in front.  Make sure you change the name every where not just where you used to set them.  2.  Try more format characters.  Sr is very useful one.  Its like saying print this no matter what.  3.  Search online for all of the Python format characters.  4.  Try to write some variables that convert the inches and pounds to centimeters and kilos.  Do not just type in the measurements.  Work out the math in Python.  24 Exercise More Variables And Printing Exercise Strings And Text While you have already been writing strings you still do not know what they do.  In this exercise we create bunch of variables with complex strings so you can see what they are for.  First an explanation of strings.  string is usually bit of text you want to display to someone or export out of the program you are writing.  Python knows you want something to be string when you put either doublequotes or singlequotes around the text.  You saw this many times with your use of print when you put the text you want to go to the string inside or after the print.  Then Python prints it.  Strings may contain the format characters you have discovered so far.  You simply put the formatted variables in the string and then percent character followed by the variable.  The only catch is that if you want multiple formats in your string to print multiple variables you need to put them inside parenthesis separated by commas.  Its as if you were telling me to buy you list of items from the store and you said want milk eggs bread and soup.  Only as programmer we say milk eggs bread soup.  We will now type in whole bunch of strings variables formats and print them.  You will also practice using short abbreviated variable names.  Programmers love saving themselves time at your expense by using annoying cryptic variable names so lets get you started being able to read and write them early on.  There are types of people.  10 binary binary donot dont Those who know and those who s.  binary donot print print print said 4r.  xX print also said ss.  hilarious False jokeevaluation Isnt that joke so funny Sr print jokeevaluation hilarious 25 Learn Python The Hard Way Release 2. 0 THiS 18 the Jefe Side of. . .  string with right side.  print wte What You Should See python ex6. py There are 10 types of people.  Those who know binary and those who dont.  said There are 10 types of people. .  also said Those who know binary and those who dont. .  Isnt that joke so funny False This is the left side of. . . a string with right side.  Extra Credit 1.  Go through this program and write comment above each line explaining it.  2.  Find all the places where string is put inside string.  There are four places.  3.  Are you sure theres only four places How do you know Maybe like lying.  4.  Explain why adding the two string and with makes longer string.  26 Exercise Strings And Text Exercise More Printing Now we are going to do bunch of exercises where you just type code in and make it run.  wont be explaining much since it is just more of the same.  The purpose is to build up your chops.  See you in few exercises and do not skip Do not paste print Mary had little lamb.  print Its fleece was white as s.  print And everywhere that Mary went.  print .  endl end2 end3 end4 end5 end6 end7 end8g endg9 watch that comma at the end.  nd2 end3 end4 Won Won Won BU wy rr 10 mg Won wr whatd that do nd5 snow try removing it to see what happens end6 print endl print end7 end8 end9 end10 endll endl2 What You Should See python Mary had little lamb.  Its fleece was white as snow.  And everywhere that Mary went.  27 Learn Python The Hard Way Release 2. 0 Cheese Burger Extra Credit For these next few exercises you will have the exact same extra credit.  1.  Go back through and write comment on what each line does.  2.  Read each one backwards or out loud to find your errors.  3.  From now on when you make mistakes write down on piece of paper what kind of mistake you made.  4.  When you go to the next exercise look at the last mistakes you made and try not to make them in this new one.  5.  Remember that everyone makes mistakes.  Programmers are like magicians who like everyone to think they are perfect and never wrong but its all an act.  They make mistakes all the time.  28 Exercise More Printing Exercise Printing Printing formatter Sr Sr Sr Sr print formatter print formatter one two three four print formatter True False False True print formatter formatter formatter formatter formatter print formatter WE Hed Lats tiie .  That you could type up right.  But dt didnt sing.  So said goodnight.  What You Should See python ex8. py 1234 one two three four True False False True Sr Sr Sr br Sr Sr br Sr Sr br Sr Sr Br Br Sr had this thing.  That you could type up right.  But it didnt sing.  Extra Credit So said goodnight.  1.  Do your checks of your work write down your mistakes try not to make them on the next exercise.  2.  Notice that the last line of output uses both single and double quotes for individual pieces.  Why do you think that is 29 Learn Python The Hard Way Release 2. 0 30 Exercise Printing Printing Exercise Printing Printing Printing Heres some new strange stuff remember type it exactly.  days Mon Tue Wed Thu Fri Sat Sun months JannFebnMarnAprnMaynJunnJulnAug print Here are the days days print Here are the months months print wow Theres something going on here.  With the three doublequotes.  Well be able to type as much as we like.  Even lines if we want or or 6.  wee What You Should See python ex9. py Here are the days Mon Tue Wed Thu Fri Sat Sun Here are the months Jan Feb Mar Apr May Jun Jul Aug Theres something going on here.  With the three doublequotes.  Well be able to type as much as we like.  Even lines if we want or or 6.  31 Learn Python The Hard Way Release 2. 0 Extra Credit 1.  Do your checks of your work write down your mistakes try not to make them on the next exercise.  32 Exercise Printing Printing Printing Exercise 10 What Was That In Exercise threw you some new stuff just to keep you on your toes.  showed you two ways to make string that goes across multiple lines.  In the first way put the characters backslash between the names of the months.  What these two characters do is putanew line character into the string at that point.  This use of the backslash character is way we can put difficulttotype characters into string.  There are plenty of these escape sequences available for different characters you might want to put in but theres special one the double backslash which is just two of them .  These two characters will print just one backslash.  Well try few of these sequences so you can see what mean.  Another important escape sequence is to escape singlequote or doublequote .  Imagine you have string that uses doublequotes and you want to put doublequote in for the output.  If you do this understand joe.  then Python will get confused since it will think the around understand actually ends the string.  You need way to tell Python that the inside the string isnt real doublequote.  To solve this problem you escape doublequotes and singlequotes so Python knows to include in the string.  Heres an example am 62 tall.  escape doublequote inside string am 62 tall.  escape singlequote inside string The second way is by using triplequotes which is just and works like string but you also can put as many lines of text you as want until you type again.  Well also play with these.  tabbycat tIm tabbed in.  persiancat Im splitnon line.  backslashcat Im cat.  fatcat ww dea disty Cat food Fishies Catnipnt Grass mew 33 Learn Python The Hard Way Release 2. 0 print tabbycat print persiancat print backslashcat print fatcat What You Should See Look for the tab characters that you made.  In this exercise the spacing is important to get right.  python exl10. py Im tabbed in.  Im split on line.  Im cat.  iii do lists Cat food Fishies Catnip Grass Extra Credit 1.  Search online to see what other escape sequences are available.  .  Use triplesinglequote instead.  Can you see why you might use that instead of .  Combine escape sequences and format strings to create more complex format.  wYW NY Remember the format Combine with doublequote and singlequote escapes and print them out.  Compare with s.  Notice how prints it the way youd write it in your file but prints it the way youd like to see it 34 Exercise 10 What Was That Exercise 11 Asking Questions Now it is time to pick up the pace.  have got you doing lot of printing so that you get used to typing simple things but those simple things are fairly boring.  What we want to do now is get data into your programs.  This is little tricky because you have learn to do two things that may not make sense right away but trust me and do it anyway.  It will make sense in few exercises.  Most of what software does is the following 1.  Take some kind of input from person.  2.  Change it.  3.  Print out something to show how it changed.  So far you have only been printing but you havent been able to get any input from person or change it.  You may not even know what input means so rather than talk about it lets have you do some and see if you get it.  Next exercise well do more to explain it.  print How old are you age rawinput print How tall are you height rawinput print How much do you weigh weight rawinput print So youre old tall and heavy.  age height weight Note Notice that we put comma at the end of each print line.  This is so that print doesnt end the line with newline and go to the next line.  35 Learn Python The Hard Way Release 2. 0 What You Should See python exll. py How old are you 35 How tall are you 62 How much do you weigh 1801bs So youre 35 old 62 tall and 180lbs heavy.  Extra Credit 1.  Go online and find out what Pythons rawinput does.  .  Can you find other ways to use it Try some of the samples you find.  .  Write another form like this to ask some other questions.  KR WwW WN .  Related to escape sequences try to find out why the last line has with that sequence.  See how the singlequote needs to be escaped because otherwise it would end the string 36 Exercise 11 Asking Questions Exercise 12 Prompting People When you typed rawinput you were typing the and characters which are parenthesis.  This is similar to when you used them to do format with extra variables asinSs Ss y.  For rawinput you can also put in prompt to show to person so they know what to type.  Put string that you want for the prompt inside the so that it looks like this rawinput Name This prompts the user with Name and puts the result into the variable y.  This is how you ask someone question and get their answer.  This means we can completely rewrite our previous exercise using just rawinput to do all the prompt ing.  age rawinput How old are you height rawinput How tall are you weight rawinput How much do you weigh print So youre old tall and heavy.  age height weight What You Should See python exl2. py How old are you 35 How many tall are you 62 How much do you weight 180l1bs So youre 35 old 62 tall and 180lbs heavy.  37 Learn Python The Hard Way Release 2. 0 Extra Credit 1.  In Terminal where you normally run python to run your scripts type pydoc rawinput.  Read what it says.  2.  Get out of pydoc by typing to quit.  3.  Go look online for what the pydoc command does.  4.  Use pydoc to also read about open file os and sys.  Its alright if you do not understand those just read through and take notes about interesting things.  38 Exercise 12 Prompting People oe Exercise 13 Parameters Unpacking Variables In this exercise we will cover one more input method you can use to pass variables to script script being another name for your . py files.  You know how you type python ex13. py to run the ex13. py file Well the ex13. py part of the command is called an argument.  What well do now is write script that also accepts arguments.  Type this program and Ill explain it in detail from sys import argv script first second third argv print The seript is calleds script print Your first variable is Eirst print Your second variable is second print Your Third variable 18 third On line we have whats called an import.  This is how you add features to your script from the Python feature set.  Rather than give you all the features at once Python asks you to say what you plan to use.  This keeps your programs small but it also acts as documentation for other programmers who read your code later.  The argv is the argument variable very standard name in programming.  that you will find used in many other languages.  This variable holds the arguments you pass to your Python script when you run it.  In the exercises you will get to play with this more and see what happens.  Line unpacks argv so that rather than holding all the arguments it gets assigned to four variables you can work with script first second and third.  This may look strange but unpack is probably the best word to describe what it does.  It just says Take whatever is in argv unpack it and assign it to all of these variables on the left in order.  After that we just print them out like normal.  39 Learn Python The Hard Way Release 2. 0 Hold Up Features Have Another Name call them features here these little things you import to make your Python program do more but nobody else calls them features.  just used that name because needed to trick you into learning what they are without jargon.  Before you can continue you need to learn their real name modules.  From now on we will be calling these features that we import modules.  Ill say things like You want to import the sys module.  They are also called libraries by other programmers but lets just stick with modules.  What You Should See Run the program like this and you must pass three command line arguments python ex13. py first 2nd 3rd This is what you should see when you do few different runs with different arguments python exl3. py first 2nd 3rd The script is called exexl13. py Your first variable is first Your second variable is 2nd Your third variable is 3rd python exl3. py cheese apples bread The script is called exexl13. py Your first variable is cheese Your second variable is apples Your third variable is bread python exl3. py Zed A.  Shaw The script is called exexl13. py Your first variable is Zed Your second variable is A.  Your third variable is Shaw You can actually replace first 2nd and 3rd with any three things.  You do not have to give these parameters either you can give any strings you want python ex13. py stuff like python exl3. py anything If you do not run it correctly then you will get an error like this python exl3. py first 2nd Traceback most recent call last File exexl3. py line in module 40 Exercise 13 Parameters Unpacking Variables Learn Python The Hard Way Release 2. 0 script first second third argv ValueError need more than values to unpack This happens when you do not put enough arguments on the command when you run it in this case just first 2nd.  Notice when Irun itI give it first 2nd 3rd which caused it to give an error about need more than values to unpack telling you that you didnt give it enough parameters.  Extra Credit 1.  Try giving fewer than three arguments to your script.  See that error you get See if you can explain it.  2.  Write script that has fewer arguments and one that has more.  Make sure you give the unpacked variables good names.  3.  Combine rawinput with argv to make script that gets more input from user.  4.  Remember that modules give you features.  Modules.  Modules.  Remember this because we ll need it later.  Extra Credit 41 Learn Python The Hard Way Release 2. 0 42 Exercise 13 Parameters Unpacking Variables Exercise 14 Prompting And Passing Lets do one exercise that uses argv and rawinput together to ask the user something specific.  You will need this for the next exercise where we learn to read and write files.  In this exercise well use rawinput slightly differently by having it just print simple prompt.  This is similar to game like Zork or Adventure.  from sys import argv script username argv prompt print Hi Im the script.  username print Id like to ask you few questions.  print Do you like me username likes rawinput prompt print Where do you live username lives rawinput prompt print What kind of computer do you have computer rawinput prompt print wee Alright so you said about liking me.  You live in tr.  Not sure where that is.  And you have computer.  Nice.  wun og likes lives computer script Notice though that we make variable prompt that is set to the prompt we want and we give that to rawinput instead of typing it over and over.  Now if we want to make the prompt something else we just change it in this one spot and rerun the script.  Very handy.  43 Learn Python The Hard Way Release 2. 0 What You Should See When you run this remember that you have to give the script your name for the argv arguments.  python exl4. py Zed Hi Zed Im the exl4. py script.  Id like to ask you few questions.  Do you like me Zed yes Where do you live Zed America What kind of computer do you have Tandy Alright so you said yes about liking me.  You live in America.  Not sure where that is.  And you have Tandy computer.  Nice.  Extra Credit 1.  Find out what Zork and Adventure were.  Try to find copy and play it.  .  Change the prompt variable to something else entirely.  Add another argument and use it in your script.  YN Make sure you understand how combined style multiline string with the format activator as the last print.  44 Exercise 14 Prompting And Passing Exercise 15 Reading Files Everything youve learned about rawinput and argv is so you can start reading files.  You may have to play with this exercise the most to understand whats going on so do it carefully and remember your checks.  Working with files is an easy way to erase your work if you are not careful.  This exercise involves writing two files.  One is your usual ex15.  py file that you will run but the other is named ex15sample. txt.  This second file isnt script but plain text file well be reading in our script.  Here are the contents of that file This is stuff typed into file.  It is really cool stuff.  Lots and lots of fun to have in here.  What we want to do is open that file in our script and print it out.  However we do not want to just hard code the name ex15sample. txt into our script.  Hard coding means putting some bit of information that should come from the user as string right in our program.  Thats bad because we want it to load other files later.  The solution is to use argv and rawinput to ask the user what file they want instead of hard coding the files name.  from sys import argv script filename argv txt openfilename print Heres your file tr filename print txt. read print Ill also ask you to type it again fileagain rawinput txtagain openfileagain print txtagain. read few fancy things are going on in this file so lets break it down real quick Line 13 should be familiar use of argv to get filename.  Next we have line where we use new 45 Learn Python The Hard Way Release 2. 0 command open.  Right now run pydoc open and read the instructions.  Notice how like your own scripts and rawinput it takes parameter and returns value you can set to your own variable.  You just opened file.  Line we print little line but on line we have something very new and exciting.  We call function on txt.  What you got back from open is file and its also got commands you can give it.  You give file command by using the .  dot or period the name of the command and parameters.  Just like with open and rawinput.  The difference is that when you say txt . read you are saying Hey txt Do your read command with no parameters The remainder of the file is more of the same but well leave the analysis to you in the extra credit.  What You Should See made file called ex15sample. txt and ran my script.  python exl5. py exl15sample. txt Heres your file exl5sample. txt This is stuff typed into file.  It is really cool stuff.  Lots and lots of fun to have in here.  Ill also ask you to type it again ex1l5sample. txt This is stuff typed into file.  It is really cool stuff.  Lots and lots of fun to have in here.  Extra Credit This is big jump so be sure you do this extra credit as best you can before moving on.  1.  Above each line write out in English what that line does.  2.  If you are not sure ask someone for help or search online.  Many times searching for python THING will find answers for what that THING does in Python.  Try searching for python open.  3.  used the name commands here but they are also called functions and methods.  Search around online to see what other people do to define these.  Do not worry if they confuse you.  Its normal for programmer to confuse you with their vast extensive knowledge.  4.  Get rid of the part from line 1015 where you use rawinput and try the script then.  46 Exercise 15 Reading Files Learn Python The Hard Way Release 2. 0 5.  Use only rawinput and try the script that way.  Think of why one way of getting the filename would be better than another.  6.  Run pydoc file and scroll down until you see the read command methodfunction.  See all the other ones you can use Skip the ones that have two underscores in front because those are junk.  Try some of the other commands.  7.  Startup python again and use open from the prompt.  Notice how you can open files and run read on them right there 8.  Have your script also do close on the txt and txtagain variables.  Its important to close files when you are done with them.  Extra Credit 47 Learn Python The Hard Way Release 2. 0 48 Exercise 15 Reading Files Exercise 16 Reading And Writing Files If you did the extra credit from the last exercise you should have seen all sorts of commands meth odsfunctions you can give to files.  Heres the list of commands want you to remember close Closes the file.  Like FileSave.  .  in your editor.  read Reads the contents of the file you can assign the result to variable.  readline Reads just one line of text file.  truncate Empties the file watch out if you care about the file.  writestuff Writes stuff to the file.  For now these are the important commands you need to know.  Some of them take parameters but we do not really care about that.  You only need to remember that write takes parameter of string you want to write to the file.  Lets use some of this to make simple little text editor from sys import argv script filename argv print Were going to erase r.  filename Print IT You donL Want that Ait CIREC print If you do want that hit RETURN.  rawinput print Opening the file. . .  target openfilename print Truncating the file.  Goodbye target . truncate print Now Im going to ask you for three lines.  49 20 21 22 23 24 25 26 27 28 29 30 31 32.  33 Learn Python The Hard Way Release 2. 0 linel rawinput line line2 rawinput line line3 rawinput line print Im going to write these to the file.  target . writelinel target . writen target . writeline2 target . writen target . writeline3 target . writen print And finally we close it.  target . close Thats large file probably the largest you have typed in.  So go slow do your checks and make it run.  One trick is to get bits of it running at time.  Get lines 18 running then more then few more etc.  until its all done and running.  What You Should See There are actually two things you will see first the output of your new script python exl6. py test. txt Were going to erase test. txt.  If you dont want that hit CTRLC C.  If you do want that hit RETURN.  Opening the file. . .  Truncating the file.  Goodbye Now Im going to ask you for three lines.  line To all the people out there.  line say dont like my hair.  line need to shave it off.  Im going to write these to the file.  And finally we close it.  Now open up the file you made in my case test . t xt in your editor and check it out.  Neat right 50 Exercise 16 Reading And Writing Files Learn Python The Hard Way Release 2. 0 Extra Credit 1.  If you feel you do not understand this go back through and use the comment trick to get it squared away in your mind.  One simple English comment above each line will help you understand or at least let you know what you need to research more.  2.  Write script similar to the last exercise that uses read and argv to read the file you just created.  3.  Theres too much repetition in this file.  Use strings formats and escapes to print out linel line2 and line3 with just one target . write command instead of 6.  4.  Find out why we had to pass as an extra parameter to open.  Hint open tries to be safe by making you explicitly say you want to write file.  5.  If you open the file with mode then do you really need the target . truncate Go read the docs for Pythons open function and see if thats true.  Extra Credit 51 Learn Python The Hard Way Release 2. 0 52 Exercise 16 Reading And Writing Files 20 21 22 23 24 Exercise 17 More Files Now lets do few more things with files.  Were going to actually write Python script to copy one file to another.  Itll be very short but will give you some ideas about other things you can do with files.  from sys import argv from os. path import exists script fromfile tofile argv print Copying from to fromfile tofile we could do these two on one line too how input openfromfile indata input. read print The input file is bytes long lenindata print Does the output file exist Sr existstofile print Ready hit RETURN to continue CTRLC to abort.  rawinput output opentofile output . write indata print Alright all done.  output. close input. close You should immediately notice that we import another handy command named exists.  This returns True if file exists based on its name in string as an argument.  It returns False if not.  Well be using this function in the second half of this book to do lots of things but right now you should see how you can import it.  Using import is way to get tons of free code other better well usually programmers have written so you do not have to write it.  53 Learn Python The Hard Way Release 2. 0 What You Should See Just like your other scripts run this one with two arguments the file to copy from and the file to copy it to.  If we use your test . t xt file from before we get this python exl7. py test. txt copied. txt Copying from test. txt to copied. txt The input file is 81 bytes long Does the output file exist False Ready hit RETURN to continue CTRLC to abort.  Alright all done.  cat copied. txt To all the people out there.  say dont like my hair.  need to shave it off.  It should work with any file.  Try bunch more and see what happens.  Just be careful you do not blast an important file.  Warning Did you see that trick did with cat It only works on Linux or OSX on Windows use type to do the same thing.  Extra Credit 1.  Go read up on Pythons import statement and start python to try it out.  Try importing some things and see if you can get it right.  Its alright if you do not.  2.  This script is really annoying.  Theres no need to ask you before doing the copy and it prints too much out to the screen.  Try to make it more friendly to use by removing features.  3.  See how short you can make the script.  could make this line long.  4.  Notice at the end of the WYSS used something called cat Its an old command that concatenates files together but mostly its just an easy way to print file to the screen.  Type man cat to read about it.  5.  Windows people find the alternative to cat that LinuxOSX people have.  Do not worry about man since there is nothing like that.  6.  Find out why you had to do output . close in the code.  54 Exercise 17 More Files Exercise 18 Names Variables Code Functions Big title right am about to introduce you to the function Dum dum dah Every programmer will go on and on about functions and all the different ideas about how they work and what they do but will give you the simplest explanation you can use right now.  Functions do three things 1.  They name pieces of code the way variables name strings and numbers.  2.  They take arguments the way your scripts take argv.  3.  Using and they let you make your own mini scripts or tiny commands.  You can create function by using the word def in Python.  Im going to have you make four different functions that work like your scripts and then show you how each one is related.  this one is like your scripts with argv def printtwoargs argl arg2 args print argl arg2 argl arg2 ok that args is actually pointless we can just do this def printtwoagainargl arg2 print argl Sr arg2 argl arg2 this just takes one argument def printoneargl print argl argl this one takes no arguments def printnone print Ll get nothin.  printtwoZed Shaw printtwoagainZedShaw 55 21 Learn Python The Hard Way Release 2. 0 printoneFirst printnone Lets break down the first function printtwo which is the most similar to what you already know from making scripts 1.  First we tell Python we want to make function using def for define.  2.  On the same line as def we then give the function name in this case we just called it printtwo but it could be peanuts too.  It doesnt matter except that your function should have short name that says what it does.  3.  Then we tell it we want args asterisk args which is lot like your argv parameter but for functions.  This has to go inside parenthesis to work.  4.  Then we end this line with colon and start indenting.  5.  After the colon all the lines that are indented spaces will become attached to this name printtwo.  Our first indented line is one that unpacks the arguments the same as with your scripts.  6.  To demonstrate how it works we print these arguments out just like we would in script.  Now the problem with printtwo is that its not the easiest way to make function.  In Python we can skip the whole unpacking args and just use the names we want right inside .  Thats what printtwoagain does.  After that you have an example of how you make function that takes one argument in printone.  Finally you have function that has no arguments in printnone.  Warning This is very important.  Do not get discouraged right now if this doesnt quite make sense.  Were going to do few exercises linking functions to your scripts and show you how to make more.  For now just keep thinking mini script when say function and keep playing with them.  What You Should See If you run the above script you should see python exl8. py argl Zed arg2 Shaw argl Zed arg2 Shaw argi First got nothin.  Right away you can see how function works.  Notice that you used your functions the way you use things like exists open and other commands.  In fact Ive been tricking you because in Python 56 Exercise 18 Names Variables Code Functions Learn Python The Hard Way Release 2. 0 those commands are just functions.  This means you can make your own commands and use them in your scripts too.  Extra Credit Write out function checklist for later exercises.  Write these on an index card and keep it by you while you complete the rest of these exercises or until you feel you do not need it 1.  Did you start your function definition with def Does your function name have only characters and underscore characters Did you put an open parenthesis right after the function name Did you put your arguments after the parenthesis separated by commas Did you make each argument unique meaning no duplicated names.  Did you put close parenthesis and colon after the arguments SN wv EP Yb Did you indent all lines of code you want in the function spaces No more no less.  8.  Did you end your function by going back to writing with no indent dedent ing we call it And when you run aka use or call function check these things 1.  Did you calluserun this function by typing its name 2.  Did you put character after the name to run it 3.  Did you put the values you want into the parenthesis separated by commas 4.  Did you end the function call with character.  Use these two checklists on the remaining lessons until you do not need them anymore.  Finally repeat this few times To run call or use function all mean the same thing.  Extra Credit 57 Learn Python The Hard Way Release 2. 0 58 Exercise 18 Names Variables Code Functions 20 21 22 23 24 Exercise 19 Functions And Variables Functions may have been mindblowing amount of information but do not worry.  Just keep doing these exercises and going through your checklist from the last exercise and you will eventually get it.  There is one tiny point though that you might not have realized which well reinforce right now The variables in your function are not connected to the variables in your script.  Heres an exercise to get you thinking about this def cheeseandcrackerscheesecount boxesofcrackers print You have cheeses cheesecount print You have boxes of crackers boxesofcrackers print Man thats enough for party print Get blanket. n print We can just give the function numbers directly cheeseandcrackers20 30 print OR we can use variables from our script amountofcheese 10 amountofcrackers 50 cheeseandcrackers amountofcheese amountofcrackers print We can even do math inside too cheeseandcrackers10 20 print And we can combine the two variables and math cheeseandcrackers amountofcheese 100 amountofcrackers 1000 This shows all different ways were able to give our function cheeseandcrackers the values it needs to print them.  We can give it straight numbers.  We can give it variables.  We can give it math.  We can even combine math and variables.  In way the arguments to function are kind of like our character when we make variable.  In fact 59 Learn Python The Hard Way Release 2. 0 if you can use to name something you can usually pass it to function as an argument.  What You Should See You should study the output of this script and compare it with what you think you should get for each of the examples in the script.  python exl19. py We can just give the function numbers directly You have 20 cheeses You have 30 boxes of crackers Man thats enough for party Get blanket.  OR we can use variables from our script You have 10 cheeses You have 50 boxes of crackers Man thats enough for party Get blanket.  We can even do math inside too You have 30 cheeses You have 11 boxes of crackers Man thats enough for party Get blanket.  And we can combine the two variables and math You have 110 cheeses You have 1050 boxes of crackers Man thats enough for party Get blanket.  Extra Credit 1.  Go back through the script and type comment above each line explaining in English what it does.  2.  Start at the bottom and read each line backwards saying all the important characters.  3.  Write at least one more function of your own design and run it 10 different ways.  60 Exercise 19 Functions And Variables 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Exercise 20 Functions And Files Remember your checklist for functions then do this exercise paying close attention to how functions and files can work together to make useful stuff.  from sys import argv script inputfile argv def printallf print f. read def rewindf . seek def printalinelinecount print linecount f. readline currentfile openinputfile print First lets print the whole filen printallcurrentfile print Now lets rewind kind of like tape.  rewindcurrentfile print Lets print thtes Jines currentline currentfile printalinecurrentline currentline currentline currentfile printalinecurrentline currentline currentline printalinecurrentline currentfile 61 Learn Python The Hard Way Release 2. 0 Pay close attention to how we pass in the current line number each time we run printaline.  What You Should See python ex20. py test. txt First lets print the whole file To all the people out there.  say dont like my hair.  need to shave it off.  Now lets rewind kind of like tape.  Lets print three lines To all the people out there.  say dont like my hair.  need to shave it off.  Extra Credit .  Go through and write English comments for each line to understand whats going on.  .  Each time printaline is run you are passing in variable currentline.  Write out what currentline is equal to on each function call and trace how it becomes linecount in printaline.  .  Find each place function is used and go check its def to make sure that you are giving it the right arguments.  .  Research online what the seek function for file does.  Try pydoc file and see if you can figure it out from there.  .  Research the shorthand notation and rewrite the script to use that.  62 Exercise 20 Functions And Files 20 21 22 23 24 25 26 27 Exercise 21 Functions Can Return Something You have been using the character to name variables and set them to numbers or strings.  Were now going to blow your mind again by showing you how to use and new Python word return to set variables to be value from function.  There will be one thing to pay close attention to but first type this in def adda print ADDING return def subtracta print SUBTRACTING return def multiplya print MULTIPLYING return def dividea print DIVIDING return print Lets do some math with just functions age add30 height subtract 78 weight multiply90 iq divide100 print Age Height Weight IQ age height weight puzzle for the extra credit type it in anyway.  iq 63 29 30 31 32 33 Learn Python The Hard Way Release 2. 0 print Here 15 piazle.  what addage subtract height multiplyweight divideig print That becomes what Can you do it by hand We are now doing our own math functions for add subtract multiply and divide.  The im portant thing to notice is the last line where we say return in add.  What this does is the following 1.  Our function is called with two arguments and b.  2.  We print out what our function is doing in this case ADDING.  3.  Then we tell Python to do something kind of backward we return the addition of b.  You might say this as add and then return them.  4.  Python adds the two numbers.  Then when the function ends any line that runs it will be able to assign this result to variable.  As with many other things in this book you should take this real slow break it down and try to trace whats going on.  To help theres extra credit to get you to solve puzzle and learn something cool.  What You Should See python ex21. py Lets do some math with just functions ADDING 30 SUBTRACTING 78 MULTIPLYING 90 DIVIDING 100 Age 35 Height 74 Weight 180 IQ 50 Here is puzzle.  DIVIDING 50 MULTIPLYING 180 25 SUBTRACTING 74 4500 ADDING 35 4426 That becomes 4391 Can you do it by hand Extra Credit 1.  If you arent really sure what return does try writing few of your own functions and have them return some values.  You can return anything that you can put to the right of an .  64 Exercise 21 Functions Can Return Something Learn Python The Hard Way Release 2. 0 2.  At the end of the script is puzzle.  Im taking the return value of one function and using it as the argument of another function.  Im doing this in chain so that Im kind of creating formula using the functions.  It looks really weird but if you run the script you can see the results.  What you should do is try to figure out the normal formula that would recreate this same set of operations.  3.  Once you have the formula worked out for the puzzle get in there and see what happens when you modify the parts of the functions.  Try to change it on purpose to make another value.  4.  Finally do the inverse.  Write out simple formula and use the functions in the same way to calculate it.  This exercise might really whack your brain out but take it slow and easy and treat it like little game.  Figuring out puzzles like this is what makes programming fun so Ill be giving you more little problems like this as we go.  Extra Credit 65 Learn Python The Hard Way Release 2. 0 66 Exercise 21 Functions Can Return Something Exercise 22 What Do You Know So Far There wont be any code in this exercise or the next one so theres no WYSS or Extra Credit either.  In fact this exercise is like one giant Extra Credit.  Im going to have you do form of review what you have learned so far.  First go back through every exercise you have done so far and write down every word and symbol another name for character that you have used.  Make sure your list of symbols is complete.  Next to each word or symbol write its name and what it does.  If you cant find name for symbol in this book then look for it online.  If you do not know what word or symbol does then go read about it again and try using it in some code.  You may run into few things you just cant find out or know so just keep those on the list and be ready to look them up when you find them.  Once you have your list spend few days rewriting the list and double checking that its correct.  This may get boring but push through and really nail it down.  Once you have memorized the list and what they do then you should step it up by writing out tables of symbols their names and what they do from memory.  When you hit some you cant recall from memory go back and memorize them again.  What You are Learning Its important when you are doing boring mindless memorization exercise like this to know why.  It helps you focus on goal and know the purpose of all your efforts.  In this exercise you are learning the names of symbols so that you can read source code more easily.  Its similar to learning the alphabet and basic words of English except this Python alphabet has extra symbols you might not know.  67 Learn Python The Hard Way Release 2. 0 Just take it slow and do not hurt your brain.  Hopefully by now these symbols are natural for you so this isnt big effort.  Its best to take 15 minutes at time with your list and then take break.  Giving your brain rest will help you learn faster with less frustration.  68 Exercise 22 What Do You Know So Far Exercise 23 Read Some Code You should have spent last week getting your list of symbols straight and locked in your mind.  Now you get to apply this to another week reading code on the internet.  This exercise will be daunting at first.  going to throw you in the deep end for few days and have you just try your best to read and understand some source code from real projects.  The goal isnt to get you to understand code but to teach you the following three skills 1.  Finding Python source code for things you need.  2.  Reading through the code and looking for files.  3.  Trying to understand code you find.  At your level you really do not have the skills to evaluate the things you find but you can benefit from getting exposure and seeing how things look.  When you do this exercise think of yourself as an anthropologist trucking through new land with just barely enough of the local language to get around and survive.  Except of course that you will actually get out alive because the internet isnt jungle.  Anyway.  Heres what you do 1.  Go to bitbucket. org with your favorite web browser and search for python.  2.  Avoid any project with Python mentioned.  Thatll only confuse you.  3.  Pick random project and click on it.  4.  Click on the Source tab and browse through the list of files and directories until you find . py file but not setup. py thats useless.  5.  Start at the top and read through it taking notes on what you think it does.  6.  If any symbols or strange words seem to interest you write them down to research later.  Thats it.  Your job is to use what you know so far and see if you can read the code and get grasp of what it does.  Try skimming the code first and then read it in detail.  Maybe also try taking very difficult parts and reading each symbol you know outloud.  Now try several three other sites 69 Learn Python The Hard Way Release 2. 0 github. com launchpad. net koders. com On each of these sites you may find weird files ending in . c so stick to .  py files like the ones you have written in this book.  final fun thing to do is use the above four sources of Python code and type in topics you are interested in instead of python.  Search for journalism cooking physics or anything you are curious about.  Chances are theres some code out there you could use right away.  70 Exercise 23 Read Some Code 20 21 22 23 24 25 26 27 28 29 30 31 Exercise 24 More Practice You are getting to the end of this section.  You should have enough Python under your fingers to move onto learning about how programming really works but you should do some more practice.  This exercise is longer and all about building up stamina.  The next exercise will be similar.  Do them get them exactly right and do your checks.  print Lets practice everything.  print Youd need to know bout escapes with that do newlines and tabs.  poem tThe lovely world with logic so firmly planted cannot discern the needs of love nor comprehend passion from intuition and requires an explanation nttwhere there is none.  ww five 10 23 print This should be five five def secretformulastarted jellybeans started 500 jars jellybeans 1000 crates jars 100 return jellybeans jars crates startpoint 10000 beans jars crates secretformulastartpoint print With starting point of td startpoint 71 32 33 34 35 36 37 Learn Python The Hard Way Release 2. 0 print Wed have beans jars and crates.  beans jars crates startpoint startpoint 10 print We can also do that this way print Wed have beans jars and crates.  secretformulastartpoint What You Should See python ex24. py Lets practice everything.  Youd need to know bout escapes with that do newlines and tabs.  The lovely world with logic so firmly planted cannot discern the needs of love nor comprehend passion from intuition and requires an explanation where there is none.  This should be five With starting point of 10000 Wed have 5000000 beans 5000 jars and 50 crates.  We can also do that this way Wed have 500000 beans 500 jars and crates.  Extra Credit 1.  Make sure to do your checks read it backwards read it out loud put comments above confusing parts.  2.  Break the file on purpose then run it to see what kinds of errors you get.  Make sure you can fix it.  72 Exercise 24 More Practice 20 21 22 23 24 25 26 27 28 29 30 Exercise 25 Even More Practice Were going to do some more practice involving functions and variables to make sure you know them well.  This exercise should be straight forward for you to type in break down and understand.  However this exercise is little different.  You wont be running it.  Instead you will import it into your python and run the functions yourself.  def def def def def def breakwords stuff This function will break up words for us.  words stuff. split return words sortwords words muNserts the words.  return sortedwords printfirstwordwords Prints the first word after popping it off.  word words. pop print word printlastwordwords Prints the last word after popping it off.  word words. pop1 print word sortsentence sentence Takes in full sentence and returns the sorted words.  words breakwords sentence return sortwords words printfirstandlast sentence Drints the first and last words of the sentence.  words breakwords sentence printfirstword words printlastword words 73 31 32.  33 34 35 20 21 22 23 24 25 26 27 28 29 30 Learn Python The Hard Way Release 2. 0 def printfirstandlastsortedsentence Sorts the words then prints the first and last one.  words sortsentence sentence printfirstword words printlastword words First run this like normal with python ex25. py to find any errors you have made.  Once you have found all of the errors you can and fixed them you will then want to follow the WYSS section to complete the exercise.  What You Should See In this exercise were going to interact with your .  py file inside the python interpreter you used peri odically to do calculations.  Heres what it looks like when do it python Python 2. 5. 1 r2863 Feb 2009 12 GCC 4. 0. 1 Apple Inc.  build 5465 on darwin Type help copyright credits or license for more information.  import ex25 sentence All good things come to those who wait.  words ex25. breakwords sentence words All good things come to those who wait.  sortedwords ex25. sortwords words sortedwords All come good things those to wait.  who ex25. printfirstwordwords All ex25. printlastword words wait.  wrods Traceback most recent call last File stdin line in module NameError name wrods is not defined words good things come to those who ex25. printfirstwordsortedwords All ex25. printlastwordsortedwords who sortedwords come good things those to wait.  sortedwords ex25. sortsentence sentence sortedwords 74 Exercise 25 Even More Practice 31 32 33 34 35 36 37 38 39 Learn Python The Hard Way Release 2. 0 All come good things those to wait.  who ex25. printfirstandlast sentence All wait.  All who Sis ex25. printfirstandlastsorted sentence Lets break this down line by line to make sure you know whats going on Line you import your ex25. py python file just like other imports you have done.  Notice you do not need to put the .  py at the end to import it.  When you do this you make module that has all your functions in it to use.  Line you made sentence to work with.  Line you use the ex25 module and call your first function ex25. breakwords.  The .  dot period symbol is how you tell python Hey inside ex25 theres function called breakwords and want to run it.  Line we just type words and python will print out whats in that variable line 9.  It looks weird but this is List which you will learn about later.  Lines 1011 we do the same thing with ex25. sortwords to get sorted sentence.  Lines 1316 we use ex25. printfirstword and ex25. printlastword to get the first and last word printed out.  Line 17 is interesting.  made mistake and typed the words variable as wrods so python gave me an error on Lines 1820.  Line 2122 is where we print the modified words list.  Notice that since we printed the first and last one those words are now missing.  The remaining lines are for you to figure out and analyze in the extra credit.  Extra Credit 1.  Take the remaining lines of the WYSS output and figure out what they are doing.  Make sure you understand how you are running your functions in the ex25 module.  Try doing this help ex25 and also help ex25. breakwords.  Notice how you get help for your module and how the help is those odd strings you put after each function in ex25 Those special strings are called documentation comments and well be seeing more of them.  Extra Credit 75 Learn Python The Hard Way Release 2. 0 3.  Typing ex25.  is annoying.  shortcut is to do your import like this from ex25 import which is like saying Import everything from ex25.  Programmers like saying things backwards.  Start new session and see how all your functions are right there.  4.  Try breaking your file and see what it looks like in python when you use it.  You will have to quit python with CTRLD CTRLZ on windows to be able to reload it.  76 Exercise 25 Even More Practice Exercise 26 Congratulations Take Test You are almost done with the first half of the book.  The second half is where things get interesting.  You will learn logic and be able to do useful things like make decisions.  Before you continue have quiz for you.  This quiz will be very hard because it requires you to fix someone elses code.  When you are programmer you often have to deal with another programmers code and also with their arrogance.  They will very frequently claim that their code is perfect.  These programmers are stupid people who care little for others.  good programmer assumes like good scientist that theres always some probability their code is wrong.  Good programmers start from the premise that their software is broken and then work to rule out all possible ways it could be wrong before finally admitting that maybe it really is the other guys code.  In this exercise you will practice dealing with bad programmer by fixing bad programmers code.  have poorly copied exercises 24 and 25 into file and removed random characters and added flaws.  Most of the errors are things Python will tell you while some of them are math errors you should find.  Others are formatting errors or spelling mistakes in the strings.  All of these errors are very common mistakes all programmers make.  Even experienced ones.  Your job in this exercise is to correct this file.  Use all of your skills to make this file better.  Analyze it first maybe printing it out to edit it like you would school term paper.  Fix each flaw and keep running it and fixing it until the script runs perfectly.  Try not to get help and instead if you get stuck take break and come back to it later.  Even if this takes days to do bust through it and make it right.  Finally the point of this exercise isnt to type it in but to fix an existing file.  To do that you must go to httplearnpythonthehardway. comexercise26. txt Copypaste the code into file named ex26. py.  This is the only time you are allowed to copypaste.  77 Learn Python The Hard Way Release 2. 0 78 Exercise 26 Congratulations Take Test Exercise 27 Memorizing Logic Today is the day you start learning about logic.  Up to this point you have done everything you possibly can reading and writing files to the terminal and have learned quite lot of the math capabilities of Python.  From now on you will be learning ogic.  You wont learn complex theories that academics love to study but just the simple basic logic that makes real programs work and that real programmers need every day.  Learning logic has to come after you do some memorization.  want you to do this exercise for an entire week.  Do not falter.  Even if you are bored out of your mind keep doing it.  This exercise has set of logic tables you must memorize to make it easier for you to do the later exercises.  Im warning you this wont be fun at first.  It will be downright boring and tedious but this is to teach you very important skill you will need as programmer.  You will need to be able to memorize important concepts as you go in your life.  Most of these concepts will be exciting once you get them.  You will struggle with them like wrestling squid then one day snap you will understand it.  All that work memorizing the basics pays off big later.  Heres tip on how to memorize something without going insane Do tiny bit at time throughout the day and mark down what you need to work on most.  Do not try to sit down for two hours straight and memorize these tables.  This wont work.  Your brain will really only retain whatever you studied in the first 15 or 30 minutes anyway.  Instead what you should do is create bunch of index cards with each column on the left on one side True or False and the column on the right on the back.  You should then pull them out see the True or False and be able to immediately say True Keep practicing until you can do this.  Once you can do that start writing out your own truth tables each night into notebook.  Do not just copy them.  Try to do them from memory and when you get stuck glance quickly at the ones have here to refresh your memory.  Doing this will train your brain to remember the whole table.  Do not spend more than one week on this because you will be applying it as you go.  79 Learn Python The Hard Way Release 2. 0 The Truth Terms In python we have the following terms characters and phrases for determining if something is True or False.  Logic on computer is all about seeing if some combination of these characters and some variables is True at that point in the program.  and or not not equal equal greaterthanequal lessthanequal True False You actually have run into these characters before but maybe not the phrases.  The phrases and or not actually work the way you expect them to just like in English.  The Truth Tables We will now use these characters to make the truth tables you need to memorize.  NOT True not False True not True False OR True True or False True True or True True False or True True False or False False AND True True and False False True and True True False and True False False and False False 80 Exercise 27 Memorizing Logic Learn Python The Hard Way Release 2. 0 NOT OR True not True or False False not True or True False not False or True False not False or False True NOT AND True not True and False True not True and True False not False and True True not False and False True True 10 True 11 False 01 True 00 False True 10 False True QO1 False True Now use these tables to write up your own cards and spend the week memorizing them.  Remember though there is no failing in this book just trying as hard as you can each day and then Jittle bit more.  The Truth Tables 81 Learn Python The Hard Way Release 2. 0 82 Exercise 27 Memorizing Logic Exercise 28 Boolean Practice The logic combinations you learned from the last exercise are called boolean logic expressions.  Boolean logic is used everywhere in programming.  They are essential fundamental parts of computa tion and knowing them very well is akin to knowing your scales in music.  In this exercise you will be taking the logic exercises you memorized and start trying them out in python.  Take each of these logic problems and write out what you think the answer will be.  In each case it will be either True or False.  Once you have the answers written down you will start python in your terminal and type them in to confirm your answers.  1.  True and True False and True and test test or True and False and True or Caos YM FS YS PL ll ll test testing and .  test testing .  test Ww .  not True and False .  not and Nn .  not 10 or 1000 1000 Oo .  not 10 or .  not testing testing and Zed Cool Guy 83 Learn Python The Hard Way Release 2. 0 18.  and not testing or 19.  Chunky bacon and not or 20.  and not testing testing or Python Fun will also give you trick to help you figure out the more complicated ones toward the end.  Whenever you see these boolean logic statements you can solve them easily by this simple process 1.  Find equality test or and replace it with its truth.  2.  Find each andor inside parenthesis and solve those first.  3.  Find each not and invert it.  4.  Find any remaining andor and solve it.  5.  When you are done you should have True or False.  will demonstrate with variation on 20 and not testing test or Python Python Heres me going through each of the steps and showing you the translation until Ive boiled it down to single result 1.  Solve each equality test 4is True True and not testing test or Python Python testing test is True True and not True or Python Python Python Python True and not True or True 2.  Find each andor in parenthesis True or True is True True and not True 3.  Find each not and invert it not True is False True and False 4.  Find any remaining andor and solve them True and False is False With that were done and know the result is False.  Warning The more complicated ones may seem very hard at first.  You should be able to give good first stab at solving them but do not get discouraged.  Im just getting you primed for more of these logic gymnastics so that later cool stuff is much easier.  Just stick with it and keep track of what you get wrong but do not worry that its not getting in your head quite yet.  It1l come.  84 Exercise 28 Boolean Practice Learn Python The Hard Way Release 2. 0 What You Should See After you have tried to guess at these this is what your session with python might look like python Python 2. 5. 1 r2863 Feb 2009 12 GCC 4. 0. 1 Apple Inc.  build 5465 on darwin Type help copyright credits or license for more information.  True and True rrue and True Extra Credit 1.  There are lot of operators in Python similar to and .  Try to find out as many equality operators as you can.  They should be like or .  2.  Write out the names of each of these equality operators.  For example call not equal.  3.  Play with the python by typing out new boolean operators and before you hit enter try to shout out what it is.  Do not think about it just the first thing that comes to mind.  Write it down then hit enter and keep track of how many you get right and wrong.  4.  Throw away that piece of paper from away so you do not accidentally try to use it later.  What You Should See 85 Learn Python The Hard Way Release 2. 0 86 Exercise 28 Boolean Practice 20 21 22 23 24 25 26 27 28 Exercise 29 What If Here is the next script of Python you will enter which introduces you to the ifstatement.  Type this in make it run exactly right and then well try see if your practice has paid off.  people 20 cats 30 dogs 15 if people print if people print if people print if people print dogs if people print if people print if people print cats Too many cats Cats The world is doomed Not many cats The world is saved dogs The world is drooled on dogs The world is dry dogs People are greater than or equal dogs People are less than or equal to dogs People are dogs.  to dogs.  dogs.  87 Learn Python The Hard Way Release 2. 0 What You Should See python ex29. py Too many cats The world is doomed The world is dry People are greater than equal to dogs.  People are less than equal to dogs.  People are dogs.  Extra Credit In this extra credit try to guess what you think the ifstatement is and what it does.  Try to answer these questions in your own words before moving onto the next exercise 1.  What do you think the if does to the code under it 2.  Why does the code under the if need to be indented spaces 3.  What happens if it isnt indented .  Can you put other boolean expressions from Ex.  27 in the ifstatement Try it.  .  What happens if you change the initial variables for people cats and dogs 88 Exercise 29 What If Fw YN Exercise 30 Else And If In the last exercise you worked out some ifstatements and then tried to guess what they are and how they work.  Before you learn more ll explain what everything is by answering the questions you had from extra credit.  You did the extra credit right 1.  What do you think the if does to the code under it An if statement creates what is called branch in the code.  Its kind of like those choose your own adventure books where you are asked to turn to one page if you make one choice and another if you go different direction.  The ifstatement tells your script If this boolean expression is True then run the code under it otherwise skip it.  .  Why does the code under the if need to be indented spaces colon at the end of line is how you tell Python you are going to create new block of code and then indenting spaces tells Python what lines of code are in that block.  This is exactly the same thing you did when you made functions in the first half of the book.  .  What happens if it isnt indented If it isnt indented you will most likely create Python error.  Python expects you to indent something after you end line with colon.  .  Can you put other boolean expressions from Ex.  27 in the if statement Try it.  Yes you can and they can be as complex as you like although really complex things generally are bad style.  .  What happens if you change the initial variables for people cats and dogs Because you are comparing numbers if you change the numbers different ifstatements will evaluate to True and the blocks of code under them will run.  Go back and put different numbers in and see if you can figure out in your head what blocks of code will run.  Compare my answers to your answers and make sure you really understand the concept of block of code.  This is important for when you do the next exercise where you write all the parts of ifstatements that you can use.  Type this one in and make it work too.  people 30 cars 40 buses 15 89 20 21 22 23 Learn Python The Hard Way Release 2. 0 if cars people print We should take the cars.  elif cars people print We should not take the cars.  else print We cant decide.  if buses cars print Thats too many buses.  elif buses cars print Maybe we could take the buses.  else print We still cant decide.  if people buses print Alright lets just take the buses else print Fine lets stay home then.  What You Should See python ex. py We should take the cars.  Maybe we could take the buses.  Alright lets just take the buses.  Extra Credit 1.  Try to guess what elif and else are doing.  2.  Change the numbers of cars people and buses and then trace through each ifstatement to see what will be printed.  3.  Try some more complex boolean expressions like cars people and buses cars.  4.  Above each line write an English description of what the line does.  90 Exercise 30 Else And If 19 20 21 22 23 24 25 26 Exercise 31 Making Decisions In the first half of this book you mostly just printed out things and called functions but everything was basically in straight line.  Your scripts ran starting at the top and went to the bottom where they ended.  If you made function you could run that function later but it still didnt have the kind of branching you need to really make decisions.  Now that you have if else and elif you can start to make scripts that decide things.  In the last script you wrote out simple set of tests asking some questions.  In this script you will ask the user questions and make decisions based on their answers.  Write this script and then play with it quite lot to figure it out.  print You enter dark room with two doors.  Do you go through door or door door rawinput if door print Theres giant bear here eating cheese cake.  What do you do print 1.  Take the cake.  print 2. . .  Screai.  at.  the bear.  bear rawinput if bear print The bear eats your face off.  Good job elif bear print The bear eats your legs off.  Good job else print Well doing is probably better.  Bear runs away.  bear elif door print You stare into the endless abyss at Cthuhlus retina.  print 1. . .  Blueberries.  print 2.  Yellow jacket clothespins.  print 3.  Understanding revolvers yelling melodies.  insanity rawinput 91 27 28 29 30 31 32.  33 Learn Python The Hard Way Release 2. 0 if insanity or insanity print Your body survives powered by mind of jello.  Good job else print The insanity rots your eyes into pool of muck.  Good job else print You stumble around and fall on knife and die.  Good job key point here is that you are now putting the ifstatements inside ifstatements as code that can run.  This is very powerful and can be used to create nested decisions where one branch leads to another and another.  Make sure you understand this concept of ifstatements inside ifstatements.  In fact do the extra credit to really nail it.  What You Should See Here is me playing this little adventure game.  do not do so well.  python ex31. py You enter dark room with two doors.  Do you go through door or door Theres giant bear here eating cheese cake.  What do you do 1.  Take the cake.  2.  Scream at the bear.  The bear eats your legs off.  Good job python ex31l. py You enter dark room with two doors.  Do you go through door or door Theres giant bear here eating cheese cake.  What do you do 1.  Take the cake.  2.  Scream at the bear.  a.  The bear eats your face off.  Good job python ex31. py You enter dark room with two doors.  Do you go through door or door You stare into the endless abyss at Cthuhlus retina.  1.  Blueberries.  2.  Yellow jacket clothespins.  3.  Understanding revolvers yelling melodies.  Your body survives powered by mind of jello.  Good job 92 Exercise 31 Making Decisions Learn Python The Hard Way Release 2. 0 python ex31l. py You enter dark room with two doors.  Do you go through door or door You stare into the endless abyss at Cthuhlus retina.  1.  Blueberries.  2.  Yellow jacket clothespins.  3.  Understanding revolvers yelling melodies.  The insanity rots your eyes into pool of muck.  Good job python ex31. py You enter dark room with two doors.  Do you go through door or door stuff You stumble around and fall on knife and die.  Good job python ex31l. py You enter dark room with two doors.  Do you go through door or door Theres giant bear here eating cheese cake.  What do you do 1.  Take the cake.  2.  Scream at the bear.  apples Well doing apples is probably better.  Bear runs away.  Extra Credit Make new parts of the game and change what decisions people can make.  Expand the game out as much as you can before it gets ridiculous.  Extra Credit 93 Learn Python The Hard Way Release 2. 0 94 Exercise 31 Making Decisions Exercise 32 Loops And Lists You should now be able to do some programs that are much more interesting.  If you have been keeping up you should realize that now you can combine all the other things you have learned with ifstatements and boolean expressions to make your programs do smart things.  However programs also need to do repetitive things very quickly.  We are going to use forloop in this exercise to build and print various lists.  When you do the exercise you will start to figure out what they are.  wont tell you right now.  You have to figure it out.  Before you can use forloop you need way to store the results of loops somewhere.  The best way to do this is with list.  list is exactly what its name says container of things that are organized in order.  Its not complicated you just have to learn new syntax.  First theres how you make list hairs brown blond red eyes brown blue green weights What you do is start the list with the leftbracket which opens the list.  Then you put each item you want in the list separated by commas just like when you did function arguments.  Lastly you end the list with rightbracket to indicate that its over.  Python then takes this list and all its contents and assigns them to the variable.  Warning This is where things get tricky for people who cant program.  Your brain has been taught that the world is flat.  Remember in the last exercise where you put ifstatements inside ifstatements That probably made your brain hurt because most people do not ponder how to nest things inside things.  In programming this is all over the place.  You will find functions that call other functions that have ifstatements that have lists with lists inside lists.  If you see structure like this that you cant figure out take out pencil and paper and break it down manually bit by bit until you understand it.  We now will build some lists using some loops and print them out thecount fruits apples oranges pears apricots change pennies dimes quarters 95 20 21 22 23 24 25 26 27 28 29 Learn Python The Hard Way Release 2. 0 this first kind of forloop goes through list for number in thecount print This is count number same as above for fruit in fruits print fruit of type fruit also we can go through mixed lists too notice we have to use since we dont know whats in it for in change print got tr i.  we can also build lists first start with an empty one elements then use the range function to do to counts for in range0 print Adding to the list.  append is function that lists understand elements. append now we can print them out too for in elements print Element was What You Should See python ex32.  This is count This is count This is count This is count This is count fruit of type apples fruit of type oranges fruit of type pears fruit of type apricots got got pennies got got dimes got got quarters Adding to the list.  Adding to the list.  GQ ws WN HED HN NON NON OD DS OD 96 Exercise 32 Loops And Lists Learn Python The Hard Way Release 2. 0 Adding Adding Adding Adding Element Element Element Element Element Element to the to the to the to the was was was was was was Extra Credit list.  LAST dist.  dist.  1.  Take look at how you used range.  Look up the range function to understand it.  2.  Could you have avoided that forloop entirely on line 22 and just assigned range directly to elements 3.  Find the Python documentation on lists and read about them.  What other operations can you do to lists besides append Extra Credit 97 Learn Python The Hard Way Release 2. 0 98 Exercise 32 Loops And Lists DA we Bw KR Exercise 33 While Loops Now to totally blow your mind with new loop the whileloop.  whileloop will keep executing the code block under it as long as boolean expression is True.  Wait you have been keeping up with the terminology right That if we write line and end it witha colon then that tells Python to start new block of code Then we indent and thats the new code.  This is all about structuring your programs so that Python knows what you mean.  If you do not get that idea then go back and do some more work with ifstatements functions and the forloop until you get it.  Later on well have some exercises that will train your brain to read these structures similar to how we burned boolean expressions into your brain.  Back to whileloops.  What they do is simply do test like an ifstatement but instead of running the code block once they jump back to the top where the while is and repeat.  It keeps doing this until the expression is False.  Heres the problem with whileloops Sometimes they do not stop.  This is great if your intention is to just keep looping until the end of the universe.  Otherwise you almost always want your loops to end eventually.  To avoid these problems theres some rules to follow 1.  Make sure that you use whileloops sparingly.  Usually forloop is better.  2.  Review your while statements and make sure that the thing you are testing will become False at some point.  3.  When in doubt print out your test variable at the top and bottom of the whileloop to see what its doing.  In this exercise you will learn the whileloop by doing the above three things i0 numbers while print AC the top 1. 18 da numbers. append 99 Learn Python The Hard Way Release 2. 0 iidil print Numbers now print The numbers for num in numbers print num What You Should See python ex. py At the top iis Numbers now At the bottom iis At the top iis Numbers now 0y LJ At the bottom iis At the top iis Numbers now On Le At the bottom is At the top iis Numbers now Gz Le At the bottom iis At the top iis Numbers now At the bottom iis At the top iis Numbers now At the bottom iis The numbers GW wNHE OS Extra Credit 1.  Convert this while loop to function that you can call and replace in the test witha variable.  numbers print At the bottom iis 100 Exercise 33 While Loops Learn Python The Hard Way Release 2. 0 2.  Now use this function to rewrite the script to try different numbers.  3.  Add another variable to the function arguments that you can pass in that lets you change the on line so you can change how much it increments by.  4.  Rewrite the script again to use this function to see what effect that has.  5.  Now write it to use forloops and range instead.  Do you need the incrementor in the middle anymore What happens if you do not get rid of it If at any time that you are doing this it goes crazy it probably will just hold down CTRL and hit CTRLc and the program will abort.  Extra Credit 101 Learn Python The Hard Way Release 2. 0 102 Exercise 33 While Loops Exercise 34 Accessing Elements Of Lists Lists are pretty useful but unless you can get at the things in them they arent all that good.  You can already go through the elements of list in order but what if you want say the 5th element You need to know how to access the elements of list.  Heres how you would access the first element of list animals bear tiger penguin zebra bear animals0 You take list of animals and then you get the first one using How does that work Because of the way math works Python start its lists at rather than 1.  It seems weird but theres many advantages to this even though it is mostly arbitrary.  The best way to explain why is by showing you the difference between how you use numbers and how programmers use numbers.  Imagine you are watching the four animals in our list above bear tiger penguin zebra runinarace.  They win in the order we have them in this list.  The race was really exciting because the animals didnt eat each other and somehow managed to run race.  Your friend however shows up late and wants to know who won.  Does your friend say Hey who came in zeroth No he says Hey who came in first This is because the order of the animals is important.  You cant have the second animal without the first animal and cant have the third without the second.  Its also impossible to have zeroth animal since zero means nothing.  How can you have nothing win race It just doesnt make sense.  We call these kinds of numbers ordinal numbers because they indicate an ordering of things.  Programmers however cant think this way because they can pick any element out of list at any point.  To programmer the above list is more like deck of cards.  If they want the tiger they grab it.  If they want the zebra they can take it too.  This need to pull elements out of lists at random means that they need way to indicate elements consistently by an address or an index and the best way to do that is to start the indices at 0.  Trust me on this the math is way easier for these kinds of accesses.  This kind of number is cardinal number and means you can pick at random so there needs to be element.  So how does this help you work with lists Simple every time you say to yourself want the 3rd animal you translate this ordinal number to cardinal number by subtracting 1.  The 3rd animal 103 Learn Python The Hard Way Release 2. 0 is at index and is the penguin.  You have to do this because you have spent your whole life using ordinal numbers and now you have to think in cardinal.  Just subtract and you will be good.  Remember ordinal ordered 1st cardinal cards at random 0.  Lets practice this.  Take this list of animals and follow the exercises where tell you to write down what animal you get for that ordinal or cardinal number.  Remember if say first second etc.  then using ordinal so subtract 1.  If give you cardinal then use it directly.  animals bear python peacock kangaroo whale platypus 1.  The animal at 1.  2.  The 3rd animal.  3.  The Ist animal.  4.  The animal at 3.  5.  The 5th animal.  6.  The animal at 2.  7.  The 6th animal.  8.  The animal at 4.  For each of these write out full sentence of the form The Ist animal is at and is bear.  Then say it backwards The animal at is the Ist animal and is bear.  Use your python to check your answers.  Extra Credit 1.  Read about ordinal and cardinal numbers online.  2.  With what you know of the difference between these types of numbers can you explain why this really is 2010 Hint you cant pick years at random.  3.  Write some more lists and work out similar indexes until you can translate them.  4.  Use Python to check your answers to this as well.  Warning Programmers will tell you to read this guy named Dijkstra on this subject.  recommend you avoid his writings on this unless you enjoy being yelled at by someone who stopped programming at the same time programming started.  104 Exercise 34 Accessing Elements Of Lists 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Exercise 35 Branches and Functions You have learned to do ifstatements functions and arrays.  Now its time to bend your mind.  Type this in and see if you can figure out what its doing.  from sys import exit def def goldroom print This room is full of gold.  How much do you take next rawinput af tn nese or in mexe howmuch int next else deadMan learn to type number.  if howmuch 50 print Nice youre not greedy you win exit else deadYou greedy bastard bearroom prant There 15 bear here print The bear has bunch of honey.  print The fat bear is in front of another door.  print How are you going to move the bear bearmoved False while True next rawinput if next take honey deadThe bear looks at you then slaps your face off.  elif next taunt bear and not bearmoved print The bear has moved from the door.  bearmoved True You can go through it now.  105 34 35 36 37 38 39 41 42 43 45 47 48 49 50 51 52 53 54 55 56 57 58 59 61 62 63 65 66 67 68 69 70 71 72 73 74 vi 76 Learn Python The Hard Way Release 2. 0 elif next taunt bear and bearmoved deadThe bear gets pissed off and chews your leg off.  elif next open door and bearmoved goldroom else print got no idea what that means.  def cthuluroom print Here you see the grat evil Cthulu.  print He it whatever stares at you and you go insane.  print Do you flee for your life or eat your head next rawinput if flee in next start elif head in next deadWell that was tasty else cthuluroom def deadwhy print why Good job exit def start print You are in dark room.  print There is door to your right and left.  print Which one do you take next rawinput if next left bearroom elif next right cthuluroom else deadYou stumble around the room until you starve.  start 106 Exercise 35 Branches and Functions Learn Python The Hard Way Release 2. 0 What You Should See Heres me playing the game python ex35. py You are in dark room.  There is door to your right and left.  Which one do you take left There is bear here.  The bear has bunch of honey.  The fat bear is in front of another door.  How are you going to move the bear taunt bear The bear has moved from the door.  You can go through it now.  open door This room is full of gold.  How much do you take asf Man learn to type number.  Good job Extra Credit 1.  Draw map of the game and how you flow through it.  Fix all of your mistakes including spelling mistakes.  Write comments for the functions you do not understand.  Remember doc comments Add more to the game.  What can you do to both simplify and expand it.  ae Bb The goldroom has weird way of getting you to type number.  What are all the bugs in this way of doing it Can you make it better than just checking if or are in the number Look at how int works for clues.  What You Should See 107 Learn Python The Hard Way Release 2. 0 108 Exercise 35 Branches and Functions Exercise 36 Designing and Debugging Now that you know ifstatements Im going to give you some rules for forloops and whileloops that will keep you out of trouble.  also going to give you some tips on debug ging so that you can figure out problems with your program.  Finally you are going to design similar little game as in the last exercise but with slight twist.  Rules For IfStatements 1.  Every ifstatement must have an else.  2.  If this else should never be run because it doesnt make sense then you must use die function in the else that prints out an error message and dies just like we did in the last exercise.  This will find many errors.  3.  Never nest ifstatements more than deep and always try to do them deep.  This means if you put an if in an if then you should be looking to move that second if into another function.  4.  Treat ifstatements like paragraphs where each if elif else grouping is like set of sentences.  Put blank lines before and after.  5.  Your boolean tests should be simple.  If they are complex move their calculations to variables earlier in your function and use good name for the variable.  If you follow these simple rules you will start writing better code than most programmers.  Go back to the last exercise and see if followed all of these rules.  If not fix it.  Warning Never be slave to the rules in real life.  For training purposes you need to follow these rules to make your mind strong but in real life sometimes these rules are just stupid.  If you think tule is stupid try not using it.  109 Learn Python The Hard Way Release 2. 0 Rules For Loops 1.  Use whileloop only to loop forever and that means probably never.  This only applies to Python other languages are different.  2.  Use forloop for all other kinds of looping especially if there is fixed or limited number of things to loop over.  Tips For Debugging 1.  Do not use debugger.  debugger is like doing fullbody scan on sick person.  You do not get any specific useful information and you find whole lot of information that doesnt help and is just confusing.  2.  The best way to debug program is to use print to print out the values of variables at points in the program to see where they go wrong.  3.  Make sure parts of your programs work as you work on them.  Do not write massive files of code before you try to run them.  Code little run little fix little.  Homework Now write similar game to the one that created in the last exercise.  It can be any kind of game you want in the same flavor.  Spend week on it making it as interesting as possible.  For extra credit use lists functions and modules remember those from Ex.  13 as much as possible and find as many new pieces of Python as you can to make the game work.  There is one catch though write up your idea for the game first.  Before you start coding you must write up map for your game.  Create the rooms monsters and traps that the player must go through on paper before you code.  Once you have your map try to code it up.  If you find problems with the map then adjust it and make the code match.  One final word of advice Every programmer becomes paralyzed by irrational fear starting new large project.  They then use procrastination to avoid confronting this fear and end up not getting their program working or even started.  do this.  Everyone does this.  The best way to avoid this is to make list of things you should do and then do them one at time.  Just start doing it do small version make it bigger keep list of things to do and do them.  110 Exercise 36 Designing and Debugging Exercise 37 Symbol Review Its time to review the symbols and Python words you know and to try to pick up few more for the next few lessons.  What Ive done here is written out all the Python symbols and keywords that are important to know.  In this lesson take each keyword and first try to write out what it does from memory.  Next search online for it and see what it really does.  It may be hard because some of these are going to be impossible to search for but keep trying.  If you get one of these wrong from memory write up an index card with the correct definition and try to correct your memory.  If you just didnt know about it write it down and save it for later.  Finally use each of these in small Python program or as many as you can get done.  The key here is to find out what the symbol does make sure you got it right correct it if you do not then use it to lock it in.  Keywords and del from not while as elif global or with assert 111 Learn Python The Hard Way Release 2. 0 else if pass yield break except import print class exec ein raise continue finally is return def for lambda Gry Data Types For data types write out what makes up each one.  For example with strings write out how you create string.  For numbers write out few numbers.  True False None strings numbers floats 112 Exercise 37 Symbol Review Learn Python The Hard Way Release 2. 0 lists String Escapes Sequences For string escape sequences use them in strings to make sure they do what you think they do.  VA el en er String Formats Same thing for string formats use them in some strings to know what they do.  ole oO.  ole Kh ole ole Oo ole ole OI ole rs ole ole yooh String Escapes Sequences 113 Learn Python The Hard Way Release 2. 0 Operators oe ole ole ol ol Some of these may be unfamiliar to you but look them up anyway.  Find out what they do and if you still cant figure it out save it for later.  114 Exercise 37 Symbol Review Learn Python The Hard Way Release 2. 0 Spend about week on this but if you finish faster thats great.  The point is to try to get coverage on all these symbols and make sure they are locked in your head.  Whats also important is to find out what you do not know so you can fix it later.  Operators 115 Learn Python The Hard Way Release 2. 0 116 Exercise 37 Symbol Review Exercise 38 Reading Code Now go find some Python code to read.  You should be reading any Python code you can and trying to steal ideas that you find.  You actually should have enough knowledge to be able to read but maybe not understand what the code does.  What Im going to teach you in this lesson is how to apply things you have learned to understand other peoples code.  First print out the code you want to understand.  Yes print it out because your eyes and brain are more used to reading paper than computer screens.  Make sure you only print few pages at time.  Second go through your printout and take notes of the following 1.  Functions and what they do.  2.  Where each variable is first given value.  3.  Any variables with the same names in different parts of the program.  These may be trouble later.  4.  Any ifstatements without else clauses.  Are they right 5.  Any whileloops that might not end.  6.  Finally any parts of code that you cant understand for whatever reason.  Third once you have all of this marked up try to explain it to yourself by writing comments as you go.  Explain the functions how they are used what variables are involved anything you can to figure this code out.  Lastly on all of the difficult parts trace the values of each variable line by line function by function.  In fact do another printout and write in the margin the value of each variable that you need to trace.  Once you have good idea of what the code does go back to the computer and read it again to see if you find new things.  Keep finding more code and doing this until you do not need the printouts anymore.  Extra Credit 1.  Find out what flow chart is and write few.  2.  If you find errors in code you are reading try to fix them and send the author your changes.  117 Learn Python The Hard Way Release 2. 0 3.  Another technique for when you are not using paper is to put comments with your notes in the code.  Sometimes these could become the actual comments to help the next person.  118 Exercise 38 Reading Code Exercise 39 Doing Things To Lists You have learned about lists.  When you learned about whilelLoops you appended numbers to the end of list and printed them out.  There was also extra credit where you were supposed to find all the other things you can do to lists in the Python documentation.  That was while back so go find in the book where you did that and review if you do not know what Im talking about.  Found it Remember it Good.  When you did this you had list and you called the function append on it.  However you may not really understand whats going on so lets see what we can do to lists and how doing things with on them works.  When you type Python code that reads mystuff. append hello you are actually setting off chain of events inside Python to cause something to happen to the myst uf list.  Heres how it works 1.  Python sees you mentioned mystuff and looks up that variable.  It might have to look backwards to see if you created with look and see if it is function argument or maybe its global variable.  Either way it has to find the mystuff first.  2.  Once it finds mystuff it then hits the .  period operator and starts to look at variables that are part of mystuff.  Since mystuf is list it knows that mystuff has bunch of functions.  3.  It then hits append and compares the name append to all the ones that mystuff says it owns.  If append is in there it is then it grabs that to use.  4.  Next Python sees the parenthesis and realizes Oh hey this should be function.  At this point it calls aka runs executes the function just like normally but instead it calls the function with an extra argument.  5.  That extra argument is . . .  mystuff know weird right But thats how Python works so its best to just remember it and assume thats alright.  What happens then at the end of all this is function call that looks like append mystuff hello instead of what you read which ismystuff. appendhello.  For the most part you do not have to know that this is going on but it helps when you get error messages from python like this python Python 2. 65 2063 Apr 16 2010 41 GCC 4. 4. 3 on linux2 119 Learn Python The Hard Way Release 2. 0 Type help copyright credits or license for more information.  class Thingobject def testhi print hi Thing a. test hello Traceback most recent call last File stdin line in module TypeError test takes exactly argument given Sa What was all that Well this is me typing into the Python shell and showing you some magic.  You havent seen class yet but well get into those later.  For now you see how Python said test takes exactly argument given.  If you see this it means that python changed a. test hello totest hello and that somewhere someone messed up and didnt add the argument for a.  That might be lot to take in but were going to spend few exercises getting this concept firm in your brain.  To kick things off heres an exercise that mixes strings and lists for all kinds of fun.  tenthings Apples Oranges Crows Telephone Light Sugar print Wait theres net 10 things in that.  11st lets fix that.  stuff tenthings. split morestuff Day Night Song Frisbee Cern Banana Girl Boy while lenstuff 10 nextone morestuff. pop print Adding nextone stuff. appendnextone print Theres items now.  lenstuff print There we go stuff print Lets do some things with stuff.  print stuff1 print stuff1 whoa fancy print stuff. pop print . joinstuff what cool print . joinstuff35 super stellar 120 Exercise 39 Doing Things To Lists Learn Python The Hard Way Release 2. 0 What You Should See python ex39. py Wait theres not 10 things in that list lets fix that.  Adding Boy Theres items now.  Adding Girl Theres items now.  Adding Banana Theres items now.  Adding Corn Theres 10 items now.  There we go Apples Oranges Crows Telephone Light Boy Girl Banana Corn Lets do some things with stuff.  Oranges Corn Corn Apples Oranges Crows Telephone Light Sugar Boy Girl Banana TelephoneLight Extra Credit Sugar 1.  Take each function that is called and go through the steps outlined above to translate them to what Python does.  For example . jointhings isjoin things.  2.  Translate these two ways to view the function calls in English.  For example jointhings reads as Join things with between them.  Meanwhile join things means Call join with and things.  Understand how they are really the same thing.  .  Go read about Object Oriented Programming online.  Confused Yeah was too.  Do not worry.  You will learn enough to be dangerous and you can slowly learn more later.  .  Read up on what class is in Python.  Do not read about how other languages use the word class.  That will only mess you up.  .  Whats the relationship between dir something and the class of something .  If you do not have any idea what Im talking about do not worry.  Programmers like to feel smart so they invented Object Oriented Programming named it OOP and then used it way too much.  If you think thats hard you should try to use functional programming.  What You Should See 121 Learn Python The Hard Way Release 2. 0 122 Exercise 39 Doing Things To Lists Exercise 40 Dictionaries Oh Lovely Dictionaries Now have to hurt you with another container you can use because once you learn this container massive world of ultracool will be yours.  It is the most useful container ever the dictionary.  Python calls them dicts other languages call them hashes.  tend to use both names but it doesnt matter.  What does matter is what they do when compared to lists.  You see list lets you do this things bt print things1 things1 print things1 print things Zi dJ You can use numbers to index into list meaning you can use numbers to find out whats in lists.  You should know this by now but what dict does is let you use anything not just numbers.  Yes dict associates one thing to another no matter what it is.  Take look stuff name Zed age 36 height 6122 print stuffname Zed print stuffage 36 print stuffheight 74 stuffeity San.  Francisco print stuffcity San Francisco You will see that instead of just numbers were using strings to say what we want from the stuff dictionary.  We can also put new things into the dictionary with strings.  It doesnt have to be strings 123 Learn Python The Hard Way Release 2. 0 though we can also do this stuff1 Wow stuff2 Neato print stuff1 Wow print stuff2 Neato print stuff city San Francisco Neato name Zed Wow age 36 height 74 In this one just used numbers.  could use anything.  Well almost but just pretend you can use anything for now.  Of course dictionary that you can only put things in is pretty stupid so heres how you delete things with the del keyword del stuffcity del stuff1 del stuff2 stuff name Zed age 36 height 74 Sos We ll now do an exercise that you must study very carefully.  want you to type this exercise in and try to understand whats going on.  It is very interesting exercise that will hopefully make big light turn on in your head very soon.  eltzles CAs San Francisco MI Detxvoeit FL Jacksonville citiesNY New York citiesOR Portland def findcitythemap state if state in themap return themapstate else return Not found.  ok pay attention citiesfind findcity while True print State ENTER to quit state rawinput 124 Exercise 40 Dictionaries Oh Lovely Dictionaries 20 21 22 23 24 Learn Python The Hard Way Release 2. 0 if not state break this line is the most important ever study cityfound citiesfind cities state print cityfound Warning Notice how use themap instead of map Thats because Python has function called map so if you try to use that you can have problems later.  What You Should See python ex40. py State ENTER to quit CA San Francisco State ENTER to quit FL Jacksonville State ENTER to quit Not found.  State ENTER to quit OR Portland State ENTER to quit VT Not found.  State ENTER to quit Extra Credit 1.  Go find the Python documentation for dictionaries a. k. a.  dicts dict and try to do even more things to them.  2.  Find out what you cant do with dictionaries.  big one is that they do not have order so try playing with that.  3.  Try doing forloop over them and then try the items function ina forloop.  What You Should See 125 Learn Python The Hard Way Release 2. 0 126 Exercise 40 Dictionaries Oh Lovely Dictionaries Exercise 41 Gothons From Planet Percal 25 Did you figure out the secret of the function in the dict from the last exercise Can you explain it to yourself ll explain it and you can compare your explanation with mine.  Here are the lines of code we are talking about citiesfind findcity cityfound citiesfind cities state Remember that functions can be variables too.  The def findcity just makes another variable name in your current module that you can use anywhere.  In this code first we are putting the function findcity into the dict cities as find.  This is the same as all the others where we set states to some cities but in this case its actually the function.  Alright so once we know that findcity is in the dict at ind that means we can do work with it.  The 2nd line of code used later in the previous exercise can be broken down like this 1.  Python sees cit yfound and knows we want to make new variable.  2.  It then reads cities and finds that variable its dict.  3.  Then theres find which will index into the cities dict and pull out whatever is at find.  4.  What is at find is our function findcity so Python then knows its got function and when it hits it does the function call.  5.  The parameters cities state are passed to this function findcity and it runs because its called.  6.  findcity then tries to look up states inside cities and returns what it finds or message saying it didnt find anything.  7.  Python takes what findcity returned and finally that is what is assigned to cit yfound all the way at the beginning.  Heres trick.  Sometimes these things read better in English if you read the code backwards.  This is how would do it for that same line remember backwards 127 Learn Python The Hard Way Release 2. 0 1.  state and city are. . .  2.  passed as parameters to. . .  3.  function at. . .  4.  find inside. . .  5.  the dict cities. . .  6.  and finally assigned to cit yfound.  Heres another way to read it this time insideout.  1.  Find the center item of the expression in this case find.  2.  Go counterclockwise and you have dict cities so this finds the element find in cities.  3.  That gives us function.  Keep going counterclockwise and you get to the parameters.  4.  The parameters are passed to the function and that returns result.  Go counterclockwise again.  5.  Finally we are at the cityfound assignment and we have our end result.  After decades of programming dont even think about these three ways to read code.  just glance at it and know what it means.  can even glance at whole screen of code and all the bugs and errors jump out at me.  That took an incredibly long time and quite bit more study than is sane.  To get that way learned these three ways of reading most any programming language 1.  Front to back.  2.  Back to front.  3.  Counterclockwise.  Try them out when you have difficult statement to figure out.  Now type in your next exercise then go over it.  This one is gonna be fun.  rom sys import exit from random import randint def death quips You died.  You kinda suck at this.  Nice job you died . . . jackass.  Such luser. .  TI have small puppy thats better at this.  10 print quipsrandint0 lenquips1 ul exit def centralcorridor 15 print The Gothons of Planet Percal 25 have invaded your ship and destroyed 16 print your entire crew.  You are the last surviving member and your last 128 Exercise 41 Gothons From Planet Percal 25 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 Learn Python The Hard Way Release 2. 0 def costume print mission is to get the neutron destruct bomb from the Weapons Armory print put it in the bridge and blow the ship up after getting into an print escape pod.  print print Youre running down the central corridor to the Weapons Armory when print Gothon jumps out red scaly skin dark grimy teeth and evil clown print flowing around his hate filled body.  Hes blocking the door to the print Armory and about to pull weapon to blast you.  action rawinput if action shoot print Quick on the draw you yank out your blaster and fire it at the Gothon.  print His clown costume is flowing and moving around his body which throws print off your aim.  Your laser hits his costume but misses him entirely.  This print completely ruins his brand new costume his mother bought him which print print you are dead.  Then he eats you.  return death elif action dodge print Like world class boxer you dodge weave slip and slide right print as the Gothons blaster cranks laser past your head.  print In the middle of your artful dodge your foot slips and you print bang your head on the metal wall and pass out.  print You wake up shortly after only to die as the Gothon stomps on print your head and eats you.  return death elif action tell joke print Lucky for you they made you learn Gothon insults in the academy.  print You tell the one Gothon joke you know print Lbhe zbgure vf fb sng jura fur fvgf nebhaq gur ubhfr fur fvgf nebhaq gur ubhfr.  print The Gothon stops tries not to laugh then busts out laughing and cant move.  print While hes laughing you run up and shoot him square in the head print putting him down then jump through the Weapon Armory door.  return laserweaponarmory else print DOES NOT COMPUTE return centralcorridor laserweaponarmory print print print print print You do dive roll into the Weapon Armory crouch and scan the room for more Gothons that might be hiding.  Its dead quiet too quiet.  You stand up and run to the far side of the room and find the neutron bomb in its container.  Theres keypad lock on the box and you need the code to get the bomb out.  If you get the code 129 makes him fly into an insane rage and blast you repeatedly in the face until 65 67 68 69 70 71 72 73 74 vi 76 71 78 79 80 81 82 83 84 85 86 87 88 89 90 OL 92 93 94 95 96 97 98 Learn Python The Hard Way Release 2. 0 def print wrong 10 times then the lock closes forever and you cant print get the bomb.  The code is digits.  code Sddd randint19 randint19 randint19 guess rawinput keypad guesses while guess code and guesses 10 print BZZZZEDDD guesses guess rawinputkeypad if guess code print The container clicks open and the seal breaks letting gas out.  print You grab the neutron bomb and run as fast as you can to the print bridge where you must place it in the right spot.  return thebridge else print The lock buzzes one last time and then you hear sickening print melting sound as the mechanism is fused together.  print You decide to sit there and finally the Gothons blow up the print ship from their ship and you die.  return death thebridge print You print und print tak print clo print wea print arm action if action print print print print print print return elif actio print print print print burst onto the Bridge with the netron destruct bomb er your arm and surprise Gothons who are trying to control of the ship.  Each of them has an even uglier wn costume than the last.  They havent pulled their pons out yet as they see the active bomb under your and dont want to set it off.  awinput throw the bomb In panic you throw the bomb at the group of Gothons and make leap for the door.  Right as you drop it Gothon shoots you right in the back killing you.  As you die you see another Gothon frantically try to disarm the bomb.  You die knowing they will probably blow up when it goes off.  death slowly place the bomb You point your blaster at the bomb under your arm and the Gothons put their hands up and start to sweat.  You inch backward to the door open it and then carefully place the bomb on the floor pointing your blaster at it.  130 Exercise 41 Gothons From Planet Percal 25 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 145 146 147 148 149 150 151 153 154 155 156 157 158 159 160 Learn Python The Hard Way Release 2. 0 def print You then jump back through the door punch the close button print and blast the lock so the Gothons cant get out.  print Now that the bomb is placed you run to the escape pod to print.  get.  off this tin can.  return escapepod else print DOES NOT COMPUTE return thebridge escapepod print You rush through the ship desperately trying to make it to print the escape pod before the whole ship explodes.  It seems like print hardly any Gothons are on the ship so your run is clear of print interference.  You get to the chamber with the escape pods and print now need to pick one to take.  Some of them could be damaged print but you dont have time to look.  Theres pods which one print do you take goodpod randint 15 guess rawinputpod if intguess goodpod print You jump into pod and hit the eject button.  guess print The pod escapes out into the void of space then print implodes as the hull ruptures crushing your body print into jam jelly.  return death else print You jump into pod and hit the eject button.  guess print The pod easily slides out into space heading to print the planet below.  As it flies to the planet you look print back and see your ship implode then explode like print bright star taking out the Gothon ship at the same print time.  You won exit ROOMS death death centralcorridor centralcorridor laserweaponarmory laserweaponarmory def thebridge thebridge escapepod escapepod runnermap start 131 161 162 163 165 166 167 168 Learn Python The Hard Way Release 2. 0 next start while True room mapnext print next room runner ROOMS centralcorridor Its lot of code but go through it make sure it works play it.  What You Should See Heres me playing the game.  python exex4l. py The Gothons of Planet Percal 25 have invaded your ship and destroyed your entire crew.  You are the last surviving member and your last mission is to get the neutron destruct bomb from the Weapons Armory put it in the bridge and blow the ship up after getting into an escape pod.  Youre running down the central corridor to the Weapons Armory when Gothon jumps out red scaly skin dark grimy teeth and evil clown costume flowing around his hate filled body.  Hes blocking the door to the Armory and about to pull weapon to blast you.  dodge Like world class boxer you dodge weave slip and slide right as the Gothons blaster cranks laser past your head.  In the middle of your artful dodge your foot slips and you bang your head on the metal wall and pass out.  You wake up shortly after only to die as the Gothon stomps on your head and eats you.  Such luser.  learnpythehardway python exex4l. py The Gothons of Planet Percal 25 have invaded your ship and destroyed your entire crew.  You are the last surviving member and your last mission is to get the neutron destruct bomb from the Weapons Armory put it in the bridge and blow the ship up after getting into an escape pod.  132 Exercise 41 Gothons From Planet Percal 25 Learn Python The Hard Way Release 2. 0 Youre running down the central corridor to the Weapons Armory when Gothon jumps out red scaly skin dark grimy teeth and evil clown costume flowing around his hate filled body.  Hes blocking the door to the Armory and about to pull weapon to blast you.  tell joke Lucky for you they made you learn Gothon insults in the academy.  You tell the one Gothon joke you know Lbhe zbgure vf fb sng jura fur fvgf nebhaq gur ubhfr fur fvgf nebhag gur ubhfr.  The Gothon stops tries not to laugh then busts out laughing and cant move.  While hes laughing you run up and shoot him square in the head putting him down then jump through the Weapon Armory door.  You do dive roll into the Weapon Armory crouch and scan the room for more Gothons that might be hiding.  Its dead quiet too quiet.  You stand up and run to the far side of the room and find the neutron bomb in its container.  Theres keypad lock on the box and you need the code to get the bomb out.  If you get the code wrong 10 times then the lock closes forever and you cant get the bomb.  The code is digits.  keypad 123 BZZZZEDDD keypad 234 BZZZZEDDD keypad 345 BZZZZEDDD keypad 456 BZZZZEDDD keypad 567 BZZZZEDDD keypad 678 BZZZZEDDD keypad 789 BZZZZEDDD keypad 384 BZZZZEDDD keypad 764 BZZZZEDDD keypad 354 BZZZZEDDD keypad 263 The lock buzzes one last time and then you hear sickening melting sound as the mechanism is fused together.  You decide to sit there and finally the Gothons blow up the ship from their ship and you die.  What You Should See 133 Learn Python The Hard Way Release 2. 0 You died.  You kinda suck at this.  Extra Credit .  Explain how returning the next room works.  .  Add cheat codes to the game so you can get past the more difficult rooms.  .  Instead of having each function print itself learn about doc string style comments.  Write the room description as doc comments and change the runner to print them.  .  Once you have doc comments as the room description do you need to have the function prompt even Have the runner prompt the user and pass that in to each function.  Your functions should just be ifstatements printing the result and returning the next room.  .  This is actually small version of something called finite state machine.  Read about them.  They might not make sense but try anyway.  134 Exercise 41 Gothons From Planet Percal 25 Exercise 42 Gothons Are Getting Classy While its fun to put functions inside of dictionaries youd think thered be something in Python that does this for you.  There is the class keyword.  Using class is how you create an even more awesome dict with functions than the one you made in the last exercise.  Classes have all sorts of powerful features and uses that could never go into in this book.  Instead youll just use them like theyre fancy dictionaries with functions.  programming language that uses classes is called Object Oriented Programming.  This is an old style of programming where you make things and you tell those things to do work.  Youve been doing lot of this.  whole lot.  You just didnt know it.  Remember when you were doing this stuff Test This Out print . joinstuff You were actually using classes.  The variable stuff is actually list class.  The . joinstuff is calling the join function of the string just an empty space is also class string class.  Its all classes Well and objects but lets just skip that word for now.  Youll learn what those are after you make some classes.  How do you make classes Very similar to how you made the ROOMS dict but easier class TheThingobject def initself self. number def somefunctionself print got called.  def addmeupself more self. number more return self. number two different things TheThing 135 Learn Python The Hard Way Release 2. 0 TheThing a. somefunction b. somefunction print a. addmeup 20 print a. addmeup 20 print b. addmeup 30 print b. addmeup 30 print a. number print b. number Warning Alright this is where you start learning about warts.  Python is an old language with lots of really ugly obnoxious pieces that were bad decisions.  To cover up these bad decisions they make new bad decisions and then yell at people to adopt the new bad decisions.  The phrase class TheThing object is an example of bad decision.  wont get into it right here but dont worry about why your class has to have object after its name.  Just always type it this way or other Python programmers will yell at you.  Well get into why later.  You see that self in the parameters You know what that is Thats right its the extra parameter that Python creates so you can type a. somefunction and then it will translate that to really be somefunctiona.  Why use self Your function has no idea what you are calling any one instance of TheThing or another you just use generic name self.  That way you can write your function and it will always work.  You could actually use another name rather than se1f but then every Python programmer on the planet would hate you so dont.  Only jerks change things like that and taught you better.  Be nice to people who have to read what you write because ten years later all code is horrible.  Next see the init function That is how you set up Python class with internal variables.  You can set them on self with the .  period just like Ill show you here.  See also how we then use this in addmeup later which lets you add to the sel f. number you created.  Later you can see how we use this to add to our number and print it.  Classes are very powerful so you should read everything you can about them and play with them.  You actually know how to use them you just have to try it.  In fact want to play some guitar right now so Im not going to give you an exercise to type.  Youre going to write an exercise using classes.  Heres how wed do exercise 41 using classes instead of the thing we created from sys import exit from random import randint class Gameobject def initself start self. quips 136 Exercise 42 Gothons Are Getting Classy 20 21 22 23 24 22 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 47 48 49 50 51 52 53 54 55 Learn Python The Hard Way Release 2. 0 def def def You died.  You kinda suck at this.  Your mom would be proud.  If she were smarter.  Such.  luiser.  have small puppy thats better at this.  self. start start playself next self. start while True prank Sg room getattrself next next room deathself print self. quipsrandint0 lenself. quips1 exit centralcorridorself print The Gothons of Planet Percal 25 have invaded your ship and destroyed print your entire crew.  You are the last surviving member and your last print mission is to get the neutron destruct bomb from the Weapons Armory print put it in the bridge and blow the ship up after getting into an print escape pod.  print print Youre running down the central corridor to the Weapons Armory when print Gothon jumps out red scaly skin dark grimy teeth and evil clown costume print flowing around his hate filled body.  Hes blocking the door to the print Armory and about to pull weapon to blast you.  action rawinput if action sShoot print Quick on the draw you yank out your blaster and fire it at the Gothon.  print His clown costume is flowing and moving around his body which throws print off your aim.  Your laser hits his costume but misses him entirely.  print completely ruins his brand new costume his mother bought him which print makes him fly into an insane rage and blast you repeatedly in the face until print you are dead.  Then he eats you.  return death elif action dodge print Like world class boxer you dodge weave slip and slide right print as the Gothons blaster cranks laser past your head.  print In the middle of your artful dodge your foot slips and you print bang your head on the metal wall and pass out.  137 56 57 58 59 61 62 63 65 67 68 69 70 2B 74 75 76 71 78 79 80 81 82 83 84 85 86 87 88 89 OL 92 93 94 95 96 97 98 103 Learn Python The Hard Way Release 2. 0 print You wake up shortly after only to die as the Gothon stomps on print your head and eats you.  return death elif action tell joke print Lucky for you they made you learn Gothon insults in the academy.  print You tell the one Gothon joke you know print Lbhe zbgure vf fb sng jura fur fvgf nebhaq gur ubhfr fur fvgf nebhaq print The Gothon stops tries not to laugh then busts out laughing and cant print While hes laughing you run up and shoot him square in the head print putting him down then jump through the Weapon Armory door.  return laserweaponarmory else print DOES NOT COMPUTE return centralcorridor def laserweaponarmory self print You print for print You do dive roll into the Weapon Armory crouch and scan the room more Gothons that might be hiding.  Its dead quiet too quiet.  stand up and run to the far side of the room and find the print neutron bomb in its container.  Theres keypad lock on the box print and you need the code to get the bomb out.  If you get the code print wrong 10 times then the lock closes forever and you cant print get the bomb.  The code is digits.  code Sddsd randint 19 randint19 randint 19 guess rawinputkeypad guesses while guess code and guesses 10 print BZZZZEDDD guesses guess rawinput keypad if guess code print The container clicks open and the seal breaks letting gas out.  print You grab the neutron bomb and run as fast as you can to the print bridge where you must place it in the right spot.  return thebridge else print The lock buzzes one last time and then you hear sickening print melting sound as the mechanism is fused together.  print You decide to sit there and finally the Gothons blow up the print Ship from their ship and you die.  return death def thebridgeself 138 Exercise 42 Gothons Are Getting Classy 110 lll 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 145 146 147 148 149 150 151 Learn Python The Hard Way Release 2. 0 def print You burst onto the Bridge with the netron destruct bomb print under your arm and surprise Gothons who are trying to print take control of the ship.  Each of them has an even uglier print clown costume than the last.  They havent pulled their print weapons out yet as they see the active bomb under your print arm and dont want to set it off.  action rawinput if action throw the bomb print In panic you throw the bomb at the group of Gothons print and make leap for the door.  Right as you drop it print Gothon shoots you right in the back killing you.  print As you die you see another Gothon frantically try to disarm print the bomb.  You die knowing they will probably blow up when print it goes off.  return death elif action slowly place the bomb print You point your blaster at the bomb under your arm print and the Gothons put their hands up and start to sweat.  print You inch backward to the door open it and then carefully print place the bomb on the floor pointing your blaster at it.  print You then jump back through the door punch the close button print and blast the lock so the Sothons canc get otc.  print Now that the bomb is placed you run to the escape pod to print get off this tin ean.  return escapepod else print.  DOES NOT COMPUTE return thebridge escapepodself print You rush through the ship desperately trying to make it to print the escape pod before the whole ship explodes.  It seems like print hardly any Gothons are on the ship so your run is clear of print interference.  You get to the chamber with the escape pods and print now need to pick one to take.  Some of them could be damaged print but you dont have time to look.  Theres pods which one print do you take goodpod randint 15 guess rawinputpod if intguess goodpod print You jump into pod and hit the eject button.  guess print The pod escapes out into the void of space then 139 152 153 154 155 156 157 158 159 161 162 163 165 166 Learn Python The Hard Way Release 2. 0 print implodes as the hull ruptures crushing your body print into jam jelly.  return death else print You jump into pod and hit the eject button.  guess print The pod easily slides out into space heading to print the planet below.  As it flies to the planet you look print back and see your ship implode then explode like print bright star taking out the Gothon ship at the same print time.  You wen exit agame Game centralcorridor agame. play What You Should See The output from this version of the game should be exactly the same as the previous version.  In fact youll notice that some of the code is nearly the same.  Compare this new version of the game with the last one so you understand the changes that were made.  Key things to really get are 1.  2.  ww ok Oe How you madeaclass Game object and put functions inside it.  How init isa special intialization method that sets up important variables.  How you added functions to the class by indenting them so they were deeper under the class keyword.  This is important so study carefully how indentation creates the class structure.  How you indented again to put the contents of the functions under their names.  How colons are being used.  The concept of self and how its used ininit play and death.  Go find out what getattr does inside play so that you understand whats going on with the operation of play.  In fact try doing this by hand inside Python to really get it.  How Game was created at the end and then told to play and how that got everything started.  Extra Credit 1.  2.  Find out what the dict is and figure out how to get at it.  Add some rooms to make sure you know how to work with class.  140 Exercise 42 Gothons Are Getting Classy Learn Python The Hard Way Release 2. 0 3.  Create twoclass version of this where one is the Map and the other is the Engine.  Hint play goes in the Engine.  Extra Credit 141 Learn Python The Hard Way Release 2. 0 142 Exercise 42 Gothons Are Getting Classy Exercise 43 You Make Game You need to start learning to feed yourself.  Hopefully as you have worked through this book you have learned that all the information you need is on the internet you just have to go search for it.  The only thing you have been missing are the right words and what to look for when you search.  Now you should have sense of it so its about time you struggled through big project and tried to get it working.  Here are your requirements 1.  Make different game from the one made.  2.  Use more than one file and use import to use them.  Make sure you know what that is.  3.  Use one class per room and give the classes names that fit their purpose.  Like GoldRoom KoiPondRoom.  4.  Your runner will need to know about these rooms so make class that runs them and knows about them.  Theres plenty of ways to do this but consider having each room return what room is next or setting variable of what room is next.  Other than that leave it to you.  Spend whole week on this and make it the best game you can.  Use classes functions dicts lists anything you can to make it nice.  The purpose of this lesson is to teach you how to structure classes that need other classes inside other files.  Remember Im not telling you exactly how to do this because you have to do this yourself.  Go figure it out.  Programming is problem solving and that means trying things experimenting failing scrapping your work and trying again.  When you get stuck ask for help and show people your code.  If they are mean to you ignore them focus on the people who are not mean and offer to help.  Keep working it and cleaning it until its good then show it some more.  Good luck and see you in week with your game.  143 Learn Python The Hard Way Release 2. 0 144 Exercise 43 You Make Game Exercise 44 Evaluating Your Game In this exercise you will evaluate the game you just made.  Maybe you got partway through it and you got stuck.  Maybe you got it working but just barely.  Either way were going to go through bunch of things you should know now and make sure you covered them in your game.  Were going to study how to properly format class common conventions in using classes and lot of textbook knowledge.  Why would have you try to do it yourself and then show you how to do it right From now on in the book Im going to try to make you selfsufficient.  ve been holding your hand mostly this whole time and cant do that for much longer.  Im now instead going to give you things to do have you do them on your own and then give you ways to improve what you did.  You will struggle at first and probably be very frustrated but stick with it and eventually you will build mind for solving problems.  You will start to find creative solutions to problems rather than just copy solutions out of textbooks.  Function Style All the other rules ve taught you about how to make function nice apply here but add these things For various reasons programmers call functions that are part of classes methods.  Its mostly marketing but just be warned that every time you say function theyll annoyingly correct you and say method.  If they get too annoying just ask them to demonstrate the mathematical basis that determines how method is different from function and they ll shut up.  When you work with classes much of your time is spent talking about making the class do things.  Instead of naming your functions after what the function does instead name it as if its com mand you are giving to the class.  Same as pop is saying Hey list pop this off.  It isnt called removefromendoflist because even though thats what it does thats not command to list.  Keep your functions small and simple.  For some reason when people start learning about classes they forget this.  145 Learn Python The Hard Way Release 2. 0 Class Style Your class should use camel case like SuperGoldFactory rather than supergoldfactory.  Try not to do too much in yourinit functions.  It makes them harder to use.  Your other functions should use underscore format so write myawesomehair and not myawesomehair or MyAwesomeHair.  Be consistent in how you organize your function arguments.  If your class has to deal with users dogs and cats keep that order throughout unless it really doesnt make sense.  If you have one function takes dog cat user andthe other takes user cat dog itll be hard to use.  Try not to use variables that come from the module or globals.  They should be fairly selfcontained.  foolish consistency is the hobgoblin of little minds.  Consistency is good but foolishly following some idiotic mantra because everyone else does is bad style.  Think for yourself.  Always always have class Name object format or else you will be in big trouble.  Code Style Give your code vertical space so people can read it.  You will find some very bad programmers who are able to write reasonable code but who do not add any spaces.  This is bad style in any language because the human eye and brain use space and vertical alignment to scan and separate visual elements.  Not having space is the same as giving your code an awesome camouflage paint job.  If you cant read it out loud its probably hard to read.  If you are having problem making something easy to use try reading it out loud.  Not only does this force you to slow down and really read it but it also helps you find difficult passages and things to change for readability.  Try to do what other people are doing in Python until you find your own style.  Once you find your own style do not be jerk about it.  Working with other peoples code is part of being programmer and other people have really bad taste.  Trust me you will probably have really bad taste too and not even realize it.  If you find someone who writes code in style you like try writing something that mimics their style.  146 Exercise 44 Evaluating Your Game Learn Python The Hard Way Release 2. 0 Good Comments There are programmers who will tell you that your code should be readable enough that you do not need comments.  Theyll then tell you in their most official sounding voice that Ergo you should never write comments.  Those programmers are either consultants who get paid more if other people cant use their code or incompetents who tend to never work with other people.  Ignore them and write comments.  When you write comments describe why you are doing what you are doing.  The code already says how but why you did things the way you did is more important.  When you write doc comments for your functions make the comments documentation for some one who will have to use your code.  You do not have to go crazy but nice little sentence about what someone does with that function helps lot.  Finally while comments are good too many are bad and you have to maintain them.  Keep your comments relatively short and to the point and if you change function review the comment to make sure its still correct.  Evaluate Your Game want you now to pretend you are me.  Adopt very stern look print out your code and take red pen and mark every mistake you find.  Anything from this exercise and from other things you have known.  Once you are done marking your code up want you to fix everything you came up with.  Then repeat this couple of times looking for anything that could be better.  Use all the tricks Pve given you to break your code down into the smallest tiniest little analysis you can.  The purpose of this exercise is to train your attention to detail on classes.  Once you are done with this bit of code find someone elses code and do the same thing.  Go through printed copy of some part of it and point out all the mistakes and style errors you find.  Then fix it and see if your fixes can be done without breaking their program.  want you to do nothing but evaluate and fix code for the week.  Your own code and other peoples.  Itll be pretty hard work but when you are done your brain will be wired tight like boxers hands.  Good Comments 147 Learn Python The Hard Way Release 2. 0 148 Exercise 44 Evaluating Your Game Exercise 45 IsA HasA Objects and Classes An important concept that you have to understand is the difference between Class and an Object.  The problem is there is no real difference between class and an object.  They are actually the same thing at different points in time.  will demonstrate by Zen koan What is the difference between Fish and Salmon Did that question sort of confuse you Really sit down and think about it for minute.  mean Fish and Salmon are different but wait they are the same thing right Salmon is kind of Fish so mean its not different.  But at the same time becase Salmon is particular type of Fish and so its actually different from all other Fish.  Thats what makes it Salmon and not Halibut.  So Salmon and Fish are the same but different.  Weird.  This question is confusing because most people do not think about real things this way but they intuitively understand them.  You do not need to think about the difference between Fish and Salmon because you know how they are related.  You know Salmon is kind of Fish and that there are other kinds of Fish without having to understand that.  Lets take it one step further lets say you have bucket full of Salmon and because you are nice person you have decided to name them Frank Joe and Mary.  Now think about this question What is the difference between Mary and Salmon Again this is weird question but its bit easier than the Fish vs.  Salmon question.  You know that Mary is Salmon and so shes not really different.  Shes just specific instance of Salmon.  Joe and Frank are also instances of Salmon.  But what do mean when say instance mean they were created from some other Salmon and now represent real thing that has Salmonlike attributes.  Now for the mind bending idea Fish is Class and Salmon is Class and Mary is an Object.  Think about that for second.  Alright lets break it down real slow and see if you get it.  Fish is Class meaning its not real thing but rather word we attach to instances of things with similar attributes.  Got fins Got gills Lives in water Alright its probably Fish.  Someone with Ph. D.  then comes along and says No my young friend this Fish is actually Salmo salar affectionately known as Salmon.  This professor has just clarified the Fish further and made 149 Learn Python The Hard Way Release 2. 0 new Class called Salmon that has more specific attributes.  Longer nose reddish flesh big lives in the ocean or fresh water tasty Ok probably Salmon.  Finally cook comes along and tells the Ph. D.  No you see this Salmon right here Ill call her Mary and Im going to make tasty fillet out of her with nice sauce.  Now you have this instance of Salmon which also is an instance of Fish named Mary turned into something real that is filling your belly.  It has become an Object.  There you have it Mary is kind of Salmon that is kind of Fish.  Object isa Class isaClass.  How This Looks In Code This is weird concept but to be very honest you only have to worry about it when you make new classes and when you use class.  will show you two tricks to help you figure out whether something is aClass or Object.  First you need to learn two catch phrases isa and hasa.  You use the phrase isa when you talk about objects and classes being related to each other by class relationship.  You use hasa when you talk about objects and classes that are related only because they reference each other.  Now go through this piece of code and replace each comment with replacement comment that says whether the next line represents an isa or hasa relationship and what that relationship is.  In the beginning of the code Ive laid out few examples so you just have to write the remaining ones.  Remember isa is the relationship between Fish and Salmon while hasa is the relationship between Salmon and Gills.  Animal isa object yes sort of confusing look at the extra credit class Animalobject pass class DogAnimal def initself name self. name name class Cat Animal def initself name self. name name class Personobject 150 Exercise 45 IsA HasA Objects and Classes Learn Python The Hard Way Release 2. 0 def initself name 2B 24 self. name name 25 26 Person hasa pet of some kind 21 self. pet None 28 Of OP 30 Class Employee Person 31 32 def initself name salary hmm what is this strange magic 34 super Employee self . init name 35 36 self. salary salary 37 33H OP Class Fishobject 40 pass 41 Class SalmonFish 44 pass 45 Class Halibut Fish 48 pass 49 50.  51 rover isa Dog 5s.  rover DogRover 53 54 oH OP satan Cat Satan 56 5s.  ss mary PersonMary 59 86 fF OP 6.  mary. pet satan 62 63 86 frank EmployeeFrank 120000 65 frank. pet rover 68 860 How This Looks In Code 151 70 71 72 2B 75 76 Learn Python The Hard Way Release 2. 0 flipper Fish crouse Salmon harry Halibut About class Nameobject Remember how was yelling at you to always use class Name object andIcouldnt tell you why Now can tell you because you just learned about the difference between class and an object.  couldnt tell you until now because you would have just been confused and couldnt learn to use the technology.  What happened is Pythons original rendition of class was broken in many serious ways.  By the time they admitted the fault it was too late and they had to support it.  In order to fix the problem they needed some new class style so that the old classes would keep working but you could use the new more correct version.  This is where class isa object comes in.  They decided that they would use the word object lower cased to be the class that you inherit from to make class.  Confusing right class inherits from the class named object to make class but its not an object really its class but do not forget to inherit from object.  Exactly.  The choice of one single word meant that couldnt teach you about this until now.  Now you can try to understand the concept of class that is an object if you like.  However would suggest you do not.  Just completely ignore the idea of old style vs.  new style classes and assume that Python always requires object when you make class.  Save your brain power for something important.  Extra Credit 1.  Research why Python added this strange ob ject class and what that means.  2.  Is it possible to use Class like its an Ob ject 3.  Fill out the animals fish and people in this exercise with functions that make them do things.  See what happens when functions are in base class like Animal vs.  in say Dog.  4.  Find other peoples code and work out all the isa and hasa relationships.  5.  Make some new relationships that are lists and dicts so you can also have hasmany relationships.  6.  Do you think theres such thing as ismany relationship Read about multiple inheritance then avoid it if you can.  152 Exercise 45 IsA HasA Objects and Classes Exercise 46 Project Skeleton This will be where you start learning how to setup good project skeleton directory.  This skeleton directory will have all the basics you need to get new project up and running.  It will have your project layout automated tests modules and install scripts.  When you go to make new project just copy this directory to new name and edit the files to get started.  Skeleton Contents LinuxOSX First create the structure of your skeleton directory with these commands mkdir projects cd projects mkdir skeleton cd skeleton mkdir bin NAME tests docs MMM Ww use directory named projects to store all the various things Im working on.  Inside that directory have my skeleton directory that put the basis of my projects into.  The directory NAME will be renamed to whatever you are calling your projects main module when you use the skeleton.  Next we need to setup some initial files touch NAMEinit. py touch testsinit. py That creates empty Python module directories we can put our code in.  setup. py file we can use to install our project later if we want try from setuptools import setup except ImportError from distutils. core import setup config description My Project Then we need to create 153 Learn Python The Hard Way Release 2. 0 author My Name urls URL te get it at.  downloadurl Where to download it.  authoremail My email.  version Q. L installrequires nose packages NAME seripts .  name projectname setup config Edit this file so that it has your contact information and is ready to go for when you copy it.  Finally you will want simple skeleton file for tests named test sNAMEtests. py from nose. tools import import NAME def setup print SETUP def teardown print TEAR DOWN def testbasic print RAN Installing Python Packages Make sure you have some packages installed that makes these things work.  Heres the problem though.  You are at point where its difficult for me to help you do that and keep this book sane and clean.  There are sO many ways to install software on so many computers that Id have to spend 10 pages walking you through every step and let me tell you am lazy guy.  Rather than tell you how to do it exactly Im going to tell you what you should install and then tell you to figure it out and get it working.  This will be really good for you since it will open whole world of software you can use that other people have released to the world.  Next install the following python packages 1.  pip from httppypi. python. orgpypipip 2.  distribute from httppypi. python. orgpypidistribute 3.  nose from httppypi. python. orgpypinose 4.  virtualenv from httppypi. python. orgpypivirtualenv 154 Exercise 46 Project Skeleton Learn Python The Hard Way Release 2. 0 Do not just download these packages and install them by hand.  Instead see how other people recommend you install these packages and use them for your particular system.  The process will be different for most versions of Linux OSX and definitely different for Windows.  am warning you this will be frustrating.  In the business we call this yak shaving.  Yak shaving is any activity that is mind numblingly irritatingly boring and tedious that you have to do before you can do something else thats more fun.  You want to create cool Python projects but you cant do that until you setup skeleton directory but you cant setup skeleton directory until you install some packages but you cant install packages until you install package installers and you cant install package installers until you figure out how your system installs software in general and so on.  Struggle through this anyway.  Consider it your trialbyannoyance to get into the programmer club.  Every programmer has to do these annoying tedious tasks before they can do something cool.  Testing Your Setup After you get all that installed you should be able to do this nosetests Ran test in 0. 007s OK Pll explain what this nosetests thing is doing in the next exercise but for now if you do not see that you probably got something wrong.  Make sure you put init. py files in your NAME and tests directory and make sure you got testsNAMEtests. py right.  Using The Skeleton You are now done with most of your yak shaving.  Whenever you want to start new project just do this 1.  Make copy of your skeleton directory.  Name it after your new project.  2.  Rename move the NAME module to be the name of your project or whatever you want to call your root module.  .  Edit your setup. py to have all the information for your project.  .  Rename testsNAMEtests. py to also have your module name.  .  Double check its all working using nosetests again.  nH nn HR .  Start coding.  Testing Your Setup 155 Learn Python The Hard Way Release 2. 0 Required Quiz This exercise doesnt have extra credit but quiz you should complete 1.  2.  Read about how to use all of the things you installed.  Read about the setup. py file and all it has to offer.  Warning it is not very wellwritten piece of software so it will be very strange to use.  .  Make project and start putting code into the module then get the module working.  .  Put script in the bin directory that you can run.  Read about how you can make Python script thats runnable for your system.  .  Mention the bin script you created in your setup. py so that it gets installed.  .  Use your setup. py to install your own module and make sure it works then use pip to uninstall It.  156 Exercise 46 Project Skeleton Exercise 47 Automated Testing Having to type commands into your game over and over to make sure its working is annoying.  Wouldnt it be better to write little pieces of code that test your code Then when you make change or add new thing to your program you just run your tests and the tests make sure things are still working.  These automated tests wont catch all your bugs but they will cut down on the time you spend repeatedly typing and running your code.  Every exercise after this one will not havea What You Should See section but instead it will have aWhat You Should Test section.  You will be writing automated tests for all of your code starting now and this will hopefully make you an even better programmer.  wont try to explain why you should write automated tests.  will only say that you are trying to be programmer and programmers automate boring and tedious tasks.  Testing piece of software is definitely boring and tedious so you might as well write little bit of code to do it for you.  That should be all the explanation you need because your reason for writing unit tests is to make your brain stronger.  You have gone through this book writing code to do things.  Now you are going to take the next leap and write code that knows about other code you have written.  This process of writing test that runs some code you have written forces you to understand clearly what you have just written.  It solidifies in your brain exactly what it does and why it works and gives you new level of attention to detail.  Writing Test Case Were going to take very simple piece of code and write one simple test.  Were going to base this little test on new project from your project skeleton.  First make ex47 project from your project skeleton.  Make sure you do it right and rename the module and get that first testsex47tests. py test file going right.  Also make sure nose runs this test file.  IMPORTANT make sure you also delete testsskeltests. pyc if its there.  Next create simple file ex47game. py where you can put the code to test.  This will be very silly little class that we want to test with this code in it class Roomobject 157 20 21 22 23 24 25 26 27 28 29 30 31 32 Learn Python The Hard Way Release 2. 0 def initself name description self. name name self. description description self. paths def goself direction return self. paths. get direction None def addpathsself paths self. paths. update paths Once you have that file change unit test skeleton to this from nose. tools import from ex47. game import Room def def def testroom gold RoomGoldRoom This room has gold in it you can grab.  Theres door to the nerth assertequalgold. name GoldRoom assertequalgold. paths testroompaths center RoomCenter Test room in the center.  north RoomNorth Test room in the north.  south RoomSouth Test room in the south.  center. addpathsnorth north south south assertequalcenter. gonorth north assertequalcenter. gosouth south testmap start RoomStart You can go west and down hole.  west RoomTrees There are trees here you can go east.  down RoomDungeon Its dark down here you can go up.  start. addpathswest west down down west. addpathseast start down. addpathsup start assertequalstart. gowest west assertequalstart. gowest. goeast start assertequalstart. godown. goup start This file imports the Room class you made in the ex47. game module so that you can do tests on it.  There are then set of tests that are functions starting with test.  Inside each test case theres bit of code that makes Room or set of Rooms and then makes sure the rooms work the way you expect 158 Exercise 47 Automated Testing Learn Python The Hard Way Release 2. 0 them to work.  It tests out the basic room features then the paths then tries out whole map.  The important functions here are assertequal which makes sure that variables you have set or paths you have built in Room are actually what you think they are.  If you get the wrong result then nosetests will print out an error message so you can go figure it out.  Testing Guidelines Follow these general loose set of guidelines when making your tests 1.  Test files go in tests and are named BLAHtests. py otherwise nosetests wont run them.  This also keeps your tests from clashing with your other code.  2.  Write one test file for each module you make.  3.  Keep your test cases functions short but do not worry if they are bit messy.  Test cases are usually kind of messy.  4.  Even though test cases are messy try to keep them clean and remove any repetitive code you can.  Create helper functions that get rid of duplicate code.  You will thank me later when you make change and then have to change your tests.  Duplicated code will make changing your tests more difficult.  5.  Finally do not get too attached to your tests.  Sometimes the best way to redesign something is to just delete it the tests and start over.  What You Should See projectssimplegame nosetests Ran tests in 0. 007s OK Thats what you should see if everything is working right.  Try causing an error to see what that looks like and then fix it.  Extra Credit 1.  Go read about nosetests more and also read about alternatives.  2.  Learn about Pythons doc tests and see if you like them better.  Testing Guidelines 159 Learn Python The Hard Way Release 2. 0 3.  Make your Room more advanced and then use it to rebuild your game yet again but this time unit test as you go.  160 Exercise 47 Automated Testing Exercise 48 Advanced User Input Your game probably was coming along great but bet how you handled what the user typed was be coming tedious.  Each room needed its own very exact set of phrases that only worked if your player typed them perfectly.  What youd rather have is device that lets users type phrases in various ways.  For example wed like to have all of these phrases work the same open door open the door go THROUGH the door punch bear Punch The Bear in the FACE It should be alright for user to write something lot like English for your game and have your game figure out what it means.  To do this were going to write module that does just that.  This module will have few classes that work together to handle use input and convert it into something your game can work with reliably.  In simple version of English the following elements Words separated by spaces.  Sentences composed of the words.  Grammar that structures the sentences into meaning.  That means the best place to start is figuring out how to get words from the user and what kinds of words those are.  Our Game Lexicon In our game we have to create Lexicon of words Direction words north south east west down up left right back.  Verbs go stop kill eat.  161 Learn Python The Hard Way Release 2. 0 Stop words the in of from at it Nouns door bear princess cabinet.  Numbers any string of through characters.  When we get to nouns we have slight problem since each room could have different set of Nouns but lets just pick this small set to work with for now and improve it later.  Breaking Up Sentence Once we have our lexicon of words we need way to break up sentences so that we can figure out what they are.  In our case weve defined sentence as words separated by spaces so we really just need to do this stutt words rawinput Stuff split Thats really all well worry about for now but this will work really well for quite while.  Lexicon Tuples Once we know how to break up sentence into words we just have to go through the list of words and figure out what type they are.  To do that were going to use handy little Python structure called tuple.  tuple is nothing more than list that you cant modify.  Its created by putting data inside two with comma like list firstword direction north secondword verb go sentence firstword secondword This creates pair of TYPE WORD that lets you look at the word and do things with it.  This is just an example but thats basically the end result.  You want to take raw input from the user carve it into words with split then analyze those words to identify their type and finally make sentence out of them.  Scanning Input Now you are ready to write your scanner.  This scanner will take string of raw input from user and return sentence thats composed of list of tuples with the TOKEN WORD pairings.  If word isnt part of the lexicon then it should still return the WORD but set the TOKEN to an error token.  These error tokens will tell the user they messed up.  Heres where it gets fun.  Im not going to tell you how to do this.  Instead Im going to write unit test und you are going to write the scanner so that the unit test works.  162 Exercise 48 Advanced User Input Learn Python The Hard Way Release 2. 0 Exceptions And Numbers There is one tiny thing will help you with first and thats converting numbers.  In order to do this though were going to cheat and use exceptions.  An exception is an error that you get from some function you may have run.  What happens is your function raises an exception when it encounters an error then you have to handle that exception.  For example if you type this into python projectssimplegame python Python 2. 6. 5 r2063 Apr 16 2010 41 GCC 4. 4. 3 on linux2 Type help copyright credits or license for more information.  int hell Traceback most recent call last File stdin line in module ValueError invalid literal for int with base 10 hell Sa That ValueError is an exception that the int function threw because what you handed int is not number.  The int function could have returned value to tell you it had an error but since it only returns integers itd have hard time doing that.  It cant return since thats number.  Instead of trying to figure out what to return when theres an error the int function raises the ValueError exception and you deal with it.  You deal with an exception by using the try and except keywords def convertnumbers try return ints except ValueError return None You put the code you want to try inside the try block and then you put the code to run for the error inside the except.  In this case we want to try to call int on something that might be number.  If that has an error then we catch it and return None.  In your scanner that you write you should use this function to test if something is number.  You should also do it as the last thing you check for before declaring that word an error word.  What You Should Test Here are the files testslexicontests. py that you should use from nose. tools import from ex48 import lexicon def testdirections What You Should Test 163 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 Learn Python The Hard Way Release 2. 0 def def def def def assertequallexicon. scannorth direction north result lexicon. scannorth south east assertequalresult direction north direction south direction east testverbs assertequallexicon. scango verb go result lexicon. scango kill eat assertequalresult verb go verb kill verb eat teststops assertequallexicon. scanthe stop the result lexicon. scanthe in of assertequalresult stop the stop in step of testnouns assertequallexicon. scanbear noun bear result lexicon. scanbear princess assertequalresult noun bear noun princess testnumbers assertequallexicon. scan1234 number 1234 result lexicon. scan3 91234 assertequalresult number number 91234 testerrors assertequallexicon. scanASDFADFASDF error ASDFADFASDF result lexicon. scanbear IAS princess assertequalresult noun bear errer IAS noun princess Remember that you will want to make new project with your skeleton type in this test case do not copypaste and write your scanner so that the test runs.  Focus on the details and make sure everything works right.  164 Exercise 48 Advanced User Input Learn Python The Hard Way Release 2. 0 Design Hints Focus on getting one test working at time.  Keep this simple and just put all the words in your lexicon in lists that are in your lexicon. py module.  Do not modify the input list of words but instead make your own new list with your lexicon tuples in it.  Also use the in keyword with these lexicon lists to check if word is in the lexicon.  Extra Credit 1.  Improve the unit test to make sure you cover more of the lexicon.  2.  Add to the lexicon and then update the unit test.  3.  Make your scanner handles user input in any capitalization and case.  Update the test to make sure this actually works.  4.  Find another way to convert the number.  5.  My solution was 37 lines long.  Is yours longer Shorter Design Hints 165 Learn Python The Hard Way Release 2. 0 166 Exercise 48 Advanced User Input Exercise 49 Making Sentences What we should be able to get from our little game lexicon scanner is list that looks like this rom ex48 import lexicon print lexicon. scango north verb go direction north print lexicon. scankill the princess verb kill stop the noun princess print lexicon. scaneat the bear verb eat stop the noun bear print lexicon. scanopen the door and smack the bear in the nose error open stop the noun door error and erron smack step the neun bear step in stop the error nose Now let us turn this into something the game can work with which would be some kind of Sentence class.  If you remember grade school sentence can be simple structure like Subject Verb Object Obviously it gets more complex than that and you probably did many days of annoying sentence graphs for English class.  What we want is to turn the above lists of tuples into nice Sentence object that has subject verb and object.  Match And Peek To do this we need four tools 1.  way to loop through the list of tuples.  Thats easy.  2.  way to match different types of tuples that we expect in our Subject Verb Object setup.  3.  way to peek at potential tuple so we can make some decisions.  4.  way to skip things we do not care about like stop words.  167 Learn Python The Hard Way Release 2. 0 We use the peek function to say look at the next element in our tuple list and then match to take one off and work with it.  Lets take look at first peek function def peek wordlist if wordlist word wordlist return word0 else return None Very easy.  Now for the match function def matchwordlist expecting if wordlist word wordlist. pop if word0 expecting return word else return None else return None Again very easy and finally our skip function def skipwordlist wordtype while peek wordlist wordtype matchwordlist wordtype By now you should be able to figure out what these do.  Make sure you understand them.  The Sentence Grammar With our tools we can now begin to build Sentence objects from our list of tuples.  What we do is process of 1.  Identify the next word with peek.  2.  If that word fits in our grammar we call function to handle that part of the grammar say parsesubject.  3.  If it doesnt we raise an error which you will learn about in this lesson.  4.  When were all done we should have Sentence object to work with in our game.  The best way to demonstrate this is to give you the code to read but heres where this exercise is different from the previous one You will write the test for the parser code give you.  Rather than giving you the test so you can write the code will give you the code and you have to write the test.  Heres the code that wrote for parsing simple sentences using the ex48 .  lexicon module 168 Exercise 49 Making Sentences Learn Python The Hard Way Release 2. 0 class ParserError Exception pass class Sentence object def initself subject verb object remember we take noun princess tuples and convert them self. subject subject self. verb verb1 self. object object1 def peek wordlist if wordlist word wordlist return word0 else return None def matchwordlist expecting if wordlist word wordlist. pop if word0 expecting return word else return None else return None def skipwordlist wordtype while peekwordlist wordtype matchwordlist wordtype def parseverbwordlist skip word lAist step if peekwordlist verb return matchwordlist verb else raise ParseError Expected verb next.  def parseobject wordlist The Sentence Grammar 169 Learn Python The Hard Way Release 2. 0 skipwordlist stop next peek wordlist if next noun return matchwordlist noun if next direction return matchwordlist direction else raise ParseError Expected noun or direction next.  def parsesubject wordlist subj verb parseverbwordlist obj parseobject wordlist return Sentencesubj verb obj def parsesentencewordlist skipwordlist stop start peek wordlist if start noun subj matchwordlist noun return parsesubject wordlist subj elif start verb assume the subject is the player then return parsesubject wordlist noun player else raise ParserErrorMust start with subject object or verb not start Word On Exceptions You briefly learned about exceptions but not how to raise them.  This code demonstrates how to do that with the ParserError at the top.  Notice that it uses classes to give it the type of Exception.  Also notice the use of raise keyword to raise the exception.  In your tests you will want to work with these exceptions which Ill show you how to do.  What You Should Test For Exercise 49 is write complete test that confirms everything in this code is working.  That includes making exceptions happen by giving it bad sentences.  170 Exercise 49 Making Sentences Learn Python The Hard Way Release 2. 0 Check for an exception by using the function assertraises from the nose documentation.  Learn how to use this so you can write test that is expected to fail which is very important in testing.  Learn about this function and others by reading the nose documentation.  When you are done you should know how this bit of code works and how to write test for other peoples code even if they do not want you to.  Trust me its very handy skill to have.  Extra Credit 1.  Change the parse methods and try to put them into class rather than be just methods.  Which design do you like better 2.  Make the parser more error resistant so that you can avoid annoying your users if they type words your lexicon doesnt understand.  3.  Improve the grammar by handling more things like numbers.  4.  Think about how you might use this Sentence class in your game to do more fun things with users input.  Extra Credit 171 Learn Python The Hard Way Release 2. 0 172 Exercise 49 Making Sentences Exercise 50 Your First Website These final three exercises will be very hard and you should take your time with them.  In this first one youll build simple web version of one of your games.  Before you attempt this exercise you must have completed Exercise 46 successfully and have working pip installed such that you can install packages and know how to make skeleton project directory.  If you dont remember how to do this go back to Exercise 46 and do it all over again.  Installing lpthw. web Before creating your first web application youll first need to install the web framework called lpthw. web.  The term framework generally means some package that makes it easier for me to do something.  In the world of web applications people create web frameworks to compensate for the difficult problems theyve encountered when making their own sites.  They share these common solutions in the form of package you can download to bootstrap your own projects.  In our case well be using the lpthw.  web framework but there are many many many others you can choose from.  For now learn lpthw. web then branch out to another one when youre ready or just keep using lpthw. web since its good enough.  Using pip install lpthw. web sudo pip install lpthw. web sudo password for zedshaw Downloadingunpacking lpthw. web Running setup. py egginfo for package lIpthw. web Installing collected packages lpthw. web Running setup. py install for lpthw. web Successfully installed lpthw. web Cleaning up. . .  This will work on Linux and Mac OSX computers but on Windows just drop the sudo part of the pip install command and it should work.  If not go back to Exercise 46 and make sure you can do it reliably.  173 Learn Python The Hard Way Release 2. 0 Warning Other Python programmers will warn you that lpthw. web is just fork of another web framework called web. py and that web. py has too much magic.  If they say this point out to them that Google App Engine originally used web.  py and not single Python programmer complained that it had too much magic because they all worked at Google.  If its good enough for Google then its good enough for you to get started.  Then just get back to learning to code and ignore their goal of indoctrination over education.  Make Simple Hello World Project Now youre going to make an initial very simple Hello World web application and project directory using lpthw.  web.  First make your project directory cd projects mkdir gothonweb cd gothonweb mkdir bin gothonweb tests docs templates touch gothonwebinit. py touch testsinit. py TE SH AE A.  Youll be taking the game from Exercise 42 and making it into web application so thats why youre calling it gothonweb.  Before you do that we need to create the most basic lpthw. web application possible.  Put the following code into binapp. py import web urls index app web. applicationurls globals class index def GETself greeting Hello World return greeting at name main app. run Then run the application like this python binapp. py http0. 0. 0. 08080 Finally use your web browser and go to the URL http localhost8080 and you should see two things.  First in your browser youll see Hello world.  Second youll see your terminal with 174 Exercise 50 Your First Website Learn Python The Hard Way Release 2. 0 new output like this python binapp. py http0. 0. 0. 08080 127. 0. 0. 159542 13Jun2011 43 HTTP1. 1 GET 200 OK 127. 0. 0. 159542 13Jun2011 43 HTTP1. 1 GET favicon. ico 404 Not Found Those are log messages that pt hw.  web prints out so you can see that the server is working and what the browser is doing behind the scenes.  The log messages help you debug and figure out when you have problems.  For example its saying that your browser tried to get favicon. ico but that file didnt exist so it returned 404 Not Found status code.  havent explained the way any of this web stuff works yet because want to get you setup and ready to roll so that can explain it better in the next two exercises.  To accomplish this ll have you break your Ipthw. web application in various ways and then restructure it so that you know how its setup.  Whats Going On Heres whats happening when your browser hits your application 1.  Your browser makes network connection to your own computer which is called localhost and is standard way of saying whatever my own computer is called on the network.  It also uses port 8080.  2.  Once it connects it makes an HTTP request to the binapp. py application and asks for the URL which is commonly the first URL on any website.  3.  Inside binapp. py youve got list of URLs and what classes they match.  The only one we have is the index mapping.  This means that whenever someone goes to with browser lpthw. web will find the class index and load it to handle the request.  4.  Now that lpthw. web has found class index it calls the index . GET method on an instance of that class to actually handle the request.  This function runs and simply returns string for what lpthw. web should send to the browser.  5.  Finally lpthw. web has handled the request and sends this response to the browser which is what you are seeing.  Make sure you really understand this.  Draw up diagram of how this information flows from your browser to lpthw. web then to index.  GET and back to your browser.  Fixing Errors First delete line 11 where you assign the greeting variable then hit refresh in your browser.  You should see an error page now that gives you lots of information on how your application just exploded.  Whats Going On 175 Learn Python The Hard Way Release 2. 0 You know that the variable greeting is now missing but lothw. web gives you this nice error page to track down exactly where.  Do each of the following with this page 1.  Look at each of the Local vars outputs click on them and see if you can follow what variables its talking about and where they are.  2.  Look at the Request Information section and see if it matches anything youre already fa miliar with.  This is information that your web browser is sending to your got honweb application.  You normally dont even know that its sending this stuff so now you get to see what it does.  3.  Try breaking this simple application in other ways and explore what happens.  Dont forget to also look at the logs being printed into your terminal as lpthw. web will put other stack traces and information there too.  Create Basic Templates You can break your Ipthw. web application but did you notice that Hello World isnt very good HTML page This is web application and as such it needs proper HTML response.  To do that you will create simple template that says Hello World in big green font.  The first step is to create templatesindex. html file that looks like this Sdef with greeting html head titleGothons Of Planet Percal 25title head body Sif greeting just wanted to say em stylecolor green fontsize 2emSgreetingem.  Selse emHelloem world body html If you know what HTML is then this should look fairly familiar.  If not research HTML and try writing few web pages by hand so you know how it works.  This HTML file however is template which means that lpthw. web will fill in holes in the text depending on variables you pass in to the template.  Every place you see greeting will be variable youll pass to the template that alters its contents.  To make your binapp. py do this you need to add some code to tell Lpt hw.  web where to load the template and to render it.  Take that file and change it like this import web 176 Exercise 50 Your First Website Learn Python The Hard Way Release 2. 0 urls Index app web. applicationurls globals render web. template. rendertemplates class Indexobject def GETself greeting Hello World return render. indexgreeting greeting if oname main app. run Pay close attention to the new render variable and how changed the last line of index. GET so it returns render.  index passing in your greeting variable.  Once you have that in place reload the web page in your browser and you should see different message in green.  You should also be able to do View Source on the page in your browser to see that it is valid HTML.  This may have flown by you very fast so let me explain how template works 1.  In.  your binapp. py youve added new variable render which is web. template.  render object.  2.  This render object knows how to load . htm1 files out of the templates directory because you passed that to it as parameter.  3.  Later in your code when the browser hits the index.  GET like before instead of just returning the string greeting you call render.  index and pass the greeting to it as variable.  4.  This render. index method is kind of magic function where the render object sees that youre asking for index goes into the templates directory looks for page named index. html and then renders it or converts it.  5.  In the templatesindex. html1 file you see the beginning definition that says this template takes greet ing parameter just like function.  Also just like Python this template is indenta tion sensitive so make sure you get them right.  6.  Finally you have the HTML in templatesindex. html that looks at the greeting vari able and if its there prints one message using the greet ing or default message.  To get deeper into this change the greeting variable and the HTML to see what effect it has.  Also create another template named templatesfoo. html and render that using render.  foo instead of render.  index like before.  This will show you how the name of the function you call on render is just matched toa .  html fileintemplates.  Create Basic Templates 177 Learn Python The Hard Way Release 2. 0 Extra Credit 1.  Read the documentation at httpwebpy. org which is the same as the 1pt hw.  web project.  .  Experiment with everything you can find there including their example code.  .  Read about HTMLS and CSS3 and make some other . html and . css files for practice.  KR WwW WN .  If you have friend who knows Django and is willing to help you then consider doing Ex 50 51 and 52 in Django instead to see what thats like.  178 Exercise 50 Your First Website Exercise 51 Getting Input From Browser While its exciting to see the browser display Hello World its even more exciting to let the user submit text to your application from form.  In this exercise well improve our starter web application using forms and storing information about the user into their session.  How The Web Works Time for some boring stuff.  You need to understand bit more about how the web works before you can make form.  This description isnt complete but its accurate and will help you figure out what might be going wrong with your application.  Also creating forms will be easier if you know what they do.  Pll start with simple diagram that shows you the different parts of web request and how the information flows Your Browser httplearnpythonthehardway. org Web Apps index. GET My Server Ive labeled the lines with letters so can walk you through regular request process 179 Learn Python The Hard Way Release 2. 0 Ts .  Youtype inthe urlhttplearnpythonthehardway. org into your browser and it sends the request outon line to your computers network interface.  .  Your request goes out over the internet on line and then to the remote computer on line where my server accepts the request.  .  Once my computer accepts it my web application gets iton line and my Python code runs the index.  GET handler.  .  The response comes out of my Python server when return it and goes back to your browser over line again.  .  The server running this site takes the response off Line then sends it back over the internet online C.  .  The response from the server then comes off the internet on line and your computers network interface hands it to your browseron line A.  Finally your browser then displays the response.  In this description there are few terms you should know so that you have common vocabulary to work with when talking about your web application Browser The software that youre probably using every day.  Most people dont know what it really does they just call it the internet.  Its job is to take addresses like httplearnpythonthehardway. org you type into the URL bar then use that information to make requests to the server at that address.  Address This is normally URL Uniform Resource Locator like httplearnpythonthehardway. org and indicates where browser should go.  The first part http indicates the protocol you want to use in this case HyperText Transport Protocol.  You can also try ftpibiblio. org to see how File Transport Protocol works.  The learnpythonthehardway. org partis the hostname or human readable address you can remember and which maps to number called an IP address similar to telephone number for computer on the Internet.  Finally URLs can have trailing path like the book part of httplearnpythonthehardway. orgbook which indicates file or some resource on the server to retrieve with request.  There are many other parts but those are the main ones.  Connection Once browser knows what protocol you want to use http what server you want to talk to learnpythonthehardway. org and what resource on that server to get it must make connec tion.  The browser simply asks your Operating System OS to open port to the computer usually port 80.  When it works the OS hands back to your program something that works like file but is actually sending and receiving bytes over the network wires between your com puter and the other computer at learnpythonthehardway. org.  This is also the same thing that happens with httplocalhost8080 but in this case youre telling the browser to connect to your own computer localhost and use port 8080 rather than the default of 80.  You could also do httplearnpythonthehardway. org80 and get the same result except youre explicitly saying to use port 80 instead of letting it be that by default.  Request Your browser is connected using the address you gave.  Now it needs to ask for the resource it wants or you want on the remote server.  If you gave book at the end of the URL then 180 Exercise 51 Getting Input From Browser Learn Python The Hard Way Release 2. 0 you want the file resource at book and most servers will use the real file bookindex. html but pretend it doesnt exist.  What the browser does to get this resource is send request to the server.  wont get into exactly how it does this but just understand that it has to send something to query the server for the request.  The interesting thing is that these resources dont have to be files.  For instance when the browser in your application asks for something the server is returning something your Python code generated.  Server The server is the computer at the end of browsers connection that knows how to answer your browsers requests for filesresources.  Most web servers just send files and thats actually the majority of traffic.  But youre actually building server in Python that knows how to take requests for resources and then return strings that you craft using Python.  When you do this crafting you are pretending to be file to the browser but really its just code.  As you can see from Ex.  50 it also doesnt take much code to create response.  Response This is the HTML css javascript or images your server wants to send back to the browser as the answer to the browsers request.  In the case of files it just reads them off the disk and sends them to the browser but it wraps the contents of the disk in special header so the browser knows what its getting.  In the case of your application youre still sending the same thing including the header but you generate that data on the fly with your Python code.  That is the fastest crash course in how web browser accesses information on servers on the internet.  It should work well enough for you to understand this exercise but if not read about it as much as you can until you get it.  really good way to do that is to take the diagram and break different parts of the web application you did in Exercise 50.  If you can break your web application in predictable ways using the diagram youll start to understand how it works.  How Forms Work The best way to play with forms is to write some code that accepts form data and then see what you can do.  Take your binapp.  py file and make it look like this import web urls hello Index app web. applicationurls globals render web. template. rendertemplates class Indexobject def GETself form web. input nameNobody greeting Hello form. name How Forms Work 181 Learn Python The Hard Way Release 2. 0 return render. indexgreeting greeting if oname main app. run Restart it hit CTRLc and then run it again to make sure it loads again then with your browser go to http localhost8080hello which should display just wanted to say Hello Nobody.  Next change the URL in your browser to http localhost8080hellonameF rank and youll see it say Hello Frank.  Finally change the nameF rank part to be your name.  Now its saying hello to you.  Lets break down the changes made to your script.  1.  Instead of just string for greeting Im now using web.  input to get data from the browser.  This function takes keyvalue set of defaults parses the nameFrank part of the URL you give it and then returns nice object for you to work with that represents those values.  2.  then construct the greeting from the new form. name attribute of the form object which should be very familiar to you by now.  3.  Everything else about the file is the same as before.  Youre also not restricted to just one parameter on the URL.  Change this example to give two vari ables like this http localhost8080hellonameFrankgreetHola.  Then change the code to get form. name and form.  greet like this greeting Ss form. greet form. name After that try the URL.  Next leave out the greetHola part so that you can see the error you get.  Since greet doesnt have default value in web.  input nameNobody then it is required field.  Now go back and make it have default in the web.  input call to see how you fix this.  Another thing you can do is set its default to greet None so that you can check if it exists and then give better error message like this form web. input nameNobody greetNone if form. greet greeting Ss form. greet form. name return render. indexgreeting greeting else return ERROR greet is required.  Creating HTML Forms Passing the parameters on the URL works but its kind of ugly and not easy to use for regular people.  What you really want is POST form which is special HTML file that has form tag in it.  This form will collect information from the user then send it to your web application just like you did above.  182 Exercise 51 Getting Input From Browser Learn Python The Hard Way Release 2. 0 Lets make quick one so you can see how it works.  Heres the new HTML file you need to create in templateshelloform. html html head titleSample Web Formtitle head body h1lFill Out This Formh1 form actionhello methodPOST Greeting input typetext namegreet br Your Name input typetext namename br input typesubmit form body html You should then change binapp.  py to look like this import web urls hello Index app web. applicationurls globals render web. template. rendertemplates class Indexobject def GETself return render. helloform def POSTself form web. input nameNobody greetHello greeting Ss form. greet form. name return render. indexgreeting greeting if oname main app. run Once youve got those written up simply restart the web application again and hit it with your browser like before.  This time youll get form asking you for Greeting and Your Name.  When you hit the Submit Creating HTML Forms 183 Learn Python The Hard Way Release 2. 0 button on the form it will give you the same greeting you normally get but this time look at the URL in your browser.  See how its http localhost8080hel11o even though you sent in parameters.  The part of the helloform. html file that makes this work is the line with form actionhello methodPOST.  This tells your browser to 1.  Collect data from the user using the form fields inside the form.  2.  Send them to the server using POST type of request which is just another browser request that hides the form fields.  3.  Send that to the hello URL as shown in the actionhello part.  You can then see how the two input tags match the names of the variables in your new code.  Also notice that instead of just GET method inside class index have another method POST.  How this new application works is 1.  The browser first hits the web application at hello but it sends GET so our index. GET function runs and returns the he loform.  2.  You fill out the form in the browser and the browser does what the form says and sends the data as POST.  3.  The web application then runs the index.  POST method rather than the index . GET method to handle this request.  4.  This index. POST method then does what it normally does to send back the hello page like before.  Theres really nothing new in here its just moved into new function.  As an exercise go into the templatesindex. html file and add link back to just hello so that you can keep filling out the form and seeing the results.  Make sure you can explain how this link works and how its letting you cycle between templatesindex. html and templateshelloform.  html and whats being run inside this latest Python code.  Creating Layout Template When you work on your game in the next Exercise youll need to make bunch of little HTML pages.  Writing full web page each time will quickly become tedious.  Luckily you can create layout template or kind of shell that will wrap all your other pages with common headers and footers.  Good programmers try to reduce repetition so layouts are essential for being good programmer.  Change templatesindex. html to be like this Sdef with greeting Sif greeting just wanted to say em stylecolor green fontsize 2emSgreetingem.  Selse emHelloem world 184 Exercise 51 Getting Input From Browser Learn Python The Hard Way Release 2. 0 Then change templateshelloform. htm1 to be like this h1Fill Out This Formh1 form actionhello methodPOST Greeting input typetext namegreet br Your Name input typetext namename br input typesubmit form All were doing is stripping out the boilerplate at the top and the bottom which is always on every page.  Well put that back into single templateslayout. html file that handles it for us from now on.  Once you have those changes create templateslayout. html file with this in it Sdef with content html head titleGothons From Planet Percal 25title head body content body html This file looks like regular template except that its going to be passed the contents of the other tem plates and used to wrap them.  Anything you put in here doesnt need to be in the other templates.  You should also pay attention to how content is written since its little different from the other tem plate variables.  The final step is to change the line that makes the render object to be this render web. template. rendertemplates baselayout Which tells lpthw. web to use the templateslayout. html file as the base template for all the other templates.  Restart your application and then try to change the layout in interesting ways but without changing the other templates.  Writing Automated Tests For Forms Its easy to test web application with your browser by just hitting refresh but come on were program mers here.  Why do some repetitive task when we can write some code to test our application What Writing Automated Tests For Forms 185 Learn Python The Hard Way Release 2. 0 youre going to do next is write little test for your web application form based on what you learned in Exercise 47.  If you dont remember Exercise 47 read it again.  You need to do bit of setup to make Python let you load your binapp.  py file for testing.  When we get to Exercise thinks bin is 52 youll change this but for now create an empty bininit. py file so Python directory.  Ive also created simple little function for lpthw. web that lets you assert things about your web applications response aptly named assertresponse.  Create the file teststools. py with these contents from nose. tools import import re def assertresponseresp containsNone matchesNone headersNone status200 assert status in resp. status Expected response Sr not in Sr status resp. status if status 200 assert resp. data Response data is empty.  if contains assert contains in resp. data Response does not contain contains if matches reg re. compile matches assert reg. matchescontains Response does not match Sr matches if headers ass rtequalresp. headers headers Once thats in place you can write your automated test for the last version of the binapp. py file you created.  Create new file named test sapptests. py with this from nose. tools import from bin. app import app from tests. tools import assertresponse def testindex check that we get 404 on the URL resp assert test resp assert make resp assert app.  request responseresp status404 our first GET request to hello app.  request hello response resp sure default values work for the form app. request hello methodPOST response resp containsNobody 186 Exercise 51 Getting Input From Browser Learn Python The Hard Way Release 2. 0 test that we get expected values data name Zed greet Hola resp app. requesthello methodPOST datadata assertresponseresp containsZed Finally use nosetests to run this test setup and test your web application nosetests Ran test in 0. 059s OK What Im doing here is Im actually importing the whole application from the binapp. py module then running it manually.  The 1pthw. web framework has very simple API for processing requests which looks like this app. request localpart methodGET dataNone host0. 0. 0. 08080 headersNone httpsFalse This means you can pass in the URL as the first parameter then change the method of the request as wellas what form data you send including the host and headers.  This works without running an actual web server so you can do tests with automated tests and also use your browser to test running server.  To validate responses from this function use the assertresponse function from tests. tools which has assertresponseresp containsNone matchesNone headersNone status200 Pass in the response you get from calling app.  request then add things you want checked.  Use the contains parameter to make sure that the response contains certain values.  Use the st atus parameter to check for certain responses.  Theres actually quite lot of information in this little function so it would be good for you to study it.  In the testsapptests. py automated test Im first making sure the URL returns 404 Not Found response since it actually doesnt exist.  Then Im checking that he11o works with both GET and POST form.  Following the test should be fairly simple even if you might not totally know whats going on.  Take some time studying this latest application especially how the automated testing works.  Make sure you understand how imported the application from binapp.  py and ran it directly for the automated test.  This is an important trick that will lead to more learning.  Writing Automated Tests For Forms 187 Learn Python The Hard Way Release 2. 0 Extra Credit .  Read even more about HTML and give the simple form better layout.  It helps to draw what you want to do on paper and then implement it with HTML.  .  This one is hard but try to figure out how youd do file upload form so that you can upload an image and save it to the disk.  .  This is even more mindnumbing but go find the HTTP RFC which is the document that describes how HTTP works and read as much of it as you can.  It is really boring but comes in handy once in while.  .  This will also be really difficult but see if you can find someone to help you setup web server like Apache Nginx or thttpd.  Try to serve couple of your . html and . css files with it just to see if you can.  Dont worry if you cant web servers kind of suck.  .  Take break after this and just try making as many different web applications as you can.  You should definitely read about sessions in web.  py which is the same as lpthw.  web so you can understand how to keep state for user.  188 Exercise 51 Getting Input From Browser Exercise 52 The Start Of Your Web Game Were coming to the end of the book and in this exercise Im going to really challenge you.  When youre done youll be reasonably competent Python beginner.  Youll still need to go through few more books and write couple more projects but youll have the skills to complete them.  The only thing in your way will be time motivation and resources.  In this exercise we wont make complete game but instead well make an engine that can run the game from Exercise 42 in the browser.  This will involve refactoring Exercise 42 mixing in the structure from Exercise 47 adding automated tests and finally creating web engine that can run the games.  This exercise will be huge and predict you could spend anywhere from week to months on it before moving on.  Its best to attack it in little chunks and do bit night taking your time to make everything work before moving on.  Refactoring The Exercise 42 Game Youve been altering the gothonweb project for two exercises and youll do it one more time in this exercise.  The skill youre learning is called refactoring or as like to call it fixing stuff.  Refactoring is term programmers use to describe the process of taking old code and changing it to have new features or just to clean it up.  Youve been doing this without even knowing it as its second nature to building software.  What youll do in this part is take the ideas from Exercise 47 of testable map of Rooms and the game from Exercise 42 and combine them together to create new game structure.  It will have the same content just refactored to have better structure.  First step is to grab the code from ex47game. py and copy it to gothonwebmap. py and copy testsex47tests. py filetotestsmaptests. py andrun nosetests again to make sure it keeps working.  189 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 Learn Python The Hard Way Release 2. 0 Note From now on wont show you the output of test run just assume that you should be doing it and itll look like the above unless you have an error.  Once you have the code from Exercise 47 copied over its time to refactor it to have the Exercise 42 map in it.  Im going to start off by laying down the basic structure and then youll have an assignment to make the map.  py file and the maptests. py file complete.  First thing to do is lay out the basic structure of the map using the Room class as it is now class Roomobject def initself name description self. name name self. description description self. paths def goself direction return self. paths. get direction None def addpathsself paths self. paths. update paths centralcorridor RoomCentral Corridor noe The Gothons of Planet Percal 25 have invaded your ship and destroyed your entire crew.  You are the last surviving member and your last mission is to get the neutron destruct bomb from the Weapons Armory put it in the bridge and blow the ship up after getting into an escape pod.  Youre running down the central corridor to the Weapons Armory when Gothon jumps out red scaly skin dark grimy teeth and evil clown costume flowing around his hate filled body.  Hes blocking the door to the Armory and about to pull weapon to blast you.  we laserweaponarmory RoomLaser Weapon Armory noe Lucky for you they made you learn Gothon insults in the academy.  You tell the one Gothon joke you know Lbhe zbgure vf fb sng jura fur fvgf nebhaq gur ubhfr fur fvgf nebhag gur ubhfr.  The Gothon stops tries not to laugh then busts out laughing and cant move.  While hes laughing you run up and shoot him square in the head putting him down then jump through the Weapon Armory door.  You do dive roll into the Weapon Armory crouch and scan the room for more Gothons that might be hiding.  Its dead quiet too quiet.  190 Exercise 52 The Start Of Your Web Game 41 42 43 45 46 47 48 49 50 SI 52 53 54 55 56 57 58 59 60 61 62 63 65 66 67 68 69 70 71 72 73 74 75 76 71 78 79 80 81 82 83 84 85 86 87 88 Learn Python The Hard Way Release 2. 0 You stand up and run to the far side of the room and find the neutron bomb in its container.  Theres keypad lock on the box and you need the code to get the bomb out.  If you get the code wrong 10 times then the lock closes forever and you cant get the bomb.  The code is digits.  wn thebridge RoomThe Bridge noe The container clicks open and the seal breaks letting gas out.  You grab the neutron bomb and run as fast as you can to the bridge where you must place it in the right spot.  You burst onto the Bridge with the netron destruct bomb under your arm and surprise Gothons who are trying to take control of the ship.  Each of them has an even uglier clown costume than the last.  They havent pulled their weapons out yet as they see the active bomb under your arm and dont want to set it off.  we escapepod RoomEscape Pod ng You point your blaster at the bomb under your arm and the Gothons put their hands up and start to sweat.  You inch backward to the door open it and then carefully place the bomb on the floor pointing your blaster at it.  You then jump back through the door punch the close button and blast the lock so the Gothons cant get out.  Now that the bomb is placed you run to the escape pod to get eff this tin can You rush through the ship desperately trying to make it to the escape pod before the whole ship explodes.  It seems like hardly any Gothons are on the ship so your run is clear of interference.  You get to the chamber with the escape pods and now need to pick one to take.  Some of them could be damaged but you dont have time to look.  Theres pods which one do you take on theendwinner RoomThe End moe You jump into pod and hit the eject button.  The pod easily slides out into space heading to Refactoring The Exercise 42 Game 191 89 90 91 92 93 94 95 96 97 98 99 101 102 103 105 106 107 108 109 110 ll 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 Learn Python The Hard Way Release 2. 0 the planet below.  As it flies to the planet you look back and see your ship implode then explode like bright star taking out the Gothon ship at the same time.  You won we ny theendloser RoomThe End noe You jump into random pod and hit the eject button.  The pod escapes out into the void of space then implodes as the hull ruptures crushing your body into jam jelly.  oon escapepod. addpaths theendwinner the endloser genericdeath Roomdeath You died.  thebridge. addpaths throw the bomb genericdeath slowly place the bomb escapepod laserweaponarmory. addpaths 0132 thebridge genericdeath centralcorridor. addpaths shoot genericdeath dodge genericdeath tell joke laserweaponarmory START centralcorridor Youll notice that there are couple of problems with our Room class and this map 1.  We have to put the text that was in the ifelse clauses that got printed before entering room as part of each room.  This means you cant shuffle the map around which would be nice.  Youll be fixing that up in this exercise.  2.  There are parts in the original game where we ran code that determined things like the bombs keypad code or the right pod.  In this game we just pick some defaults and go with it but later 192 Exercise 52 The Start Of Your Web Game 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 Learn Python The Hard Way Release 2. 0 3.  4.  youll be given extra credit to make this work again.  Ive just made genericdeath ending for all of the bad decisions which youll have to finish for me.  Youll need to go back through and add in all the original endings and make sure they work.  Ive got new kind of transition labeled that will be used for catchall action in the engine.  Once youve got that basically written out heres the new automated test testsmaptest . py that you should have to get yourself started from nose. tools import from gothonweb. map import def def def def testroom gold RoomGoldRoom This room has gold in it you can grab.  Theres door to the north assertequalgold. name GoldRoom assertequalgold. paths testroompaths center RoomCenter Test room in the center.  north RoomNorth Test room in the north.  south RoomSouth Test room in the south.  center. addpathsnorth north south south assertequalcenter. gonorth north assertequalcenter. gosouth south testmap start RoomStart You can go west and down hole.  west RoomTrees There are trees here you can go east.  down RoomDungeon Its dark down here you can go up.  start. addpathswest west down down west. addpathseast start down. addpathsup start assertequalstart. gowest west assertequalstart. gowest. goeast start assertequalstart. godown. goup start testgothongamemap assertequalSTART. goshoot genericdeath assertequalSTART. gododge genericdeath room START. gotell joke assertequalroom laserweaponarmory Refactoring The Exercise 42 Game 193 20 21 22 23 Learn Python The Hard Way Release 2. 0 Your task in this part of the exercise is to complete the map and make the automated test completely validate the whole map.  This includes fixing all the genericdeath objects to be real endings.  Make sure this works really well and that your test is as complete as possible because well be changing this map later and youll use the tests to make sure it keeps working.  Sessions And Tracking Users At certain point in your web application youll need to keep track of some information and associate it with the users browser.  The web because of HTTP is what we like to call stateless which means each request you make is independent of any other requests being made.  If you request page put in some data and click link to page all the data you sent to page just disappears.  The solution to this is to create little data store usually in database or on the disk that uses number unique to each browser to keep track of what that browser was doing.  In the little pt hw.  web framework its fairly easy and theres an example showing how its done import web web. config. debug False urls eoount eourt.  reset reset app web. applicationurls locals session web. session. Sessionapp web. session. DiskStoresessions initializercount class count def GETself session. count return strsession. count class reset def GETself session. kill return if oname main app. run To make this work you need to create sessions directory where the application can put session storage.  Do that run this application and go to count.  Hit refresh and watch the counter go up.  Close the browser and it forgets who you are which is what we want for the game.  Theres way to make the browser remember forever but that makes testing and development harder.  If you then go to reset and back to count you can see your counter reset because youve killed the session.  Take the time to understand this code so you can see how the session starts off with the count equal to 194 Exercise 52 The Start Of Your Web Game Learn Python The Hard Way Release 2. 0 0.  Also try looking at the files in sessions to see if you can open them up.  Heres Python session where open up one and decode it import pickle import base64 base64. b64decode open sessionsXXXXX . read dp1nScountnp2nI1nsSipnp3nV127. 0. 0. 1np4nsSsessionidnp5nSXxxXnp6ns.  base64. b64decode open sessionsXXXXX . read pickle.  loads fTeounts ap uwI2Z700. 0. 1 sesstondd XXXXX The sessions are really just dictionaries that get written to disk using pickle and base64 libraries.  There are probably as many ways to store and manage sessions as there are web frameworks so its not too important to know how these work.  It does help if you need to debug the session or potentially clean them out.  Creating An Engine You should have your game map working and good unit test for it.  now want to make simple little game engine that will run the rooms collect input from the player and keep track of where play is in the game.  Well be using the sessions you just learned to make simple game engine that will 1.  Start new game for new users.  2.  Present the room to the user.  3.  Take input from the user.  4.  Run their input through the game.  5.  Display the results and keep going until they die.  To do this youre going to take the trusty binapp. py youve been hacking on and create fully working session based game engine.  The catch is Im going to make very simple one with basic HTML files and it1l be up to you to complete it.  Heres the base engine import web from gothonweb import map urls game GameEngine Index app web. applicationurls globals little hack so that debug mode works with sessions Creating An Engine 195 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 47 48 49 Learn Python The Hard Way Release 2. 0 if web. config. getsession is None store web. session. DiskStoresessions session web. session. Sessionapp store initializerroom None web. config. session session else session web. config. session render web. template. rendertemplates baselayout class Indexobject def GETself this is used to setup the session with starting values session. room map. START web. seeother game class GameEngine object def GETself if session. room return render. showroomroomsession.  room else why is there here do you need it return render.  youdied def POSTself form web. input actionNone there is bug here can you fix it if session. room and form. action session. room session. room. goform. action web. seeother game if name main app. run There are even more new things in this script but amazingly its an entire web based game engine in small file.  The biggest hack in the script are the lines that bring the sessions back which is needed so that debug mode reloading works.  Otherwise each time you hit refresh the sessions will disappear and the game wont work.  Before you run binapp. py you need to change your PYTHONPATH environment variable.  Dont know what that is know its kind of dumb you have to learn what this is to run even basic Python programs but thats how Python people like things.  In your terminal type 196 Exercise 52 The Start Of Your Web Game Learn Python The Hard Way Release 2. 0 export PYTHONPATHSPYTHONPATH.  On Windows do set PYTHONPATHPYTHONPATH .  You should only have to do it once per shell session but if you get an import error then you probably need to do this or you did it wrong.  You should next delete templateshelloform. html and templatesindex. html and create the two templates mentioned in the above code.  Heres very simple templatesshowroom. html Sdef with room hl Sroom. name h1 pre Sroom. description pre Sif room. name death pa hrefPlay Againap Selse form actiongame methodPOST input typetext nameaction input typeSUBMIT form That is the template to show room as you travel through the game.  Next you need one to tell someone they died in the case that they got to the end of the map on accident which is templatesyoudiedhtml hlYou Diedh1 pLooks like you bit the dust. p pa hrefPlay Againap With those in place you should now be able to do the following 1.  Get the test testsapptests. py working again so that you are testing the game.  You wont be able to do much more than few clicks in the game because of sessions but you should be able to do some basics.  2.  Remove the sessionsx files and make sure youve started over.  3.  Run the python binapp. py script and test out the game.  You should be able to refresh and fix the game like normal and work with the game HTML and engine until it does all the things you want it to do.  Creating An Engine 197 Learn Python The Hard Way Release 2. 0 Your Final Exam Do you feel like this was huge amount of information thrown at you all at once Good want you to have something to tinker with while you build your skills.  To complete this exercise Im going to give you final set of exercises for you to complete on your own.  Youll notice that what youve written so far isnt very well built it is just first version of the code.  Your task now is to make the game more complete by doing these things 1.  onnn Fix all the bugs mention in the code and any that didnt mention.  If you find new bugs let me know.  .  Improve all of the automated tests so that you test more of the application and get to point where you use test rather than your browser to check the application while you work.  .  Make the HTML look better.  .  Research logins and create signup system for the application so people can have logins and high scores.  .  Complete the game map making it as large and feature complete as possible.  .  Give people help system that lets them ask what they can do at each room in the game.  .  Add any other features you can think of to the game.  .  Create several maps and let people choose game they want to run.  Your binapp. py engine should be able to run any map of rooms you give it so you can support multiple games.  .  Finally use what you learned in Exercises 48 and 49 to create better input processor.  You have most of the code necessary you just need to improve the grammar and hook it up to your input form and the GameEngine.  Good luck 198 Exercise 52 The Start Of Your Web Game Next Steps Youre not programmer quite yet.  like to think of this book as giving you your programming brown belt.  You know enough to start another book on programming and handle it just fine.  This book should have given you the mental tools and attitude you need to go through most Python books and actually learn something.  It might even make it easy.  recommend you continue with httpwww. djangobook. com and start going through the 2nd Edition of The Django Book.  Even if you never plan on doing Python web programming going through the book will cement your skills in Python using an actual practical activity.  It is also better framework than the lpthw. web you were using but all of the concepts youve learned so far apply to the Django web framework.  Just take your time ask questions and youll get through it.  You could probably start hacking away at some programs right now and if you have that itch go ahead.  Just understand anything you write will probably suck.  Thats alright though suck at every program ming language first start using.  Nobody writes pure perfect gold when theyre beginner and anyone who tells you they did is huge liar.  Finally remember that this is something you have to do at least couple hours night for while before you can get good.  If it helps while youre struggling to learn Python every night hard at work learning to play guitar.  work at it about or hours day and still practice scales.  Everyone is beginner at something.  199 Learn Python The Hard Way Release 2. 0 200 Next Steps Advice From An Old Programmer Youve finished this book and have decided to continue with programming.  Maybe it will be career for you or maybe it will be hobby.  Youll need some advice to make sure you continue on the right path and get the most enjoyment out of your newly chosen activity.  Ive been programming for very long time.  So long that its incredibly boring to me.  At the time that wrote this book knew about 20 programming languages and could learn new ones in about day to week depending on how weird they were.  Eventually though this just became boring and couldnt hold my interest anymore.  This doesnt mean think programming is boring or that you will think its boring only that find it uninteresting at this point in my journey.  What discovered after this journey of learning is that its not the languages that matter but what you do with them.  Actually always knew that but Id get distracted by the languages and forget it periodically.  Now never forget it and neither should you.  Which programming language you learn and use doesnt matter.  Do not get sucked into the religion surrounding programming languages as that will only blind you to their true purpose of being your tool for doing interesting things.  Programming as an intellectual activity is the only art form that allows you to create interactive art.  You can create projects that other people can play with and you can talk to them indirectly.  No other art form is quite this interactive.  Movies flow to the audience in one direction.  Paintings do not move.  Code goes both ways.  Programming as profession is only moderately interesting.  It can be good job but you could make about the same money and be happier running fast food joint.  Youre much better off using code as your secret weapon in another profession.  People who can code in the world of technology companies are dime dozen and get no respect.  People who can code in biology medicine government sociology physics history and mathematics are respected and can do amazing things to advance those disciplines.  Of course all of this advice is pointless.  If you liked learning to write software with this book you should try to use it to improve your life any way you can.  Go out and explore this weird wonderful new intellectual pursuit that barely anyone in the last 50 years has been able to explore.  Might as well enjoy it while you can.  Finally Pll say that learning to create software changes you and makes you different.  Not better or worse 201 Learn Python The Hard Way Release 2. 0 just different.  You may find that people treat you harshly because you can create software maybe using words like nerd.  Maybe youll find that because you can dissect their logic that they hate arguing with you.  You may even find that simply knowing how computer works makes you annoying and weird to them.  To this have one just piece of advice they can go to hell.  The world needs more weird people who know how things work and who love to figure it all out.  When they treat you like this just remember that this is your journey not theirs.  Being different is not crime and people who tell you it is are just jealous that youve picked up skill they never in their wildest dreams could acquire.  You can code.  They cannot.  That is pretty damn cool.  202 Advice From An Old Programmer STEVENS INSTITUTE of TECHNOLOGY Text Mining with Python 2016 clipizzistevens. edu SSE Reasons for Text Mining 8590 percent of all corporate data Is in some kind of unstructured form e. g.  text Unstructured corporate data is doubling in size every 18 months Tapping into these information sources is not an option but need to stay competitive Text mining is semiautomated process of extracting knowledge from Unstructured data sources a. k. a.  text data mining or knowledge discovery in textual databases El STEVENS INSTITUTE of TECHNOLOGY Using Text Mining Benefits of text mining are obvious especially in text rich data environments e. g.  law court orders academic research research articles finance quarterly reports medicine discharge summaries biology molecular interactions technology patent files marketing customer comments etc.  Electronic communization records e. g.  Email Spam filtering Email prioritization and categorization Automatic response generation STEVENS INSTITUTE of TECHNOLOGY Challenges in Text Mining ie Very high number of possible dimensions All possible word and phrase types in the language Unlike data mining records docs are not structurally identical records are not statistically indeoendent Complex and subtle relationships between concepts in text Comcast merges with TimeWarner TimeWarner is bought by Comcast Ambiguity and context sensitivity automobile car vehicle Toyota Apple the company or apple the fruit STEVENS INSTITUTE of TECHNOLOGY Text Mining Terminology Corpus Term dictionary Terms Word frequency Concepts Partofsoeech tagging stemming Morphology Stop words Termbydocument matrix Synonyms Occurrence matrix Tokenizing Singular value decomposition Latent semantic indexing STEVENS INSTITUTE of TECHNOLOGY Two Mining Phases Text preparation.  Beyond the typical data mining cleaning there are some semantic steps involved here Information Extraction.  There are several ways To extract information from clean data based on the goal of the search STEVENS INSTITUTE of TECHNOLOGY Text preparation Basic data cleaning Tokenization stopwords removal stemmingLemmatization Statistical Analysis Additional Content Analysis STEVENS INSTITUTE of TECHNOLOGY Tokenization The simplest way to represent text is with single string but if is difficult to process text in this format Often it is more convenient to work with list of tokenselements The task of converting text from single string to list of Tokens Is known as tokenization There are toolsfunctions within libraries providing this function they take string and returns list of tokens STEVENS INSTITUTE of TECHNOLOGY stopwords removal It is process To eliminate from the set of wordstokens with no semantic value There are words that have no semantic value in all the contexts such as articles and pronouns and those are part of any standard stopwords removal Orocess There are other words with intrinsic semantic value but irrelevant for the specific case.  Those may be part of the list of stopwords for that case STEVENS INSTITUTE of TECHNOLOGY hl33slUui StemmingLemmatization This is step to eliminate words with the same semantic value Stemming is the process for reducing words to their stem base or root form.  Examples are fish for fishing fished and fisher argu for argue argued argues arguing and argus Lemmatization is the process of determining the lemma for given word where lemma is the canonical form dictionary form or citation form of set of words.  For example run runs ran and running are from the same canonical form run.  It may be based on an analysis of part of soeech for the words.  Part of speech are linguistic categories such as noun and verb stemmer operates on single word without knowledge of the context and therefore cannot discriminate between words which have different meanings depending on part of soeech.  They also may create stem with no dictionary value like argu above.  However stemmers are typically easier to implement and run faster and the reduced accuracy may not matter for some applications STEVENS INSTITUTE of TECHNOLOGY Natural Language ToolKit NLTK Is Python suite of libraries and programs for symbolic and statistical natural language processing NLP httpnitk. org Created by Steven Bird Edward Loper Ewan Klein Provides Basic classes for representing data relevant to natural language processing.  Standard interfaces for performing tasks such as tokenization tagging and parsing.  Standard implementations of each task which can be combined to solve complex problems.  STEVENS INSTITUTE of TECHNOLOGY Modules lw hl33slUui fis The NLTK modules include token classes for representing and processing individual elements of text such as words and sentences probability classes for representing and processing probabilistic information.  tree classes for representing and processing hierarchical information over text.  tagger tagging each word with partofsoeech sense etc parser building trees over text includes chart chunk and probabilistic parsers classifier classify text into categories includes feature featureSelection maxent naivebayes draw visualize NLP structures and processes corpus access tagged corpus data STEVENS INSTITUTE of TECHNOLOGY 75 Accessing NLTK Standard Python import command from nlitk. corpus import gutenberg gutenberg. items austenemma. txt austenpersuasion. txt austensense.  txt biblekjv. 1xt blakepoems. ixt . . . . . . . .  shakesoearehamlet. txt shakespearemacbeth. txt whitmanleaves. txt from from nitk. corpus import stopwords stop stopwords. words english print fori in sentence. split if not in stop STEVENS INSTITUTE of TECHNOLOGY 73 What you can do with NLTK Tokenize and tag some text import nitk sentence At eight oclock on Thursday morning Arthur didnt feel very good.  tokens nltk. wordtokenizesentence tokens At eight oclock on Archusr cia ot eal tagged nltk. postagtokens STEVENS INSTITUTE of TECHNOLOGY 14 Tokens and Types The term word can be used in two different ways 1.  Torefer to an individual occurrence of word 2.  Toreferto an abstract vocabulary item For example the sentence my dog likes his dog contains five occurrences of words but four vocabulary items.  To avoid confusion use more precise terminology 1.  Word token an occurrence of word 2.  Word Type vocabulary item STEVENS INSTITUTE of TECHNOLOGY 75 Tokens and Types continued In NLTK tokens are constructed trom their types using the Token constructor from nlitk. token import mywordtype dog dog mywordtoken Tokenmywordtype dog Token member functions include type and loc STEVENS INSTITUTE of TECHNOLOGY 74 Tokenization from nitk. token import WSTokenizer tokenizer WSTokenizer textstr Hello world.  This is test tile.  tokenizer. tokenizetextstr Hello Ow world. 1w This2w Is 3w a4w Test 5w file. . 6w STEVENS INSTITUTE of TECHNOLOGY 17 3h 3shlUuxR Texts as Lists of Words Text Lama Ph. D.  student in Interdisciplinary Graduate Program in InformaticsIGPI University of lowa.  My advisor is Professor Kang Zhao in Department of Management Science.  My research interests include analyzing social support and social network based on social media data such as online health community and Weibo.  am also interested in building recommendation system text mining and association rules mining.  textI am Ph. D.  student in Interdisciplinary Graduate Program in InformaticsIGPI University of Iowa.  My advisor is Pro fessor Kang Zhao in Department of Management Science.  My research interests include analyzing social support and social network based on social media data such as online health community and Weibo.  am also interested in building recommendation system ext mining and association rules mining.  texttext. split text am Ph. D.  student in Interdisciplinary Graduate Program in InformaticsIGPI University of Iowa.  My advisor is Professor Kang Zhao in Department of Management Science.  My esearch interests include analyzing social support and social network based on social media data such as online health community and Weibo.  am also interested in building ecommendation system text minina and association rules minina.  STEVENS INSTITUTE of TECHNOLOGY Nee ee Searching TEXT nltk import nltk. corpus from nltk. text import Text ee STEVENS INSTITUTE of TECHNOLOGY 19 search concordance searching TEXT nltk Searching words appear in similar range of contexts similar Common context STEVENS INSTITUTE of TECHNOLOGY Computing with Language Simple Statistics frequency distribution import nltk fdistl nltk. FreqDisttest fdistl fdistl. mostcommon50 STEVENS INSTITUTE of TECHNOLOGY ee Computing with Language Simple Statistics Collocations and Bigrams nltk. bigramstext generator object bigrams at 0x10e87e2d0 Llistnltk. bigramstext am am Ph. D.  Ph. D.  student student in in Interdiscipli nary Interdisciplinary Graduate Graduate Program Program in in Informatic sIGPI InformaticsIGPI University University of of Iowa.  Iowa.  My My advisor advisor is is Professor Professor Kang Kang Zhao Zh ao in in Department Department of of Management Management Science.  Science.  My My research research interests interests include include analyzing analyzing social social support support and and social ocial network network based based on on social social media media data data such such as as online online health health commu nity community and and Weibo.  Weibo.  am am also also interested interested in in building building recommendation recommendation system system text text mining mining and and association assoc iation rules rules mining.  Listnltk. trigramstext STEVENS INSTITUTE of TECHNOLOGY 39 ee Mkt Categorizing and Tagging Words Divide string into substrings nitk. tokenize Partofspeech nitk. postag AT Article NN Noun VB Verb IJ Adjective IN Preposition CD Number END Sentenceending punctuation STEVENS INSTITUTE of TECHNOLOGY 73 Categorizing and Tagging Words textI am Ph. D.  student in Interdisciplinary Graduate Program in InformaticsIGPI University of Iowa.  My advisor is Professor Kang Zhao in Department of Management Science.  My research interests include analyzing soci al support and social network based on social media data such as online health community and Weibo.  am also in terested in building recommendation system text mining and association rules mining.  tokensnltk. wordtokenizetext tokens am Ph. D.  student in Interdisciplinary Graduate Program in Informatics IGPI University of Iowa .  My advisor is Professor Kang Zhao in Dep artment of Management Science .  My research interests include analyzing social upport and social network based on social media data such as online heal th community and Weibo .  am also interested in building recommendation syst em text mining and association rules mining .  tagged nltk. postagtokens tagged PRP an VeP pT Ph. D.  NNP student NN in IN Interdisciplinary J3 Graduate NNP Program NNP in IN Informatics NNP IGPI NN Pt cs hae .  rep University NNP Caf.  IN Iowa NNP c. 4 Ny.  PRPS advisor NN is VBZ Professor NNP Kang NNP Zhao NNP in IN Departmen NNP of IN Management NNP Science NNP .  .  My PRP research NN interests NNS include VBP analyzing VBG social JJ support NN and cC social 33 network NN based VBN on IN social J3 media NNS data NNS such JJ as IN online JJ health NN community NN tand CC Weibo NNP .  .  PRP am VBP also RB interested JJ in IN building VBG recommendation NN system NN text NN min ing NN and CC association NN rules NNS mining NN .  .  ee STEVENS INSTITUTE of TECHNOLOGY 54 Introducing WordNet large lexical database or electronic dictionary Covers most English nouns verbs adjectives adverbs Electronic format makes if amenable to automatic manipulation Used in many applications document retrieval and sorting machine translation. . . .  STEVENS INSTITUTE of TECHNOLOGY 25 What is WORDNET Machine readable semantic dictionary interlinked by semantic relations Developed by PRINCETON University Large lexical database for English language Language forms scale free network with small average shortest path having words as nodes and concepts as links source httpwordnet. princeton. edu ME STEVENS INSTITUTE of TECHNOLOGY Whats so special about WordNet Traditional dictionaries are organized alphabetically so words that are grouped together on the same page are unrelated WordNet Is organized by meaning so words in close proximity are related STEVENS INSTITUTE of TECHNOLOGY 37 Use of wordnet Easily navigable Used as online dictionary for English Freely for public availability structure to show relations in the form of noun verb adjective adverb synonymn hypernym ls kind of . . .  hyponym . . .  is kind of troponym particular ways to . . .  meronym parts of. . .  source httpwordnet. princeton. edu STEVENS INSTITUTE of TECHNOLOGY 28 Basic Design of WordNet WordNet entries are wordconcept mappings One concept can be expressed by many words synonymy car auto automobile close shut One word can express many concepts polysemy club stick club nightclub club playing card STEVENS INSTITUTE of TECHNOLOGY 29 Basic Design of WordNet WordNets building blocks sets of synonyms synsets hit beat big large queue line Each synset expresses distinct concept.  Currently WordNet contains appr.  117000 synsets ME STEVENS INSTITUTE of TECHNOLOGY 39 Basic Design of WordNet WordNet stores and allows one to retrieve all concepts that given word can express all words that express given concept STEVENS INSTITUTE of TECHNOLOGY Graphic representation using Tree structure STEVENS INSTITUTE of TECHNOLOGY 35 hl33slUui Graphic representation using Force Graph STEVENS INSTITUTE of TECHNOLOGY 33 Sentiment Analysis iw Sentiment thought view or attitude especially one based mainly on emotion instead of reason Sentiment Analysis opinion mining use of natural language processing NLP and computational techniques to automate the extraction or classification of sentiment from typically Unstructured text Can be applied to get product reviews consumer attitudes trends STEVENS INSTITUTE of TECHNOLOGY 34 Sentiment Analysis Approaches Machine learning Naive Bayes Maximum Entropy Classifier Support Vector Machine Markov Blanket Classifier Unsupervised methods Use lexicons STEVENS INSTITUTE of TECHNOLOGY 35 Limitation of NLTK Language limitations Corpora limitations Taxonomy limitations Minimal support for large sets of small text Limited predictive capabilities Limited associative capabilities STEVENS INSTITUTE of TECHNOLOGY Text as network Wordij WORD is package containing set of tools for text analysis lt takes plain UTF8txt format files as inout It creates Tiles to be analyzed by Wordi itself or by external tools One of the most information reach file is The network of words Network is based on cooccurrence of words within given window of words STEVENS INSTITUTE of TECHNOLOGY 27 3h 3shlUuxR iy Using Wordij Source File text file in UTF8 format Drop List File file with list of words that will be dropped Drop words pairs appearing less often than words pairs appearing less often will be not included in the output files Window size for extracting word pairs two words equal to or less than window size preceding and after each word in the tex STEVENS INSTITUTE of TECHNOLOGY 3g Wordij files STEVENS INSTITUTE of TECHNOLOGY Text Parsing with Python 2016 clipizzistevens. edu SSE What is Text Parsing Common programming task Extract or split sequence of characters Applications Simple file parsing Data extraction Find and replace Parsers syntactic analysis Natural Language Processing STEVENS INSTITUTE of TECHNOLOGY Ss Python Text Parsing Methods ie String Functions Faster easier to understand and maintain If you can do DO IT Different builtin functions Regular Expressions concise way for complex patterns amazingly powerful wide variety of operations when you go beyond simple think about regular expressions STEVENS INSTITUTE of TECHNOLOGY Managing Strings We can get at any single character in string using an index specified in square brackets The index value must be an integer and starts at zero The index value can be an expression that is computed STEVENS INSTITUTE of TECHNOLOGY Character Too Far You will get python error if you attempt to index beyond the end of string.  So be careful when constructing index values and slices Zot abc print zot5 Traceback most recent call last File stdin line in moduleIndexError string index out of range STEVENS INSTITUTE of TECHNOLOGY Strings Have Length There is builtin function len that gives us the length of string STEVENS INSTITUTE of TECHNOLOGY Looping Through Strings Using while statement and an iteration variable and the len function we can construct loop to look at each of the letters in string index index 22 individually STEVENS INSTITUTE of TECHNOLOGY Looping and Counting This is simple loop that loops through each letter in string and counts the number of times the loop encounters the character.  word banana count for letter in word if letter count count orint count STEVENS INSTITUTE of TECHNOLOGY Slicing Strings We can also look at any continuous section of string using colon operator The second number is one beyond the end of the slice up to but not including If the second number Is beyond the end of the String it stops at the end STEVENS INSTITUTE of TECHNOLOGY String Concatenation When the operator is applied to strings it means concatenation STEVENS INSTITUTE of TECHNOLOGY Using in as an Operator The in keyword can also be used to check to see if one string is in another string The in expression is logical expression and returns True or False and can be used in an if statement String Comparison if word banana print All right bananas.  if word banana print Your word word comes before banana.  elif word banana print Your word word comes after banana.  else print All right bananas.  STEVENS INSTITUTE of TECHNOLOGY 75 String Library Python has number of string functions which are in the string library These functions are already built into every string we invoke them by appending the function to the string variable These functions do not modify the original string instead they return new string that has been altered greet Hello Bob zap greet. lower print zap hello bob print greet Hello Bob print Hi There. lower hi there STEVENS INSTITUTE of TECHNOLOGY 73 String Library str. capitalize str. centerwidth fillchar str. endswithsuffix start end str. findsub start end str. lstripchars str. replaceold new count str. lower str. rstripchars str. stripchars str. upper STEVENS INSTITUTE of TECHNOLOGY 14 Searching String We use the find function to search for substring within another string find finds the first occurrence of the substring If the substring Is not found find returns Remember that string position starts at zero STEVENS INSTITUTE of TECHNOLOGY 75 search and Replace The replace function Is like search and replace operation in word processor It replaces all occurrences of the search string with the replacement string greet Hello Bob nstr greet. replaceBobJane print nstr Hello Jane greet Hello Bob nstr greet. replaceoxX print nstr HellX BXb STEVENS INSTITUTE of TECHNOLOGY 74 Stripping Whitespace Sometimes we want to take string and remove whitespace at the beginning andor end Istrio and rstrip to the left and right only stripo Removes both begin and ending whitesoace STEVENS INSTITUTE of TECHNOLOGY 17 Example From stephen. marquarduct. ac. za Sat Jan 16 2008 data From steohen. marquarduct. ac. za Sat Jan 16 2008 atpos data. find print atpos 21 sopos data. find atpos print sopos host dataatpos sopos print host UCT. aC. Za STEVENS INSTITUTE of TECHNOLOGY Regular Expressions In computing regular expression also referred to as regex or regexp provides concise and flexible means for matching strings of text such as particular characters words or patterns of characters.  regular expression is written in formal language that can be interoreted by regular expression processor.  httoen. wikipedia. orgwikiRegularexpression ME STEVENS INSTITUTE of TECHNOLOGY 19 Understanding Regular Expressions Very powerful and quite cryptic Fun once you understand them Regular expressions are language unto themselves language of marker characters programming with characters Itis kind of an old school language compact STEVENS INSTITUTE of TECHNOLOGY eee Regular Expression Quick Guide iw Matches the beginning of line Matches the end of the line Matches any character Matches whitespace Matches any nonwhitespace character Repeats character zero or more times Repeats character zero or more times nongreedy Repeats chracter one or more times Repeats character one or more times nongreedy aeiou Matches single character in the listed set AXYZ Matches single character not in the listed set az09 The set of characters can include range Indicates where string extraction is to start Indicates where string extraction is to end STEVENS INSTITUTE of TECHNOLOGY The Regular Expression Module lw Before you can use regular expressions in your program you must import the library using import re You can use re. search to see if string matches regular expression similar to using the find method for strings You can use re. findall extract portions of string that match your regular expression similar to combination of find and slicing var510 STEVENS INSTITUTE of TECHNOLOGY 25 Using re. search like find hand openmboxshort. txt for line in hand line line. rstrip if line. findFrom print line import re hand openmboxshort. txt for line in hand line line. rstrip if re. searchFrom line print line STEVENS INSTITUTE of TECHNOLOGY 73 Using re. search like startswith hand openmboxshort. txt for line in hand line line. rstrip if line. startswithFrom print line import re hand openmboxshort. txt for line in hand line line. rstrip if re. searchFrom line print line STEVENS INSTITUTE of TECHNOLOGY 24 STEVENS INSTITUTE of TECHNOLOGY 39 Hello Hello everybody 155 What are you All This is the very last class 200 Scott Guetens doing well.  207 So lets wait another few minutes.  So few sessions.  Its 211 628 so lets start the home time at 6.  30 220 so in theory you have min.  But considering that the number is kind of limited.  226 If you want to take more time for your presentation you can definitely do that.  The more time doesnt mean an hour but can be 15 min instead of min.  So its definitely up to you.  237 We have dont know exactly how many of you did that 251 easy teams but have 258 one team that presented last week and that its raised by the way and lets see 303 what is going to be today.  314 So just to have quick start.  Yeah.  Yeah.  Yeah Good.  Good.  just had question.  If was in group.  Do we all need to submit the report 318 Dean Manomat individually or just one person.  327 Yeah mean you know if you can submit that the same exact report if you have presentation or the submit that and the python that.  329 Dean Manomat Okay.  thought it was just one so didnt submit it on Sunday but can submit it after.  342 Dean Manomat Thank you.  350 Scott Guetens Sorry Professor Another question did.  Were we supposed to submit the presentation as well along with the the report and the code 351 you dont have to.  400 Its generally what people do.  But mean you dont have to.  403 Scott Guetens Okay thanks.  408 was.  was wondering if could volunteer to go first by chance.  409 Scott Guetens Yeah okay thats fine.  can.  can.  422 Scott Guetens can go if everyones ready.  425 Oh okay go ahead.  428 Thats what theyve been Asked Leona.  Yeah.  434 Scott Guetens Who Who is that 438 Leona Chia Yeah you and me Were in the same team man.  440 Scott Guetens What this is Scott.  444 Scott Guetens Oh thought it was being talking.  Im sorry.  Thats okay.  was like Wait what dont remember.  Work with you.  Okay that makes sense.  447 Scott Guetens All right.  458 Scott Guetens Is everyone able to see my screen 501 Yep.  504 Scott Guetens Let me put this up.  506 Scott Guetens and can everyone see the Powerpoint 509 Yep.  512 Scott Guetens All right.  So im gonna go ahead and get started.  So 514 Scott Guetens 519 Scott Guetens did my final project on the publicly available Federal aviation administrations digital obstacle file.  520 Scott Guetens and ran data analysis on it with my Python script that wrote.  So the digital obstacle file is do dot at file that the faa puts out every 56 days and it gets updated with obstacle data and when say obstacle.  Ill Ill explain what that means as go forward.  531 Scott Guetens so 555 Scott Guetens the contents of my my project.  My report here is that the first slide will be the project goals and the introduction to the data obstacle file.  557 Scott Guetens Ill go into little bit about my methodology for data analysis.  609 Scott Guetens Ill show you some of my results that came from that came upon using my script and then some conclusions that came to in this project.  613 Scott Guetens So the goals of my project.  My goal was to improve the safety of the airspace for air traffic control systems and pilots.  By analyzing this 626 Scott Guetens data digital obstacle for obstacle file that the Faa puts out to kind of get some ideas about where these obstacles are are primarily located some of the more common obstacles and then the less common obstacles 637 Scott Guetens what the highest obstacles And when say Hi mean height above ground level so they they say agl which is above ground level and that height 655 Scott Guetens wanted to see like what are some of the highest obstacles that they record data on.  thought it was pretty interesting given whats been on the news the last couple of months what actually was the highest.  But well get to that and then also wanted to see if there was way could build an interactive map 706 Scott Guetens of all these obstacles.  The conclusion came to was was not really but ill Ill get to that as well.  723 Scott Guetens So just also want to mention I.  So analyzed this data set to ab same these insights and and to reach this goal.  730 Scott Guetens all right.  So some of the methodologies used in my program for data analysis.  741 Scott Guetens So some ways manipulated the data.  This data set consist of over 550000 data points.  So it was lot of data to sort through.  So some of the methodologies use for grouping categorizing and sorting the data.  calculated some summary statistics.  748 Scott Guetens created some visualizations.  807 Scott Guetens did some data manipulations and processing and did try to do correlation 811 Scott Guetens analysis which didnt really come to much.  You can see the result over here.  tried to do correlation analysis between the latitude and longitude and then the 817 Scott Guetens the 829 Scott Guetens above ground level.  Basically how tall it is how high the object the obstacle is.  But came to find that there was not really correlation based upon where the obstacles located and the height of the object.  830 Scott Guetens So 848 Scott Guetens sorry my screen froze.  850 Scott Guetens Can you hear me cool Okay.  Sorry.  So heres my first set of results that got.  So some 854 Scott Guetens things calculated in this data were the largest item.  The the tallest item above ground level was in in this data set that was recorded which is mostly contained.  904 Scott Guetens contains fa reported data through studies and things like that.  So the the the highest item that was there was balloon that was recorded at 14947 feet.  917 Scott Guetens The lowest item was fence was at feet but it was interesting that theyre recording 928 Scott Guetens offense.  also dont understand how its feet tall.  935 Scott Guetens But some interesting data the average height above ground level was 164. 6 feet 939 Scott Guetens so and then the Median height above ground level.  Of all the data was 86 feet and to the right here you can see made an interesting box plot of all of the different types of 948 Scott Guetens data points so took the obstacle name.  Scott Guetens which was in specific field in the data.  And yeah Scott Guetens calculated how high each one it or use the above ground level data point to see basically like what is this spread the distribution of Scott Guetens of how and how low each individual object is Scott Guetens And you can see theres around 19 different types of objects that are reported.  Some of them are pretty general terms like one just says Plant cant really tell exactly what type of plant that is Hank.  Im not really sure.  Make water tank.  Scott Guetens but there were only 20 used.  And like said there were we over 50000 or over 500000 data points so clearly they follow some sort of methodology or system there.  But anyway you could see how broadly spread the data is in this box plot.  Scott Guetens and interestingly and its its.  It went so far as it it went above my Scott Guetens above my Scott Guetens graph here but it recorded the balloon as as way higher than the you can kind of see this cluster of all of the other objects and how high they are.  So that was definitely an outlier that struggled to deal with and and actually think it broke my plot little bit.  Scott Guetens But let me on here.  Scott Guetens So some more results came to.  So the States with the most obstacles are some of the bigger States Texas California Florida Illinois and Kansas over here on the left.  Scott Guetens and then you can see how many obstacles each of those locations have.  Id also like to point out that this data set also includes non some nonus data Scott Guetens which was didnt really wasnt really able to calculate in here with the States because there are different fields as you can see on the bottom right city or state but like over here you have the country which is Puerto Rico Scott Guetens and it those data points are calculated as well because they the Faa still cares about those for all surrounding United States flights.  Scott Guetens And then over here you see the States with the least amount of Scott Guetens data points or of obstacles recorded.  Thats DC.  Delaware or Dial in Vermont and Hawaii.  Scott Guetens So then broke it down to cities and analyze the the cities with the most at least so you can see Junction City.  It occurred lot in this Scott Guetens in this data.  didnt know what Jackson City was so looked it up as was running my report and realized that Junction City is just really common name for city.  And so Scott Guetens when built this piece of the code.  actually found bug Scott Guetens where it was not so should have had check for what state the city was in.  But Instead just got all of the data points for all of the towns name Junction City.  Scott Guetens and that all added up to be greater than some of the bigger areas that you can see below that are actual just singlename cities.  Scott Guetens So then you have Miami San Diego Columbus Chicago.  Pretty big cities makes lot of sense.  Scott Guetens and then it is with the least.  just thought it was interesting to put couple of them in there.  There were bunch of cities with one obstacle when was running through it.  But Scott Guetens these were just the the top ones on the list that saw.  And then in the top right You can see some really interesting data on the most common types of obstacles that exist.  So you have the by far Scott Guetens largest amount of obstacles are towers and the hour can mean lot of things.  And in doing some research about the data set itself.  learned that the next line is also our but its transmission line specific tower which is Scott Guetens like transmission line for like think cell phone towers or something.  was reading.  Scott Guetens But so the top are really towers all different kinds of towers whatever that means generally.  Scott Guetens And then you have polls.  was really surprised to see windmills in there.  Theres lot of windmills.  found that really interesting because didnt know there were still so many windmills around the country.  But apparently thats something that general aviation cares lot about.  So theres 76000 of them record in this data set Scott Guetens buildings makes lot of sense actually would have expected that to be like the most common.  Scott Guetens But you could see there it only 58000 Scott Guetens and then the least common that they recorded.  You can see that there is only one gate wind indicator whatever that means.  Only one ship.  dont understand why it only recorded one ship Scott Guetens like said this is one of the limitations Ill get to that.  But this is one of the limitations of the data set.  This is not all encompassing.  Its only what the faa has.  It is as its at its disposal in terms of the studies they conduct and things like that.  Scott Guetens just make sure im not going over time.  Scott Guetens and then Scott Guetens heat cool system again.  Im not sure what that means.  And then Arch was picturing like the St.  Louis arch things like that.  Scott Guetens And then on the bottom right here you can see the highest and lowest obstacles that they had.  The highest are all balloons.  So thats what was referring to earlier when was Scott Guetens discussing what was what has been in the news the past couple of weeks.  imagine Scott Guetens theyve updated this data set because dont know if mentioned every 56 days they update it.  Scott Guetens and imagine that they started really tracking these balloons after that news cycle Scott Guetens going forward.  This was just an interesting thing.  did where built scatter plot of the latitude longitude decimal conversion decimal converted data points.  Scott Guetens and what it did was draw pretty cool map of the United States.  So thought that was interesting.  Not too much mathematical value here but thought it was pretty cool thing that did where you can really see in it we can.  Up to you.  We we can see you but we cannot hear you anymore.  Scott.  Scott.  we lost You got okay and lets wait moment for Scott to come back.  Im becoming an expert on aviation.  So thats sec.  On the presentation on the aviation data.  Then had the student master student doing her on so slowly but surely and becoming an expert in aviation.  Okay.  So lets wait another few seconds and then if Scott cannot join back.  we will go to the next.  In the meantime Who What To be the next mean based on alphabetical order would say umbrella would be the first.  Are you ready Okay mean Im sorry that your first name last name.  You are with the first.  Okay so lets do that.  So lets go ahead.  April Amaral Okay.  let me.  Oh hold on.  Scott.  Scott Guetens Hi Professor Sorry.  My laptop totally froze.  Okay Ill get it back.  Do you want someone else to do the presentation while you will fix it up.  Scott Guetens So where where did it cut off dont even know with the map of us.  So Scott Guetens yeah am reselling my laptop.  Now itll just be minute.  But Scott Guetens yes so yeah someone else can go if they want.  Well way.  okay sounds good.  Ive been looking glad.  Sorry about that.  Yep.  So April Amaral yeah sorry.  Let me share the screen.  April Amaral Okay Im were sharing.  Okay.  April Amaral So did my project on the official world golf ranking website.  April Amaral And okay.  So heres just little overview of what my project was.  Ill give you little background April Amaral on the official world.  Golf ranking website what it is and how they April Amaral do their rankings.  April Amaral And then ill talk about my analysis of the data set which was specifically for week 14 which is the weekend ending on April ninth 2023 and then ill talk about my conclusions from my analysis.  April Amaral Okay.  So what is owdr its system of rating the performance levels of male professional golfers all around the world.  April Amaral The rankings is based on players position in individual tournaments or rolling of year period.  April Amaral The the website produces new rankings every week.  April Amaral and the calculate the rankings by dividing the toll points My number of events played in this average.  Then whoever has the highest average that is April Amaral at the top of the ranking and it goes highest lowest.  April Amaral So in my analysis took this data set and April Amaral filtered it and we only use and manipulated to only use specific columns April Amaral of the data set.  So looked up the Ill ill.  Ill show you in minute when which columns picked.  But April Amaral used to find the top 10 players in the ranking the top.  April Amaral the bottom 10 players in the ranking the players who have increased their rank since the end of 2022 the players of all who have decreased their rank and who have not changed the rank since the end of 2022.  April Amaral also created loop for person to select country.  And the April Amaral it will display the top 10 players from the selected country.  April Amaral also created some charts for the top 10 countries with the most players.  April Amaral and also have chart for number of events played per percentage of players.  So here we go.  So here is April Amaral what came up for the top and bottom 10 for the ranking.  April Amaral So use the columns of what their current rank is the rank of April Amaral the end of 2022 which country.  Theyre in the players name.  Their total points and number of events.  April Amaral And April Amaral so here we have April Amaral the rings that have changed since 2022 so the top here we have.  April Amaral who has increased their rank.  April Amaral Since the end of 2022 we have about 994 April Amaral players and then whos decreased their ranks in Santo 2022.  We have 7399 April Amaral and who has the same rank is just this short list here.  April Amaral And April Amaral okay so like said created loop for person to select country and the top 10 players from that country.  So here have an example of France and the United States.  April Amaral It gives all that information.  The players name their points.  April Amaral also have Italy and Japan.  and also another example for Chile.  April Amaral and then have example here If you selected country thats not in the list would say no players found.  and then you just hit exit to and the loop.  April Amaral And then okay.  So here is my chart for the top countries with the most players.  April Amaral and.  as you can see the United States has the most.  April Amaral And here is my hi chart for number of of events played by percentage of players.  so April Amaral based off of the data set.  So the the highest ranking right it is by the most events played so the highest would be probably in the 3. 9 April Amaral 4. 9 in the most are in the Theyve only played one to events.  April Amaral Okay.  And so what can conclude from this think this would be useful for gambling personally dont April Amaral gamble but feel like this Information wouldnt be useful for people that do that sort of thing and and this would be helpful for upcoming sponsorships sponsors who wanna April Amaral see who who is better April Amaral playing and also for tournament participation as well.  And this is also would be good for players to view their competition even though you know golf is individual sport.  Its good to see how other people are playing.  April Amaral and that is it Thats all got any questions.  Okay think its its its good job.  So are you golf player or would Just am.  Well just picked it up.  So im still be beginner.  Okay all right All right.  Are you enjoying do enjoy it.  Yes.  okay.  mean im runner and dont do many other sports and to me golf its kind of question marker just to say with your chart.  But mean that thats me.  anyway.  Okay thanks lot.  So lets go back to Scott Guetens Yep.  am ready to go.  Hopefully.  My laptop doesnt break again.  Scott Guetens need to look new laptop clearly Scott Guetens let me share my screen.  So think Scott Guetens got to the point where was on the the scatter plot just click through.  Scott Guetens So yeah was just pointing out that made this interesting scatter plot like said not really much mathematical value here for analysis purposes but thought it was interesting how when plotted the data on like an xy axis Scott Guetens of the latitude and longitude decimal values that it basically drew map of the us because you can see how prominent these Scott Guetens data points are throughout the Us.  You could see MacOs.  You could see Canada Alaska pretty clearly.  Scott Guetens So just thought that was pretty interesting.  Scott Guetens and in conclusion so the goal of my study was to improve the safety of the airspace for air traffic control systems and pilots.  Scott Guetens And so used various data analysis strategies to Scott Guetens understand this data such as summary statistics data visualization manipulation correlation and categorization and few limitations that faced while and analyzing this data was the quality of the data as you saw in my box plot.  Outliers were really challenge for me for figuring out how to get them out of the box plot.  It got it to point where wasnt able to to exclude it which really skewed my data.  Scott Guetens That was just the limitation of my ability in python think.  But then the accuracy of the data was also limitation.  So one of the fields in the and in the data file was the accuracy of each data point like how well the fa knows Scott Guetens that that object is where they think it is.  Scott Guetens And that was was trying to find way to incorporate that into my analysis.  But that started to get really complicated.  But so that was more of limitation of of my understanding of this really complex data file.  Scott Guetens And then finally the generalization like mentioned previously this is an analysis just on this one fairly large data file but its obviously not all encompassing of of any other similar data sets Scott Guetens so overall the Df.  The it.  Data set provides the valuable insights into the aerial obstacles monitored by the Faa and can be used to enhance the safety of the airspace.  Scott Guetens This project was really interesting for me because actually work on the Scott Guetens air traffic control system that the air traffic controllers use the software system to direct all and route air traffic above 10000 feet.  So thought this would be interesting to see Scott Guetens like.  Scott Guetens why do we kind of distribute the airspace into different different heights.  Scott Guetens So use that.  And used my experience for my job to kind of build this data analysis and and found it really interesting if its all right.  If have another quick minute.  want to show Scott Guetens the interactive map that built as well with my python program.  dont know if you guys are able to see this it might take second to load.  Scott Guetens Can you see that Not yet Scott Guetens Okay let me know if its visible.  So once you load that think let let me give you couple of feedback one is on when you show the data by State and Cds obviously states that are big are cities that are bigger.  They have more objects.  So it would be more of an indication to normalize the numbers by the size of the state of speed.  because at that point you may have more of an index of sort of risk that you have in that particular again city or state.  The other thing that it would be interesting to do is to find the sort of correlation between objects and accidents.  So using another data set with accidents hopefully they are jail located at the At the point.  You can see that we have the objects that are more at risk.  or it can be more risk for accidents because not necessarily just model of height.  So it could be the shape.  It could be all other things.  So thats something mean not criticizing what you do but it will be and whats next for the for the project that that you did.  Scott Guetens Yeah definitely agree.  Its interesting because one of the data points with thought which thought was little strange to include but its its pretty cool that they do is you can actually they They indicate the color of the object in the data set.  They have like they have like group of of points for that and thats one of the fields.  Scott Guetens and and like marker so so that Scott Guetens would go probably hand in hand with what youre talking about.  Like if can find like an an accident data set.  know the majority of accidents in in the error occur typically from like birds like bird strikes.  Scott Guetens But you know maybe theres still some correlation that thatd be interesting to look at for sure.  Scott Guetens Yeah.  So but Scott Guetens yeah so so real quick.  just wanted to show used the Api called folium.  dont know if youre familiar with it to to try to plot all these data points.  So tried to do it with the full data set.  It was not possible.  The it was it.  Basically what it does is it builds an an HTML file Scott Guetens that calls in bunch of like supporting mapping files.  And built this interactive Scott Guetens datas data set.  But was only able.  had to kinda Scott Guetens make the data set little bit smaller.  had to manipulate it so focused on everything higher than 10 everything higher than Scott Guetens 1000 feet.  Scott Guetens So the vast majority of the data is is short is lower than 10000 feet so you can see theres still quite bit of of pieces of data.  You can see.  You know we talked about Texas.  Theres quite piece quite few pieces in text but just like you said its big state.  Scott Guetens you know big cities in that state.  You can see like where lot of the big ones are.  Scott Guetens But just thought this was an interesting piece that oh.  spent bit of time on that.  thought it was pretty cool.  wanted to share Good job.  Okay.  Scott Guetens Thank you.  All right.  So following the are you okay Presenting Leona Chia Yes sorry.  was trying to click that.  Yeah can let me Leona Chia open Leona Chia my presentation.  Leona Chia dont know why didnt do that earlier.  My bad Leona Chia see shared screen.  Leona Chia Okay let me know.  Once you guys can see that.  Yup we can stay it.  Dean Manomat Yeah.  Leona Chia Okay.  So just you can see it still.  Yep.  Yep.  Leona Chia Okay.  just use your template that you sent out as an example.  So Leona Chia fancy ones.  Leona Chia anyway.  So we did our project.  Me Dean and Nina.  Leona Chia on public and media perception of mass shooting.  Leona Chia Let me give you some background.  Leona Chia Okay so Leona Chia obviously within the last month there was lot of media attention on like mass shooting it.  It just kind of feels like its been increasing lot.  We wanted to make sure that Leona Chia it was real guess real.  Or was it like sensationalized by the media We didnt do we didnt correlate this to mental health or gun loss As you can see the assumptions were that as you see in the screen just because Leona Chia the scope is quite big.  Leona Chia But anyway.  so the project will was to investigate the public and media perception.  So using subjectivity instead of you know like said mental work on law mental state or gun loss Leona Chia to to as the cause of mass shooting or to find out the cause when analyzing the rate of number of mass shooting.  We were limited to whats already out there need to obviously normalize some data while balancing Leona Chia relevant view viewpoints on the topic.  So theres lot of Leona Chia noise and or data in the media attention obviously for mass shooting.  So we had to deal with lot of guess combing through articles dealing with subjective discussion data also can be challenging.  Leona Chia So any one.  Leona Chia This is understanding.  think thats Dean.  Dean Manomat Yeah.  So Dean Manomat the problem to solve the problem to find the root cause of the mass shooting.  We identified Eric.  so we use believe different sources and reports from each stores Dean Manomat to look through what they had to say about the mass shootings and what their reasoning is behind them.  So.  Dean Manomat using the public forums we Dean Manomat analyzed we we use analysis and method planning Dean Manomat data extraction mythology Dean Manomat developed visualizations which we will see later in the presentation.  And then we evaluated it in terms of interpretations.  Leona Chia So in the data understanding again.  So we have to collect data just to see the trends if it was actually growing or increasing.  Or again based on media was it just sensationalized So we grab some data and Csv file.  Leona Chia and made graph from that which will show you way later because all the attachment which is in the end.  anyway.  And then we have to understand some of the outliers so based on the excel that we have Leona Chia the baseline of what was considered mass shooting.  Was Leona Chia it it changed Basically so Federal was started in at as as the definition for Leona Chia mass shooting.  But then in 2013 they actually moved it to 3.  So you can see Leona Chia quite big spike from from those dates.  Leona Chia and it.  Leona Chia anyway.  So from the articles we grab Leona Chia Conservative leading Liberal leading and then read it as kind of the neutral round just to see where theyre going like where it Leona Chia it was headed to for root cause.  Obviously with this topic guns are going to be prevalent and some other Leona Chia words are going to be prevalent.  So we kind of have to understand the context.  So we had to use Bikerams just to get those Leona Chia right.  Leona Chia And then here we have to prepare few like said this Csv file.  We need grass from that.  Leona Chia Another thing that we had to do because like New York Times and Cnn theyre always ever changing.  Theyre constantly updating and some of them have policies to kinda Leona Chia stop people from scraping data.  So what did was on those took Leona Chia the content and just copy and paste and put into txt file and then some like fast.  We were able to do that just like we did in the homework and then red it.  We had to do little bit more.  We actually had to be developer level and then we had to create an app Leona Chia for it.  And then after that then we can scrape the comments from certain post.  Leona Chia So Nina or Dean.  Mina Shafik No got it so Mina Shafik like they said we extracted all the data through our graph shows the result of mass shootings.  Mina Shafik We went in looking at this neutral so we didnt go in trying to face one side or the other.  Mina Shafik We wanted some of the things that we popped up.  Is is there greater new need for solution for solution Mina Shafik So what were the keywords that people were saying what are the causes Was it mental health gun control etc.  etc.  Mina Shafik So we use natural language pressing through python to take the sediment values of the discussion.  Again we look for common words and diagrams for every single one of the data sets Mina Shafik we created data visualization.  This is the sorry Mina Shafik we have.  Mina Shafik My heads not there Today Leona Chia We created word clouds to run it to run it through.  We also created the sentiment analysis for every single one of the websites ran it through Mina Shafik for any of the keywords what was believed to be the issue.  Mina Shafik and then we compared all the different opinions from each one.  Mina Shafik and what was similar about them to try and fix and see what the issue that theyre presenting.  Again we did not go in Mina Shafik with into this project looking for specific cause.  You know Mina Shafik we go to next slide.  Leona Chia Im going to actually move to the Leona Chia the work.  We cloud the attachments that way we can talk about it then.  Leona Chia so really quick so obviously it has been increasing like said the trend line from 2013.  You can see the big spike afterwards.  The trend line is going up and just use linear interpolation of those.  And then again.  Leona Chia It looks like its going to be normalizing because of Covid.  You can see that spiked out from 2020 to 2021.  Then it went back up and it looks almost like its normalizing.  But in fact the average yearly number of shooting actually has increased Mina Shafik and sorry.  One more thing and actually something that we brought up during this point of the day is for majority of that time people were Mina Shafik quarantine people were isolated.  Mina Shafik so that could have been one of the causes.  There is also less people out on the streets.  If anybody here drives Mina Shafik your commute to anywhere during Covid if you were an essential worker was Mina Shafik 10 times faster.  Leona Chia Alright so this is for the more liberal leaning like whoever did cnn Leona Chia and go.  Dean Manomat Yeah so took look at this word cloud for the Cnn article and as you can see gone firearm violence.  Those are like the biggest words and the Cnn article is definitely more liberal leaning article where they kind of focus more on Dean Manomat like regulation and gun control kind of things being solution for Dean Manomat all these shootings.  Leona Chia you know.  Mina Shafik So.  So ran for ran the one for Fox which we assumed was Mina Shafik going to be about what it was.  Mina Shafik So again some of the biggest words were gone Government antidepressant.  But the surprising thing about the about Fox was it actually lean more into Mina Shafik mental health awareness for gun control Mina Shafik Not so much as to Mina Shafik that the guns are the violence itself.  Again we assume that.  Mina Shafik And yeah it was it.  It ran through exactly how we expected it.  To Mina Shafik none of the Mina Shafik articles went against what we thought they were going to Leona Chia Oops.  Sorry.  Leona Chia and then the last one should be reddit.  So this one was more neutral and dean you wanna Dean Manomat the way they kind of saw it was kind of from the point of view from it seemed like actual normal people almost where everyone had different kind of opinion because guess Cnn and Fox are all Dean Manomat news sources and they have certain biases that theyre going for.  But Reddit seem to be more of like just everyone in the community putting out their thoughts and everything.  So it kind of was mix of the Leona Chia which wasnt surprising.  So anyway.  So the next time we if we would do this for future improvement is definitely to expand the sources Leona Chia using existing peer reviewed Leona Chia and then obviously normalizing the metrics.  So population versus total gun control maybe in the State.  Leona Chia actually Leona Chia evaluating and accept sorry assessing mass shooting instances not just the overall sense of what each Leona Chia news channel.  This outlook is but more of comparison between each one.  Leona Chia Yeah.  Leona Chia thats pretty much all we did.  Okay sounds great.  So what you did was basically reading the news in different way.  So reading the news analyzing it.  we are more and more on reading the news by the titles.  So thats exactly the opposite of that.  So not just reading the news but digging into it.  So what was your experience So Leona Chia for me When did it.  was honestly not surprised.  Obviously with you know like gun control and mental illness from from both sides.  The thing that surprised me is how much they focus on certain details.  So for me you know.  Leona Chia im not trying to be polite political here but lot of the Times.  Yes know gun control is sensitive subject.  But to me lot of times when we when we speak to like liberal leaming Leona Chia views.  Leona Chia Yes gun controls the thing but they also talk about mental illness.  But in lot of the articles that we read it was very few and far between of just having mental illness being one of the topics that they bring bring up.  It was more towards its guns guns and more guns.  Leona Chia whereas when we looked at Leona Chia the conservative leaning of views.  Yes they talk.  They are very defensive about their guns as we kinda all mostly know.  But what surprised me is how much of the mental illness that they bring up.  But when you read the title it definitely doesnt say that.  Mina Shafik Yeah actually was just saying agree with her.  Mina Shafik Didnt expect the more conservative side to be so much more focused on mental health Mina Shafik and the Liberal side.  guess Mina Shafik when we were going through it.  We expected the liberal side to be more mental health.  not cold.  like mental health and Mina Shafik the Conservative side to be more.  Mina Shafik guess.  Gun awareness if if you know.  Mina Shafik but it wasnt like that at all.  The thing that surprised me the most was reddit.  Mina Shafik because feel like Reddit is where everybody goes to Mina Shafik voice their opinion.  Mina Shafik and thought it was going to be very liberal.  But it wasnt.  Yeah.  mean that the the news they have an agenda.  So whatever is the agenda but its not necessarily the readers agenda being able to dig into it.  Its really essential.  Now think for second and think in terms of the next generation of chat erez agmoni when people would use bots like that to go into the news and getting distilled version of the news 150 that is exactly the opposite.  So unfortunately think that like that will happen meaning that we will be more and more manipulated by whoever is going to do this somebody for us.  So my opinion is really important.  So to create our own opinions.  So whatever it is mean.  dont have any bias on that but only if we create deep rooted opinion then we can really mean contribute to to the calls or the solving problems.  So when problems with happen and mean must.  Shooting is problem that needs to be fixed because thats real.  So.  anyway.  Do you wanna want something Leona Chia No just couldnt agree more.  Okay all right.  So we have more Kyle.  It is not here.  Thomas Thomas.  Thomas Poklikuha hey Sorry about that.  Yes can present.  Give me s.  Yep.  Thomas Poklikuha Okay.  Thomas Poklikuha So what did for my project is wanted to analyze Thomas Poklikuha the Nda draft combined data to Nba draft success as grew up as an athlete so wanted to kind of dive into the field of athletics and see how Thomas Poklikuha data drives drafts.  Thomas Poklikuha So the like.  said the purpose of this was kinda to define how define and analyze how athleticism and different attributes affected Nba draft success.  Thomas Poklikuha So at the Combine all of these players do series of tests.  and then they get graded Thomas Poklikuha on.  How Well they do them.  They bench press they sprint they do agility test and all that.  wanted to see if could build correlation between these attributes and how well they did getting drafted.  Thomas Poklikuha Meaning if you got drafted number one overall that means you did really really good job in the draft and you cant score any Thomas Poklikuha better than that.  Thomas Poklikuha also wanted to see if there was any key factors that Thomas Poklikuha overwhelmingly drove teams to draft you.  If there was handful of attributes.  Thomas Poklikuha If there was physical or anything that was an outlier of hey you do really good in this one test.  Youre going to get drafted.  Thomas Poklikuha So just to give you little snippet of my code was able to.  tried to define athleticism Thomas Poklikuha as fairly as could for anyone who is an athlete.  Thats really really hard thing to do.  just because someone runs really fast or conventional out of weight doesnt necessarily mean that theyre good athlete.  Its kind of an overall encompassing term.  Thomas Poklikuha So Thomas Poklikuha just for the sake of this code defined it as how high you could jump.  Thomas Poklikuha How much you could bench your agility and how fast you could sprint.  And all of those data points were taken from the combine.  Thomas Poklikuha And then once gave each player Thomas Poklikuha score.  could then Thomas Poklikuha create comparisons and correlations from each attribute to draft success and Thomas Poklikuha different draft ranges that had high athleticism.  So as you can see in this this first plot if you were drafted one.  We can also see your call the we just if you No you didnt share the screen yet.  Thomas Poklikuha Oh really.  Yep.  Thomas Poklikuha Oh Im sorry.  Thats okay.  Thomas Poklikuha Oh well you go back and let me go back to slide then please.  Yeah.  Thomas Poklikuha So these are the attributes that wanted to generate coefficients from.  Thomas Poklikuha So they do all of these at the combined.  The sprint agility test body fat bench vertical.  Thomas Poklikuha All of this stuff they measure at the Nba Combine and wanted to generate coefficients and see how each of these affected the your draft success.  Thomas Poklikuha So already went over that slide.  So the next slide is is how defined athleticism.  This was the score that gave which was also the vertical.  Thomas Poklikuha the bench.  The agility test and sprint Thomas Poklikuha from from this score can Thomas Poklikuha give score to each player from 2012 to 2016 which is what the data set Thomas Poklikuha tracked.  So years of of data.  Thomas Poklikuha And then was able to plot the average athleticism by pick range.  So Thomas Poklikuha kind of.  Logically it makes sense that the first tenth pick Thomas Poklikuha they have higher athleticism score than the other picks.  If youre better athlete it kind of makes sense that Thomas Poklikuha youre gonna get picked high because youre Thomas Poklikuha you have an easier time playing basketball and make it look easier.  Thomas Poklikuha As for the picks through 11 through 40.  Theres no real change in that.  Its kind of Theres no Thomas Poklikuha clear picture of its clear drop off or clear increase.  Thomas Poklikuha And then also because had the score for each player drafted in those years could determine who the best athlete was Thomas Poklikuha from my scoring system and the best athlete was man shepherd who youre an if youre nick fan you know who that is but Thomas Poklikuha hes good basketball player.  Worst athlete is also easy to calculate.  Once you have the score and to print all of the stats.  Thomas Poklikuha So went ahead and did that something else that did for all of the Thomas Poklikuha attributes that are tested at the combined.  plotted them against the draft position and plotted them with the average across all of the years.  So the red line here is the average across all of the years.  Thomas Poklikuha and this little text up here just tells you Thomas Poklikuha how much is above average and how much is below average.  Thomas Poklikuha So for all of these all of the attributes that were tested in the combined.  Thomas Poklikuha did this and you can see where the number one draft pix are by this red dot.  so you can see how they stack up against the field Thomas Poklikuha bottom line is the summary.  Theres no clear indicator.  So set out to try to find what factor matters the most in Thomas Poklikuha draft success and theres not one which Thomas Poklikuha makes sense because each year different teams have different needs for players.  So Thomas Poklikuha sometimes the worst team the League drafts first and they need point guard who tends to be shorter and quicker Some other times.  The worst teams in the League need centers who are tall and slower.  So youre not going to get perfect picture of.  If youre really fast youre going to be really successful.  Thomas Poklikuha But was looking for key key elements and Thomas Poklikuha its its useful.  Thomas Poklikuha but it doesnt have that clear and concise Thomas Poklikuha attributes or couple of attributes that really indicate success in the future.  Thomas Poklikuha Some limitations of this data is like said.  The team needs depending on what the team whose drafting you need is is gonna depend on what attributes they tend to draft height verticals speed agility all that stuff.  Thomas Poklikuha If wanted to go further with my analysis could have Thomas Poklikuha compared the results to actual actual Nba success.  Thomas Poklikuha How many years they played how many all stars Thomas Poklikuha they were voted on how much money they made or or how healthy they remain throughout their career.  But overall just looking at the combined data.  think did pretty good job of of visualizing the data Thomas Poklikuha and drawing correlations between the attributes and the draft success.  Thomas Poklikuha So that is concludes my presentation.  Im sorry that started it late accidentally.  Any questions can answer them now.  One not consideration is not even question.  One thing that could have been done would be to class or all the athletes by the role that they could play.  because at the very end as you were saying By the end of your presentation it really depends what team is looking for.  So for certain positions you have more one characteristic than the other and so on.  So it would be interesting to all of them by the role that they would play and see how the overall as the red this is can play role into being selected.  What do you think Thomas Poklikuha Yeah agree.  Its Thomas Poklikuha saw about doing it Thomas Poklikuha in way but defining what team needs Thomas Poklikuha is difficult.  You can do it based off of position.  But sometimes when players change positions it becomes difficult to track that.  Yeah yeah yeah yeah.  Thomas Poklikuha So Thomas Poklikuha about doing that and clearing up and and making it cleaner.  But like said once you get to that level and they start changing things it gets difficult to track.  Yeah.  Yeah yeah yeah.  Okay sounds good.  Good job.  Thomas Poklikuha Thank you.  All right.  think that we have only Kyle.  That is not so.  That is not in the session.  So thats basically it all that all.  really hope that you enjoyed the course that you enjoyed playing with the either for those of you who didnt quote the at all before.  hope that was not too bad for you.  and if you have something to share about your experience in this course would be super happy to hear because mean your input is really valuable to me because will use it for the next semester or the following comments.  and think will randomly pick someone.  Eliza.  Do you have any comments.  comments wise mean like said in previous class like had never used Python in very advanced way before.  definitely had my hand held the entire time when had used it professionally in the past.  definitely My one comment was the jump from homework to homework gave me heart attack.  But thats about the only negative thing have to say.  think it was.  definitely think the course was very useful definitely helped my overall coding ability for work too.  Sounds good.  Okay So thats basically the end of the class.  So the end of the course will post the the final grades shortly so we normally have 72 h.  So to post it and will and plan to stay in the that range.  if you have any question and still have couple of assignments to review before going to the final grade.  One meaning didnt check some of the quizzes.  Actually that we are controversial overall.  You did great mean.  The class was very good.  mentioned it few times so im teaching 24 classes.  This semester is most of the semester.  So so this is the and the majority if not all of the Wn.  Students are professionals.  while the Non wn that can be on campus or to be online our regular students.  Most of the the majority of the cases nonprofessional.  There is big difference.  There is big difference in terms of size of the class.  So the size of of class like this one its more manage polar.  Its more interactive.  My opinion at the very end is more effective when you have class like 55 students so that they have in the ws version of and 2024.  This semester think are.  mean it.  Its broadcasting basically but also there there is big difference in t.  So what is at stake.  When you are professional you are embarrassing your own time.  You are taking time out of your personal life.  Your job for this courts for spending time with me.  and grateful for that.  So and definitely want to give you back as much as possible and really appreciate all the comments that you may have.  This is not always the same when you have regular students so they are for use more on the grade.  So for all of you the grade that is important but also the knowledge is important.  You are going to use what you are learning in the program in genital and in this course in for your job.  So when you are professional you basically have possible goals.  Do better in the area where you currently are either in your company or switched into different company or take the opportunity for career change.  and both the cases there is quite lot at stake for for you.  So that means that that you may have more issues at the very beginning because of the professional as most of the time some years of experience.  But that means that that last time you were on on on the books learning something mean.  That was several years ago while for young kid coming out of the undergraduate program they are more fresh.  So really understand that that could be more deep figure for you.  So again think share my experience.  So was in industry for more than 25 years and then went back to her academy to get my Phd.  And start with my Phd.  Age on 50 and and change.  and that mean it.  It was not easy.  What was mean It was fun but was not an easy fan lets say.  and really understand your point of view and really appreciate the time you are You are spending in this program the time you spend on this code so that you spend with me.  So again.  Thank you all.  appreciate you being in the class and really hope that that was useful for you.  Whatever question you have whatever can be of any help would be happy to do so.  So all the best enjoy the rest of your evening and the rest of your time and hope to see you some time soon.  All the best.  Thanks so much Professor.  Have good night.  Who Killed the Virtual Case File Written by Harry Goldstein Published IEEE Spectrum September 2005 Overview September 2000 FBI IT begins Upgrade Project Virtual Case File VCF planned to replace the Automated Case Support ACS system April 2005 Project failed spectacularly and was cancelled.  FBI scrapped 105 million worth of unusable code FBI background why was the VCF so important As of 2004 the FBI had 4050 different investigative databases and applications So of course there were lot of duplicate information and functions The FBIs work environment is paperbased Agents document every step and build case files Each form goes through approval chain Automated Case Support ACS Most heavily used investigative application Stores forms related to investigations Debuted in 1995 and was considered antique even then Cumbersome inefficient limited capabilities Complicated menus Allows basic searches The Trilogy September 2000 FBI Upgrade Project approved by Congress Project consisted of parts Information Presentation provide new Pentium PCs scanners printers and servers Transportation Network provide secure local and wide networks User Application identify way to replace the FBIs 40something investigative software applications 34 component ultimately became the VCF The Trilogy June 2001 Applications International Corp.  SAIC awarded contract for software part Trilogy supposed to be delivered by the middle of 2004 But in 119 the inability if the FBI to share information became public knowledge The FBIs information systems were woefully inadequate.  The FBI lacked the ability to know what it knew.  119 commission report 2004 Trilogy is shifted to high gear VCEF Goals Automate the FBIs paper based work environment Allow agents and intelligence analysts to share investigative information Replace the Automated Case Support system eo ee ee eR First problem no general direction The FBI didnt have blueprint The FBI couldnt make coherent or consistent operational or technical decisions about creating policies and methods for sharing data and making tradeoffs between information access and security NRC report 2004 The team began to feel their way in the dark.  Characterized investigative processes and mapped them to the FBIs databases Defining the requirements FBIs team and SAICs engineers hashed out what functions the VCF would perform Requirements document ended up being 800 plus pages long Violated the first software planning rule keep it simple Included system layout and application logic Agents would bring web pages to sessions to demonstrate how they wanted VCF to look eo ee ee eR Defining the requirements The requirements were not sufficiently defined in terms of completeness and correctness Later in the project they required continuous redefinitions This had cascading effect on what had already been designed and produced More money January 2002 FBI requested an additional 70 million to accelerate Trilogy.  Congress approved 78 million SAIC agreed to deliver the initial version of VCF in December 2003 instead of June 2004 SAIC and the FBI were committed to creating an entirely new system in 22 months FBI wanted to switch to VCF using flash cutover Contracts problems Trilogy contracts were changed to reflect the new deadlines Trilogy contracts didnt specify any formal criteria for the FBI to accept of reject the finished VCF software Trilogy contracts specified no formal project schedule In particular they specified no milestones And yet more money December 2002 FBI asked Congress for additional 137. 9 million for the Trilogy The inspector general issued report on the FBIs IT management The lack of critical IT investment management processes for Trilogy contributed to missed milestones and led to uncertainties about costs schedule and technical goals Undisturbed by the findings Congress approved 123. 2 million Total cost of Trilogy so far 581 million el a.  et ee The writing Meanwhile SAIC programmers were cranking code using spiral development methodology Roughly 400 change requests of the system were made by FBI from December 2002 to December 2003 Some were cosmetic but others required adding new functions to the system Example page crumb eo ee ee eR Changing the VCF Many changes of the program had to be made by all of SAICs development teams SAIC officials admit that in the rush to get the program finished in time they didnt ensure that all the teams were making the changes the same way The inconsistency meant that when one module needed to communicate with another error sometimes occurred tile Delivering the VCF SAIC began testing the VCF in the fall of 2003 13 December 2003 SAIC delivered the VCF to the FBI only to have it declared DOA The FBI found 17 functional deficiencies it wanted SAIC to fix before the system was deployed Additional tests revealed 400 more deficiencies VCF The end June 2004 The FBI contracted an independent reviewer to recommend what the FBI should do with the VCF Delivered in January 2005 the report said High level documents including the concept of operations were neither incomplete inconsistent and didnt map to user needs The software cannot be maintained without difficulty It is therefore unfit to use oe VCE After April 2005 FBI officially cancelled the VCF project May 2005 FBI announced Sentinel.  4phase 4years project intended to do the VCFs job and provide the FBI with web based case management system Sentinels estimated cost was unrevealed FBIs officials seem confident that the FBI can handle the complicated project SYSTEMS wa ENGINEERING COMPLEX SYSTEMS RESEARCH CENTER ENTERPRISES Natural Language Processing NLP for Requirements Engineering Extracting Formal Structures from Text by Dr.  clipizzistevens. edu October 2021 Agenda ENGINEERING RESEARCH CENTER October 2021 UNCLASSIFIED The context ENGINEERING RESEARCH CENTER requirement is singular documented needwhat particular product or service should be or how it should perform.  It is statement that identifies necessary attribute capability characteristic or quality of system in order for it to have value and utility to user Mitre Requirements engineering RE is the process of defining documenting and maintaining requirements in the engineering design process.  It is common role in systems engineering and software engineering Wikipedia October 2021 UNCLASSIFIED The context ENGINEERING RESEARCH CENTER Acomplete collection of requirements for given system can provide an abstract representation of the system itself.  The resulting model is as accurate as the the process and the method that is used to generate it within given range of time validity The collection of requirements has traditionally been topdown approach requiring SMEs with convergent vision SMEs may not be as available as needed systems may change in time October 2021 UNCLASSIFIED The context ENGINEERING RESEARCH CENTER We are focusing on requirement engineering with reverse engineering approach extracting requirements from existing material Requirements is generic term and it may have different meaning depending on the context It could be an ERA model if the focus is on data representation it could be systemigram if focus is on modeling system it could be causal chain October 2021 UNCLASSIFIED Natural Language as source of Data RESEARCH CENTER 8590 percent of all corporate data is in some kind of unstructured form such as text and multimedia Gartner 2019 Tapping into these information sources is need to stay competitive Examples of application of Natural Language Processing insurance claim processing law court orders academic research research articles finance reports analysis medicine discharge summaries technology patent files marketing customer comments Source Tractica October 2021 UNCLASSIFIED Challenges in Natural Language Processing ENGINEERING RESEARCH CENTER Semantic ambiguity and context sensitivity automobile car vehicle Toyota Apple the company or apple the fruit Syntacticformal ambiguity Misspelling Different words for the same concept e. g.  street st.  Implicit knowledge We talk about things giving for granted common or specific knowledge October 2021 UNCLASSIFIED Implementing NLP RESEARCH CENTER Language is changing constantly and NLP is following the changes going from processing based on predefined structures taxonomiesontologies syntax to structures deducted from the text itself Limitations of the traditionaldeductive symbolic approach Today language is more fragmented has less structure has more jargons Different points of view may provide different interpretations Machine Learninginductive approach Extracting numerical structure from text Different structures for different points of view Different structures automatically extracted over time Implementing NLP limitations RESEARCH CENTER Understanding Language is not just processing.  Understanding is human characteristic analyzed by philosophers as part of Epistemology An accurate by human standard understanding can come only from model of human mind The current leading models in NLPNLU are focused on the algorithmic part missing real model representing how the knowledge is created and used.  It is basically representing the brain not the mind.  The leading model for NLP GPT3 by OpenAl has 175 billion parameters feeding neural network providing results as black box October 2021 UNCLASSIFIED 10 NLPbased tools and techniques for RE tools clustered by NLP4RE tasks and then by RE phases NLP techniques and their frequency of use L.  Zhao et al.  Natural Language Processing for Requirements Engineering Systematic Mapping Study ACM Comput.  Surv.  vol.  54 no.  October 2021 UNCLASSIFIED 11 State of the art bottom line RESEARCH CENTER We considered 134 tools and approaches to apply NLP to Requirement Engineering The main insights resulting from the analysis were that no approach completely fulfilled the criteria of self extracting requirementsstructures Solutions leveraging on Machine Learning with semi supervised approach seems to be promising M.  Vierlboeck C.  Lipizzi and R.  Nilchiani Natural Language Processing for Requirements Engineering Structure Extraction An Integrative Literature Review Under review October 2021 UNCLASSIFIED 12 Our Approach ingredient the Network RESEARCH CENTER The approach is based on corpus representing the domain we want to model The corpus does not have formal structure connecting its semantic elements Using approaches based on wordsngrams proximity and applying techniques such as Word2Vec we create semantic network representing the corpus In the network the nodes are wordsngrams and the edges are calculated based on their proximity October 2021 UNCLASSIFIED 13 Our Approach ingredient Network Theory RESEARCH CENTER We apply partitionclustering method based on Louvain Community Detection creating topics For the nodes in the cluster we calculate composite metric based on degree centrality page rank and betweenness centrality We pick the nodes with the highest values for the metric those are the candidates subjects in their clusters October 2021 UNCLASSIFIED 14 Our Approach 3rd ingredient The Room Theory The room theory is framework to address the relativity of the point of view by providing computational representation of the context The non computational theory was first released as schema theory by Sir Frederic Bartlett 18861969 and revised for Al applications as framework theory by Marvin Minsky mid 70 For instance when we enter physical room we instantly know if it is bedroom bathroom or living room Roomsschemataframeworks are mental frameworks we use to organize remembered information and represent an individualsdomainspecific view of the reality We create computational rooms by processing large corpora from the specific domaincommunity generating numerical dataset embeddings table.  The table is representation of the wordsngrams where each one of them is ndimensional vector and we use it as knowledge base for the contextpoint of view C.  Lipizzi D.  Borrelli and F.  Capela The Room Theory computational model to account subjectivity into Natural Language Processing October 2021 UNCLASSIFIED 15 ie How the room theory works Room theory enables the use of contextsubjectivity in the analysis of the incoming documents Contextsubjectivity can be the point of of view of subject matter expert The contextsubjectivity in the analysis is represented by domain specific numerical knowledge base created from large domain specific representative corpus that is then transformed into numerical dataset embeddings table 1.  point of view for the comparison the room.  This is represented by the embeddings table extracted from largerepresentative corpus from the specific domain 2.  Alist of extended keywords using synonyms and misspellings to be used for the analysis the benchmark Our Approach putting things together RESEARCH CENTER We prune the list of ngrams using the room theory We create ego networks for the subjects.  The degrees of separation is function of the size of the cluster The ego networks represent the semantic dependency between the nodes within the topics The approach can be extended to interclusters relations to recreate the complete formal representation Why all of this is relevant The current MLbased models are limited to similarity between semantical elements but they do not consider more complex relationships between them such as semantic hierarchy October 2021 UNCLASSIFIED 18 Our Approach putting things together The flow on top provides adjustments based on domainspecific knowledge The flow at the bottom is the actual workflow on the system documentation How we use it so far We used it to determine the causal chain in the domain of technologies Each technology has components that are other technologies required for the first one.  For example cell.  phones batteries display antennas . . .  Our Approach next steps RESEARCH CENTER With the proper funding we will implement the following missing elements Upgrading the causal chain applicationupgrading the overall approache Using the room theory to make the entitiesnodes more relevant Implement the interclusters relations Implement feedback mechanism to update the benchmarks Test it on multiple domains Extending it to applications where edgesrelationships have semantic value such as for Systemigrams and ERA We will create bipartite2mode graph EF such that if is an entity and is relationship there is an edge aj e7 Aif and only if is associated to relationship We will then extract 1mode graph with entities only.  Two entities will be connected if and only if the share the same relationship.  The common relationship will be the label in the Systemigrams or ERA The extraction of relationships will be done using the room theory SYSTEMS CENTER FOR ENGINEERING COMPLEX SYSTEMS RESEARCH CENTER ENTERPRISES STEVENS INSTITUTE of TECHNOLOGY THE INNOVATION UNIVERSITY Thank you Dr.  clipizzistevens. edu You have in notebook you cannot really do that.  430 So the notebook is basically executed the step by step.  439 And mean it.  Presume that someone is doing it.  444 It is great when you do presentation.  It is great.  450 If you want to have it as sort of showcase when you go for the job and you want to show that you are doing coding in proper way and you use it and thats fantastic.  451 use it in out of my projects.  So when go to client or response or and say Okay want to show you the code and how the code is working with the results step by step it is great but what we do here is not.  505 Great so please submit the the dog pie.  An individual file.  Now theres file up and now it and not work with the notebook.  530 You could export the not Booker into dot.  542 Pie they export is not clean file.  There are some control characters that are comments that are not comments.  549 So if you really want to use if you are religiously philosophy are against writing dot pie it is okay.  604 Use your notebook export the notebook in the pie but then you need to check it and edit it because you want to have something.  619 That is not fake comments or things that are not supposed to be in file.  623 So thats the reason why strongly encourage you to use any id you can use pi Sharma.  638 You can use you name it Eclipse.  Thats fine.  647 You can use dont know.  Sometimes use text editor that that is called.  652 dont even remember how its call it sublime text.  703 That is tech study or with just little bit of sugar on the indentation on the quotation.  Things like that.  708 But minimal.  So whatever you use thats fine for me.  720 But what we want if the dog is dot pie as it would be generated if you run it.  725 So thats something.  Lets move on.  736 really dont think that is to mean we we can do that.  743 The.  752 Minimize this.  Okay let me share the screen again.  758 And let me go here.  So what you were supposed to do 807 Its basically just to write 814 You your name here.  So for all the rest there was not much to do so it was just way to become familiar with the that user interface that this program has this Pi Sharma or any other Id.  821 Be sure that you have python and python is running properly and thats basically it.  842 mean that very few points.  There are 20 points for this assignment just because its very basic.  851 For this first assignment we are not enforcing in street way the policy on late submission but to read one because we want to be sure that you do it in the proper way.  903 You still find on Python is working you can run by charma and thats the first reason.  913 The second reason is because is the first assignment.  Things can go wrong.  926 The installation is not going.  Okay.  Thats absolutely fine.  931 Also know not really presenting anything more than last class meaning meaning mean the reason why want you to submit before the beginning of the class is because can present the solution of the program of the assignment.  937 But in this case anonymous presenting it because its pretty much the same man that you already had in that the Except site pi No.  screen.  The that was on canvas because we we sub.  mean we are giving us some slack.  That doesnt mean that there is any change on the deadline for the submission of what next assignment.  So next assignment is you 60clock next Wednesday pdf so not because you started late.  You will start late.  You will finish late the the next one.  So thats deadline for next one is going to be next Wednesday.  At 60clock think we can go at this point on something that want to show you first before we go to the slides.  So let me go with that this shortcut video for momenta Hi Professor dont hear any audio for the video.  Oh okay so let me fix that.  dont know why Okay let me stop sharing for the cell phone that Alright so lets do it in different way.  So.  Okay can you all go to the canvas And click on history of software Are you okay With that Okay.  Once you are on the canvas again click So go.  Yeah click on this one.  And you will have the video starting So Ill give you min.  In min will start talking again.  Hopefully click on the video.  Watch the video and we will come back in min.  Purple.  Yeah we are watching video on software engineering.  Software development is min video and is on canvas police teleconnect and watch it Alright.  So done with the video.  Thank you for letting me know and let me presume recording.  Okay.  So the video was brief introduction to the key theory of software.  So how it started how evolved Let me share the screen again.  Let me go with the some slides.  So so this first batch of light.  So its something that you will see again in few classes with more details.  But really wanted to give you some of the key concepts that we are going to use while we will talk about developing software.  Initially software was not discipline per se.  So was creating computers so and make them work so pretty much they were fully integrated with the hardware.  Then they realize that the hardware can stay.  But if you change the software then be hard to where can do different things and that that was mid fifth 19 fifties.  Okay.  And it began sort of separation on the 2.  Initially the first program that we are other additions other engineers.  There was no real discipline in information technology believe it or not.  When graduated in math there was no information technology school in the university where was starting the university.  was starting was univac city in Rome that in the international ranking is in the top 100.  So it it.  What we so E.  Is not bad university but never nevertheless mean it was beginning of eighties and 1900 eightys.  That means that that is not something that is ancient history not Texas working working at least but its something that developed quite fast How we can evaluate the cost of software development.  So if you think you want to develop to build region you want to build building for an airplane.  So you basically at the cost of of development with software think are little bit different.  So there are main components.  One is actual that the the actual developer.  So right in the code there is component that is testing the code that so making sure that there are no errors.  So sometimes sometimes er errors are very difficult to sport is highly recommended that some one who develop or the team who developed the software is not the team doing the testing so they have different goals and different men and mental attitudes so if you develop the code you want to Make the code working.  If you are testing you want code to to fail.  So the first case you have positive attitude.  The the the second case you have negative attitude that you want to see where and how they call this failing.  So developing testing testing.  But then there is wide lot more on maintenance.  So software can change because needs can change.  You can have different marketing conditions different conditions.  Whatever is the use of the software that you wrote So those components are to be considered the when you develop software.  So again your have the course of development the cost of testing and they also mainly some software has to be maintained for long time.  So in in the government in some banks we still have software that was wrote to cobalt.  We are talking about language that is not used since good 40 years.  So probably less 30 years.  But thats it.  So it was.  mean when started the coding was coding in forth running cobalt so and it was almost 40 years ago.  So this is to say can you imagine how much maintenance has been done to piece of code that is 30 and change year old and hes still running because hes doing critical things So there was an interesting case when the Government gave money to people during the pandemic the money we are given that to the seeded sensor based on program that was running on the local.  Lets say tax department.  Those departments are seen using cobalt but they had to do changes to accommodate.  mean the the manager government was giving and they had trouble finding people doing the coding with.  So mean most of the cobalt developers are retired or theyre not around for any reason.  So when you develop software there are different things that you want to consider so lets start on how you do the internal process.  So the thing that you normally do when you develop again breeder building or whatever is the whats so called the waterfall approach.  So you basically start with the requirements then you do the planning.  You allocate the resources you start doing the developments.  Then you do some testing and then you release the entire program.  Thats okay.  So basically you do requirements design implementation.  And then you release the the prop up to the user and you start the main.  Most of the socalled legacy systems.  So we were talking about cobalt programs those are some of the legacy are based on waterfall.  Obviously advantages.  You can optimize the allocation of resources or the initial location resources.  You can define the requirements upfront but you dont have flexibility meaning if something will go wrong because there was misunderstanding between the user and the developer because the conditions change.  Whatever is the reason you cannot go back.  So thats why at the very end only 16 of the systems developed software systems developed using the waterfall approach in 1995.  That was kind of the peak of this type of development.  Only 16 was really successful meaning.  At the very end didnt really work.  That we are software engineering started trying to apply an engineering approach to the development of software software engineering is to computer science pretty much like system engineering is to other developments.  So software engineering is the system engineering of software development We will talk little bit more about software engineering.  But let let me just end this short presentation with some basic practical principles.  So you want to use open source software.  So using open source software you have the possibility to adjust the software you are using you had the possibility to count on large community of developers that may have had the the same problem that you may have obviously not everything its Super great.  So if you buy commercial software you have an accountability that you dont have with the open source but on the other end if you need to do any change to commercial software the only way that you can get it is to go to the developer.  The owner of the software and saying Can you change this in that And then if you are dont know where is on.  Chances are you will get it if you are someone else.  smaller company mean is just dropping your request in box hoping that sometimes the next release or the following release of the software will incorporate the the changes that you require user industry standards.  So there are pretty much standards for most of the things that that you are doing.  You do not want to invent wheel make the the graphical user interface separated from the actual program they have different characteristics most of the time.  You require different skills in all the projects that Im doing.  have different people.  Were working on the back end and on the front end.  When you work on the back end you you are more on languages like Python.  You were more on applying or translating algorithms and processes into code.  When you are on the front end you are more on tools.  Flask or other there are on the the graphical aspects of the interface so different skills.  Most of the time people doing one is not doing well.  The second one with Python.  There are some libraries to develop graphical user interface but still at the quality.  E.  Is not great so Im not using those libraries in my projects but just develop graphical user interface in traditional way.  So you basically have the user inputting some data or files.  Then then the graphical user interface is taking the files passing the files to the back end system.  That is processing it and then is retarding another file.  That is the first one process that what is the process and the graphical user interface We present the results in the proper way.  So thats the streamline that the pipeline of how those things can be.  Now if the backend is notebook you cannot really do that.  So.  And thats another example.  Why we want to have dot.  By.  So you cannot really integrate the things as they should Alright so let me stop sharing for second and let me check if there is any question If not the we will continue with another presentation.  That is adding some building blocks to the knowledge that we have so far to python of Python.  And this is what we would do.  Each class.  will try to be brief because want you to do an inclass assignment in class assignments.  At least the first assignments will be with no grading meaning is just for you to practice and we will do.  Group assignments so will open breakout rooms.  You will do your will give you 15 min or so.  You will write on the code in the team.  Then one or more of the teams will present what they did or will share.  mean the process that they followed and then will present solution and then will introduce the as assignment for next week and that will be the end of the class Alright so so like pretty much all the languages.  Python as components like barriers so functions.  And then the mother Madigal overrid also the subset or overrid those and you have ways to represent basic logic building blocks on of any process.  The data conditional sequences and loops So in Python there are many components that are built in and other components that you add the importing in your code function.  So we will go to the functions in few classes.  So variables can be numerica integer floating can be strings lists tuples.  We will define all those things later on.  But just to familiarize little bit dictionaries.  So we will go into those different types.  So again you can assign values to variables.  In this case you are assigning to the variable X.  The number you wanna are assigning to so in this case you are assigning number an integer.  In this case you are assigning string.  This is list that we will go back to that.  But just to give first idea.  So lists are in square brackets and there are elements inside the list that are separated by comma.  Those can be variable so can be strings can be.  Numbers can be lists so you can have list that is composed by this.  So then you need to figure it out how to access it to the element.  The elements of more interesting some all all the body of both are reusable like in this case.  You had meet.  was Pam.  If you say meet equal sausage then you are reassigning.  You are replacing the previous value with the new by so thats an example.  Not all the variables can be reusable so we would go back to name so variable.  So we mentioned that you can use pretty much any combination of let thats numbers under scores.  Hmm You cannot use what are called the reserve the words so and if right else those are some of the recent words.  So you want to be sure that you do not use those words for naming your variables.  And now important thing that we already mentioned last week is is to have to give to the variables names that are selfexplanatory of the role that the variable is playing in your code.  So if you are using variable to measure the weight you want to call the variable weight and so on.  Comparison operators.  So so you can have all the traditional overriders so greater than less than equal up equal equal signs.  So thats something that we definitely need to keep in mind.  So if we do conditional we want to be sure that instead of using one equal sign use equal signs less than equal and so on.  Probably little bit different from normala is notable to that is exclamation.  Mark equal some other program some some other languages are using the less and greater together.  But mean confused version of on report.  didnt try since age so dont know if its in there but everyone is using an exclamation market equal for the not equal as condition.  Th.  There is Crm that is called the Every logical process can be recreated using combination of sequences conditionals and loops.  So if you have those building blocks you can create any process.  Then mean that wed buy dont you have function So that very high level you dont want to go at that low level but you could.  So because of that.  Pi dont like any other language.  Is providing way to do those so sequential is that the most natural one dont know is starting from top to bottom from left to right.  So thats an example of sequential step.  So what you see on the left side is diagram that is pseudocode.  The for up the code that they you would eventually write.  So you assign the value to to the variable X.  You print the variable then you do equal plus 2.  Thats another example of replacing the value or the previous value.  You have the plus meaning you bring the new value and you will get in this case for so thats the program.  And thats the output again.  This is sequential conditional.  Again on the left side.  You have flow chat conditional side and are represented by roomboards.  So in this case you assign and what is inside the is sort of pseudo code.  So you assign X.  The variable the to the variable oops.  Then you ask if is less than 10 if yes you will print smaller then you ask is greater than 5.  If yes is bigger and if no one or the is satisfied it will print.  mean.  At any case we will print finish when you do.  If statements you use the double equal cool be careful.  Is not one equal.  We use the one E.  Well only to assign values to variables not in the conditionals and then at Yay.  In the if statement you use the call on and when there is call on in Python you have the following line that is invented.  So if today is October thirtieth rent happy birthday job if the condition is not satisfied will not go into the indented part of the code but well go to the next one.  Were Al if its else.  If today is June 21 then preinta happy with the loading Elsa meaning is not.  October 30 is not June 21.  You go here.  There is no other.  If you preint good month.  So again else is pretty much that she told us so.  If The previous conditions are not satisfied.  Then you go to the else condition.  Each time there is call or not there is an indentation So again be careful to use the double equal.  Be careful using the the indentation.  Those are or the most common errors.  When you start coding in python so you forget to use the tui wells.  You just one and you get an aerobics.  And the second is you do do the program in indentation and the program is not doing what is super positive loops.  Thats the second the third condition up.  So again you have the flow charter.  In this case you have you assigned to the variable and you ask if is greater than If yes like.  In this case you print the number and then you subtract one to the number to go back and you will continue.  Still the the value will be and then you will print finish.  So when you do loops you need to be sure that there is an exit condition.  So if we dont have this equal and minus one it will be an infinite rule.  So in the the program we stay there forever because if theyre going condition well never be unsatisfied.  So it will be always greater than 0.  So again be sure when you do an elite Looper whatever is the mean in this case we are using it for in except site we use the while.  So those are both good options.  Be sure that you have and exit condition.  So for is another way by Donna is dealing with the loops.  So in this case you have list of names and you are looping in this list.  So for name.  There is kind of dummy variable in list of names so the first value that this name is getting when starting is the first name so it will print the first name that is Frank.  Then well go back to the beginning of the loop and at that point name we take the second value that is married.  Well print Mary and so on until the end of the list so thats another example how to use loops.  We use the the the while through.  This is another example.  While countdown is less than 100.  So you print.  So you start assigning 25 to the value mean it will.  There for while.  So you start with the value you subtract one till its finished.  That is something that is not exactly right here.  So thats an infinite loop.  If you start with the same value and you ask why thats different from 0.  You subtract one feel at the certain point will become and will stop.  So again be aware on the infinite loop in this case is always through and well continue whatever.  In this case there is another in loops.  You can have pieces of code so you can have just doing something like in this case.  Or in this case youll print the name or you can have additional logic in it.  So in this case you have numbers that will become list in the range.  10.  And for this is the dummy vary Ebola that we will use in the loop and only the looper.  So in numbers so initially it will be 0.  So print that is 0.  Then if is equal you break.  So basically it will continue till springing and then it will break.  And this is pretty much the same the reminder meaning if dividing the number of by 10 we have rest of 0.  The reminder of then it will print it.  If its not well continue the so things here de breaker.  So in this case Breaker will take you out of the loop.  In this case continue that is basically doing nothing and go to the next iteration.  So break out of the loop continue skip and and then go to the next Thats another example.  So again you have list and then you start the loop you ask is the name If the name is starting thats one of the attributes so that you can have strings.  So name is string at the first crown.  That will be frank.  If name starts with the M.  Printer.  Name all in the uppercase.  Oh the first round would not print anything meaning well skip the first one then the second one will be Mary.  Then start with Emma.  Mary is starting with Emma again keeping mind that the copy DNA is different from small Emma and then it will be printed and will continue.  Eva will be stop will be skipped and Mohammed that will be printed We mentioned that so some of the common errors again call on means indentation.  There is no indentation here.  If you try to run this you will get an effort.  This case the indentation is good but you need to have double equal here.  Not single legal the single equal is only to assign values to variables and then you have all the links Alright so we made it the pretty fast so we will have time.  Let me stop sharing that.  So what Im going to do now is basically to introduce the in class except size And then will create breakout rooms.  You will work on it.  We give you at this point can give you even 20 min.  Then will take back the control.  will ask teams to present day solutions or just to discuss the issues that they may have had that and then will present solution and will introduce the assignment for next week alright so let me start sharing again and let me Go here.  So thats the inclass exercise.  Write program name the Exchange Dot.  Dy that will mimic the conversion or Ann amount of us dollar.  So into currency of the users.  Choice.  We will work only on the integers meaning this tool cannot be using real life because mean exchange rates are with decimal.  If you use this amounts you will get errors.  Using what Im going to introduce in moment.  Meaning is just an exercise so can never be used in real cases.  So you will ask how many dollar that you want to exchange.  And you input your value name of the currency and this will be string whatever you like.  What is the exchange rate Again All of them both.  The Us.  Dollar and exchange rate has to be integer and the output will will be the program.  Writing you can exchange 100.  You will take this value from here for and this will be the multiplication between the Us.  Dollar and the exchange rate.  So you are going to leverage on what you did the in accept siz.  meaning this one.  So you will have the same loop.  You will have Tim Miller you will call them in different way instead of first.  Hmm.  Name or or you can leave whatever you like.  Can you please mute your microphone please And then obviously you need to change little bit because its not as aation but in this case its product.  Also you need to add the third request.  That is the name of the of decar and see.  But then pretty much singular so you can do save as and rename it and work on the the new version changing editing what you need to change.  So what you will do will will be to check if the input is nomadic and you will use the python.  Building function is digit.  So if the name just like we saw Just like we saw here.  If name start with Emma.  In this case would be if value is digit.  But its working oops.  Hes working pretty much.  Using those building types mean you dont really need to go to that.  But eventually using the link you can get all the building functions including the oops including other is Dj.  If not you will start again the looper using the statement continue again is digit is not particularly smart but is considering the as numerical.  The integers.  So if you have comma because is floating point there are decimals it will consider it non numerical oh and thats why this is just an exercise is not something that has anything practicing on the application.  So you will start the loop.  You prompt the user for the name of the currency from the user for the exchange rate.  Calculate the number all the currency doing the multiplication bring the result with separation that can be just print blank or using like we did the last time.  The Backslash and backslash means that there is special character and that means new line.  That means before printing this Xyz Xyz.  You pretty the blank line Oh is it just to give nice answer to the user Okay.  So Im stopping sharing.  Im creating Breakout rooms so will create that breakout rooms pretty much with participants each.  So will.  Oh let me do something for that need to publish.  think its of any data.  Okay.  Already published the the text on the in classics etc.  And Im creating the rooms.  Please go to the rooms you have about 20 min to work on.  It.  Then some one of you will present the results.  Then will talk on the results.  Okay my version.  And then will introduce the next exercise.  And that could be the end.  So Im creating Im opening all the rooms so please go to the rooms.  All right.  So Im resuming the recording.  So you are all back How was it It was good.  have one question so we edited out the previous assignment that we did so.  Should when were submitting this should should we make it into new file or we can just submit the the file that we edited there Alright Oh okay.  So there is no submission here.  The the in class assignments are just for practicing.  You when we will approach the second half of the courts.  will use the in class assignments for extra points.  So its not going to be lot of points but there would be some points for reasons.  One to incentivize you to attend the classes and the second is to give you the opportunity to get some additional points.  To the the grade that you will greet you.  You will get but for the time being there is no submission.  Has just for practicing and we will do the same for few weeks.  So it depends on.  mean how both they attendance and your grades are going to be based on those parameters.  will 100 move.  mean that the graded for those again it will be You cannot hear me.  can hear you.  dont know about.  can hear you Okay okay so the points that you will get with the in class excel is well be on top other regular points meaning if you do not do anything you will not get anything.  But you are not going to lose anything.  So apart from the opportunity to get the extra points.  But we will go there in few weeks and will not reexplain everything.  Alright So volunteers who want to present that solution Again there is no judgment.  Its just to share the process that you follow the the results that you had and thats it.  There is no judgment there is no great.  You can go Anyone.  You want to volunteer Okay.  Sure dont have.  But will if you want me to Yeah please.  Okay.  Alright so can you see Yep.  Okay.  So kind of base it off of what did the first time around with using little bit of that cheat sheet you gave us.  And so only managed to write few lines but what have is you know while true put documents input and then would have the user enter the dollar amount.  And if dollar is digit it would be enter new value and then break and else and after that is kind of where got stuck because wanted to get to point where can have them name the currency.  And input the name the name of the currency and then sort of figure out what the exchange rate would be.  But thats sort of think.  At that point the breakout room ended and got stuck on what to do.  Next.  Okay so let that.  Let me give you some comments on that.  So the the first one in Python small letters and capital letters are different.  Wila is Small.  W.  The the capital W.  In while that by the way we will not be recognized as the statement while so and this is in line one.  So in line one you want to change.  Yes.  And thats the first thing and it so you will see one of the errors that went away.  The the second when you have column like in line 3.  The phone one has to be named.  So you want Line to be indented.  Further more.  Like that Okay.  And Al so is okay in that position because is the alternative to the if and then mean you are getting an error in line seeks and because obviously thats nothing.  But those were the main issues Okay.  So lines is no statement.  So right Because you were starting writing something but then you stopped and thats why youve got an error.  Yeah.  But thats fine.  Okay okay alright alright.  So anyone else.  could share Yeah please.  So this is what did while through and then Usd to for the first input.  And then if it is digit then the current see that you want.  Then while true again for the exchange rate and then total and then the final output.  So how many Us.  Dollars you wanna exchange 100 convert to yen and 4.  Thats 0.  Yeah.  Okay but you cannot.  Hmm leave right So there is no done.  Option to leave the loop But that thats okay.  mean was just mean you had 20 min.  You couldnt do much Okay wha whats supposed to be different Well if you look back at the Excel side you will probably remember that there was testing for Dan and breaking the loop.  Okay.  So in this case a.  mean that yeah you have exit.  The but is not looper at this point Right mean loop should continue so.  There is no reason at this point to do loop or but then if if successful you just exit.  So you want to continue the loop or the like the user would say Im done Okay.  But its okay.  mean it is working.  And thats fine.  You had 20 min and thats absolutely great.  For 20 min Alright.  Thank you.  Thank you.  Okay.  So let me share the screen and let me go to this.  This.  So Im going to show you different solutions.  So this this one is the basic one.  So you have while through print.  Nothing meaning.  Im leaving one blank line.  Then that the first is dollar amount.  How many Us.  Dollars you want to exchange You type the value or down to exit and checking if done you will print thanks for using the tool and you will break and at that point you will exit completely the program.  If it is not done then you check.  If these are value is passing.  The test is digita if not its wrong.  Input continue you go back.  If it is number then you ask for the second value.  That is the name you ask for the con the conversion rate that is number checking.  If is digita if not the wrong input continue you go back and then if everything is okay you calculate the converge and you print the value.  So if you run it You have 11 you know.  Have any name hear about 33 And thats it.  And then weve done.  No it is working.  Buddy reality.  You have.  dont know.  22.  want to convert in.  dont know.  Udos And lets lets say the exchange rate is point 97 Im getting an error out.  So we already knew that the that is digit.  It is not considering the desk months so meaning it is running but its running on the only with the in the jets.  So Im maxing in from this one and want to show you another way to do it.  So in Python we have the possibility to intercept the errors meaning in this case what Im doing same thing at the beginning.  So Im asking the user to input the the number of bill left.  If Donna exit then try to transform the value into floating.  If the user instead of typing number any number is typing string would get an error.  So try is basically intercepting the error meaning trying to do this operation.  If there is an aurora and is the accept condition print wrong impot.  Please enter numbers only and then continue and then same thing asking for the name whatever the name is then the the conversion rate same thing.  Try accept and if there is an error continue meaning go back.  Otherwise do.  The conversion value and print it with the try statement.  could in theory intercept any kind of error so can specify the type of error that got and eventually do different things for different types of error.  If you dont specify anything meaning any error you go to the accept statements.  So if ran this one So if have number of dollars that is 22. 5 hes okay.  Cut and see.  No no whatever.  Exchange rate 2. 3 2. 4 and then have the actual value Yeah will definitely share the files.  So if go if do something like have 22.  And want to convert that to something and exchange rate Its not number.  At this point will get an error So again the option the options you have to test.  If value that has been inputed by the user is an number on or not.  The options are either using is digit but is digit as the limitation of testing only integers meaning that if you have an integer then its okay.  Its if you have floating point number number with decimal values then its not going to work.  So with the try except you do the statement that that you want to do so again.  Keep in mind that the input is retarding string meaning that you need to transform the string into number.  So we did that in this case.  So we transform the floating or integer.  Whatever is the case So.  But if is not and Imbara that they use type that is string you would get an error.  So you definitely want to have something where the is digita.  But again is ditched.  Has nameations or try extent again.  Keep in mind that when you have column not then you need to do the Provera invitation So thats big it will published right away the the solutions Okay.  And they are on canvas now and you already have accept size one.  Let me share it that You still have some comments.  So this exercise one excel size one.  Its really very similar probably easier than the exercise that you just so in this case the conversion will be from sales.  Use too far and half so the user should be prompted for input and just like sex size or the one that you did in class and will be what is the temperature in sales use You want to convert and the user will type something.  The output that would be the value of the temperature in furniture would be whatever it.  So in this case its like the equivalent of 15 degrees sets us is 60 Fahrenheit.  So you do.  The looper you do.  You check that.  The input is numerical suggestion is to use the try acceptor.  But if you use the is digit is okay as well.  Keeping in mind that that that point.  The the tool will not work with values with the desk amounts so you calculate the number of degree using this formula so that the the the number of degrees in Fahrenheit thats all the temperature in Fahrenheit equal temperature in Celsius multiplied by 1. 8 plus 32.  Then you print the results.  So blank line.  Either you print nothing meaning you will print blank line or you will use the new line notation like we did the few other times.  And thats basically it.  So questions Alright.  Yeah.  Good.  Got it Do you want Yeah do you have few minutes after lecture wanna figure out like the mistake that made in in my career.  Thank you.  Absolutely.  Yeah yeah.  mean if you want to share right now thats absolutely fine.  If you want to share with the class if not the thats fine as well we we can just say had similar problems as previous people so itd be redundant.  tts STEVENS le INSTITUTE of TECHNOLOGY rT Handling Data clipizzistevens. edu SSE What Kind of Data lw Relational databases Data warehouses Transactional databases Advanced DB and information repositories Objectoriented and objectrelational databases Spatial databases Timeseries data and temporal data Text databases and multimedia databases Heterogeneous and legacy databases Web STEVENS INSTITUTE of TECHNOLOGY What is Database Databasea collection of interrelated data stored and organized in such way that allows for easy retrieval of information.  Entities refers fo real or abstract things object e. g.  students Courses Relationships e. g.  Jack enrolled in EM 624 More recently also includes active components often called business logic or domain logic Business Logic determines how data Is transformed or calculated and how it is routed to people or software workflow.  ee STEVENS INSTITUTE of TECHNOLOGY ots Database Management System DBMS DBMS is software system designed to create manipulate retrieve data in database.  It is piece of software that sits in front of collection of data and mediates applications accesses to the data E. g. a simple DBMS is your phone directory which holds contact names and phone numbers of people you talk to.  The primary goal of DBMS is to simplifyenhance the storing and accessing of data.  STEVENS INSTITUTE of TECHNOLOGY fi.  Describing Data Data Models data model is collection of concepts for describing data schema is description of particular collection of data using given data model The relational model of data is the most widely used model today Main concept relation basically table with rows and columns.  Every relation has schema which describes the columns or fields ee STEVENS INSTITUTE of TECHNOLOGY Levels of Data Abstraction Views describe how users see the data Conceptual schema defines an er Views logical structure Physical schema describes the files and indexes used sometimes called the ANSISPARC model STEVENS INSTITUTE of TECHNOLOGY cfs Example University Database Conceptual schema Studentssid string name string login string age integer gpareal Coursescid string cnamesitring creditsinteger Conceptual Schema Enrolledsidstring cidstring External Schema View Courseinfocidstringenrollmentinteger co Physical schema DB Relations stored as unordered files.  Index on first column of Students.  STEVENS INSTITUTE of TECHNOLOGY Advantages of DBMS Data independence Efficient data access Data integrity security Data administration Concurrent access crash recovery Reduced application development time So why not use them always Expensivecomplicated to set up maintain This cost complexity must be offset by need Generalpurpose not suited for soecialpurpose tasks e. g.  text search ee STEVENS INSTITUTE of TECHNOLOGY fi.  Database Management System Specialized software Available for PC workstations mainframes supercomputers Is expected to Allow users to create new databases schema Give users the ability fo querymodity the data Support the storage of very large amounts of data Control access to data from many users at once Major vendorsproducts Oracle IBM DB2 Microsoft SQL Server Access STEVENS INSTITUTE of TECHNOLOGY DBMS Components Storage manager Stores on disk data metadata indexes logs Query processor Parses queries optimizes by selecting query plan executes the plan on the data Transaction manager Logs database changes to support recovery after system crashes Supports concurrent execution of transactions STEVENS INSTITUTE of TECHNOLOGY 10 cfs Transactions ACID Properties Atomic All of the work In transaction completes commit or none of if completes Consistent transaction transforms the database from one consistent state to another consistent state.  Consistency is defined in terms of constraints Isolated The results of any changes made during transaction are not visible until the transaction has committed Durable The results of ag committed transaction survive failures STEVENS INSTITUTE of TECHNOLOGY 11 Designing the Database Data model Entity Arftribute Primary key Secondary keys STEVENS INSTITUTE of TECHNOLOGY 12 off EntityRelationship Modeling Database designers plan the database design in process called entityrelationship ER modeling Peter Chen 1976 ER diagrams consists of entities attributes and relationships Entity classes Instance Identifiers STEVENS INSTITUTE of TECHNOLOGY 13 Relationships Between Entities Sg Entity Attribute Relationship Weak Multivalued Weak Entity Attribute Relationship STEVENS INSTITUTE of TECHNOLOGY 14 Entityrelationship diagram model STEVENS INSTITUTE of TECHNOLOGY 15 Normalization Normalization.  Is the process of organizing the fields and tables of relational database to minimize redundancy and dependency Minimum redundancy Maximum data integrity Best processing performance Normalized data occurs when attributes in the table depend only on the primary key STEVENS INSTITUTE of TECHNOLOGY 16 NonNormalized Relation Ye FD Microsoft Access NonNormalized Relation Table 11374 side saat 150 15 AAA Automotive Main St.  nae 14 Wind 1759 Hood an 15 AAA Automotive 123 Main St.  11506 14 Wind St 2273 Head Light 75 17 NAPA 178 Green Ave.  11506 114 Wind St 3451 Grill 425 15 AAA Automotive 123 Main St.  11506 14 Wind St 2394 Windshield 550 19 All About Glass 145 Highway 13106 110 Fifth Av 11125 Windshield Wip25 17 NAPA 178 Green Ave 13106 1110 Fifth Av 11759 Hood 225 15 AAA Automotive 123 Main St 13106 110 Fifth Av 1888 Roof panel 650 15 AAA Automotive 123 Main St 13106 1110 Fifth Av 1374 Left side panel 150 15 AAA Automotive 123 Main St 143106 110 Fifth Av 1375 Right side pane150 15 AAA Automotive123 Main St 13106 2s 110 Fifth Av 1655 Radialtires 175 21 Tire World 1153 Highway 12206 19 Mall Dr.  1699 Chrome Hubcag 225 29 Chrome Center 197 Beulah Ave 2206 19 Mall Dr.  11991 Gas cap 80 17 NAPA 178 Green Ave 2206 19 Mall Dr.  1766 Trunk lid 450 15 AAA Automotive 123 Main St 2906 92 Star Ct.  2395 Rear windshield550 19 All About Glass 145 Highway 2906 92 Star Ct.  2274 Tail Light 65 17 NAPA 178 Green Ave 2906 92 Star Ct.  2497 Rearbumper 495 15 AAA Automotive123 Main St 2906 92 Star Ct.  STEVENS INSTITUTE of TECHNOLOGY STEVENS INSTITUTE of TECHNOLOGY Data Warehousing Data warehouses and Data Data Warehouse Marts Organized by business dimension or subject Multidimensional Historical Use online analytical processing ETL stands for Extract Transform Load ODS for Operational Data Storage Benefits for end users Access data quickly and easily via Web browsers because they are located in one place Consolidated view of organizational data STEVENS INSTITUTE of TECHNOLOGY 19 cfs Relational Query Languages Languages for describing queries on relational database Structured Query Language SQL Predominant applicationlevel query language Procedural STEVENS INSTITUTE of TECHNOLOGY 20 Relational Algebra Domain set of relations Basic operators select project union set difference Cartesian product Derived operators set intersection division join Procedural Relational expression specifies query by describing an algorithm the sequence in which operators are applied for determining the result of an expression STEVENS INSTITUTE of TECHNOLOGY 21 SQL Characteristics Data stored in columns and tables Relationships represented by data Data Manipulation Language Data Definition Language Transactions Abstraction from physical layer STEVENS INSTITUTE of TECHNOLOGY 22 Example of SQL query Operator Produce table containing subset of rows of argument table satisfying condition ocondition relation Example Database Person Select cHobby stamps Person STEVENS INSTITUTE of TECHNOLOGY 23 SQL Database Examples Commercial IBM DB2 Oracle RDMS Microsoft SQL Server Sybase SQL Anywhere Open Source with commercial options MySQL Ingres Significant portions of the world economy use SQL databases STEVENS INSTITUTE of TECHNOLOGY 24 The change of the 30B Database Market STEVENS INSTITUTE of TECHNOLOGY 25 ee What Is Biggest Data Management .  Problem Coming Year STEVENS INSTITUTE of TECHNOLOGY 26 ots NoSQL lw Definition from www. nosqldatabase. org Next Generation Databases mostly addressing some of the points being nonrelational distributed opensource and horizontal scalable.  The original intention has been modern webscale databases.  The movement began early 2009 and is growing rapidly.  Often more characteristics apply as schemafree easy replication support simple API eventually consistent BASE not ACID ProductsProjects httowww. nosaldatabase. org lists 122 NoSQL Databases Cassandra CouchDB Hadoop Hbase MongoDB Neod4j Etc.  ee STEVENS INSTITUTE of TECHNOLOGY 27 ots BASE Transactions Acronym contrived to be the opposite of ACID Basically Available the system does guarantee the availability of the data Soft state the state of the system could change over time so even during times without input there may be changes going on due fo eventual consistency thus the state of the system is always soft.  Eventually Consistent The system will eventually become consistent once if stops receiving Input Characteristics Weak consistency stale data OK Availability first Best effort Approximate answers OK Simpler and faster SS STEVENS INSTITUTE of TECHNOLOGY 28 re Terminology MongoDB example RDBMS MongoDB Table Collection Rows JSON Document Index Index Join Embedding Linking STEVENS INSTITUTE of TECHNOLOGY 29 ee 6h llr Documentoriented data model MongoDB uses documentoriented model using collections Main characteristics Schemaless Collections can be created onthefly when first referenced Capped collections Fixed size older records dropped after limit reached Collections store documents STEVENS INSTITUTE of TECHNOLOGY 30 Map Reduce Technique for indexing and searching large data volumes Two Phases Map and Reduce Map Extract sets of KeyValue pairs from underlying data Potentially in Parallel on multiple machines Reduce Merge and sort sets of KeyValue pairs Results may be useful for other searches Map Reduce techniques differ across products Implemented by application developers not by underlying software STEVENS INSTITUTE of TECHNOLOGY 31 overview Hadoop is framework for running applications on large clusters built of commodity hardware.  The Hadoop framework transparently provides applications both reliability and data motion.  Hadoop implements computational paradigm named MapReduce.  In addition it provides distributed file system HDFS that stores data on the compute nodes providing very high aggregate bandwidth across the cluster.  Both MapReduce and the distributed file system are designed so that node failures are automatically handled by the framework Hadoops Distributed File System is designed to reliably store very large files across machines in large cluster.  It is inspired by the Google File System.  Hadoop DFS stores each file as sequence of blocks all blocks in file except the last block are the same size.  Blocks belonging to file are replicated for fault tolerance.  The block size and replication factor are configurable per file.  Files in HDFS are write once and have strictly one writer at any time from Hadoop wiki ee STEVENS INSTITUTE of TECHNOLOGY 32 ee 6h llr Knowledge Discovery Process in practice Data Preparation Data Preparation estimated to take 70 80 of the time and effort STEVENS INSTITUTE of TECHNOLOGY 33 Data Processing Flow Analysis Types of Data Quality Problems Ambiguity Uncertainty Erroneous data values Missing Values Duplication etc STEVENS INSTITUTE of TECHNOLOGY 34 Data Preparation Data in the real world is dirty incomplete lacking attribute values lacking certain attributes of interest or containing only aggregate data noisy containing errors or outliers inconsistent containing discrepancies in codes or names No quality data no quality mining results Quality decisions must be based on quality data Data warehouse needs consistent integration of quality data Assessment of quality reflects on confidence in results STEVENS INSTITUTE of TECHNOLOGY 35 Data Flaw and Data Quality Two general ways to deal with DQ problems Resolve them and then apply analysis on clean data Classic Data Quality approach Account for them in the analysis on dirty data E. g.  put data into probabilistic DBMS Often not considered as DQ STEVENS INSTITUTE of TECHNOLOGY 36 ee 6h llr Major Tasks in Data Preprocessing Data cleaning Fillin missing values smooth noisy data identify or remove outliers and resolve inconsistencies Data integration Integration of multiple databases data cubes or files Data transformation Normalization and aggregation Data reduction Obtains reduced representation in volume but produces the same or similar analytical results STEVENS INSTITUTE of TECHNOLOGY 37 Forms of data preprocessing STEVENS INSTITUTE of TECHNOLOGY 38 STEVENS INSTITUTE of TECHNOLOGY Functions clipizzistevens. edu Richie Oyeleke SSE eee What is function Black box STEVENS INSTITUTE of TECHNOLOGY Definition Function refers to collection of program statements or block of code that runs only when tt is called.  Aavantages Hides the complexity or difficulty involved in the execution of task Programs are easier to create 1. .  removes redundancy or repetition of lines of codes ee STEVENS INSTITUTE of TECHNOLOGY Types of Functions BuilTiIn Functions Userdefined Functions Functions can also be imported from external libraries Functions take arguments as an input and return values STEVENS INSTITUTE of TECHNOLOGY BuiltIn Functions we Weve already used some builtin functions rangen returns list list from n1 sumx returns the sum of leny returns the length of print range5 print sum1 10 print lena STEVENS INSTITUTE of TECHNOLOGY Stored Steps UserDefined Functions STEVENS INSTITUTE of TECHNOLOGY Structure of function complete program function consists of two main parts namely Function definition includes Starting with the det keyword Function name identifier Function Parameters Body of the function Function call fo initiate function execution or evokes It if must include Function name Function arguments STEVENS INSTITUTE of TECHNOLOGY UserDefined Functions As an example say we want to calculate the area of triangle given its height and width def triangleareaheight width area width2. 0 height return area STEVENS INSTITUTE of TECHNOLOGY UserDefined Functions Say we want the square root of number Thats lot of work for an approximate answer.  If only somebody else had already done the hard work for us. . .  STEVENS INSTITUTE of TECHNOLOGY Arguments An argument is value we pass into the function as its INOUT When we call the function We use arguments so we can direct the function to do different kinds of work when we call if at different times We put the arguments in parenthesis after the name of the function big maxHello world STEVENS INSTITUTE of TECHNOLOGY Parameters paramefter Is variable which we use in the function definition that is handle that allows the code in the function to access the arguments for particular function invocation.  def greetlang if lang es print Hola elif lang tr print Bonjour else print Hello greeten Hello greetes Hola greetfr Bonjour STEVENS INSTITUTE of TECHNOLOGY Return Values Often function will take its arguments do some computation and return value to be used as the value of the function call in the calling expression.  The return keyword Is used for this STEVENS INSTITUTE of TECHNOLOGY 10 Return Value fruitful function is one that produces result or return value The return statement ends the function execution and sends back the result of the function STEVENS INSTITUTE of TECHNOLOGY 11 Arguments Parameters and Results big maxHello world eararneter print big STEVENS INSTITUTE of TECHNOLOGY 12 Multiple Parameters Arguments We can define more than one def addtwoa parameter in the function addedatb definition return added We simply add more addtwo3 arguments when we call the print function We match the number and order of arguments and parameters Output STEVENS INSTITUTE of TECHNOLOGY 13 eee Default argument values def makesandwichmeat cheese cheddar bread rye print Ill have sandwich with meat cheese and bread bread.  makesandwichham makesandwichspam makesandwichspam cream cheese Ill have sandwich with ham cheddar and rye bread.  Ill have sandwich with spam cheddar and rye bread.  Ill have sandwich with spam cream cheese and rye bread.  STEVENS INSTITUTE of TECHNOLOGY 16 cf.  Varying number of arguments args is way to pass to function as many arguments as we need without first soecifying it in the function definition args is not reserved word def printallargs print args printall1 Hi printallHello Welcome STEVENS INSTITUTE of TECHNOLOGY 17 Summary The use of functions Organize your code into paragraphs capture complete thought and name it Dont repeat yourself make if work once and then reuse It If something gets too long or complex break Up logical chunks and put those chunks in functions Make library of common parts of code that you do over and over andor share with others STEVENS INSTITUTE of TECHNOLOGY 14 Roles of Variables Most variables are local only recognized in the function that defined them Global variables are recognized everywhere that means they keep their values both inside the function and in the rest of the program STEVENS INSTITUTE of TECHNOLOGY 17 tts ks Local vs.  Global ie Author Cheryl Dugas local vs global STEVENS INSTITUTE of TECHNOLOGY 18 Functions and Scope Local vs Global Variables that are defined within functions only exist there If you assign variable with the same name as one that exists outside the function it will have the new value only inside the function def testfuncn nxx2 print print return None 16 xX y4 print testfunc4 print ee STEVENS INSTITUTE of TECHNOLOGY 21 Imported Functions We can import librariesoackages of functions E. g.  the math library has mathematical functions import math 3. 87298334621 print math. sqrt15 STEVENS INSTITUTE of TECHNOLOGY 22 Imported Functions You can import the whole library import math print mth. sqrt10 3. 16227766017 You can import just one function from math import sqrt You can also import the library with nickname import math as mth print mth. sqrt10 STEVENS INSTITUTE of TECHNOLOGY 23 Useful Links lw httosen. wikibooks. orgwikiPythonProgrammingFunctions httowww. learnoython. orgenFunctions httomatplotlib. orguserspyplot tutorial. pAtm httomatplotliob. orggallery. htmllines bars andmarkers STEVENS INSTITUTE of TECHNOLOGY 24 STEVENS INSTITUTE of TECHNOLOGY Python Modules clipizzistevens. edu SSE Python Package Links Python Standard Library hitodocs. python. org2libra Builtin Functions httodocs. oython. org2libraryfunctions. html Python Package Index over 39500 packages httpspypi. oython. orgpypi Matplotlib plotting library httpmatplotliob. orgindex. html NumPy scientific numerical package httpwww. numpy. or pandas Python Data Analysis Library hitppandas. pydata. or STEVENS INSTITUTE of TECHNOLOGY 26 Builtin Functions abs all any ascii bin bool bytearray bytes callable chr classmethod compile complex delattr dict dir divmod enumerate eval exec filter float format frozenset getattr flobals hasattr hash Builtin Functions help hex id input int isinstance issubclass iter len list locals map max memoryview min next object oct open ord pow print property range repr reversed round set cfs setattr slice sorted staticmethod str sum super tuple type vars zip import STEVENS INSTITUTE of TECHNOLOGY 27 PyLab STEVENS INSTITUTE of TECHNOLOGY 28 matplotlib Most popular python library for plots httpmatplotlib. org Created by John D.  Hunter JDH Integrates well with IPython for interactive plot development The plots themselves are interactive you Can zoom in on section of the plot and pan around.  STEVENS INSTITUTE of TECHNOLOGY 29 Matplotlib simple plotting library Matplotlib lets you make all the basic types of charts Bar charts pie charts line charts scatter plots etc.  We use the pyplot set of functions from matplotlib and typically use nickname to make things easier import matplotlib. pyplot as plt range100 number2 for number in plt. plotxy plt. show STEVENS INSTITUTE of TECHNOLOGY 30 Line Plot Plot an array of values against 123. . .  or an optional array of values plotx cms array of numbers yvalues to be plotted optional array of axis labels optional color default blue optional marker default none optional line style default solid Option plt. ylabelline label STEVENS INSTITUTE of TECHNOLOGY 31 . . .  options Color Blue Green Red Cyan Magenta Yellow Black White Marker Point .  Pixel Circle Square Diamond Thin diamond Cross Plus Star Hexagon Alt.  Hexagon Pentagon Triangles Vertical Line Horizontal Line Line Style Solid Dashed Dashdot .  Dotted STEVENS INSTITUTE of TECHNOLOGY 32 Scatter Plot Plot points from two arrays of numbers and scatterxy some options Sarrayofsizes size for each point Sn one standard size color color as letter or hex marker shape ocircle ssquare STEVENS INSTITUTE of TECHNOLOGY 33 Bar Chart lw Create bar chart using an array of leffedge positions and one of bar heights.  bar array of bar heights array of leftedge positions can be 012. .  Options include width width of bar ee STEVENS INSTITUTE of TECHNOLOGY 34 Pie Chart Produces pie chart from an array of numbers pie array of numbers Options include labels array of label names ee STEVENS INSTITUTE of TECHNOLOGY 35 Histogram Creates histogram trom an array of values plot array of numbers yvalues Options include CcumulativeTrue creates Cumulative histogram bins Number of bins default 10 STEVENS INSTITUTE of TECHNOLOGY 36 Multiple plots subplot lets you have multiple charts in one import matplotlib. pyplot as plt 12345 12240915 plt. subplot221 plt. plotxy plt. subplot222 plt. scatterxy plt. subplot223 plt. piey plt. subplot224 plt. barxy plt. show STEVENS INSTITUTE of TECHNOLOGY 37 NumPy Numerical Python httpwww. numpy. org Created by Travis Oliphant Mainly for scientific computing BUT advantages for data analysis ndarray Fast and efficient array object Can handle large quantities of data more efficiently ndarray can be read by other software Some other basic python tasks e. g.  finding the average of numbers in list can be done more easily with NumPy Ee STEVENS INSTITUTE of TECHNOLOGY 32 offs Numpy and arrays import numMpy as np np. arange15. reshape3 array0 10 11 12 13 14 a. shape a. ndim a. dtype. name int64 a. itemsize a. size 15 typea class numpy. ndarray np. array6 array6 typeb class numpy. ndarray STEVENS INSTITUTE of TECHNOLOGY 39 pandas Designed to make working with structured data fast and easy hnttpoandas. oydata. org Created by Wes McKinney Uses DataFrame similar to and matlab DataFrame has both row and column labels More later. . .  Ee STEVENS INSTITUTE of TECHNOLOGY 40 tts STEVENS le INSTITUTE of TECHNOLOGY he Python Pandas clipizzistevens. edu SSE pandas Python Data Analysis Library providing highperformance easytouse data structures and data analysis tools for the Python programming language.  STEVENS INSTITUTE of TECHNOLOGY es Why Pandas .  pandas is built on top of NumPy and Is intended to integrate well within scientific computing environment with many other 3rd party libraries Flexibility of Python Working with Big data which excel struggles with Source httppandas. pydata. orgpandasdocsstable ee STEVENS INSTITUTE of TECHNOLOGY pandas Comparison with SQL pandas SQL DataFrame table column variable row observation groupby GROUP By Source httppandas. pydata. orgpandasdocsstablecomparisonwithsql. htm Ee STEVENS INSTITUTE of TECHNOLOGY Pandas Data Structures lw Two commonly used data Structures in pandas are Series DataFrame STEVENS INSTITUTE of TECHNOLOGY Series Series dimensional array like structure that holds identical data.  For example collection of integer numbers so Source httppandas. pydata. orgpandasdocsstable Ee STEVENS INSTITUTE of TECHNOLOGY SERIES series can be created as follows pandas. Seriesdata index dtype Data e. g.  constants list etc.  Index same length as data Dtype data type import pandas as pd pd. Series2 sa sa STEVENS INSTITUTE of TECHNOLOGY SERIES FromTo dictionary from pandas import pd. Series2 indexa sa sfia dictionary dicts fia Seriesdictionary Index comes from sorted dictionary keys STEVENS INSTITUTE of TECHNOLOGY Working with SERIES series work with Numpy STEVENS INSTITUTE of TECHNOLOGY ee 6h it DataFrame DataFrame is 2dimensional data structure in table like form. i. e.  Consists of rows and columns lf can hold heterogeneous data STEVENS INSTITUTE of TECHNOLOGY 10 Oe Creating DataFrame DataFrame can be created as follows pandas. DataFrame data index columns dtype data constants list series dict efc.  Index row labels columns column labels dtype the data for each column ee STEVENS INSTITUTE of TECHNOLOGY 11 Creating Data Frames df pd. DataFrame np. random. randn 46 indexstudentl1 student2 student3 student4 columnslistABCDEF df df pd. DataFramenp. random. randn46 indexstudentlstudent2student3student4 columnslist ABCDEF df STEVENS INSTITUTE of TECHNOLOGY 12 Data Loading Text file data readcsv readtable Structured data JSON XML HTML Works well with existing libraries Excel Depends on xlrd and openpyxl packages Database pandas. io. sql module readframe STEVENS INSTITUTE of TECHNOLOGY 13 Working with Excel files Samples iw import pandas as pd df pd. readexcelexcelcompdata. xlsx Import Excel files dftotal dfJan dfFeb dfMar Adding column for totals STEVENS INSTITUTE of TECHNOLOGY 14 Group by one11111 two22222 letteraabbc df pd. DataFramed one df. groupbyletter one. sum letterone df. groupbyletterone. sum letterone ee STEVENS INSTITUTE of TECHNOLOGY 15 Descriptive statistics df. mean one 2. 263617 two 1. 316694 three 1. 975041 Also Count SUM median min max abs orod std var skew kurt quantile cumsum Cumprod Ccummax cummin STEVENS INSTITUTE of TECHNOLOGY 16 Plotting import numMpy as np import pandas as pd one np. random. rand10 two np. random. rand10 df pd. DataFramed df. plotstyleox Eee STEVENS INSTITUTE of TECHNOLOGY 17 Additional Functions Data Aggregation GroupBy Pivot Tables Time Series PeriodsFrequencies Time Series with Different Frequencies DownsamplingUpsampling Plotting with Time Series autoadjust scale Advanced Analysis Decile and Quartile Analysis Signal Frontier Analysis Future Contract Rolling Rolling Correlations and Linear Regression ee STEVENS INSTITUTE of TECHNOLOGY 18 Sample of functions lw datastructure pd. readcsvfilename. csv Read acsv file into Pandas data structure print datastructure. info Print raw information on the pandas data structure del datastructure columnname Delete the column columnname print datastructure. neadn Print the first records in the data structure print datastructure columnname. valuecounts Print the number of elements in the column column name for its different values datastructure2 datastructure. groupbycolumnname. sum Grouping the the data by columnname.  This will keep only unique values print datastructure. Count. idxmax Print the element with the highest occurrence print datastructure. describe Print the descriptive statistics for the data structure ee STEVENS INSTITUTE of TECHNOLOGY 19 STEVENS INSTITUTE of TECHNOLOGY Software Development clipizzistevens. edu SSE Beginning of software Software separated from the hardware in 1950s emerged as distinct technology became independent product Original programmers recruited trom the ranks of hardware engineers and mathematicians used adhoc techniques from their former fields STEVENS INSTITUTE of TECHNOLOGY ts Inherent Problems with Software jw Development Requirements are constantly changing The client might not know all the requirements in advance Frequent changes are difficult to manage Identifying checkpoints for planning and cost estimation Is difficult There is more than one software system New system must offen be backward compatible with existing system legacy system STEVENS INSTITUTE of TECHNOLOGY The Software Project Cycle STEVENS INSTITUTE of TECHNOLOGY What are the costs of SW development Roughly 60 are development costs 40 are testing costs.  For custom software evolution costs offen exceed development costs Costs vary depending on the type of system being developed and the requirements of system attributes such as performance and system reliability Distribution of costs depends on the develooment model used STEVENS INSTITUTE of TECHNOLOGY on Relative costs to fix errors Cost to fix an error increases as it is found later in the development process STEVENS INSTITUTE of TECHNOLOGY ks Design LargerComplex Programs Building something larger requires good software engineering Topdown Start from requirements then identify the pieces to write then write the pieces Bottomup Start building pieces you know test them combine them and keep going until you have your program Debugging Programming is the art of debugging blank sheet of paper Testing Because nothing complicated and man made is flawless Maintenance By far the most expensive part of any program STEVENS INSTITUTE of TECHNOLOGY Definitions Software life cycle Set of activities and their relationships to each other to support the develooment of software system Software develooment methodology Acollection of techniques for building models applied across the software life cycle STEVENS INSTITUTE of TECHNOLOGY Software Life Cycle The term Lifecycle is based on the metaphor of the life of person STEVENS INSTITUTE of TECHNOLOGY ER Shhl3S lure IEEE Std 1074 Standard for Software Life Cycle Activities Software Development Activities example Requirements Analysis What is the problem STEVENS INSTITUTE of TECHNOLOGY 11 Waterfall metaphor Used in construction and manufacturing collect the requirements create design follow the design during the entire construction transfer finished product to the user solve residual problems through maintenance Intuitively appealing metaphor good design avoids the expensive late rework waterfall became the dominant paradigm STEVENS INSTITUTE of TECHNOLOGY 12 Waterfall model Elaborate upfront activities Most of the legacy systems are still largely based on the waterfall STEVENS INSTITUTE of TECHNOLOGY 13 Advantages Disadvantages wy Thorough requirements definition Design proven Documentation emphasized Planning details Known quantities Lack of flexibility for change Less opportunity for innovation Test compressed Customer only sees result at end Developer works from static specification not with customer Time lag between design and results STEVENS INSTITUTE of TECHNOLOGY 14 Fact Checks ie In 1995 31 of all software projects were cancelled 53 were challenged completed only with great difficulty with large cost or time overruns or substantially reduced functionality only 16 could be called successful Obviously the waterfall metaphor did not solve the problems of software develooment STEVENS INSTITUTE of TECHNOLOGY 15 BandAid Anticipation of changes If changes can be anticipated at design time they can be controlled by parameterization encapsulations etc.  waterfall model still can be used Experience confirms many changes are not anticipated by the original designers inability to change software quickly and reliably means that business opportunities are lost only bandaid solution STEVENS INSTITUTE of TECHNOLOGY 16 ER Shhl3S lure BandAid Prototyping Create prototype to capture requirements Problem volatility continues after prototype has been completed Another bandaid STEVENS INSTITUTE of TECHNOLOGY 17 What is SW Engineering SW engineering is an engineering discipline concerned with all aspects of SW production starting from the early stages of system specification through to the maintenance of the system after it has started to be used all aspects of SW production not only the technical processes but also deals with project management development of tools methods and theories to support SW production STEVENS INSTITUTE of TECHNOLOGY 18 Difference between SWE and we Computer Science CS . . .  is concerned with theories and methods which establish basis for computers and SW systems while . . .  SWE. . .  . . .  is concerned with the practical problems of producing SW CS is as essential for SW engineers as . . .  . . .  Physics Is for electrical or mechanical engineers STEVENS INSTITUTE of TECHNOLOGY 19 Process Maturity software develooment process is mature if the development activities are well defined and If management has some control over the quality budget and schedule of the project Process maturity is described with set of maturity levels and the associated measurements metrics fo manage the process Assumption With increasing maturity the risk of project failure decreases CMM Capability Maturity Model SEI Humphrey PEE eee STEVENS INSTITUTE of TECHNOLOGY 20 CMM levels 1.  Initial Level also called ad hoc or chaotic 2.  Repeatable Level Process depends on individuals Champions 3.  Defined Level Process is institutionalized sanctioned by management 4.  Managed Level Activities are measured and provide feedback for resource allocation process itself does not change 5.  Optimizing Level Process allows feedback of information to change process itself STEVENS INSTITUTE of TECHNOLOGY 21 What does Process Maturity Measure The real indicator of process maturity is the level of oredictability of project performance quality cost schedule Level Random unpredictable performance Level Repeatable performance from project to project Level Better performance on each successive project Level Substantial improvement order of magnitude in one dimension of project performance Level Substantial improvements across all dimensions of project performance STEVENS INSTITUTE of TECHNOLOGY 22 Pros and Cons of Process Maturity je Benefits Increased control of projects Predictability of project cost and schedule Objective evaluations of changes in techniques tools and methodologies Predictability of the effect of change on project cost or schedule Problems Need to watch lot big brotherbig sister Overhead to capture store and analyze the required information Agile Methodologies Deemphasize the importance of process maturity STEVENS INSTITUTE of TECHNOLOGY 23 What is Agile Process Product and developing process respond to change without breaking the system Modules can be mixed reused scaled and reconfigured as required Close collaboration with the userCcustomer is taken into account fo facilitate change STEVENS INSTITUTE of TECHNOLOGY 24 The Manifesto for Agile Software Development We are uncovering better ways of developing software by doing it and helping others do it.  Through this work we have come to value Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following plan That is while there is value in the items on the right we value the items on the left more.  agilemanifesto. org Kent Beck et al STEVENS INSTITUTE of TECHNOLOGY 25 Agile Principles. . .  ie 1. Customer satisfaction by rapid delivery of useful software 2. Welcome changing requirements even late in development 3. Working software is delivered frequently weeks rather than months 4. Working software is the principal measure of progress 5. Sustainable develooment able to maintain constant pace 6. Close daily cooperation between business people and developers STEVENS INSTITUTE of TECHNOLOGY 26 . . . Agile Principles 7.  Facetoface conversation is the best form of communication colocation 8.  Projects are built around motivated individuals who should be trusted 9.  Continuous attention to technical excellence and good design 10.  Simplicitythe art of maximizing the amount of work not doneis essential 11.  Selforganizing teams 12.  Regular adaptation to changing circumstances STEVENS INSTITUTE of TECHNOLOGY 27 ts Some Agile Methods Extreme Programming best known 12 practices Pair Programming Agile Unified Process Simplified version of Rational Unified Process Test Driven Development Scrum Daily Meeting Sprints Kanban JustinTime delivery STEVENS INSTITUTE of TECHNOLOGY 28 Scrum Agile Methods STEVENS INSTITUTE of TECHNOLOGY 29 Architecture Agile Development Even in an Agile project you need foundations ArchitectureEngineering is the foundation of your software Agile development is suicidal before architecture is clear Use prototypes to quickly finalize architecture STEVENS INSTITUTE of TECHNOLOGY 30 ot Multimedia Software Development Lifecycle Multimedia software development is similar to any other kind of software develooment Is complex Involves large number of people Takes long time to develop Has deadlines to meet Has budget limitations Has user requirements STEVENS INSTITUTE of TECHNOLOGY 31 ot Multimedia Software Development Lifecycle Multimedia software have life cycle Media production Involves producing graphics audio and video material Has media production timeline Software production Involves putting various components and media together Has develooment timeline STEVENS INSTITUTE of TECHNOLOGY 32 Multimedia Software Development Lifecycle STEVENS INSTITUTE of TECHNOLOGY 33 Software development Trends. . .  STEVENS INSTITUTE of TECHNOLOGY 34 Sl . . .  software development Trends STEVENS INSTITUTE of TECHNOLOGY 35 Practical Principles Use Open Source Software as much as possible Open and cost effective Media production Use Python as much as possible Proven highproductivity language very open portable Use Industry Standards Again open cost effective Use standard module interface Allows scripting GUIls are separate components Easy to simulate allows automated testing Communicate with HW through TCPIP Open easy to simulate test STEVENS INSTITUTE of TECHNOLOGY 36 So recording started again.  Its February 15th and is 631.  000 So lets start.  will share my screen.  008 And well start as usual with the sort of road map that we have.  016 So thats the road map.  We are right here February 15 next week.  023 We are not going to have class because its President Day on Monday and Mondays classes are on Wednesday meaning there would be no class for us.  029 So we will skip one class.  Enjoy the break on 624 will introduce exercise number four.  044 That will be little bit more complex.  So having two weeks may be good for you.  056 Again the assignments are at growing level of complexity so each assignment its little bit more complex than the previous one.  103 So dont fall behind.  Keep current.  115 Stay stay with the slides.  120 Review what you did and the solution that has been or will be published to make the comparison 124 to understand what went wrong if something went wrong in your code.  134 See the differences between your submission and mine.  139 If your submission was doing good but just to see probably another way for doing the same thing.  145 So next assignment would be 50 points as well.  153 And there will be the same approach of writing the code and at the same time and then writing narrative by describing the results.  159 Something that is really relevant.  Dont underestimate that part because again in 624 211 we are not doing python because we are in computer science but we are doing Python to do something.  222 So the doing something is basically the narrative the conclusion that you can draw.  232 After getting the matrix and extracting the matrix from the data using Python.  240 So.  Let me jump to the assignment.  249 So the assignment was the first one with files.  258 And some of you may have had little bit of issues in reading the file.  304 So you need to make sure that theres the directory where both of my files and my programs are.  312 So you need to make sure that both files and program will set data files and program will stay in the same director.  325 If not mean you can tell Python to open find whatever it is that even if it is in the cloud.  335 But then things will become little bit more complex because when you move from one platform to another one 346 then the path that you defined in the name of the file may not work anymore.  352 So second consideration.  403 Make sure that you use the names for variables.  407 That is mnemonic.  That is something that is kind of representing the content of the variable.  414 So use the name Gen Fab 2016 file for the handle of the file.  421 Um you have yes questions 430 No.  Okay.  Mute yourself.  Um you have been asked to keep the header on the file.  434 There are several ways for doing it.  446 The easiest way is to initialize the counter of the rows at minus one meaning one that will be the second meaning that you are keeping the head.  448 Another way could be to read the off the loop for the first line and then in the loop all the remaining lines.  504 So those are both reasonable valuable solutions.  515 You can pick each one.  This one is probably the easiest one.  523 Yeah.  You will read something that you will not consider but thats fine.  529 You would do anyway.  So read the five part one was the first file.  533 So read the file.  mean opened the file assigning the pointer to the handler.  540 Then initialize the counter.  548 That is one counter for the.  That the number of lines in the file.  552 And then there are two more counters.  601 One for the subscriber.  One for the customer.  605 And then created list of elements that downloaded from the file is not the only way of handling the printing the last of the first rows 610 but is possibility.  We will work with pandas today.  627 Pandas are data structure.  When you deal with CSV file and in general when you deal with files and in particular files containing numbers 633 pandas are way much more efficient than variables of any kind either release or dictionaries.  650 So but in this case because we didnt introduce yet pandas she we find greater and less great.  703 So those are the initialization so that did then started the loop for on the file and appended each line to the content this.  714 Then added that one to the counter.  731 Again Im not sure if you already sold that but if you want to add the number to variable 735 mean adding meaning in place or meaning adding the value to existing value 751 you can either do something right like row counter one equal row counter one plus one or you can use this notation that is more compact.  757 There is always tradeoff between being compact and being more readable.  809 So in this case its not that much readable as having row counter one equal row counter one plus one but is more compact.  815 But once you know it you can use it.  So row counter one plus equal one in this case adding one to the existing bag.  825 Then Im asking if the term subscriber is in the row.  836 If it is in the row adding one to the subscriber counter.  840 If customer is in row adding one to the customer counter.  845 When you will finish the loop you will have the number of lines to the number of subscribers and the number of customers.  851 So at that point you are ready for whatever you have been required to do.  901 You also have in the variable content all the lines and you can print the last five lines.  908 So.  So keep in mind that if you were being asked to print the first five lines in content 920 you still have the first line that is the header meaning you shouldnt start from.  929 mean in this case Im actually printing the source so Im doing something different from one.  938 What is the right here My apologies.  But it is good to see that.  944 So instead of range zero five is one six because the first one is the header.  949 So it is not doing what is in the printing in that line 31 but the concept is the same.  959 Then can calculate in the percentage of customers.  use the round by two.  You dont have to but when you use around you have set number of decimal numbers to the result that will look nice.  So Im calculating the percentage sum and then Im printing the results for the first file.  So there are that much rows in the data file.  Of those that match is customer that matches subscriber and that this is the percentage of customers compared to the total.  Pretty much the same thing for the second file.  So same initialization because Ive not been asked the.  So this is actually something that you dont need there anyway.  Yeah.  Im in.  Okay.  Sorry.  So instead of doing.  This for printing at the end and doing within the loop.  So within the loop Im printing the first five lines.  So.  If the counter is less than six printing the line.  If not will skip it.  Incrementing the all the counters.  Culturally the percentage.  Print in the results.  Then part three.  Uh in comparing roll counter one withdraw account to two and if its the one is bigger than the second the thats the.  The message that they would send.  If no other message then Im asking if the percentage in the first file is greater than the percentage in second file.  And the message.  When printed.  Thats what you have.  So the lines.  The number of rows.  mean that it is should be the summation of those two equal these one assuming because they are either customers or subscriber.  But when you have file from the award dont assume anything because there could be errors.  You couldnt have blank.  You can have misspelled name and you will not get it.  So dont consider the summation equal to the total as proof of what you are doing is good because sometimes the numbers can be different and then you have all the rest.  Okay.  So questions so far.  All right.  So.  Lets move on and lets talk we will talk about three different.  Topics on the same larger topic that is handling data.  Let me share the screen again.  Let me go here and lets talk about the handling data.  So this part is genetic.  So it can be used in any language.  It can even be used without real language but just in philosophical terms.  So we work with data.  So we mentioned last week that data could be text file could be as we could be other.  There are many different.  Types of data that you can get that you can have relational database so you can have data warehouses you can have transactional databases like the list of transactions in supermarket.  You can have other forms of data.  You can have data that you download from the web or that you scroll from the web from web page.  You can have geographical data.  You can have time series.  So there are multitude of data.  Most of the data in that structured environment are in databases.  So databases are the large integrated collection of data with some characteristics that are kind of the common denominator of the different databases that you can have.  And in particular all of them they have what is called the database management system Dbmr.  So there is this software.  For the user to interact with the data is something that is making the handling the data easier than just working with CSP files.  When you describe the data there are several levels of data.  So you have the physical data meaning the zero one that are in whatever is.  The device that you are using can be hard disk.  Whether it is the hard disk it can be the cloud can be whatever.  But the very end there is collection on zero one.  This collection on zero one is allocated in the physical device in different ways.  When you delete the if and you actually do not delete the file you just delete the pointer to the file.  So you have this storage system lets say is the equivalent of disk that your data are not sequentially plays in one location or in another.  Because if that was the case when you delete the file and then there will be portions that will be not allocated because that you are deleting file that is that big and you have file the new file is that big and you have some waste portion that not necessarily will be filled by the next file that that can be bigger.  So what the system is doing is creating content allocation table that is sort of directory that is pointing to the system that want to access the data is pointing it to the pieces that are scattered on the physical device is like map.  So that the file dont know data the is not contiguous in the space but is scattered in the physical device.  When you delete the data dont see as we finder you basically delete the entry to the file.  So this map of the treasure will be deleted.  So thats what you do when you delete find.  That means that eventually you can recreate the file later on.  So dont trust the delete file and you return your device.  The only way is to physically erase the file.  The device meaning writing zero or whatever is different character across the entire disk.  That will require hundred times the time that you would need to just erase the pointer.  Table of Contents.  The Table Allocation.  The allocation table.  But thats the only way.  So you have the physical data on the device.  You have this sort of table of content pointing to the location basically associating the name of define with that where its pieces are in the disk.  Then you have more logical component.  So what is this file representing It is representing students.  Is representing clients.  So thats the schema the conceptual schema that is on top of the physical schema.  And then you have different views.  So you have the data from the university but you have different views because cannot see the salaries of most of my colleagues.  You cannot see some personal information of your colleagues.  So whatever.  But HRA can see both can see information about the students information about the employees.  So based on who you are you have different view.  So those are the levels of abstraction that you have when you deal with the fire.  When you have Dbmr database management system you have support somehow in doing your job in interacting with the.  Data you have.  So is something that is helping you retrieving the data aggregating the data making sure that if you have multiple people accessing the same data there will be no conflict on that.  It is generic term but there are different nuances of this concept of conflict.  So database management system the BMC as a.  mean in real world there are several products doing the job.  Oracle was the leader.  IBM with DB2 was another big name.  Microsoft as several of them. Naveen is a graduate student at stevens institute of technology who is very interested in AI. Naveen is from Bahrain, a small island in the Middle East but his homeland is Kerala, Inida. There are all of those are commercial products that are noncommercial products.  Open source minus one PostgreSQL.  So those two are the two most commonly used but not the only ones.  The main components of deep VMs are storage manager that is basically managing the table of content.  There is query process so that is something helping the user to access information.  Then you have transaction manager working on the logs on the changes on the database and working on reducing the conflicts in terms of concurrent execution of the transactions.  So those three are the three main components of the VMs.  The job that the department is doing.  Its generally referred to as a. c. h ID atomic meaning its all or manner consistent isolated durable.  So all of those are very important characteristics.  Consider if you have uh power failure and you initiated transaction power failure or the transaction is being interrupted what is going to happen How much did you lose So the is handling those situations with all or nothing meaning that either the transaction has been completed or its never been initiated.  Thats the logic.  So you know how it works and you know what to expect.  Thats an example.  Or.  mean managing conflicts.  You are reserving seat in concert.  You want to be sure that no one will take that seat till you complete the transaction.  When you design database you want to design the concept or model of it.  So there are three main characteristics of data model.  Entity attributes and keys.  So those are the main components.  In the middle 1970s Peter Chen created the entity relationship modeling.  That is way to handle entity relationships and keys.  So in that very basic representation you have like in the chart you have the entity that is represented with rectangular shape the object and then you have the sort of Boyds that are the relationship and then you have the attributes so that that the oval referring to the entity.  So in this case you have two entities shopper and item shopper buys item an item as three attributes.  That is type price and sorts.  Thats an example.  Is very basic example.  In real life things are quite complex and complicated because there are lot of entities and other relationships and all those attributes.  So thats an example of something that you can see in real life.  Why you need such mass you need something like that because sometimes you really need to have picture of the day that you have for several reasons.  Because you want to change something and you want to see what the implications can be.  Or because you have been audited and the auditor want to see what are the impacts of the transactions on lets say clients.  And logical schema is what is doing that.  So there are federal laws requiring that the traceability of data and processes for all the company that the data are publicly traded meaning you need to have representation of the data and the processes that your company is doing.  Its little bit more selective than that.  Only the processes that are related to money generation or management.  But pretty much 99 of the processes are somehow impacting or impacted by money.  Um one thing that we do when we handle datasets is normalization.  So instead of giving theoretical definition will use an example.  mean the screenshot is from the Stone Age but the concept is pretty much the same.  So you have in this case the Ebola.  That can be excel in this case is access but that doesnt really matter.  So you have that in the same structure in the same database or spreadsheet.  You have information about the order information about the supplier information about the class.  And then that means that if for example the customer changes the address then you need to go into each one of the rows where that customer is and change it.  So its definitely not efficient.  The normalization its aimed to address this point creating separate tables for each one of the logical entities.  So in that case you had three logical entities that is order suppliers and customers.  So if customer is changing the address you change the address only in the customer table and thats it.  You need to make sure.  So we mention Keyser when we talked about entity relationship model.  You need to make sure that there is way to connect the different tables.  So you need to be sure that you have customer number that can be addressed and that the customer number can be somehow linked to the other table.  So you need to have keys defining that single record to let you access that.  When you are in larger environment you may not.  Im in the plane.  database may not serve you enough so you may have different databases for different functions of your endeavor whatever it is company university or your own eventually.  And then you need to have something paging all all of that and kind of extracting massaging and presenting in different way.  So those megastructures are generally called the data warehouses where you have that single component.  So that data databases and then you have a.  software that is taking pieces is required integrated them and presented to the user.  So those are named the EPL that is for extractor transformer loader.  And what they do is just that.  So they take pieces from the different parts different databases within the data warehouse.  And they do eventually some cleaning of the data.  They do some integration of the data add some characteristics from the operations that you can do across the different databases and present the result to the user.  So those are the episodes.  We talked about the how to mean the DMZ didnt have the possibility to me.  They give the possibility to the user to interact with the data.  So to interact that you need the language.  So Edgar called the uh created the relational query language or structure the query language escuela.  That is the golden standard.  The.  For interacting with the relational database.  Its is standard.  But pretty much each vendor they have few differences making them not 100 compatible.  So there is a.  core functions that are across all the databases.  Excuse me but.  Some of the vendors may have additional functions because obviously they say this is why my database my dbmr is better than the others.  So.  Relational algebra is basically what is behind school.  You can write program in the actual escuela as all the logical structures that can.  Define language you can have conditional sequences loops.  So all the basic functions are there.  generally in my programs.  So when user as well generally.  And the logic in Python.  And then just cool the data after the processing from the database.  Once have the data do the remaining operations in Python.  But the logic can be either on the Python side or on the execution side because both have the possibility to do that.  But because we fight on that have more libraries and more possibilities to do things in more efficient way.  move the logic more on the Bible side than ask you outside.  So mean we do have course that is pretty much teaching as well.  created it few years ago is an undergraduate course think is ISC to 25 and is data engineering that is very centered on that as well.  So those are some of the names already mentioned few of them IBM DB2 Oracle Microsoft and then may as well general use may as well in my applications.  Well use either my to lot of both that is not here.  My name is pretty common.  The reason why some people do not use my school are because my school has been bought by Oracle.  Meaning yes it is open source but is from someone who is selling databases as one of the main parts of the offer.  Meaning at certain point they can say you know what we will not dismiss my as well.  And if you want to continue you need to pay us money or the commercial version of it.  So and thats why lot of people is not using may as well but is using this there are more tools actually more add on to my as well and Im enjoying my as you little less than when it will become commercial product will do the migration.  Not everything is in relational databases.  So there is portion of the data that is not international that no relational is growing and is growing lot because the universe is not relational and we are getting data from all over the sources and they can be in any format when you have relational database that you need to define whether it is like an Excel spreadsheet that you need to define the header you need to define the entities and the attributes and then you will populate the database with the data.  But if you are getting something you have no idea how is going to be formatted then you cannot use predefined structure.  So when data is not structured then you may have problem.  Most of the social media are using dual approach.  They have no relational database to get the information from to collect the information from the user.  Everything that we post and everything that they steal from us will go in unstructured structure.  And it is no relation and no well database Facebook created.  Cassandra that is no relational database.  dont use it.  use another product.  Well talk about that in minute.  But as backend they have relational database.  So when you ask for your profile profile of people those are data that are in relational database.  So the frontend is not relational.  The backend is more like.  So again the main reason for not having everything in relational database is the lack of flexibility.  So thats the main reason for that.  When we go in.  No excuse allowed non as well.  There is no real definition that are known as well.  It started around 2009 and is growing.  user MongoDB be among those.  When collect the tweets from the forum analyzing social phenomena and when download the tweets tweets are in format that is the same font that is gene similar that is the same format that is in the structure of MongoDB meaning dumping the tweets into MongoDB is super easy.  MongoDB is also an internal structure that can be mapped the to to an additional database meaning that once have my tweets on MongoDB and want to do just like the example was mentioning with Facebook want to create relational database on some of the characteristics.  At that point the transition is easier.  One of the main differences on relational databases is that they do not provide the same level of support than the relational are providing.  There is no.  Stress on the integrity of the transaction.  So its best effort is pretty much the same thing that you have when you access web page.  Is there or is not You can access it or you cannot for any reason.  So its best therefore.  Meaning that all the logic that you have in relational database is now.  To your code.  So if you want to have integrity on the transaction you need to take care of it.  If you want to have any other of the features that relational database may have you need to do it yourself.  So it is tradeoff on one side.  You dont care about the schema of the database why you should do in relational.  But on the other side you dont have all the functionalities that the relational database may provide.  So this is table comparing relational database with MongoDB.  There is to correspondence between the two.  MapReduce is another approach in relational database that has two steps.  So map you basically upload your data and each day that is the logical data is defined as appear key value.  And then when you do user you basically work on this bear to key values.  To go to the subset of the dataset that you want to get is not as strict as relational database where you can go directly on the individual record but when you have large quantity of data may be faster.  Hadoop is one of the examples so use of MapReduce approach.  But generally speaking Hadoop is providing support for distributed file systems meaning you can have where systems is generic term and can be stored as can be devices.  So few years ago we received donation of several Mac Mini so we couldnt do much with the Mac Mini.  So because they were not that much powerful we created the circle the network of those Mac Mini and we put an overall layer of Hadoop managing the individual communities as resources.  For the larger system that we created.  That seems to be just like nice pastime.  But if you consider that we are in the process of having mega computers working on things like the GP that cannot run on your computer but if you have warden and network of computers with somehow logic approach you know the master leave with something like Hadoop then you can have comparable computing power without having single super powerful machine.  So it will become more and more popular.  When Hadoop was created everyone was thinking Hadoop is the future.  Reality is not many people are.  We know what Hadoop is but most likely theyre using it.  Because when you have way that all the data most of the time you have and in the cloud solution.  So you have remote storage solutions.  Meaning you have no idea what is the organization of data than Amazon or Google or Microsoft may have.  So you just access the data.  Most likely they have Hadoop meaning Hadoop is really getting good share of the market.  But in terms of number of installation is not that big and dont know my as well.  So thats an interesting paradox but thats the way it is.  When we work with the town one of the key parts of the process is the data preparation.  When you work in an academic environment where when you are doing exercises in course most of the time the data you have is pretty clean is predigested.  But in reality this is not the case.  So when you have data that you take from real life the data is dirty.  So you need to clean it.  The data preparation mean 70 80 of time and effort is pretty much like that.  So it depends on the type of data.  So sometimes its already pretty clean.  Some of the times is now.  So the data preparation is really essential because at the very end the quality of the data is in relative terms is the quality of the analysis.  So if you have mean if you consider models like Charter GP again those models are machine learning how machine learning is.  But we will talk about that next week next two weeks and next class.  So those models they have two components.  They have the algorithm and the data.  So the algorithms are basically discovering patterns in the data.  And then there is another component matching your request with the partners.  There has been this common meaning that if you dont have enough data you dont have enough partners.  If you dont have enough partners the answers will be crappy.  So machine learning model the quality of machine learning model is the quality of the data.  So the quality and the quantity of the data.  So we are not remembering many billion words that are in the chapter GPT.  But pretty much its all the data that is available in open source.  It took them week with the same energy that is required to run few thousand CDs in the US.  So that match its sort of brute force.  But thats another story we talk next to us.  So but overall the quality of data is the quality of analysis in particular when you have that data driven system.  So like in machine learning.  If you have not enough data or an or low quality of data there is no way that you can do anything meaningful.  So the data preparation let me keep some of them up is basically on three main categories.  The actual cleaning Well mean the cleaning means you have some mixing values.  You can have outliers you can have some values that seems to be wrong semantically.  Uh you may have inconsistencies.  So all of those are part of the cleaning then the integration.  When you want to analyze problem you want to have as many different sources as possible because different sources will give you better view of the topic that you are analyzing.  Why our markets are so good in pinpointing us.  Because they have information from Google and Facebook on the page that we see online.  They have that information from the credit cards on what we spend.  They have information from EZPass where we drive.  They may have information from physical vendor.  So when we go in store and there are cameras analyzing where we go and then the data is integrated with the social media if you have Facebook.  Facebook is also the owner May is also the owner of all the Instagram and WhatsApp meaning that each one of them is giving different view of you.  And then you have system collecting put in together integrating those different aspects of information about you and creating profile that at that point that is very strong because it is again the different aspects of your life.  So the data integration is really essential and sometimes is really difficult because data can be different forms can be with different semantic keywords.  You can call something in way or in the other you can call street.  The answer is the result or the full name or dot.  So when you try to integrate the you need to consider that mean that the street is the easy case but that could be cases more complex.  Transformation.  We mentioned the normalization but there is also the aggregation.  If you have information about the number of times an event happened and then the duration of the event well if you had those two values separated probably you cannot do much because lets say we are in the business of analyzing accidents cut accidents.  If you know that there are five accidents.  And the driver is driving since ten years is something.  But if it is ten accidents and the driver is driving one year then is completely different.  So the integration could be creating new call on that with Accidents year.  Thats an example of transformation.  So again cleaning integration transformation.  Okay.  So thats the first part the questions so far.  All right so lets move on.  And lets go to the second part that is about the functions.  So we are back to Python.  So from the theory now we are in the language functions.  Functions certainly are an important part of Python.  Probably is the reason or are the single most important reason why Python is so popular.  There are quite lot of functions that you can get from outside but several thousand other functions meaning in each domain.  You may have multiple choices for library user that can make your life easier.  typical example that they use.  And started working in artificial intelligence in 1985 86.  At that time we didnt have languages like Python so we had Fortran we had Lisp but it was language that was room based that was created for creating expert systems or group based systems.  But when we had to create an algorithm so one of the oldest most commonly used algorithms is called the decision tree.  So we had to build our own version in at least Fortran or one day rather of the decision tree algorithm.  What do now basically import library and then from the library call the function.  So in two lines am solving what would cost me probably hundred lines.  So not hundreds but probably 50.  Yes.  So it its major difference.  So functions can be functions that you define.  Functions.  So that are part of the standard Python functions that you import from external libraries.  So for example was using before is the last one is imported from external libraries.  Between functions.  So range some length.  So those are examples of functions.  And those are built in in B. C.  By then you can define function.  So to define function you use the reserved word the then you name the function.  In parentheses you have the arguments meaning what you are passing to.  The function is function to calculate an equation.  Then you need to pass the values or the variables for the equation for the calculation or you cannot.  You can pass nothing and have the function doing something like in this case.  So Im passing nothing and the function is printing.  Hi Jim.  So what do is basically if the program is this function that can be anywhere in the code generally use them in the very beginning for clarity.  And then call the function with hello passing nothing.  And when call the function enter here and then will get Jim then oops continue my program print zip and then hello again.  And we print again at the same values.  Just like the conditional of when you create function you want to have colony at the end and the content of the function is indented.  So theres that syntax.  So this is function.  When and how you use functions.  You use functions when you have sort of recurring use of the same code.  Like in this case you define function that is called the triangle area and you expect in the function to have height and width.  And then what the function is doing is calculating the area.  So with divided by two multiplied by height and then the function is returning the value.  If you look at the other function the first one that we saw this one is not returning anything.  Functions can have written value or cannot.  So in this case there is no written function.  So you call the function and the function is doing something lets say without returning.  Anything in this case is returning the area.  So lets see how is used.  So is use the new pass.  Does the with the say hi.  And then you want to bring the area the triangle passing to the function.  Those two values.  If you want to change the values you can use the same function.  So thats the real reason why.  One of the main reasons why you want to use the functions.  So instead of writing in times the same code you write once and then reuse it if you have function that is doing its job just once.  You may consider not having function not for optimization purposes.  You can have it because is more readable is pretty much like having blocks that are doing something in your code.  We dont use classes in that as logical structuring python because dont see the reason for that.  But when you use classes the classes are like mean few years ago lot of people were building to object oriented programing.  Those classes are the equivalent of objects so they contain functions and values.  So they are like single entities that can run in your program or can be called by another program to run independently from the original program.  So thats the class.  Most of the functions that we imported from outside are structured with the classes because you may want to use only portion of the entire library.  Another example of this is the square root.  So you calculate the square root.  You first ask if its negative but you can not have the square root of the negative number and the return will be none.  Then you say if its zero then you return zero.  Then you define start and limit.  And then you set the loop.  So you do the calculation for the square.  So if you want to print the square root of 15 you basically just pass the number to the function.  Then this 15 will take the place of this this and everything will be calculated as as value of 15.  Next time you call it with different number than will have different body.  So that number is the argument that you are passing to the function.  So thats another example with no return of value.  So the function.  Is generating greeting for the user based on the language.  So if the language is.  Yes Spanish is.  Hola.  If its French is bonjour.  Otherwise is hello.  So if you call the function with the then you will get the allo.  Yes.  Hola.  are you.  So thats an example of passing values to the function but the function having no written value.  Is doing something different based on the input value that is receiving.  The the town value again that can be there or cannot be there.  So this super basic stupid function is great and returning.  Hello.  So basically when you print Greta Glenn you will get the hello Glenn and whatever is the other you would get.  Hello.  Obviously there is not much reason for creating function doing just one thing.  You just write hello.  But thats an example.  Just to explain how the written value may work.  You can have multiple written values and you need to handle that.  Um.  Thats an example of using the return value.  Uh go here.  So in this case it was just printing directly without greater value.  In this case is returning the value of the greeting.  So if you pass in you will return.  You will get hello as return value.  And thats the printing and so on.  So you have that if you have function like this one.  So the argument is hello world.  And this argument that will become the parameter for your function that will return the result this will go into big so and then when you print big you would get w.  If you have more retail values you will have multiple values instead of big.  That would be in May.  Thats how many return values youll have and those values will be separated by comma.  So if its written and then it would it would be mean instead of one that would be big comma.  Something else.  Um.  You can pass multiple arguments so you can have the food eventually.  For us the arguments.  Thats an example.  So you have the function make sandwich.  You have meat cheese Ebola cheddar bread equal rye print.  The idea of sandwich with meat cheese and bread.  When you bring the.  mean thats the function.  The function is printing those.  If you pass ham the only variable in the function that has no default value is meat.  And this ham will replace meat meaning you will get.  Ill have sandwich with ham cheddar brant and rye bread.  Right Brett Yes.  Same sperm if you have more than one.  The second one we replace the first value with the default value meaning it will replace.  These are cheddar cheese.  Equal cheddar.  So the one it will print would be INAUDIBLE of sandwich with spam cream cheese and rye bread.  So again you can have defaults.  Uh you can have variable number of arguments.  This is something that we dont use much because we tend to be little bit confusing.  But with Python you can do it.  Again you use the function either when you have piece of code that you want to reuse multiple times in your program and or when you want to have your code structured in way that is more with logic blocks in some other readability.  Generally speaking dont use functions if dont reuse the same code.  But some other people again with more an object oriented view they tend to think about objects that are either classes or functions.  Nothing wrong either way.  just feel more comfortable using functions to only when have code that is going to be repeated.  Another point that is relevant.  One of you started using function for the previous assignment and that kind of got lost in that.  The concept of local variable and global variables.  So variables within function will say in the function like in the.  Unless they are defined as global.  When that function is defined as global then they will keep the value.  Lets have some examples.  So you have this function where that is called foo and is getting two arguments and y.  define as global variable than assign the value five to the variable the value ten to the variable b.  flip in this function and and then print the inside food and then print and Y.  So theres function.  So in the program assign a1b two 3y4.  Then print that before calling the function and have and and thats what have.  have one two three and four.  Then call the function passing it 25 and 50.  Meaning Im going here.  am printing inside the function.  We are here.  And then in has been defined as five and thats what you get to be is 18 is ten because its been defined as ten in the function X.  So we pass.  was three EPS in was four.  In this case.  Uh.  And so we passed the 25 and 50.  But we flip them within the function and you have 1525 when you are outside of the function you print because was global.  It kept the value that was inside the function.  was not global meaning even if inside the function was then is not global and we have the value to back and thats what you have.  And then and Y.  Same thing.  They have the value that are outside of the function.  So again local global.  Keep in mind that that only functions so that they are explicitly defined as global will retain the value when they leave the function.  How many times they use that Not many.  But is it possible mean you want to have function to have as much flexibility as possible.  You may not want to have global variable like keeping up the volume but sometimes in specific cases it may be useful.  Thats another example.  You can do all the operations you want.  Of course.  Imported fudge.  So mentioned before that there are several thousand functions in dont know whats going on.  Can you please stop messing up with my screen Thank you.  So.  Functions in this case.  So you can import functions.  Let me stop shooting for second and launch again.  All right.  Think to disable that function because mean you can just not intentionally write on my slide and that is not going to be nice for the rest of us.  So Martha is one of the libraries that is available in in by done that.  So you the statement is an important name of the library and then within the library math there are lot of sub functions and you can call up for example the square root instead of writing our own function the square root so over 15 and you will have the result.  So thats an example.  The other way to use it is a.  To import only the portion of the function that that you need.  So in this case from math importing all the security.  Keep in mind that when you import function in reality you are importing in your program the entire library.  Meaning you are creating something that can be big.  So some of the functions are really big.  Math is big is not the biggest but there are some that are really big.  And they point in your program.  We say in memory using lot of memory.  So if you have also quite lot of data then the combination of your program being giant and the larger dataset you may run out of memory.  So in those cases keep in mind that you can import only the portions that you need and then the occupation of memory will be reduced.  Another way to import the libraries is to use nicknames.  So like in this case mean this case Im not getting match because Im just saving one character.  But some of the libraries they have longer name and then you use only two or three characters to call them.  So in this case when you import library and you add nickname where the syntax is import name of the library as the name that you give.  Instead of using the original name you can use the nickname same way as the original name.  And thats basically little better about you.  What else with the links Lets talk little bit more about those modules those packages.  So again there are some built in functions.  We know that we used some of them.  One of the most commonly used is lot of it is for graphs for creating graphs.  Graphs can be graphs like in Excel or pie charts bar charts histograms.  All of those can be created with Matlock.  We will go back to visualizations in few weeks but just keep in mind that Matlock is the starting point lets say for doing visualization in Python.  In the past Python was not great in visualization.  Now there are many other libraries doing great job.  So thats an example of the application.  Again Matlock Lib is long name so we generally use as key to make it short.  So at that point you import specialty and then when you use it you just use PLC as an example plotting.  This is line plot with all the options you want in types of marker call or line scatterplot the bar chart the pie chart the histograms.  You can have multiple plots on the same screen with subplots like this one.  So thats my plotline though.  Another super common is numpy numerical python.  One of the advantages of numpy is that it is using another type of variable.  So is not.  This is not dictionary but is called array.  Array are like lists but with some differences.  Only numbers can be on that think arrays as vectors.  So thats the best way to represent an array.  So in array is vector vector as dimension.  So if you have vector in two dimension the vector wed have two values that could be and Y.  So it will be point at that point if you have vector in dimensional space then in the variable of the array will be in square brackets and there would be components for it.  We will use that bit down the road.  And its really the foundation of data analysis.  So the combination of new PI and pandas that you would see in moment its what you really want.  Arrays can have multiple dimensions.  So like mean it really depends.  Like matrixes but can be dimensions.  And thats.  Are probably the most commonly used libraries library in data science.  Not because its doing lot of data science but.  So is is way to represent data structures.  So you have the data you want to have the data in data structure that could be representational like Excel and then you want to use it.  Those structured data frames are similar to what is using MATLAB in our right if you are more familiar with that Wes McKinney created when he started working in financial company in Wall Street and then he asked the company down the road to make it open source.  And they agreed fortunately for us and we are all using that.  One of the advantages of pandas is that the foundation is known by meaning.  Most of the functions are provided by pandas.  Are with the engine.  All we now know by.  All right.  So lets talk little bit more about those pandas.  So just to begin.  Nothing to do with the animal even if obviously they play on the ambiguity is for python data analysis library again that its relatively recent and is the most commonly used library for data science.  There are two types of structures.  One there is one dimensional structure.  Okay.  Lets say here.  One dimensional two dimension.  So we will use them quite lot.  There is kind of correspondence to with either as well or Excel.  So DataFrame in Pandas is table they call on is variable row are observations and you have way to group by to merge somehow or to extract from existing structures.  So serious one dimensional data frames two dimensional most of the time.  We call that frame even the one dimensional.  So those are the structures that we will use.  Well be talking about in pandas.  The variables would be pandas objects.  So wed be no arrays would be no.  Uh.  dont know dictionaries or lists.  Uh.  Thats an exemplar of one dimensional structure.  So you import pandas.  Thats another case when you use nickname.  And then you create the PANDAS data structure called the and you create the structure from those numbers.  You create indexes for each one.  And then when you print the structure thats what youll get.  Then you can address one element using the other as an index.  You can import from dictionaries.  You can import.  mean because its rooted in numpy.  You can do operations directly on the vector on the entire structure making it way much more efficient.  Down the road.  We will talk about how to better use.  This approach instead of doing loops.  So when you multiply the entire rule by another row its way much more efficient that using numpy slash pandas instead of doing loop multiplying each element pet each element.  Python is not very efficient in loops is even.  Less efficient in loops.  Within loops.  Nested loops if you can avoid that.  And we will talk about that later on.  That would be really helpful.  Anyway.  So you will have several examples of that.  Just to give you an idea want to share with you for moment that.  Something that Dylan may remember.  Thats script that wrote few weeks ago for putting together the data on classes and.  Guilty from what they what they its really pain in the neck.  Its not very flexible is not giving much of the the any information that we want.  And thats what made me think so.  was in charge for scheduling classes for several semester.  Now my colleague VLAN is taking over unfortunately for me unfortunately for him.  But this life and the way did it was using Excel.  But there was gap between the information available on the work day and the information on my spreadsheet.  So each time had to do something manually to clean the data add somebody else and when you do it manually you have no guarantee that you had consistency across the times.  You do the same operation using program like the one you have on your screen you define the process and then you are sure that each time that you do it the you basically apply the same rules.  Because there are parameters in play.  Instead of having the values of those parameters they can be.  Because when you download the data from Workday you have all the courses for the entire sequence.  So Im interested to the courses for the school systems and enterprises.  So want to extract the only those with certain prefix.  Thats an example.  Or want to focus on one semester.  So.  created configuration file where all of those parameters are up there and then read the file and my programmer will basically use the parameters to function.  So the reason why Im showing that is because Im using pandas.  So Im using pandas to read the configuration file.  So let me see if can show you what Im talking about.  Just one sec.  So thats the configuration file.  And so the configuration file as the name of the file that Im reading.  The name of the file with the information about the faculty the information on the suffix of courses that we offer to our corporate sponsors.  The name of the semester the programs that we call over programs that are kind of mix program.  So undergraduate and then have black list programs that they want to exclude anyway and whitelist courses that they want to include anyway.  And the number the threshold of enrollment to be considered as real course thats an example.  Is configuration file is something that you do to avoid to write in your program values that can change over time.  So at this point can use the same program for different semesters.  So without changing the program.  So Im reading the configuration file into pandas and then extracting the name of the file with the courses with the faculty and all the rest.  So thats way to read that.  mean it seems to be complex but its not that much.  Same thing for mean reading the configuration reading the fine from what they read in the fine from faculty.  So for all of those Im using pandas.  So with pandas you can read the as we you can read the Excel files text.  Its pretty much all the possible all the most commonly used sources and some of the less common.  You remember in last assignment that we had to do something to skip the header.  With pandas you can say head on zero and that header will be out of the category.  You can transform pandas into list.  mean in this case its relatively big.  Lets see.  However this one should be big enough.  So thats basically what you get from.  From what day So you have all the courses for the entire university.  Its quite lot and you are not interested much in the header and you need to select only courses with the thing with the certain graphics.  So anyway.  Thats an example of use.  So in this case what did was cleaning of the input file meaning eliminating those causes in the empanadas you have.  And in order in the conditions the end is with the commercially ampersand whatever you want to call this symbol here.  And the vertical is from that order to end an order and adding the conditions.  Then.  Once they added the conditions Im adding.  Fisher So want to know what is the program What is.  If its an undergraduate and graduate or thinks that that an end in saving everything is going to be fine that will copy into my Excel spreadsheet.  So thats typical example of real world use of pandas.  Could have done that without pandas Sure could have done it with CSB.  But mean doing things like cleaning the input.  knew could do without pandas but then would need lot of loops.  So right now its pretty fast.  If do with loops it would take forever.  So anyway that would be just an example.  So let me stop sharing at this point.  hope didnt scare you with that.  And uh at this point its eight or five.  We have good time for and in class exercise.  So let me introduce the in class exercise.  So let me share the screen again.  They let me go here.  So the in class exercise that we do will be on using functions of course.  So you take three numbers from the user then you do check if the numbers are numeric or not.  You will do it using function that you create and then you will print the factorial or the fourth of the three numbers and you will calculate the floating value of the solution or the linear equation that is multiplied by plus equals zero where and are the two other numbers that you extracted that that you received from the user.  You will use your own functions both for the factorial and the linear equation.  Dont use external libraries so you will use external libraries for the rest of your life.  But for this particular exercise you are not going to use it.  Okay.  So let me stop sharing.  Let me publish.  Those are so.  published the solution for the previous.  Assignment.  And then.  Okay.  published all the data all the slides and in class exercise and let me create breakout rooms.  Okay.  There are nine breakout rooms with three or four participants per room.  So its eight way to give you lets say 20 minutes to start working on the assignment.  Then we will reconvene and we will share some of the results and your creations.  So the rooms are open.  See you in about 20 minutes.  Okay.  So Im resuming the recording.  All the rooms are now closed because this.  And how was it Any volunteer.  All right.  So let me share the screen.  And let me goo here.  Okay.  So the program was taking the three numbers from the user and then calculate the factory for the first one.  And then the solution the linear equation created from the other two numbers.  Um we have been required to have to create function to determine if the number is numeric or not and then function for the factorization and the function for the linear equation.  So the function for checking if numeric is pretty straightforward.  So we taking value and then is trying to do to calculate to transform the value into floating.  And if there is no error meaning it is okay and try it with down at if get an error with thousand n.  So meaning is not numerical.  The factorization is recursive function so the factorial of zero is one always checking first if the input number is zero if yes with the other one otherwise we will recursively call the factorial till well and the loops.  linear equation.  So again you have multiplied by plus equals zero meaning is equal mine or divided by eight.  So and thats basically what youll have.  Thats probably not very intuitive.  But instead of having each individual number ask the to the user created loop on the three numbers and the three numbers will go into list.  So the list will have three numbers that are the three numbers that the user will input.  So initialize the counter all of the requests of numbers to zero one.  The counter is less or one two.  will ask it.  Please enter number.  And just want to give the user sense of how many numbers he included.  So if is the first time will be please enter number that is one or zero out of three and the second will be two out of three and three out of the three.  Then thats just printer and then the input will be in separate line just for better visual.  Then Im calling the function to determine if its numeric.  So its passing the number and getting over here.  If it will get an then it will be numeric.  And then if not well continue.  And then well increase the counter to one.  Not to ask the second one once it will finish in number list that you have you will have the three values and then will print the factorial on the number.  That will be the first element of the of the lesser.  And will pass this value to the factorial function and will get the number.  Then for the linear equation Im placing the result in this variable here and then passing the entire list to the function.  mean could have passed just the last two elements but its kind of easier this way.  And then using the first element that is meaning the second element of the list and the third element of the list that it is bit.  And Im getting the value here and then Im printing it.  So if execute it.  And that the number 22.  Three.  But before.  So the factorial of 22 is this number the solution be being an equation from the sig on the two numbers Is this one in the process couldnt have probably around.  Instead of having the plain number would look nicer.  But thats what have.  Okay.  Questions have question.  Yes.  Good.  In the second part where youre trying to find for the linear equation you rearrange the equation and put exit the left hand side.  Thats how it works.  Is that is that way to put the equation as it is Because if the equations bigger it might be difficult.  Do you know what what you want on the left hand side Is it way to put the equation as is Well mean what you need is the solution.  If you look at the kind of formula that used is basically putting an on the left side.  So if you look at that the.  Right.  Solution is X.  Yes.  Im saying.  Suppose we have an equation thats lot bigger than this.  Is that way to improve the equation just as it is without bringing what you want to the left hand side Well mean you can create function for that.  But the very end you have mean linear equation.  If is linear you have only two elements.  So you have one element that can be as big as you want.  But the very end is coefficient is number and then you have second element that is another number.  So for linear equations is one variable is like that.  Then is linear equation with multiple variables.  Then you need to change completely the approach in the way you write it.  mean yes you can write in different way but mean its its simple arithmetic of transformation that you need to do.  mean again in line 33 thats basically placing on the left side and all the rest on the right side.  But thats the way to solve the linear equation.  So again that if you the linear equations can be complicated when you have multiple variables at that point you have system and you need to mean probably using new PI you need to do the calculation but that would be different story.  So you will use pretty much linear algebra at that point.  mean in this case it is kind of straightforward.  dont know exactly how.  Give you better answer to your question.  Why do you think Okay.  think for linear equation it might be easier to do what we did but was just wondering if it was like quadratic equation.  It would be harder to.  Right.  function like this Yeah.  mean do if it were quadratic equation instead of linear one if you have quadratic equation instead of what you have in line 33 you should write formula for it.  But dont expect to have the formula right as input.  So you need to know what the formula is.  So you have only the coefficient of the coefficients and then you apply the formula with the square root and all the rest.  Okay.  All right.  Thank you.  Yeah.  And mean the more complex is the equation and the more complex is going to be on line 33.  But thats basically where you solved the equation in sense.  All right.  Okay.  So let me stay here for second and let me spend few minutes in.  How So if you look at the example that use here as you can see have some functions.  So those are the functions that Im using.  Im using pandas Im using PI and Im using this function because there is conflict between the versions of the functions that Im using.  And was getting warning and want to eliminate the warning using this library.  But thats mean is not functionally relevant.  You need to have those libraries in your system.  So to import those libraries you want to go into settings.  You go into your projects.  So in this case was it was management and.  You have.  Those are the libraries that they have in this project.  If you dont have library you need to add it.  So you go with plus.  And then you do dont know new library.  want to install TensorFlow for example.  So.  You select the library you want to install you do install package and that will be installed at the point that when by Sharma will finish the indexing on the library that will appear here you may have every once in while things like theres small arrow here that is telling you that there is newer version.  So you selected the you go here to upgrade and then.  All this is updating.  And then at that point have the latest version.  Let me do the same thing for this one.  But you can see here that is installing the package and then.  Its read.  You have another way for doing it.  That is going to buy them packages.  And you can do the same thing.  So you can do.  For example this one you have over here the description.  And then you do install and you have it.  So thats basically how it works.  Importing libraries now.  Let me now introduce the exercise for Exercise four is not that much different from what you did in Exercise three.  There is one relevant difference though.  So is it on the same CD bike So those are the files that we will use.  So let me close this.  So those are the two files that you will use.  So one file is from November.  It is in 2021.  And this is little bit older.  So.  If you compare the two files you will see that the two fights that you have three two duration sometimes of time.  In this case you dont have.  The trip duration but you have started an ending so you can calculate the duration from those two values.  So why they changed it We dont know.  But thats matter of fact.  They changed it and we need to live with that.  So in this something that is unfortunately pretty normal real life.  So you rely on data they change the format.  mean that what they think is happening all the time.  So they change the format and you need to adjust your code.  So thats pretty much the main difference compared to the previous assignment.  So you will have.  You will read the fine.  You will create the function of print details and you will loop into the list of lists or the pandas say if you want to do it using pandas.  So this is explained as list of lists and not as pandas but you can do the way you want.  So you will look into the two files.  Those two files meaning you have big list that will be with each element will be one line.  And then if you want one element in one particular day then you need to go into the list of list.  But we saw that last week.  So for example this is the the third element the meaning the third row in the file thats something like that.  If you want the data that would be the first element for the fifth entry but could be the second or whatever.  So you need to have two pointers.  The first pointer is the pointer to the record and the second pointer is the pointer to the element within that segment or whatever it is.  So these print details will loop into the.  Lisa and will collect the daily trip duration that you will get from Andy that started that.  So.  mean that in the first one you have the duration and the second one you dont.  So you want to calculate any way in duration so you need to do it.  mean you need to subtract the the ended the from the ended the started to have the duration.  Then you print blank line and then you print the average daily trip duration.  The five most popular starting and ending stations.  And the number of members and casual users.  Keeping in mind that even the user type changed.  So you have here that you have member and casual in the past.  So you had subscribers and customers or something at that thing.  Yeah.  You have customers and subscribers.  So why let in the new one You were members and casual.  So thats another difference.  So there are two differences.  Again the file as different data structure for example.  One is the redirection.  The other note.  So you need to handle that.  Then you will compare the results from the two files and the comparison will be based on the numbers that you created here.  Then you will print the end of file processing and you will write and two page split.  reporter describing based on the data your findings you can have with some additions doesnt need to be two page but cannot be two lines.  So thats basically it.  Let me stop sharing.  Let me stop sharing this and.  Let me make sure that published the the inclass exercise.  mean the solution.  Im publishing.  In the new assignment.  And you should be good to go.  Okay.  Questions All right so Im stopping the recording.  Assignment is going to go.  So anyway the mid term whatever is going to be the format will be in in parts.  210 So one part will be questions like there is question here.  222 No no no no There is no on.  Campus.  So is all online.  232 M.  24 is Ws meaning is online.  233 So if we will do in realtime we will be realtime.  240 But online but you will have certain amount of time.  241 But it will be online.  The reason why Im doing that is because thats the way it is for the online version of the class meaning in the on campus.  248 The on campus version students have and an alpha for the mid term and want to make sure that the online and the on campus are compatible.  310 So the meter the midterm is going to be parts one part will be.  327 Could you please mute yourself Joel One part is going to be questions what is software 336 Not that generic but question.  So the second part will be code that you need to fix and the third part is going to be smaller pieces of code that you will write from Scratch.  346 Obviously the PC so code that you will write from scratch are not compatible with the assignments like exercise for exercise.  5.  That you would see by the end of the class.  401 So parts questions code the to fix evaluate force and then fix code to right from scratch.  417 So this is going to be the midterm.  429 Then we will all enjoy the the spring break and then we will reconvene close to the end on the map.  432 All right.  So questions so far.  444 Okay so let me go into.  452 One topic that dont like much to address but unfortunately have to.  458 So in the exercise for we had more or less more than 10 students.  506 So dont remember the exact number but is more than 10 students in clusters who did very similar.  516 If not identical assignments.  dont think lot could mean that they are identical apart from the names of the variables.  527 So cheating all the changing the names of the variables or moving pieces.  542 One line up and on while one line down.  Its really poor way of cheating.  551 So if you want to cheat cheat.  Well thats what already said few times and Im repeating.  600 So just want to let you know what is the process that we are following in detective.  607 So from the syllabus cheating of any kind including code sharing between students in individual assignments as all the assignments that they have in this class apart from the inclass assignment is considered cheating is plagiarism and may result in 615 grade.  Normally what do take the value for the assignment.  642 Lets say is 100 meaning is perfect.  divide that by the number of students involved in this sort of plgeries over the years we kind of perfected the approach.  644 So let me explain how this has been done.  707 So we use MOS.  There is tool that has been developed by Sanford University.  711 Most stands for measure of software similarity and it works with different languages including python.  717 Moss measures the similarity between pace of files from list we provide list of assignments so the example on the right it obviously not from these classes in Java download.  727 mean.  copied the plasm copied by citing the source from website in mean from an article posted on Medium.  744 So we provide the whole list submissions and then the tool is matching onetoone while the results have decent good degree of reliability.  758 There could be miscalculations new to several factors.  819 noticed that the most relevant one is the different lengths of the files.  821 So in the example on the right side that you have in from the more similar to the less seen in era you have the comparison between the submissions.  835 So the first one means that there is 96 similarity between those when is different.  854 And it can happen like in this case.  consider the lowest number so think its fair again.  902 Its tool may need to be adjusted.  914 So the way we do we basically compare side by side the cases with the highest level of to do this we use the details that moss is providing and if its something that is not clear open that different windows in plane editor and compared them side by 922 side its very time consuming approach but unfortunately we need to be fair in the grades that we provide.  950 Once we have that number develop model in excel that is mean the one on the right is screenshot of the model.  So in the model we have the Max Square meaning what is the school or other points that they would give if it was individually done can be 100 meaning.  Its perfect solution can be 30 whatever it is.  So does this quarter that will be divided somehow than the number of students that involved in the case.  The percentage of similarity.  That is combination of what moss is telling us.  And our review after this stage based on that we calculate the penalty because there are some assignments that are intrinsically similar.  Due to the the type of questions so that am in it.  added the the average similarity that is calculated from this table.  So transform the Pdf all the HTML into spreadsheet and then calculated the the average.  Once have the average this will go here and then the penalty is applied only if is higher than the average class.  Similarity.  Once they have dependent.  Its just subtracting the score.  The panelty and have the actual score.  Some assignments may have more than one part.  Each part is evaluated individually have the weights for the different parts and and and then mean averaging wedding.  The tuna will get the.  So thats basically the process.  Now we take pleasure is very seriously so we need to be fair.  With all the students.  If some of you are working together and someone else is struggling to do by himself or herself then the second individual will be penalized and thats not right.  When you start losing points because again open again the penalty is points in that you are losing.  So in of getting 100 you will get 59.  So losing points at the very end may result in failing the course Im not going to give any makeup assignment when you will lose points due to plagiarism because mean its your fault.  You knew that but you did it so again.  We need to be fair.  We need to play by the rules.  There is nothing wrong again.  It wasnt one of the first slides and want to repeat it.  There is nothing wrong in using for specific part of your code not for the entire code.  Obviously the sorts like stack overflow or rather but you need to side the except sorts.  Page URL that you are using.  If you dont and someone else is using the same sorts.  And thats someone else that is not citing the source as well.  We cannot say if you use the same sorts or you just walk together.  So because what we see is that the code is identical at the certain level and then for us there is plaggery.  So even if the process has been tested in previous semester it could be wrong that like any process if its wrong step up and let us know keeping in mind that this is not negotiation so before asking for review make sure that you have solid case.  So we are spending time in detecting those cases.  What the fairness all of the class 100.  Be respectful of the saveness of our time and the time or the other students.  So if a.  Case will not be solved we will send it to the Sevenths owner Board.  What is going to happen after that Its out of our reach.  Meaning.  They may decide to expect the student because there was the students because there was case of plagiarism or reckon result not.  You were wrong keeping in mind that we have trains of the old case and the trace is in the slides that presented to you.  So really hope that this is clear.  want to stop the sharing for moment just to check.  If you have any question on that again all of these is not done to punish you in any way.  But just to be fair so there assignments are individual.  You are supposed to do them by yourself you can use outside the help from online resource.  We do have chat gpt now.  So we dont know exactly how to deal with that from both the Su.  And the faculty standpoint keeping in mind that if you use chat Gp.  Someone else can use it and then there is the results may be very similar and then you will be considered in cheating case just like that.  But we cannot really detect if its from Chat Gpt or not.  But if others will do the same then the outcome will be very similar because yes we will not generate exactly the same code but will be very similar and then the bladger Isma would be keeping in mind that.  Chad gpt is not processing your files so there is no way that you can get something on file that you provide to the.  Its called the Nlm.  Large language model like Chat and Gpt down the road.  We may develop chat gpt as chutor.  So Im working on it to create those large language models with given knowledge base that we can use for students.  But dont know if and when this is going to happen anyway.  So thats basically it.  Please be fair.  Don Sheet.  You are here to learn you are not here just to get good grade because there is risk that you will not learn and you will not get good grade.  So meaning you are wasting your time your money so let us help you as much as we can.  If you have problems check with us 200 and we can eventually have keywords not chat repeatedly but human beings.  Helping people in the class.  But dont cheat please.  All right.  So let me now go into the assignments.  So the assignments had certain level of complexity.  So was mentioning since the very beginning that the courts as and that increasing level of complexity.  So we will have little bit of break in the next assignment.  So next assignment will be probably little bit less complex than this one.  But the trend is just like that so there will be growing level of complexity if you already knew how to code the that could be good news for you because now you will be more challenged than the initial ones.  If not dont underestimate the complexity meaning.  Dont leave the time to do the assignment at the very last minute.  But allocated the proper time for the assignment.  One note on technical aspects Im using new generation of Max with the apple Cdicon meaning the architecture of the computer is not based on Intel but is based on an Amd micro Profile.  If you have python version.  That was developed for the Intel may not work properly with the the Amd.  The new apple Silicon Microprocessors.  So go to the python download the website and download the version.  That is not the Intel version Im telling it because all the scripts that they had were either getting warnings or not worrying at all.  tried million different things so and then stepped into case on the overflow.  Saying the problem its apple city.  could try to ask to chat.  Gpt didnt work.  The reason why didnt work is because the chat Gpt is trained on data up to 2021 apple silicon was introduced.  The after that meaning it has no information from 2021 to today including this one.  But anyway so be sure if you have Mac latest generation you use the proper version of pipe.  For the assignment so the assignment was about just processing text.  The Csv files Csv files related to let me go to the files.  Related by the way does the model that was mentioning and those are the formulas.  The Im using.  So the files.  Where are this one And.  And is other.  So the main problem with those files was the fact that in one you have the duration in the other.  You have not in one.  You have user type that can be subscriber or customer in the newest version on top of not having the duration.  You dont have user type but you have member casual and is an advisor either member or casual.  So those are the main differences.  So in order to do that you can use either unless or list.  Will review with you body options.  So this option is using lists.  When you use list you actually use lists lists meaning each record that you will read will be one element or the list.  And then if you want to access one element of one record you need to address.  You need to address can you please mute yourself You need to address the list into the list.  Yeah.  So like in this case.  All right.  So Im importing the Csv library that will use for reading the file and importing this daytime.  That will help me.  Calculating the during.  So thats basically the function that will do.  The printer.  did quite lot of initializations and then started the mean the file is taking list with duration.  Start time and station and if member or casual is list of lists and will pass the first file first and then the second.  So initializing elements start in the loophole checking.  If his member will add one if its casual will add to the counter occasional.  Then if is none of those meaning is blank will skip and continue.  Then Im checking.  If the name now Im for use on the name of the stations and calculate checking.  If the name is in already.  Already in the dictionary if its yes will add one at the counter.  We did the same thing when we calculated the occurrence of the names in in class exercise.  Im not going to spend time on it because we already did it.  Then same thing for the end.  So this is for the start.  Insertion and the station and then when finish will print the results.  So thats to tell the format for the data.  That is year month day hour minute seconds so open the file in reading.  This is not necessary but edit.  Then created the an empty list that will host the content of the first file.  In this case and.  Then started at the process of the file and then Im checking.  If is source subscriber or customer if not will continue and calculating start time and time using the function daytime that was mentioning here then the difference.  Hi Round it just to have nicer view of it.  And then added the the element to the list that will pass for processing and then will continue as well.  And Im sorry.  This was the second one.  Stay on the first one the first one is the one with subscriber customers and now members and casual meaning and need to replace subscriber with member and customer with cashew so before appending to the file it could list the records on the file.  had to change.  What is inside of it Same thing for the second file without this last portion because its not customer.  didnt use either cases.  The duration so the first one headed it Duration.  But didnt use it just to have the same process.  could have.  Then Im calling.  Excuse me.  The function for the first file for the second file closing not required.  But did it.  The files and annual processing if read it.  Thats the result.  First file second file and so on.  So does the version with the list.  Its about 120 lines.  Lets see we would pan.  This is going to be shorter.  Its about 80.  So we are saving 40 lines again.  Its not an exact count because there are comments.  So there are blank lines but pretty much they both use the same number of blanks and comments meaning the difference is compatible so the only thing that that they imported here was pandas.  So the print details.  Its very different from the previous one.  The previous one was kind of complex function with lot of initialization.  With lot of loops when you have pandas.  Most of the time you will have way much less loops.  So with pandas you can do operations within the structure without doing the looph.  If you want to do an average and you have list you need to calculate what is in it.  299 do the summation and then divide by the number of elements with pandas.  You just call the average function that is beating in pandas from the foundation in.  Theres odd number.  So calculated the mean in this case what Im passing is not the entire file but Im passing only for each one of the files Im passing the second.  So duration.  The most popular star station the most popular the end station the number of casual users and the number of members so just that Im not passing the old file but Im passing only the results.  And then calculating the mean from the second so could have used just second.  So but wanted nice presentation with how What Submits and seconds.  110 and thats why did what they did.  And in the main program opening the file read it into panda structure initializing list that will contain the value that will be processed by the function.  could have used the one single data frame.  use the separate data frames just for class.  So mmm start with this format so in pandas you have day time transforming one set of values into daytime.  But you need to specify the format.  could have done like did here using.  Bari ebola for the format of the data.  But didnt but thats mean its not going to save much because its basically just times.  And could have say few characters probably same thing for the end.  Duration is the difference.  And then appended the the value into the empty spring list.  Most frequent station.  Thats the beauty of Pandas.  Instead of doing loop you just do count.  And Max and you have it.  Then added the to the list.  Same thing for the end station.  Now on the first file.  want to count the number of members but the members are in column that is called user type and not like the other one.  Members subscribers and the name is not members but is subscribe member but is subscriber.  So 200.  didnt do any transformation of the name but just counted the different thing using it in the same way.  So this is for subscriber.  This is for customer than that pretty much similar thing for the second file with the only difference being instead of looking for the column user type.  Im looking for the column member.  Casual.  Instead of introducing subscribers and counting member instead of counting customer counting cashual so and then the the lists to yeah to the list and then calling the function and process.  That will process the results.  And then and all the file processing running.  And you will have the same exception.  Results like check them.  So Again.  It had the some level of complexity.  Let me stop sharing and checking.  If you have any question.  All right.  just want to get.  Feedback from Villa.  Now what do you think So the solution that you presented in the second half.  Its just now.  It seems much more obvious to me than it did in the past.  Because when you demonstrate how to write the date time its its very its very clear.  The one thing that because was trying to work with pandas the one thing that was unclear to me that missed in my code was the Div.  MoD function that you use Could you explain actually little bit what that does Thank you.  Yeah.  Sure.  Yep.  Okay.  So you mean that Let me start sharing again.  think it was in the the seventh line up top.  In the beginning.  Okay.  Or in the eighteenth line.  Yeah.  Okay yeah mean thats something that that you dont need to do meaning just way to better represent the value.  So if you dont do any of those if you look at here when run it the version where the.  With the with the list.  dont have hours minutes and seconds.  just have minutes.  So what you could do.  You have the number of cycles.  So with Python.  You have that function.  This this mode that is dividing the value in this case the number of seconds by 3006 are calculating and its placing in those variables.  You can do in more basic way.  So you can take the second.  So divide the seconds by 3600 and get the mean you understand By 60 and you have minutes by 60 and you have minutes by 3600 and you had the hours and then you can round it and you have it so thats just more compact way for doing it but its not required.  mean the logic of the program wouldnt change at all.  If you look at the the way can calculated the here.  It was this one.  Its basically is divided by 60 and rounded to the second value.  And thats the number of many.  So you can do the same to calculate the minutes here right and then divide by 3600 to get the Howards.  So again.  Its mine or detail.  The reason why each time Im picking on villain is working with me with us on the scheduling and the engine of the school.  Since few months and because in the scheduling developed python program by python script to mean simplify somehow the whole process.  really want villain to be able to take over on death and use it in the semester to come and then it will be useful for many other things that you may want to do or we may want.  We may like him to do so just which like why Im picking on.  Im sorry if Im doing that but really want to be sure that from your standpoint you dont have questions.  No appreciate it.  Im more than happy to comment anytime you like.  Okay yeah mean most of the time the questions that villain may have are questions that someone else may have.  So strongly encourage you all to ask me.  Thinks if something seems to be not particularly clear all right so let me continue sharing and let me go now into the the slides.  So we will cover few things and we will cover little bit of introduction to Aa machine learning and then we will talk about software development.  Then we will do the inclass assignment.  really want to give you as much time as possible.  Some of you ask me to give more time for practicing and would definitely love to do that all right.  So.  We do have courts on AI machine learning for systems and enterprises that created couple of years ago and ran it each full with the proficiency in Pied on as prereview is quotes that is sort of an advanced version of another course that created that is M.  23.  There is knowledge this callery but that courts is not using coding but its just using tool with graphical user interface.  And its not particularly onto AI but its more on daily science and algorithms that are used in machine learning.  But its not specifically on machine learning.  So what is artificial intelligence There is no artificial intelligence because there is no definition of national intelligence.  We cannot define national intelligence.  We cannot really talk about their artificial version of it.  So we dont understand how human mind is currently working not knowing it.  We the only thing that would that we could do is consider it as sort of black box and place questions and see if they answers are similar to you right now.  There is no generalized artificial intelligence so meaning.  There is no system including chat.  Gpt.  For sure.  They can really be considered anarchifician intelligence.  The heat sorry ourificial intelligence its long one right So because there is no definition.  People consider in the years artificial intelligence.  Any system that somehow had some level.  Of human behavior.  So if you consider the first robots have been developed fully mechanical so other localis was one of the inventors related to not my own.  By the way and people told that was.  Reproduction of human being.  So obviously it was highly overrated going fast forward during World War 2.  Alan Tuding was the one who created systems for counter balance.  The encryption for decreasing basically the encrypted messages from the Nazis creating system that is considered one of the first.  On machine intelligence in broad sense he also created what we still call the to the the tutoring tests that will explain in minute.  So started working in artificial intelligence in 1986.  It was in an arrangement company within.  An information technology group.  And was working on what were called the expert system sort of knowledgebased systems that are what we now call the symbolic part of artificial intelligence.  At that time there was quite lot of expectations.  Big hikes on activation intelligence.  But we failed.  We failed for several reasons lets say main reasons.  One was the lack of computing power.  So mean my expert systems run on either computer called Excel Star.  That was the one Steve Jobs used as aspiration for the Max and the micro operating system and then scale down version was running on Mac so that time had meeting that was the one that you probably saw in pictures.  Square the thing with the teeny tiny monitor with flowoppy disk in it so thats what we had.  We use the languages so that we are either lisp.  That was language or developing expert system.  So then and now defined the company name the digital equipment that pulls.  Then both by compar that was bought by HP.  And then disappeared.  Initial version of it.  They created language that was called the Ops.  5.  That was rulebased language and quite powerful that not sure exactly why but could run on Max.  So developed this expert system that was in wealth management 200 and that was for mean based on symbolic of what we now call symbolic approach.  So one problem was the lack of capacity of mean computing power.  The second was the lack of power in terms of languages.  So with Python you can call library and then you can use an algorithm directly from the library.  100 back in time we had to write the algorithm from scratch each time.  So you can create your own libraries but at the very end its going to physically copy that version into your code and do it again.  So.  It was not easy.  The third element is the lack of data.  So now everything is digitally and we can leverage on the data to create models.  So we couldnt do at that.  So now we have probably dont know 80 or all the information in the world that are in the digital format.  Oh no they did because he has some legacy but hes close to that.  At the time it was probably 8.  So meaning everything that is on machine learning that is hey based on data.  We we couldnt done it because we didnt have the data to work.  So thats and then the expectations we are.  mean we failed to deliver for those reasons.  But we failed.  And then what happened What was called the winter of young.  So nothing happened that pretty much 20 years 15 years And then with the more powerful computers with the more powerful languages with more data than that we have what we have now and then we think that we have what we have now and then we think that with the data we can do that is not exactly true.  So mentioned that the tuling tests the tuling tests is pretty much like that.  You have wall on one side of the wall.  You have human being questioner place in questions on the other side us something that can be another human being.  Or can be machine.  The human is placing questions to whatever is on the other side.  And its placing questions over all possible kinds.  If the answers would be satisfactory and on the other side there is computer.  Then the computer the system passed the touring test.  Obviously.  From being rigorous test because it really depends on who is placing the questions.  So if the questions are very basic then answers can be easy.  So ask the chat.  Gpt if it could pass the tuding test and the answer was very appropriate.  By the way it depends.  Who is asking me questions and thats exactly right.  So right now there is no computer no system that can pass generalized tool test.  So when we talk about the AI we are basically in the all the automation not everything that is automation is artificial intelligence.  But what we do in artificial intelligence is automate somehow processes.  So some of the automation is not particularly intelligent.  So consider tidy up in industrial.  Environment is just working on the boats.  Its not doing anything else.  Is robot is efficient but its not intelligent.  So there could be robots that are not intelligence.  Consider your that is cleaning you know.  Not very intent way.  The floor.  So those are robots with little bit of intelligence but not much.  250 within artificial intelligence.  You can have systems the focus on autonomy.  Or now breathing down our TV show intelligence.  There are types overificial intelligence that is theificial intelligence that is based on symbol symbols can be rules like was mentioning of the expert systems.  It can be taxonomy.  Taxonomies are are structure to represent to semantically represent domain.  Think about the animal kingdom.  So you have mammals and then you can dream down and have all the different animals.  So thats an example of taxonomy.  You can have taxonomies for pretty much everything with semantic complexity so you can have taxonomy for an industry.  for class of companies for one company.  Things like that.  So thats the symbolic approach.  The second approach that is based on representation on knowledge that is kind of saying we were born with rules that are embedded into our brain.  And we follow the rules.  We learn.  But there is sort of sorting board that we follow.  So thats one approach.  The second approach is what in the past that was considered Mp.  Dcism that is based on know nothing.  When was born knew nothing.  When was born.  Then with experience learned and created my own knowledge.  So thats the data driven approach.  And thats the machine learning approach.  So you start from the data and you get your knowledge from the data data.  Science is helping both because in ourificial intelligence you may have models 300 based on data that you want to.  mean the data that you want to clean that you want to aggregate things like that and even more on machine.  So data.  Science provides elements to artificial intelligence in general but in particular in machine learning.  So we mentioned the one of the reasons why we now are receivingly talking about machine learning artificial intelligence and we couldnt do it in Mid eightys because we have more data.  So we have more data meaning we can use it as form of experience.  And when you do machine learning machine learning is basically model with components one the algorithm and one the data one without the other.  Wouldnt work.  So in machine learning that is great in terms of algorithm what But with the poor data it getting poor performances in London in China they have quite lot of cameras analyzing faces.  So face recognition in those countries is working way much better than in Norway.  We are the rules for privacy are more strict so the algorithm are the same.  But the Norwegian systems are appropriating results that not as good as the results in China and the results in London.  So again the same algorithm different data.  If you consider we mentioned Chat Gpt that is based on process we have the key algorithm is called transformats.  The algorithm is based on artificial neural networks.  There is way to multiplies.  Series of Mavericks is one of the other.  When you do the multiplication you basically use weights in at each stage when you pass from mean one stage to the next one.  Those are weights are called parameters to the next one.  Those weights are called parameters doing similarity with the human mind.  Those parameters would be similar to the new.  So right now Chat Gpt is based on version of of transformats that is called Gpt.  while it is already available.  Gpt.  Tree and is going to be available.  Gpt.  For shortly Gpt.  has half billion parameters.  Gpt.  as wide 1. 5 1. 6 billion parameters.  The human brain as close to billion neurons.  So in terms of complexity they can be seen in in terms of efficiency is completely different story.  So the human brain is based on knowledge.  The knowledge is created through text in broad sense meaning what we hear what we read but is also based on visual us because mean we see things and for what we see we create knowledge we have the ability to memorize sound sound we generate additional knowledge and then smell the touch.  So all of those are generating the knowledge.  Then we have the ability to develop mean to present the results as conversation.  So we have language element chart Gpt and only text and only the language model.  So is more limited is working on that getting the text analyzing the text.  The detecting.  Then taking your question and matching your question with the pattern of patterns that are the closest and then adding layer of language modeling to present the results in conversational way.  So chat gpt its basically like Google.  But with the ability to compile the results in sentences and present them as compensation so and hes considering also the elements.  So each time you create conversation is consisting in the pattern of your requests.  The other elements that you provide in previous requests.  In the same session.  mean its an interesting model like keep in mind that to create it open.  AI span 1. 5 million dollar in energy energy at that was the equivalent of running 1200 or number close to that medium size.  Cds in the Us.  Because of its lot of processing.  So we cannot create chat.  Gpt at Stevens.  So thats for sure unless something will change in dramatic.  So the that was mentioning before we definitely underperform compared to those giant modules.  Anyway.  So some of the directions of AI.  Natural language processing.  So mentioned the chat.  Gpt is good example.  robotics is becoming bigger and bigger.  Robotics is not just playing robotics but is also augmented.  The capabilities for humans that can be physical or can be launched in logical would be like Gpt.  Physical like can be.  There are devices that are physical like can be.  There are devices that are that some people in warehouses are wearing.  Uhhhhhhhhhhh Ahhhhhhhhhh Ahhhhhhhhhh Ahhhhhhhhh As an example.  You can think of what the defense industry can do.  Just think about.  dont mind.  So we Gadnara is one of the would say is the leader in market analysis in technologies and.  Among other things is doing what is called the hype cycle.  So the hype cycle its basically representation of technologies in multidimensional view.  So you have when you launch technology that technology is generating lot of hype.  So they hype is growing.  think about Chat gpt in one week.  Reached the million users.  So there is growing expectation.  Then after that either.  Then after that either will will fall into the mean the expectations will be not met in the proper way and we will go down or can become prime time and being used as regular prime.  Time and being used as regular technology like we use cellular phones.  Or so you have innovation.  Take over expectation this illusion.  Mentor.  Eventually an adventure or productivity so you can place in this chart the technologies that are running right now.  There is sort of life cycle and there is time factor.  So when you have technologies that are tagged as more than 10 years that means who knows In technology 10 years its its very long time.  Everything can happen in technology in 10 years.  So you have quantum computing.  You have generalized artificial intelligence autonomous vehicles that are mean seen as may happen may not but its kind of interesting.  One thing that is growing this edge.  AI.  That is an interesting application.  So you think for second that when you have dont know your Alexa box.  The intelligence is not in the box but is in the server so when you have quite lot of chat Gpt you place question but the answer is not in your computer but is in Dave Server.  So when you have molded that are very big very complex you cannot run them on your computer.  And you rely on server with intelligence.  But this is kind of generating delay that is due to the communication.  So because we have now more computing power at our disposal in our hands like the cellular phones like the computer Im using for my zoom corner.  We can have more of our intelligence.  The peripherical level that can be at the very end of the chain meaning on our computer on our phone or in the points of agregation.  But thats something that already happened in the entertainment industry.  Netflix they have content distribution network that is quite interesting.  Meaning not everything.  100 and streaming from God only knows server far far away most of the time they have equivalent of warehouses where content that is more used at that level when you have very large condominium so they may have their own netflix server mean there should be bigger and there are some other conditions.  But thats the reality in artificial intelligence.  You can do something similar so you can have some of the technology.  That is not all in one place but kind of distributed in the old shape.  Obviously you dont need to have system that is oversighing the distribution of intelligence.  But thats one technology that what mentioned.  But thats another view.  Thats emerging technical so strongly encourage you to go through the slides and see what is there the chat on the right is kind of interesting.  Everybody is talking about the AI machine learning.  So thats the number of companies public companies citing mentioning AI machine learning in the earning code.  So from to 10 years ago to thousands right now pretty much.  Everybody is talking about.  will use yeah for something Im already using.  AI.  Another interesting bottom right How AI is perceived.  So right now we are still in the positive less apocalyptic of AI.  AI can help hey is good.  Who knows mean that there are controversial opinions.  So back in time there was you know mask that was against it and then he invested in open AI creating chat Gpt but thats another story.  So applications.  Amazon is using some forms of machine learning machine learning can work side by side with both software engineer and system engineering software engineering.  Its kind of the system engineering for computer science meaning when you have cell phone level or complexity you can not just code.  You need to consider the old thing.  You need to consider the system where your piece of software is running.  Going back to Chat Gpt mentioned that transformers as the core of the but in reality is process.  So the process is pretty much like they collected notion of pretty much everything that was available as open source.  Then you had the humans going through sample of it and doing the cleaning because there could be some inappropriate content that you want to eliminate and then its also doing the the humans in the Loop are also doing tagging of the content in mean sampling and tagging.  Then that samples tagging means you probably did the about image recognition.  So you have million images.  And then you said Okay this is cat.  This is dog.  This is rhino and so on.  So you need to tag things at the very beginning to have the algorithm using the criteria that is extracting from your behavior to classify future elements that you are passing to the system.  So the process has again starting point that is human on subset of the system tagging it for content.  Then they have system that is taking another portion of the data and using the criteria is tagging in automatic way.  The humans go back and assign score to that with the score.  They have another piece of system that is based on recurrent neural network.  That is looking at the results and then its working on larger piece of data and is refining the results of the first round based on the mean to maximize the score assigned by the humans at the very end.  This system has been trained to classify to tag and then to classify and then it will work on the entire data set.  So at that point you have what initially called the patterns meaning those tagging of elements.  but again there is human in the loop.  When you have everything that is tagged then you apply the transformats match the requests with the partners but only after the human.  Did quite lot of it.  And this is designing system.  So its in between software engineering and system engineering.  So you will check this slides with details.  Some of the applications of AI in broad sense so speech recognition that we know that is working up to certain point in banking industry monitoring fruits in military industry we have drones.  We have fully unmanned drones but thats another story.  That we can probably considering is 745.  wish had story in another moment.  So thats basically it.  Let me check if there are questions and if not will move to the next set of slides.  will go relatively fast on them.  You will have those lights anyway and we have eventually courses on quite lot of courses on that topic.  So the topic is software development and software engineering.  So few classes ago we mentioned that software started as an integral part of the hardware.  So when Alan Turing was used to right programs it was actually moving switches in board.  So it was flexible.  But the software was actually hardware.  In sense so later on they became separate discipline with some specific characteristics.  So when you develop software you are developing something that by definition can be changed when you develop breed the bridges there.  So you can do minimal changes.  But not much in software.  When you develop system you can change it.  You can adapt you can make it evolve and thats major difference.  So one of the issues.  This slide is slide that is probably the most commonly used slide in software engineering.  saw it the first time probably 30 years ago and since seeing this night around and kept it for historical reasons it kind of give the sense of how much it can be lost in translation when the information is passed between the different actors in the software developed so you have the client you had the formalitation on the needs in contract.  You have the specs you have.  The developers writing the code you have the debuggers fixing things in certain way.  So each one its adding Can you please mute yourself Hello okay.  So each time at each step you are losing something.  So and thats probably the main reason why so many software projects failed when you develop software you have portion.  That is the actual development portion of the disturbance and portion and it is meant.  Maintenance is sort of lifecycle the sooner you will detect the errors the lower will be the cost to fix it.  So again Life cycle.  Reality is some software never die though we are seen using software growth 50 years ago in cobola.  That is running in the government that is running in banks and mean maintaining it is becoming more and more complex.  Because people retired people died and no one really knows anymore.  didnt do how to fix it.  There are some cases they can eventually share with you.  So there is standard for the software life cycle and developed by the iteration.  The typical approach that was used at the very beginning was the waterfall approach.  That is what we normally use when we do an engineering project building or car or bridge.  So we define the requirements.  We design the system based on the requirements.  We start the coding we do the testing.  We pass the system to the client and we start them.  Maintenance.  So thats basically what is called the waterfall approach.  One.  The advantages are pretty clear.  You can plan in the proper way.  You can allocate resources in the proper way.  You can do the requirements.  Definition in the bad way possible but everything is frozen in time meaning when you start the process you can never stop it meaning if at certain point utilizes something is wrong.  Your loss.  So there is lack of flexibility.  Thats single most important issue issue.  Its so important that only 16 of the developments in 1995 that caused the peak of this approach worth success.  So then some ways to address the issue.  So doing more parametric approach to add flexibility.  Do little bit of prototyping by the very end.  There was no structure the approach of it.  And thats basically when people start thinking about software engineering.  So we need to have an engineering approach to the software development computer.  Science is essential to software engineering as physics is essential for mechanical or electrical engineering.  So thats way to say it.  They are different.  mean.  Trust me.  lot of people still like confusing computer science with software engineering is mean those people are in industry and in academy.  We do have people in our university not really understanding what one is doing compared to the other one.  We are hiring new faculty for software engineering at the school of systems and Enterprises.  One of the questions that they always ask What are the difference for you between computer science and software engineering And generally hear all kinds of answers.  So generally see software.  was member of the software engineer partner member of the Software Engineering Institute for couple of years.  million years ago.  The way see software engineering is like system engineering for computers.  Science.  So you need computer science.  But computer science is coding is optimizing the performance of your code.  Software engineering is thinking about your code as part of mobile complex problem or environment and dealing with all the components but most of them all the time.  When you see an add they are looking for developer and they are asking for software engineer or vice versa.  So there is not much clarity in some people but the difference is pretty clear.  Actually.  So this software engineering institute that gives based is hosted by the company man on university in Pittsburgh created the capability maturity model.  Cmm.  that is defining the phases of the development and then monitor it.  But there are levels from the initial level.  There is dock codak.  There is no real engineering approach.  Up to the level where everything is reasonable and all the processes and data are fully traceable.  There are very few if none companies in Level but the idea is to monitor each development each change and trace it and make it more robust and independent by the other processes.  But in order to do that you really need to those are more details on the different levels you really need to have an approach of continuous monitoring like the brother big system meaning there is an overhead that is really significant that can be justified when you have very large project but would not be justified when you have smaller projects.  So thats why people started thinking about agile middle.  The agile processor.  Its really rooted in prototyping interacting revising intermediate results refining the results till the launch of the project.  Is definitely not as rigorous as Cmm.  But is kind of tradeoff so give you guidelines.  But theyre not measuring every step that you are to.  You are taking so interaction collaboration responding to changes.  So all of those are essential portion of the agile software development.  There are several methods labeled as Gile scram is one of the most popular and is based on the same overall approach that is stated by the manifesto.  So would stop here.  would probably go all the way to the end.  Some practical principles.  User as much open source software as possible is opener is cost effective.  Obviously there is no number.  You can call it.  Something is not working meaning.  You need to rely on the community but on some urban sales the community is huge.  So think about python.  You have problem in python.  You go to stack overflow or other and you will get an answer in.  So on the other side the you want to create your own version or one function.  You just take the function.  Most likely the function is written in on and you can change the code to make the function work exactly as you want if you are the commercial software.  You cannot do that.  The only thing you can do is file request for change to the provider to the end dollars and then the vendor.  Will take your requests will place the request in queue and then eventually will apply in one of the following releases based on what other are asking Don is the most popular language Hmm.  Is open is portable.  So we know that its portable up to certain point.  was mentioning the issues had moving from Intel to Amd.  But its portable anyway.  The libraries the libraries in Python is what is really making the difference.  Using this standard.  Do not reinvent the wheel.  Use standard modules for interfaces.  Again use libraries Probably not pandas not Python.  But there are other languages for that develop the graphical user interface as separate from the back end portion.  There are different.  They follow different life.  Cycles and you want to be sure that people developing one as different skills as people on the other side.  So thats basically it.  just want to open but not run.  Now this presentation.  Yeah you will have it in your canvas.  2.  Is it one of the most famous cases of failure in software development Is related to FBI developing the virtual case file.  So before this project the Api didnt have shared file system case file system meaning if you have case you need to grow to the person who was handling the case and asked the person because there was no way to share information.  You can imagine how bad this could have been.  So they decided to create this common repository of cases and they started investing several million dollar of cases.  And they started investing million dollar then became billion dollar.  And then it failed without the reason is pretty much what was in the slide with the in different positions in different statuses was kind of lost in translation.  So there was no one taking the full responsibility of the system.  There was not enough exchange of information between the different actors.  And lets basically whats generated.  The failure.  So go through the slides.  200 and the failure so go through the slides.  This lights are at the original slides in from 2005 from triple spectrum and mean that its kind of interesting to see whats going on.  There are couple of other links that they will post in moment on canvas.  One is some details on the capability maturity model.  If youre interested in the other will be on some cases of and it can be interesting to watch it just few minutes.  Okay so its about 80clock.  So its really want you to work for 1520 min at least.  On an inclass exit size.  That will be something like this.  So you have you want to build system to analyze passwords and to either take the password as valid one or reject it.  So those are the conditions for checking the password.  At least one letter between all those small letters one number one of those one letter as capital letters one.  Those special characters.  Minimum length 6.  Maximum 12.  And you want to create function doing it.  So you want to create function that will take list of passwords analyze them and retire.  Or printer.  The password that passed the the criteria that was stated from one to 6.  So the input will be something like that and the output will be the following password has been accepted that the only one of those satisfying all the great idea is the first one and thats what you will.  Okay.  So will stop sharing.  At this point.  will create breakout rooms and then will post everything.  So we have breakout rooms each participants.  will create the rooms Im opening all the rooms.  So you have about 1520 min to work on it.  would be here anyway.  In in the meantime will post the recording and make sure that the material will be available to you.  So see you in 1520 min.  Im opening the rooms.  Please join them.  All right.  So all the rooms are closed.  Im assuming the recording questions.  Issues volunteers.  All right so let me share the screen and let me go.  Here to present.  Then class assignment so again obviously is more structured is more commented that you could have done in 15 min.  So.  But thats the very having time it should be done.  So you have the definition little bit of the requirements.  Im using function that is called stringa that will show you in moment how this can work.  The function validating the password is taking one password at the time.  So checking if is outside of the range in terms of length.  If this is the case we and then Im using within the function list with the remaining conditions.  So let me go back here.  So if you dont consider the length there are conditions.  So those conditions.  In the meantime let me copy this because wouldnt use it in moment.  So this list that will contain the check of those conditions.  Are initialized an Eas Eastern the the values are initialized to N.  Then if the element So what Im doing is transforming the single word into list.  When you transform string into list the elements of the list will be the word the characters in the world.  So Im checking.  If this character is in the list of small letter so that define the in the main program 100.  If this condition is past is changing the first check.  Here from N.  To y.  Then the second check is on.  If so this was the first.  Now the second is the numbers checking.  If if if the element is there then will change the sake on the to third condition the capital letters.  If the element is there we will change into why again.  And if the element is in the special character we change to again and then it will.  If An is in the okay list meaning there is one condition that is not right.  We will exit the loop and we return and otherwise we dont know why so well continue till either will check all the characters and or will get an and would go out first.  So now the list can be created as plain list like this one.  Thats legitimate way of doing it or using the function that it was mentioning this string you can get.  The list of small letters list screen Ascii lowercase same thing for the capital uppercase and the number.  So either way you will have in those variables the list of lower cases upper cases and strings and special character is just doesnt want to call the the function.  So then Im printing.  Enter the list of passwords and then we will loop into the at least of passwords and that will mean thats way to do the loop.  You can write the loop in more explicit way but it will be the same and then.  The following mean when you have you do the loop in list of password.  So mean over here.  Im splitting.  Im sorry Im splitting the list in an individual password keeping in mind that the password.  Sorry about that are separated by comma.  So over here Im creating the list of passwords.  Then Im looping into the into the passwords passing it to the function and then if there the return is why will print the password.  That is why will print the password.  That is okay.  Otherwise will.  Oh if if run it Passing from the value.  And then and thats what have.  Okay.  So before we go to the assignment want to spend another few minutes in introducing tools that you may need for the as the assignment.  So one its pretty straightforward is that Calculating the correlation correlation is one of the single most important part of the preprocessing of file so quoted means.  You analyze the variables in your data set and you see if they are correlated meaning either one is growing the other is growing.  And thats the positive correlation one is growing the other is decreasing.  Over.  So thats some.  And this is the negative correlation.  If you want to do this analysis because you will get insights from that.  So if you see that the dont know the more experience you have the more you are paid.  Thats an insight that you have on the data.  Or there are other cases.  But again that is probably the single most important part of the preprocessing that you do on the data.  So Im using pandas for printing seaborna to print it in more nicer way.  This script was not working on the python version.  That was designed for Intel so had to change the python interpreter to make it run the one that you have on on camp that you will have on campus is the latest version its pretty much the same as the one before the only thing that changed in my case is the interpretter so importing those functions Renamed the file into pandas data structure.  Calculating the correlation matrix and representing it as beach.  Ual and then saving into file.  If run it.  The file is relatively big.  Thats what you have.  So you have.  dont know.  The more blue is more positive correlation the more greyish is more negative correlation.  So you have more salary when you are older.  As Nfl player and when you have more experience so more experience and pro bowler are the with the highest level of correlation.  In this case.  So and thats one.  The second one.  That they want to show to you is this explorer explorer its very powerful script not because of the script itself but because all these data profiling library that is doing quite lot of things.  So if ran it.  It will go into the file generating bunch of subdrivals.  So while it is generating let me go.  Let me go Here Now its finished.  So that is being generated.  Now Im opening it so is an HTML.  Reporter with the everything you want to know about the file.  So you have an overview.  You have number of variables.  Observation missing call missing cells and things like that.  32.  You have menu.  You can jump directly to correlation.  For example and you have the correlation.  You can jump on missing values.  And eventually you can have dates or different representation.  And on the variables you have the distribution that in some cases can be useful like in this one.  You have an analysis of this on the distribution this Q.  And can give you insights.  So in this case the age its around 24 and there are very few that are more than 30 and thats makes sense.  So anyway thats basically the scripts that will share in in canvas in moment.  Let me go now back to the assignment.  So the assignment is on that.  Think have it in better version.  Yeah okay so there are paths one general questions.  This will be pretty much similar in terms of structure to what you will get in the mid term.  So what is jailed software What is waterfall approach Why is not successful The fine machine learning.  And then you had the code.  So the coding is based on this.  Data set here that is on Covid.  The data set has been downloaded from the Cdc website is not the latest.  Eventually you can download the latest and do the same work on newer version if you like and so if you go here you see that there are age groups.  There are age groups and you have conditions and you have thats so you basically have for all the age groups.  What are the number of deaths for each condition So basically what you want to do is to create graph.  graphs.  One is Bach chart and one is pie chart.  mean those are not the real example.  Its from completely different excessive but you want to have something similar you want to have butch.  You want to have pie chart eventually in one single representation we saw an example last week when introduced.  So you want to create list of counters so the very end what you want to do using function getting the different parts you want to.  Calculate the mean Comorbidd means.  All of those are cases of covid.  19.  But most of the people Guy just because of Covid but because we are mobility is leading to fatal outcome.  So we want to analyze the commodity in the CoOP condition.  So mean causing the deaths so and in particular we want to analyze the commodities in the population of less than 35 years of age.  So meaning 24 and 2534.  So mean use the in the example.  At least you could do with Python with Panandas is up to you but the very end that you want to have representation that to the presentations that is one pie chart and one.  Giving insights on on the cover for that population.  As usual you will generate couple of page with an interpretation interpretation.  Again please pay.  Attention is not describing the process but this describing the findings.  So if you describe the process we will take points off because this is not what we are asking.  We are asking an interpretation of the analysis so you will submit your program.  And then Nara Div.  As dog.  Pdf and the part one meaning the answers to those questions can be either in separate dog Pdf file or added as comments to your pytor file.  So thats basically it sorry for the longer its 44.  will publish everything that we use today and if you have any question let me know.  Theres question.  Yes interpretation.  Okay So lets say that you will have in this case in particular you will have several comorbidities that can be more relevant.  And driving to the course of that.  Does that happen The interpretation would be in the population that we are analyzing most frequent comorbidity is that one.  Because you can do correlation.  You can analyze what the correlation can be between the different groups.  Eventually or you can just stay in that group and describe the finding.  So when you have okay mean that posted the videos on data storytelling check those thats exactly what you want to do.  You want to extract story out of the data.  So the data just the way they are.  They are not saying much.  So if you describe process and then give your report to someone who doesnt really know what you are doing it not getting much insights.  So think about that.  That someone doctor medical doctor asked that you as the other scientist can you analyze the file and let me know what what is the most common Com or Bdd or what what are the most common commodities that for this group Of individuals.  So you want to create something that will be useful for the end user not as an explanation over the process.  We did something similar to an explanation of the process for testing but actually that was not even an explanation of the process but was just describing how to test all the options.  All the branches in your code.  So in this case what we are asking is not that is not the testing is not the explanation of the process but its really your findings.  So think about that.  You are writing an article for the New York Times.  Thats the target.  So you want to write something that people are knowing nothing about.  Python about data science about visualization that can get can read think about visualization that can get can read think about.  dont know someone who is not an engineer.  He is not mathematician he is not mathematician hes nothing to do.  He is not software developer but just reader.  250 general paper so thats the goal.  will keep sharing some examples.  But again dont do just description of the process.  But do something that can be published on the new.  Your times mean not necessarily.  We ended up the way but that kind of the the one that you are going to write.  All right.  Okay so thats the end of the class.  Agile Tools for RealWorld Data OREILLY Wes McKinney DataPython Python for Data Analysis The scientific and data Looking for complete instructions on manipulating processing analysis communities cleaning and crunching structured data in Python This handson have been waitin 1g for book is packed with practical case studies that show you how to effectively solve broad set of data analysis problems using several this book he Or years Python librariesincluding NumPy pandas matplotlib and Python.  oaded with concrete Written by Wes McKinney the main author of the pandas library Python for Data Analysis also serves as practical modern practical advice yet introduction to scientific computing in Python for dataintensive applications.  Its ideal for analysts new to Python and for Python ft ull of insight about programmers new to scientific computing.  how all the bieces it Use the IPython interactive shell as your primary together.  It should development environment become canonical Learn basic and advanced NumPy Numerical Python features Get started with data analysis tools in the pandas library reference for technica Use highperformance tools to load clean transform computing in Python merge and reshape data Create scatter plots and static or interactive visualizations jor years fo come.  with matplotlib Fernando Prez Apply the pandas groupby facility to slice dice and research scientist at UC Berkeley summarize datasets one of the originators of Python Work with time series data in many different forms Learn how to solve problems in web analytics social sciences finance and economics through detailed examples Wes McKinney is the main author of pandas the popular open source Python library for data analysis.  Wes is an active speaker and participant in the Python and open source communities.  He worked as quantitative analyst at AQR Capital Management and Python consultant before founding DataPad data analytics company in 2013.  He graduated from MIT with an S. B.  in Mathematics.  Twitter oreillymedia facebook. comoreilly OREILLY oreilly. com US 39. 99 CAN 41. 99 ISBN 9781449319793 LL iii MUI 8144931979 Python for Data Analysis Wes McKinney OREILLY Beijing Cambridge Farnham K6ln Sebastopol Tokyo Python for Data Analysis by Wes McKinney Copyright 2013 Wes McKinney.  All rights reserved.  Printed in the United States of America.  Published by OReilly Media Inc.  1005 Gravenstein Highway North Sebastopol CA 95472.  OReilly books may be purchased for educational business or sales promotional use.  Online editions are also available for most titles httpmy. safaribooksonline. com.  For more information contact our corporateinstitutional sales department 8009989938 or corporateoreilly. com.  Editors Julie Steele and Meghan Blanchette Indexer BIM Publishing Services Production Editor Melanie Yarbrough Cover Designer Karen Montgomery Copyeditor Teresa Exley Interior Designer David Futato Proofreader BIM Publishing Services Illustrator Rebecca Demarest October 2012 First Edition.  Revision History for the First Edition 20121005 First release 20130517 Second release See httporeilly. comcatalogerrata. csp isbn978 1449319793 for release details.  Nutshell Handbook the Nutshell Handbook logo and the OReilly logo are registered trademarks of OReilly Media Inc.  Python for Data Analysis the cover image of goldentailed tree shrew and related trade dress are trademarks of OReilly Media Inc.  Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.  Where those designations appear in this book and OReilly Media Inc.  was aware of trademark claim the designations have been printed in caps or initial caps.  While every precaution has been taken in the preparation of this book the publisher and author assume no responsibility for errors or omissions or for damages resulting from the use of the information con tained herein.  ISBN 9781449319793 LS 1368653545 Preface 1.  Table of Contents Preliminaries . . . . . . . . . .  ccc ccc cece ccc ccc ceccecceccescecceees What Is This Book About Why Python for Data Analysis Python as Glue Solving the TwoLanguage Problem Why Not Python Essential Python Libraries NumPy pandas matplotlib IPython SciPy Installation and Setup Windows Apple OS GNULinux Python and Python Integrated Development Environments IDEs Community and Conferences Navigating This Book Code Examples Data for Examples Import Conventions Jargon Acknowledgements Introductory Examples . . . . . . . . . . . . . . ceeeceeeceeeceeeeeeeeeee 1. usa. gov data from bit. ly Counting Time Zones in Pure Python NDDUNBBWWNNN HE Counting Time Zones with pandas MovieLens 1M Data Set Measuring rating disagreement US Baby Names 18802010 Analyzing Naming Trends Conclusions and The Path Ahead IPython An Interactive Computing and Development Environment IPython Basics Tab Completion Introspection The run Command Executing Code from the Clipboard Keyboard Shortcuts Exceptions and Tracebacks Magic Commands Qtbased Rich GUI Console Matplotlib Integration and Pylab Mode Using the Command History Searching and Reusing the Command History Input and Output Variables Logging the Input and Output Interacting with the Operating System Shell Commands and Aliases Directory Bookmark System Software Development Tools Interactive Debugger Timing Code time and timeit Basic Profiling prun and run Profiling Function LinebyLine IPython HTML Notebook Tips for Productive Code Development Using IPython Reloading Module Dependencies Code Design Tips Advanced Python Features Making Your Own Classes IPythonfriendly Profiles and Configuration Credits NumPy Basics Arrays and Vectorized Computation . . . . . . . . . . . . . . . . .  The NumPy ndarray Multidimensional Array Object Creating ndarrays Data Types for ndarrays iv Table of Contents Operations between Arrays and Scalars Basic Indexing and Slicing Boolean Indexing Fancy Indexing Transposing Arrays and Swapping Axes Universal Functions Fast Elementwise Array Functions Data Processing Using Arrays Expressing Conditional Logic as Array Operations Mathematical and Statistical Methods Methods for Boolean Arrays Sorting Unique and Other Set Logic File Input and Output with Arrays Storing Arrays on Disk in Binary Format Saving and Loading Text Files Linear Algebra Random Number Generation Example Random Walks Simulating Many Random Walks at Once Getting Started with pandas . . . . . . . . . . . . . . . . e sees eee eeeeee Introduction to pandas Data Structures Series DataFrame Index Objects Essential Functionality Reindexing Dropping entries from an axis Indexing selection and filtering Arithmetic and data alignment Function application and mapping Sorting and ranking Axis indexes with duplicate values Summarizing and Computing Descriptive Statistics Correlation and Covariance Unique Values Value Counts and Membership Handling Missing Data Filtering Out Missing Data Filling in Missing Data Hierarchical Indexing Reordering and Sorting Levels Summary Statistics by Level Using DataFrames Columns 102 103 103 104 105 106 108 109 en tr 111 112 112 115 120 122 122 125 125 128 132 133 136 137 139 141 142 143 145 147 149 150 150 Table of Contents Other pandas Topics 151 Integer Indexing 151 Panel Data 152 6.  Data Loading Storage and File Formats . . . . . . . . . . . . . . . ecceeceeceeceeeeees 155 Reading and Writing Data in Text Format 155 Reading Text Files in Pieces 160 Writing Data Out to Text Format 162 Manually Working with Delimited Formats 163 JSON Data 165 XML and HTML Web Scraping 166 Binary Data Formats 171 Using HDF5 Format 171 Reading Microsoft Excel Files 172 Interacting with HTML and Web APIs 173 Interacting with Databases 174 Storing and Loading Data in MongoDB 176 7.  Data Wrangling Clean Transform Merge Reshape . . . . . . . . . . . . . . seseeeeeee 177 Combining and Merging Data Sets 177 Databasestyle DataFrame Merges 178 Merging on Index 182 Concatenating Along an Axis 185 Combining Data with Overlap 188 Reshaping and Pivoting 189 Reshaping with Hierarchical Indexing 190 Pivoting long to wide Format 192 Data Transformation 194 Removing Duplicates 194 Transforming Data Using Function or Mapping 195 Replacing Values 196 Renaming Axis Indexes 197 Discretization and Binning 199 Detecting and Filtering Outliers 201 Permutation and Random Sampling 202 Computing IndicatorDummy Variables 203 String Manipulation 205 String Object Methods 206 Regular expressions 207 Vectorized string functions in pandas 210 Example USDA Food Database 212 vi Table of Contents 8.  Plotting and Visualization . . . . . . . . . . . . . .  cece cece eee cece ceeeeneens 219 Brief matplotlib API Primer 219 Figures and Subplots 220 Colors Markers and Line Styles 224 Ticks Labels and Legends 225 Annotations and Drawing on Subplot 228 Saving Plots to File 231 matplotlib Configuration 231 Plotting Functions in pandas 232 Line Plots 232 Bar Plots 235 Histograms and Density Plots 238 Scatter Plots 239 Plotting Maps Visualizing Haiti Earthquake Crisis Data 241 Python Visualization Tool Ecosystem 247 Chaco 248 mayavi 249 Other Packages 249 The Future of Visualization Tools 249 9.  Data Aggregation and Group Operations . . . . . . . . . . . . . . . . . cceeeceeeeeee eens 251 GroupBy Mechanics 252 Iterating Over Groups 255 Selecting Column or Subset of Columns 256 Grouping with Dicts and Series 257 Grouping with Functions 258 Grouping by Index Levels 259 Data Aggregation 259 Columnwise and Multiple Function Application 262 Returning Aggregated Data in unindexed Form 264 Groupwise Operations and Transformations 264 Apply General splitapplycombine 266 Quantile and Bucket Analysis 268 Example Filling Missing Values with Groupspecific Values 270 Example Random Sampling and Permutation 271 Example Group Weighted Average and Correlation 273 Example Groupwise Linear Regression 274 Pivot Tables and CrossTabulation 275 CrossTabulations Crosstab 277 Example 2012 Federal Election Commission Database 278 Donation Statistics by Occupation and Employer 280 Bucketing Donation Amounts 283 Donation Statistics by State 285 Table of Contents vii 10.  Time Series 0. . .  ccc cece eee cence eee eee eee eeeeee seen seen eeeeees Date and Time Data Types and Tools Converting between string and datetime Time Series Basics Indexing Selection Subsetting Time Series with Duplicate Indices Date Ranges Frequencies and Shifting Generating Date Ranges Frequencies and Date Offsets Shifting Leading and Lagging Data Time Zone Handling Localization and Conversion Operations with Time Zoneaware Timestamp Objects Operations between Different Time Zones Periods and Period Arithmetic Period Frequency Conversion Quarterly Period Frequencies Converting Timestamps to Periods and Back Creating PeriodIndex from Arrays Resampling and Frequency Conversion Downsampling Upsampling and Interpolation Resampling with Periods Time Series Plotting Moving Window Functions Exponentiallyweighted functions Binary Moving Window Functions UserDefined Moving Window Functions Performance and Memory Usage Notes 11.  Financial and Economic Data Applications . . . . . . . . . . . . . . . . .  cess eeeeeeeee eee Data Munging Topics Time Series and CrossSection Alignment Operations with Time Series of Different Frequencies Time of Day and as of Data Selection Splicing Together Data Sources Return Indexes and Cumulative Returns Group Transforms and Analysis Group Factor Exposures Decile and Quartile Analysis More Example Applications Signal Frontier Analysis Future Contract Rolling 290 29.  293 294 296 297 298 299 301 303 304 305 306 307 308 309 311 312 312 314 316 318 319 320 324 324 326 327 329 329 330 332 334 336 338 340 342 343 345 345 347 viii Table of Contents Rolling Correlation and Linear Regression 350 12 Advanced NOMPY cscs . s isis sac ce sms swe mana swe sme na ome ow soa tm sma ams ae sea 353 ndarray Object Internals 353 NumPy dtype Hierarchy 354 Advanced Array Manipulation 355 Reshaping Arrays 355 versus Fortran Order 356 Concatenating and Splitting Arrays 357 Repeating Elements Tile and Repeat 360 Fancy Indexing Equivalents Take and Put 361 Broadcasting 362 Broadcasting Over Other Axes 364 Setting Array Values by Broadcasting 367 Advanced ufunc Usage 367 ufunc Instance Methods 368 Custom ufuncs 370 Structured and Record Arrays 370 Nested dtypes and Multidimensional Fields 371 Why Use Structured Arrays 372 Structured Array Manipulations numpy. lib. recfunctions 372 More About Sorting 373 Indirect Sorts argsort and lexsort 374 Alternate Sort Algorithms 375 numpy. searchsorted Finding elements in Sorted Array 376 NumPy Matrix Class 377 Advanced Array Input and Output 379 Memorymapped Files 379 HDF5 and Other Array Storage Options 380 Performance Tips 380 The Importance of Contiguous Memory 381 Other Speed Options Cython f2py 382 Appendix Python Language Essentials . . . . . . . . . . . . . . . . ceecceeceeeceeeceeeeeeees 385 433 Table of Contents ix Preface The scientific Python ecosystem of open source libraries has grown substantially over the last 10 years.  By late 2011 had long felt that the lack of centralized learning resources for data analysis and statistical applications was stumbling block for new Python programmers engaged in such work.  Key projects for data analysis especially NumPy Python matplotlib and pandas had also matured enough that book written about them would likely not go outofdate very quickly.  Thus mustered the nerve to embark on this writing project.  This is the book that wish existed when started using Python for data analysis in 2007.  hope you find it useful and are able to apply these tools productively in your work.  Conventions Used in This Book The following typographical conventions are used in this book Italic Indicates new terms URLs email addresses filenames and file extensions.  Constant width Used for program listings as well as within paragraphs to refer to program elements such as variable or function names databases data types environment variables statements and keywords.  Constant width bold Shows commands or other text that should be typed literally by the user.  Constant width italic Shows text that should be replaced with usersupplied values or by values deter mined by context.  This icon signifies tip suggestion or general note.  xi This icon indicates warning or caution.  Using Code Examples This book is here to help you get your job done.  In general you may use the code in this book in your programs and documentation.  You do not need to contact us for permission unless youre reproducing significant portion of the code.  For example writing program that uses several chunks of code from this book does not require permission.  Selling or distributing CDROM of examples from OReilly books does require permission.  Answering question by citing this book and quoting example code does not require permission.  Incorporating significant amount of example code from this book into your products documentation does require permission.  We appreciate but do not require attribution.  An attribution usually includes the title author publisher and ISBN.  For example Python for Data Analysis by William Wes ley McKinney OReilly.  Copyright 2012 William McKinney 9781449319793.  If you feel your use of code examples falls outside fair use or the permission given above feel free to contact us at permissionsoreilly. com.  Safari Books Online Ss Safari Books Online www. safaribooksonline. com is an ondemand digital altar library that delivers expert content in both book and video form from the worlds leading authors in technology and business.  Technology professionals software developers web designers and business and cre ative professionals use Safari Books Online as their primary resource for research problem solving learning and certification training.  Safari Books Online offers range of product mixes and pricing programs for organi zations government agencies and individuals.  Subscribers have access to thousands of books training videos and prepublication manuscripts in one fully searchable da tabase from publishers like OReilly Media Prentice Hall Professional AddisonWesley Professional Microsoft Press Sams Que Peachpit Press Focal Press Cisco Press John Wiley Sons Syngress Morgan Kaufmann IBM Redbooks Packt Adobe Press FT Press Apress Manning New Riders McGrawHill Jones Bartlett Course Tech nology and dozens more.  For more information about Safari Books Online please visit us online.  xii Preface How to Contact Us Please address comments and questions concerning this book to the publisher OReilly Media Inc.  1005 Gravenstein Highway North Sebastopol CA 95472 8009989938 in the United States or Canada 7078290515 international or local 7078290104 fax We have web page for this book where we list errata examples and any additional information.  You can access this page at httporeil. lypythonfordataanalysis.  To comment or ask technical questions about this book send email to bookquestionsoreilly. com.  For more information about our books courses conferences and news see our website at httpwww. oreilly. com.  Find us on Facebook httpfacebook. comoreilly Follow us on Twitter httptwitter. comoreillymedia Watch us on YouTube httpwww. youtube. comoreillymedia Preface xiii CHAPTER Preliminaries What Is This Book About This book is concerned with the nuts and bolts of manipulating processing cleaning and crunching data in Python.  It is also practical modern introduction to scientific computing in Python tailored for dataintensive applications.  This is book about the parts of the Python language and libraries youll need to effectively solve broad set of data analysis problems.  This book is not an exposition on analytical methods using Python as the implementation language.  When say data what am referring to exactly The primary focus is on structured data deliberately vague term that encompasses many different common forms of data such as Multidimensional arrays matrices Tabular or spreadsheetlike data in which each column may be different type string numeric date or otherwise.  This includes most kinds of data commonly stored in relational databases or tab or commadelimited text files Multiple tables of data interrelated by key columns what would be primary or foreign keys for SQL user Evenly or unevenly spaced time series This is by no means complete list.  Even though it may not always be obvious large percentage of data sets can be transformed into structured form that is more suitable for analysis and modeling.  If not it may be possible to extract features from data set into structured form.  As an example collection of news articles could be processed into word frequency table which could then be used to perform sentiment analysis.  Most users of spreadsheet programs like Microsoft Excel perhaps the most widely used data analysis tool in the world will not be strangers to these kinds of data.  Why Python for Data Analysis For many people myself among them the Python language is easy to fall in love with.  Since its first appearance in 1991 Python has become one of the most popular dynamic programming languages along with Perl Ruby and others.  Python and Ruby have become especially popular in recent years for building websites using their numerous web frameworks like Rails Ruby and Django Python.  Such languages are often called scripting languages as they can be used to write quickanddirty small programs or scripts.  dont like the term scripting language as it carries connotation that they cannot be used for building missioncritical software.  Among interpreted languages Python is distinguished by its large and active scientific computing community.  Adop tion of Python for scientific computing in both industry applications and academic research has increased significantly since the early 2000s.  For data analysis and interactive exploratory computing and data visualization Python will inevitably draw comparisons with the many other domainspecific open source and commercial programming languages and tools in wide use such as MATLAB SAS Stata and others.  In recent years Pythons improved library support primarily pandas has made it strong alternative for data manipulation tasks.  Combined with Pythons strength in general purpose programming it is an excellent choice as single language for building datacentric applications.  Python as Glue Part of Pythons success as scientific computing platform is the ease of integrating and FORTRAN code.  Most modern computing environments share similar set of legacy FORTRAN and libraries for doing linear algebra optimization integration fast fourier transforms and other such algorithms.  The same story has held true for many companies and national labs that have used Python to glue together 30 years worth of legacy software.  Most programs consist of small portions of code where most of the time is spent with large amounts of glue code that doesnt run often.  In many cases the execution time of the glue code is insignificant effort is most fruitfully invested in optimizing the computational bottlenecks sometimes by moving the code to lowerlevel language like C.  In the last few years the Cython project httpcython. org has become one of the preferred ways of both creating fast compiled extensions for Python and also interfacing with and code.  Solving the TwoLanguage Problem In many organizations it is common to research prototype and test new ideas using more domainspecific computing language like MATLAB or then later port those Chapter Preliminaries ideas to be part of larger production system written in say Java or C.  What people are increasingly finding is that Python is suitable language not only for doing research and prototyping but also building the production systems too.  believe that more and more companies will go down this path as there are often significant organ izational benefits to having both scientists and technologists using the same set of pro grammatic tools.  Why Not Python While Python is an excellent environment for building computationallyintensive sci entific applications and building most kinds of general purpose systems there are number of uses for which Python may be less suitable.  As Python is an interpreted programming language in general most Python code will run substantially slower than code written in compiled language like Java or C.  As programmer time is typically more valuable than CPU time many are happy to make this tradeoff.  However in an application with very low latency requirements for ex ample high frequency trading system the time spent programming in lowerlevel lowerproductivity language like to achieve the maximum possible performance might be time well spent.  Python is not an ideal language for highly concurrent multithreaded applications par ticularly applications with many CPUbound threads.  The reason for this is that it has what is known as the global interpreter lock GIL mechanism which prevents the interpreter from executing more than one Python bytecode instruction at time.  The technical reasons for why the GIL exists are beyond the scope of this book but as of this writing it does not seem likely that the GIL will disappear anytime soon.  While it is true that in many big data processing applications cluster of computers may be required to process data set in reasonable amount of time there are still situations where singleprocess multithreaded system is desirable.  This is not to say that Python cannot execute truly multithreaded parallel code that code just cannot be executed in single Python process.  As an example the Cython project features easy integration with OpenMP framework for parallel computing in order to to parallelize loops and thus significantly speed up numerical algorithms.  Essential Python Libraries For those who are less familiar with the scientific Python ecosystem and the libraries used throughout the book present the following overview of each library.  Essential Python Libraries NumPy NumPy short for Numerical Python is the foundational package for scientific com puting in Python.  The majority of this book will be based on NumPy and libraries built on top of NumPy.  It provides among other things fast and efficient multidimensional array object ndarray Functions for performing elementwise computations with arrays or mathematical operations between arrays Tools for reading and writing arraybased data sets to disk Linear algebra operations Fourier transform and random number generation Tools for integrating and Fortran code to Python Beyond the fast arrayprocessing capabilities that NumPy adds to Python one of its primary purposes with regards to data analysis is as the primary container for data to be passed between algorithms.  For numerical data NumPy arrays are much more efficient way of storing and manipulating data than the other builtin Python data structures.  Also libraries written in lowerlevel language such as or Fortran can operate on the data stored in NumPy array without copying any data.  pandas pandas provides rich data structures and functions designed to make working with structured data fast easy and expressive.  It is as you will see one of the critical in gredients enabling Python to be powerful and productive data analysis environment.  The primary object in pandas that will be used in this book is the DataFrame two dimensional tabular columnoriented data structure with both row and column labels frame totalbill tip sex smoker day time size 16. 99 1. 01 Female No Sun Dinner 10. 34 1. 66 Male No Sun Dinner 21. 01 3. 5 Male No Sun Dinner 23. 68 3. 31 Male No Sun Dinner 24. 59 3. 61 Female No Sun Dinner 25. 29 4. 71 Male No Sun Dinner 8. 77 Male No Sun Dinner 26. 88 3. 12 Male No Sun Dinner 15. 04 1. 96 Male No Sun Dinner 10 14. 78 3. 23 Male No Sun Dinner pandas combines the high performance arraycomputing features of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases such as SQL.  It provides sophisticated indexing functionality to make it easy to reshape slice and dice perform aggregations and select subsets of data.  pandas is the primary tool that we will use in this book.  Chapter Preliminaries For financial users pandas features rich highperformance time series functionality and tools wellsuited for working with financial data.  In fact initially designed pandas as an ideal tool for financial data analysis applications.  For users of the language for statistical computing the DataFrame name will be familiar as the object was named after the similar data.  frame object.  They are not the same however the functionality provided by data.  frame in is essentially strict subset of that provided by the pandas DataFrame.  While this is book about Python will occasionally draw comparisons with as it is one of the most widelyused open source data analysis environments and will be familiar to many readers.  The pandas name itself is derived from panel data an econometrics term for multidi mensional structured data sets and Python data analysis itself.  matplotlib matplotlib is the most popular Python library for producing plots and other 2D data visualizations.  It was originally created by John D.  Hunter JDH and is now maintained by large team of developers.  It is wellsuited for creating plots suitable for publication.  It integrates well with Python see below thus providing comfortable interactive environment for plotting and exploring data.  The plots are also interactive you can zoom in on section of the plot and pan around the plot using the toolbar in the plot window.  IPython IPython is the component in the standard scientific Python toolset that ties everything together.  It provides robust and productive environment for interactive and explor atory computing.  It is an enhanced Python shell designed to accelerate the writing testing and debugging of Python code.  It is particularly useful for interactively working with data and visualizing data with matplotlib.  Python is usually involved with the majority of my Python work including running debugging and testing code.  Aside from the standard terminalbased IPython shell the project also provides Mathematicalike HTML notebook for connecting to Python through web browser more on this later.  Qt frameworkbased GUI console with inline plotting multiline editing and syntax highlighting An infrastructure for interactive parallel and distributed computing will devote chapter to Python and how to get the most out of its features.  strongly recommend using it while working through this book.  Essential Python Libraries SciPy SciPy is collection of packages addressing number of different standard problem domains in scientific computing.  Here is sampling of the packages included scipy. integrate numerical integration routines and differential equation solvers scipy. linalg linear algebra routines and matrix decompositions extending be yond those provided in numpy.  linalg.  scipy. optimize function optimizers minimizers and root finding algorithms scipy. signal signal processing tools scipy. sparse sparse matrices and sparse linear system solvers scipy. special wrapper around SPECFUN Fortran library implementing many common mathematical functions such as the gamma function scipy. stats standard continuous and discrete probability distributions density functions samplers continuous distribution functions various statistical tests and more descriptive statistics scipy. weave tool for using inline code to accelerate array computations Together NumPy and SciPy form reasonably complete computational replacement for much of MATLAB along with some of its addon toolboxes.  Installation and Setup Since everyone uses Python for different applications there is no single solution for setting up Python and required addon packages.  Many readers will not have complete scientific Python environment suitable for following along with this book so here will give detailed instructions to get set up on each operating system.  recommend using one of the following base Python distributions Enthought Python Distribution scientificoriented Python distribution from En thought httpwww. enthought. com.  This includes EPDFree free base scientific distribution with NumPy SciPy matplotlib Chaco and Python and EPD Full comprehensive suite of more than 100 scientific packages across many domains.  EPD Full is free for academic use but has an annual subscription for nonacademic users.  Pythonxy httppythonxy. googlecode. com free scientificoriented Python distribution for Windows.  will be using EPDFree for the installation guides though you are welcome to take another approach depending on your needs.  At the time of this writing EPD includes Python 2. 7 though this might change at some point in the future.  After installing you will have the following packages installed and importable Chapter1 Preliminaries Scientific Python base NumPy SciPy matplotlib and IPython.  These are all in cluded in EPDFree.  Python Notebook dependencies tornado and pyzmq.  These are included in EPD Free.  pandas version 0. 8. 2 or higher.  At some point while reading you may wish to install one or more of the following packages statsmodels PyTables PyQt or equivalently PySide xlrd Ixml basemap pymongo and requests.  These are used in various examples.  Installing these optional libraries is not necessary and would would suggest waiting until you need them.  For example installing PyQt or PyTables from source on OS or Linux can be rather arduous.  For now its most important to get up and running with the bare minimum EPDFree and pandas.  For information on each Python package and links to binary installers or other help see the Python Package Index PyPI httppypi. python. org.  This is also an excellent resource for finding new Python packages.  To avoid confusion and to keep things simple am avoiding discussion of more complex environment management tools like pip and virtua via lenv.  There are many excellent guides available for these tools on the Internet.  Some users may be interested in alternate Python implementations such as IronPython Jython or PyPy.  To make use of the tools presented in this book it is currently necessary to use the standard Cbased Python interpreter known as CPython.  ed Windows To get started on Windows download the EPDFree installer from httpwww. en thought. com which should be an MSI installer named like epdfree7. 31win x86. msi.  Run the installer and accept the default installation location CPython27.  If you had previously installed Python in this location you may want to delete it manually first or using AddRemove Programs.  Next you need to verify that Python has been successfully added to the system path and that there are no conflicts with any priorinstalled Python versions.  First open command prompt by going to the Start Menu and starting the Command Prompt ap plication also known as cmd. exe.  Try starting the Python interpreter by typing python.  You should see message that matches the version of EPDFree you installed CUsersWespython Python 2. 7. 3 EPDfree 7. 31 32bit default Apr 12 2012 37 on win32 Type credits demo or enthought for more information.  Installation and Setup If you see message for different version of EPD or it doesnt work at all you will need to clean up your Windows environment variables.  On Windows you can start typing environment variables in the programs search field and select Edit environ ment variables for your account.  On Windows XP you will have to go to Control Panel System Advanced Environment Variables.  On the window that pops up you are looking for the Path variable.  It needs to contain the following two directory paths separated by semicolons CPython27CPython27Scripts If you installed other versions of Python be sure to delete any other Pythonrelated directories from both the system and user Path variables.  After making path alterna tion you have to restart the command prompt for the changes to take effect.  Once you can launch Python successfully from the command prompt you need to install pandas.  The easiest way is to download the appropriate binary installer from httppypi. python. orgpypipandas.  For EPDFree this should be pandas0. 9. 0. win32 py2. 7. exe.  After you run this lets launch Python and check that things are installed correctly by importing pandas and making simple matplotlib plot CUsersWesipython pylab Python 2. 7. 3 EPD free 7. 31 32bit Type copyright credits or license for more information.  IPython 0. 12. 1 An enhanced Interactive Python.  Introduction and overview of IPythons features.  quickref Quick reference.  help Pythons own help system.  object Details about object use object for extra details.  Welcome to pylab matplotlibbased Python environment backend WXAgg.  For more information type helppylab.  In import pandas In plotarange10 If successful there should be no error messages and plot window will appear.  You can also check that the Python HTML notebook can be successfully run by typing ipython notebook pylabinline If you use the Python notebook application on Windows and normally ta use Internet Explorer you will likely need to install and run Mozilla Firefox or Google Chrome instead.  EPDFree on Windows contains only 32bit executables.  If you want or need 64bit setup on Windows using EPD Full is the most painless way to accomplish that.  If you would rather install from scratch and not pay for an EPD subscription Christoph Gohlke at the University of California Irvine publishes unofficial binary installers for Chapter1 Preliminaries all of the books necessary packages hitpwww. lfd. uci. edugohlkepythonlibs for 32 and 64bit Windows.  Apple 0S To get started on OS you must first install Xcode which includes Apples suite of software development tools.  The necessary component for our purposes is the gcc and compiler suite.  The Xcode installer can be found on the OS install DVD that came with your computer or downloaded from Apple directly.  Once youve installed Xcode launch the terminal Terminal. app by navigating to Applications Utilities.  Type gcc and press enter.  You should hopefully see some thing like gcc 1686appledarwin10gcc4. 2. 1 no input files Now you need to install EPDFree.  Download the installer which should be disk image named something like epdfree7. 31macosxi386. dmg.  Doubleclick the . dmg file to mount it then doubleclick the . mpkg file inside to run the installer.  When the installer runs it automatically appends the EPDFree executable path to your . bashprofile file.  This is located at Usersyouruname. bashprofile Setting PATH for EPD free7. 31 PATHLibraryFrameworksPython.  frameworkVersionsCurrentbinPATH export PATH Should you encounter any problems in the following steps youll want to inspect your . bashprofile and potentially add the above directory to your path.  Now its time to install pandas.  Execute this command in the terminal sudo easyinstall pandas Searching for pandas Reading httppypi. python. orgsimplepandas Reading httppandas. pydata. org Reading httppandas. sourceforge. net Best match pandas 0. 9. 0 Downloading httppypi. python. orgpackagessourceppandaspandas0. 9. 0. zip Processing pandas0. 9. 0. zip Writing tmpeasyinstallH5m1X6pandas0. 9. 0setup. cfg Running pandas0. 9. 0setup. py bdistegg distdir tmpeasyinstallH5m1X6 pandas0. 9. 0eggdisttmpRhLGoz Adding pandas 0. 9. 0 to easyinstall. pth file Installed LibraryFrameworksPython.  frameworkVersions7. 3libpython2. 7 sitepackagespandas0. 9. 0py2. 7macosx10. 51386. egg Processing dependencies for pandas Finished processing dependencies for pandas To verify everything is working launch IPython in Pylab mode and test importing pan das then making plot interactively Installation and Setup ipython pylab VirtualBox VMsWindowsXP ipython Python 2. 7. 3 EPD free 7. 31 32bit default Apr 12 2012 34 Type copyright credits or license for more information.  IPython 0. 12. 1 An enhanced Interactive Python.  Introduction and overview of IPythons features.  quickref Quick reference.  help Pythons own help system.  object Details about object use object for extra details.  Welcome to pylab matplotlibbased Python environment backend WXAgg.  For more information type helppylab.  In import pandas In plotarange10 If this succeeds plot window with straight line should pop up.  GNULinux Some but not all Linux distributions include sufficiently uptodate versions of all the required Python packages and can be installed using 48 the builtin package management tool like apt.  detail setup using EPD Free as its easily reproducible across distributions.  Linux details will vary bit depending on your Linux flavor but here give details for Debianbased GNULinux systems like Ubuntu and Mint.  Setup is similar to OS with the exception of how EPDFree is installed.  The installer is shell script that must be executed in the terminal.  Depending on whether you have 32bit or 64bit system you will either need to install the x86 32bit or x8664 64bit installer.  You will then have file named something similar to epdfree7. 31rh5x8664. sh.  To install it execute this script with bash bash epdfree7. 31rh5x8664. sh After accepting the license you will be presented with choice of where to put the EPDFree files.  recommend installing the files in your home directory say homewesm epd substituting your own username for wesm.  Once the installer has finished you need to add EPDFrees bin directory to your PATH variable.  If you are using the bash shell the default in Ubuntu for example this means adding the following path addition in your . bashrc export PATHhomewesmepdbin PATH Obviously substitute the installation directory you used for homewesmepd.  After doing this you can either start new terminal process or execute your . bashrc again with source . bashrc.  10 Chapter Preliminaries You need compiler such as gcc to move forward many Linux distributions include gcc but others may not.  On Debian systems you can install gcc by executing sudo aptget install gcc If you type gcc on the command line it should say something like gcc gcc no input files Now time to install pandas easy install pandas If you installed EPDFree as root you may need to add sudo to the command and enter the sudo or root password.  To verify things are working perform the same checks as in the OS section.  Python and Python The Python community is currently undergoing drawnout transition from the Python series of interpreters to the Python series.  Until the appearance of Python 3. 0 all Python code was backwards compatible.  The community decided that in order to move the language forward certain backwards incompatible changes were necessary.  am writing this book with Python 2. 7 as its basis as the majority of the scientific Python community has not yet transitioned to Python 3.  The good news is that with few exceptions you should have no trouble following along with the book if you happen to be using Python 3. 2.  Integrated Development Environments IDEs When asked about my standard development environment almost always say IPy thon plus text editor.  typically write program and iteratively test and debug each piece of it in IPython.  It is also useful to be able to play around with data interactively and visually verify that particular set of data manipulations are doing the right thing.  Libraries like pandas and NumPy are designed to be easytouse in the shell.  However some will still prefer to work in an IDE instead of text editor.  They do provide many nice code intelligence features like completion or quickly pulling up the documentation associated with functions and classes.  Here are some that you can explore Eclipse with PyDev Plugin Python Tools for Visual Studio for Windows users PyCharm Spyder Komodo IDE Installation and Setup 11 Community and Conferences Outside of an Internet search the scientific Python mailing lists are generally helpful and responsive to questions.  Some ones to take look at are pydata Google Group list for questions related to Python for data analysis and pandas pystatsmodels for statsmodels or pandasrelated questions numpydiscussion for NumPyrelated questions scipyuser for general SciPy or scientific Python questions deliberately did not post URLs for these in case they change.  They can be easily located via Internet search.  Each year many conferences are held all over the world for Python programmers.  PyCon and EuroPython are the two main general Python conferences in the United States and Europe respectively.  SciPy and EuroSciPy are scientificoriented Python conferences where you will likely find many birds of feather if you become more involved with using Python for data analysis after reading this book.  Navigating This Book If you have never programmed in Python before you may actually want to start at the end of the book where have placed condensed tutorial on Python syntax language features and builtin data structures like tuples lists and dicts.  These things are con sidered prerequisite knowledge for the remainder of the book.  The book starts by introducing you to the Python environment.  Next give short introduction to the key features of NumPy leaving more advanced NumPy use for another chapter at the end of the book.  Then introduce pandas and devote the rest of the book to data analysis topics applying pandas NumPy and matplotlib for vis ualization.  have structured the material in the most incremental way possible though there is occasionally some minor crossover between chapters.  Data files and related material for each chapter are hosted as git repository on GitHub http github. compydatapydatabook encourage you to download the data and use it to replicate the books code examples and experiment with the tools presented in each chapter.  will happily accept contri butions scripts Python notebooks or any other materials you wish to contribute to the books repository for all to enjoy.  12 Chapter Preliminaries Code Examples Most of the code examples in the book are shown with input and output as it would appear executed in the IPython shell.  In code Out5 output At times for clarity multiple code examples will be shown side by side.  These should be read left to right and executed separately.  In code In code2 Out5 output Out6 output2 Data for Examples Data sets for the examples in each chapter are hosted in repository on GitHub http github. compydatapydatabook.  You can download this data either by using the git revision control commandline program or by downloading zip file of the repository from the website.  have made every effort to ensure that it contains everything necessary to reproduce the examples but may have made some mistakes or omissions.  If so please send me an email wesmckinngmail. com.  Import Conventions The Python community has adopted number of naming conventions for commonly used modules import numpy as np import pandas as pd import matplotlib. pyplot as plt This means that when you see np. arange this is reference to the arange function in NumPy.  This is done as its considered bad practice in Python software development to import everything from numpy import from large package like NumPy.  Jargon Pll use some terms common both to programming and data science that you may not be familiar with.  Thus here are some brief definitions MungeMungingWrangling Describes the overall process of manipulating unstructured andor messy data into structured or clean form.  The word has snuck its way into the jargon of many modern day data hackers.  Munge rhymes with lunge.  Navigating This Book 13 Pseudocode description of an algorithm or process that takes codelike form while likely not being actual valid source code.  Syntactic sugar Programming syntax which does not add new features but makes something more convenient or easier to type.  Acknowledgements It would have been difficult for me to write this book without the support of large number of people.  On the OReilly staff Im very grateful for my editors Meghan Blanchette and Julie Steele who guided me through the process.  Mike Loukides also worked with me in the proposal stages and helped make the book reality.  received wealth of technical review from large cast of characters.  In particular Martin Blais and Hugh Brown were incredibly helpful in improving the books exam ples clarity and organization from cover to cover.  James Long Drew Conway Fer nando Prez Brian Granger Thomas Kluyver Adam Klein Josh Klein Chang She and Stfan van der Walt each reviewed one or more chapters providing pointed feedback from many different perspectives.  got many great ideas for examples and data sets from friends and colleagues in the data community among them Mike Dewar Jeff Hammerbacher James Johndrow Kristian Lum Adam Klein Hilary Mason Chang She and Ashley Williams.  Iam of course indebted to the many leaders in the open source scientific Python com munity whove built the foundation for my development work and gave encouragement while was writing this book the Python core team Fernando Prez Brian Granger Min RaganKelly Thomas Kluyver and others John Hunter Skipper Seabold Travis Oliphant Peter Wang Eric Jones Robert Kern Josef Perktold Francesc Alted Chris Fonnesbeck and too many others to mention.  Several other people provided great deal of support ideas and encouragement along the way Drew Conway Sean Taylor Giuseppe Paleologo Jared Lander David Epstein John Krowas Joshua Bloom Den Pilsworth John MylesWhite and many others Ive forgotten.  Id also like to thank number of people from my formative years.  First my former AQR colleagues whove cheered me on in my pandas work over the years Alex Reyf man Michael Wong Tim Sargen Oktay Kurbanov Matthew Tschantz Roni Israelov Michael Katz Chris Uga Prasad Ramanan Ted Square and Hoon Kim.  Lastly my academic advisors Haynes Miller MIT and Mike West Duke.  On the personal side Casey Dinkin provided invaluable daytoday support during the writing process tolerating my highs and lows as hacked together the final draft on 14 Chapter Preliminaries top of an already overcommitted schedule.  Lastly my parents Bill and Kim taught me to always follow my dreams and to never settle for less.  Acknowledgements 15 CHAPTER Introductory Examples This book teaches you the Python tools to work productively with data.  While readers may have many different end goals for their work the tasks required generally fall into number of different broad groups Interacting with the outside world Reading and writing with variety of file formats and databases.  Preparation Cleaning munging combining normalizing reshaping slicing and dicing and transforming data for analysis.  Transformation Applying mathematical and statistical operations to groups of data sets to derive new data sets.  For example aggregating large table by group variables.  Modeling and computation Connecting your data to statistical models machine learning algorithms or other computational tools Presentation Creating interactive or static graphical visualizations or textual summaries In this chapter will show you few data sets and some things we can do with them.  These examples are just intended to pique your interest and thus will only be explained at high level.  Dont worry if you have no experience with any of these tools they will be discussed in great detail throughout the rest of the book.  In the code examples youll see input and output prompts like In 15 these are from the IPython shell.  Va oe To follow along with these examples you should run Python in Pylab 43 mode by running ipython pylab at the command prompt.  1. usa. gov data from bit. ly In 2011 URL shortening service bit. ly partnered with the United States government website usa.  gov to provide feed of anonymous data gathered from users who shorten links ending with . gov or . mil.  As of this writing in addition to providing live feed hourly snapshots are available as downloadable text files.  In the case of the hourly snapshots each line in each file contains common form of web data known as JSON which stands for JavaScript Object Notation.  For example if we read just the first line of file you may see something like In 15 path cho2usagovbitlydata201203161331923249. txt In 16 openpath . readline Out16 Mozilla5. 0 Windows NT 6. 1 WOW64 AppleWebKit535. 11 KHTML like Gecko Chrome17. 0. 963. 78 Safari535. 11 US nk tz AmericaNew York gr MA A6qOVH wfLOtf orofrog al enUSenq0. 8 hh 1. usa. gov http www.  facebook.  com17AQEFzjSi1. usa. govwfLotf http www. ncbi. nlm. nih. govpubmed22415991 1331923247 hc 1331822918 cy Danvers 11 42. 576698 70. 954903 Python has numerous builtin and 3rd party modules for converting JSON string into Python dictionary object.  Here Ill use the json module and its loads function invoked on each line in the sample file downloaded import json path chO2usagovbitlydata201203161331923249. txt records json. loadsline for line in openpath If youve never programmed in Python before the last expression here is called list comprehension which is concise way of applying an operation like json.  loads to collection of strings or other objects.  Conveniently iterating over an open file handle gives you sequence of its lines.  The resulting object records is now list of Python dicts In 18 recordso Out 18 ua uMozilla5. 0 Windows NT 6. 1 WOW64 AppleWebKit535. 11 KHTML like Gecko Chrome17. 0. 963. 78 Safari535. 11 ual uenUSenq0. 8 uc uUS ucy uDanvers ug uA6qgOVH ugr uMA uh uwfLdtf uhc 1331822918 uhh u1. usa. gov ul uorofrog ull 42. 576698 70. 954903 1.  httpwww. usa. govAboutdeveloperresources1usagov. shtml 18 Chapter Introductory Examples unk ur uhttpwww.  facebook. com17AQEFzjSi1. usa. govwfLOtf ut 1331923247 utz uAmericaNewYork uu uhttpwww. ncbi. nlm. nih. govpubmed22415991 Note that Python indices start at and not like some other languages like R.  Its now easy to access individual values within records by passing string for the key you wish to access In 19 recordsotz Out19 uAmericaNewYork The here in front of the quotation stands for unicode standard form of string en coding.  Note that Python shows the time zone string object representation here rather than its print equivalent In 20 print recordsotz AmericaNewYork Counting Time Zones in Pure Python Suppose we were interested in the most oftenoccurring time zones in the data set the tz field.  There are many ways we could do this.  First lets extract list of time zones again using list comprehension In 25 timezones rectz for rec in records KeyError Traceback most recent call last homewesmbookscriptswhettingipython in module timezones rectz for rec in records KeyError tz Oops Turns out that not all of the records have time zone field.  This is easy to handle as we can add the check if tz in rec at the end of the list comprehension In 26 timezones rectz for rec in records if tz in rec In 27 timezones10 Out 27 uAmericaNew York uAmericaDenver uAmericaNewYork uAmericaSao Paulo uAmericaNewYork uAmericaNewYork uEuropeWarsaw Just looking at the first 10 time zones we see that some of them are unknown empty.  You can filter these out also but Ill leave them in for now.  Now to produce counts by 1. usa. gov data from bit. ly 19 time zone Ill show two approaches the harder way using just the Python standard library and the easier way using pandas.  One way to do the counting is to use dict to store counts while we iterate through the time zones def getcountssequence counts for in sequence if in counts countsx else countsx return counts If you know bit more about the Python standard library you might prefer to write the same thing more briefly from collections import defaultdict def getcounts2sequence counts defaultdictint values will initialize to for in sequence countsx return counts put this logic in function just to make it more reusable.  To use it on the time zones just pass the timezones list In 31 counts getcountstimezones In 32 countsAmericaNewYork Out32 1254 In 33 lentimezones Out33 3440 If we wanted the top 10 time zones and their counts we have to do little bit of dic tionary acrobatics def top countscountdict n10 valuekeypairs count tz for tz count in countdict. items valuekeypairs. sort return valuekeypairsn We have then In 35 topcountscounts Out35 33 uAmericaSao Paulo 35 uEuropeMadrid 36 uPacificHonolulu 37 uAsiaTokyo 74 uEuropeLondon 191 uAmericaDenver 382 uAmericaLos Angeles 400 uAmericaChicago 20 Chapter Introductory Examples 521 1251 uAmericaNewYork If you search the Python standard library you may find the collections . Counter class which makes this task lot easier In 49 from collections import Counter In 50 counts Countertimezones In 51 counts. mostcommon10 Out51 uAmericaNewYork 1251 521 uAmericaChicago 400 uAmericaLos Angeles 382 uAmericaDenver 191 uEuropeLondon 74 uAsiaTokyo 37 uPacificHonolulu 36 uEuropeMadrid 35 uAmericaSao Paulo 33 Counting Time Zones with pandas The main pandas data structure is the DataFrame which you can think of as repre senting table or spreadsheet of data.  Creating DataFrame from the original set of records is simple In 289 from pandas import DataFrame Series In 290 import pandas as pd import numpy as np In 291 frame DataFramerecords In 292 frame Out 292 class pandas. core. frame. DataFrame Int64Index 3560 entries to 3559 Data columns heartbeat 120 nonnull values 3440 nonnull values al 3094 nonnull values 2919 nonnull values cy 2919 nonnull values 3440 nonnull values gr 2919 nonnull values 3440 nonnull values hc 3440 nonnull values hh 3440 nonnull values kw 93 nonnull values 3440 nonnull values 1l 2919 nonnull values nk 3440 nonnull values 3440 nonnull values 1. usa. gov data from bit. ly 21 3440 nonnull values tz 3440 nonnull values 3440 nonnull values dtypes float644 object14 In 293 frametz10 Out 293 AmericaNewYork AmericaDenver AmericaNewYork AmericaSaoPaulo AmericaNewYork AmericaNewYork EuropeWarsaw Name tz The output shown for the frame is the summary view shown for large DataFrame ob jects.  The Series object returned by frametz has method valuecounts that gives us what were looking for In 294 tzcounts frametz. valuecounts In 295 tzcounts10 Out295 AmericaNewYork 1251 521 AmericaChicago 400 AmericaLosAngeles 382 AmericaDenver 191 EuropeLondon 74 AsiaTokyo 37 PacificHonolulu 36 EuropeMadrid 35 AmericaSaoPaulo 33 Then we might want to make plot of this data using plotting library matplotlib.  You can do bit of munging to fill in substitute value for unknown and missing time zone data in the records.  The fillna function can replace missing NA values and unknown empty strings values can be replaced by boolean array indexing In 296 cleantz frametz. fillnaMissing In 297 cleantzcleantz Unknown In 298 tzcounts cleantz. valuecounts In 299 tzcounts10 Out299 AmericaNewYork 1251 Unknown 521 AmericaChicago 400 AmericaLosAngeles 382 22 Chapter Introductory Examples AmericaDenver 191 Missing 120 EuropeLondon 74 AsiaTokyo 37 PacificHonolulu 36 EuropeMadrid 35 Making horizontal bar plot can be accomplished using the plot method on the counts objects In 301 tzcounts10. plotkindbarh rot0 See Figure 21 for the resulting figure.  Well explore more tools for working with this kind of data.  For example the field contains information about the browser device or application used to perform the URL shortening In 302 framea1 Out 302 uGoogleMapsRochesterNY In 303 framea50 Out303 uMozilla5. 0 Windows NT 5. 1 rv10. 0. 2 Gecko20100101 Firefox10. 0. 2 In 304 framea51 Out304 uMozilla5. 0 Linux Android 2. 2. 2 enus LGP925V10e BuildFRG83G AppleWebKit533. 1 KHTML like Gecko Version4. 0 Mobile Safari533. 1 EuropeMadrid PacificHonolulu AsiaTokyo EuropeLondon Missing AmericaDenver AmericaLosAngeles AmericaChicago Unknown AmericaNewYork 200 400 600 800 1000 1200 1400 Figure 21.  Top time zones in the 1. usa. gov sample data Parsing all of the interesting information in these agent strings may seem like daunting task.  Luckily once you have mastered Pythons builtin string functions and regular expression capabilities it is really not so bad.  For example we could split off the first token in the string corresponding roughly to the browser capability and make another summary of the user behavior In 305 results Seriesx. split0 for in frame. a. dropna In 306 results5 Out 306 Mozilla5. 0 GoogleMapsRochesterNY 1. usa. gov data from bit. ly 23 Mozilla4. 0 Mozilla5. 0 Mozilla5. 0 In 307 results. valuecounts8 Out 307 Mozilla5. 0 2594 Mozilla4. 0 601 GoogleMapsRochesterNY 121 Opera9. 80 34 TESTINTERNETAGENT 24 GoogleProducer 21 Mozilla6. 0 BlackBerry85205. 0. 0. 681 Now suppose you wanted to decompose the top time zones into Windows and non Windows users.  As simplification lets say that user is on Windows if the string Windows is in the agent string.  Since some of the agents are missing Ill exclude these from the data In 308 cframe frameframe. a. notnull We want to then compute value whether each row is Windows or not In 309 operating system np. wherecframea. str. containsWindows satay 62 Windows Not Windows In 310 operating system5 Out 310 Windows Not Windows Windows Not Windows Windows S2SRPWNPF OC ame Then you can group the data by its time zone column and this new list of operating systems In 311 bytzos cframe. groupbytz operating system The group counts analogous to the valuecounts function above can be computed using size.  This result is then reshaped into table with unstack In 312 agg counts bytzos. size. unstack. fillnao In 313 agg counts10 Out 313 Not Windows Windows tz 245 276 AfricaCairo AfricaCasablanca AfricaCeuta AfricaJohannesburg AfricaLusaka 24 Chapter Introductory Examples AmericaAnchorage AmericaArgentinaBuenos Aires AmericaArgentinaCordoba AmericaArgentinaMendoza oOoRSs rFPROR Finally lets select the top overall time zones.  To do so construct an indirect index array from the row counts in agg counts Use to sort in ascending order In 314 indexer agg counts. sum1. argsort In 315 indexer10 Out 315 tz 24 AfricaCairo 20 AfricaCasablanca 21 AfricaCeuta 92 AfricaJohannesburg 87 AfricaLusaka 53 AmericaAnchorage 54 AmericaArgentinaBuenos Aires 57 AmericaArgentinaCordoba 26 AmericaArgentinaMendoza 55 then use take to select the rows in that order then slice off the last 10 rows In 316 countsubset agg counts. takeindexer10 In 317 countsubset Out 317 Not Windows Windows tz AmericaSaoPaulo 13 20 EuropeMadrid 16 19 PacificHonolulu 36 AsiaTokyo 35 EuropeLondon 43 31 AmericaDenver 132 59 AmericaLos Angeles 130 252 AmericaChicago 115 285 245 276 AmericaNewYork 339 912 Then as shown in the preceding code block this can be plotted in bar plot Ill make it stacked bar plot by passing stackedTrue see Figure 22 In 319 countsubset. plotkindbarh stackedTrue The plot doesnt make it easy to see the relative percentage of Windows users in the smaller groups but the rows can easily be normalized to sum to then plotted again see Figure 23 In 321 normedsubset countsubset. divcountsubset. sum1 axis0 In 322 normedsubset. plotkindbarh stackedTrue 1. usa. gov data from bit. ly 25 AmericaNewYork AmericaChicago AmericaLosAngeles AmericaDenver Zz EuropeLondon AsiaTokyo PacificHonolulu MH Not Windows AmericaS20 Paulo iy GH Windows re 200 400 600 800 1000 1200 1400 EuropeMadrid Figure 22.  Top time zones by Windows and nonWindows users AmericaNewYork Not Windows GH Windows AmericaChicago AmericaLosAngeles AmericaDenver tz EuropeLondon AsiaTokyo PacificHonolulu EuropeMadrid AmericaSaoPaulo BH Figure 23.  Percentage Windows and nonWindows users in topoccurring time zones All of the methods employed here will be examined in great detail throughout the rest of the book.  MovieLens 1M Data Set GroupLens Research httpwww. grouplens. orgnode73 provides number of collec tions of movie ratings data collected from users of MovieLens in the late 1990s and 26 Chapter Introductory Examples early 2000s.  The data provide movie ratings movie metadata genres and year and demographic data about the users age zip code gender and occupation.  Such data is often of interest in the development of recommendation systems based on machine learning algorithms.  While will not be exploring machine learning techniques in great detail in this book will show you how to slice and dice data sets like these into the exact form you need.  The MovieLens 1M data set contains million ratings collected from 6000 users on 4000 movies.  Its spread across tables ratings user information and movie infor mation.  After extracting the data from the zip file each table can be loaded into pandas DataFrame object using pandas. readtable import pandas as pd unames userid gender age occupation zip users pd. readtableml1musers. dat sep headerNone namesunames rnames userid movie id rating timestamp ratings pd. readtableml1mratings. dat sep headerNone namesrnames mnames movieid title genres movies pd. readtableml1mmovies. dat sep headerNone namesmnames You can verify that everything succeeded by looking at the first few rows of each Da taFrame with Pythons slice syntax In 334 users5 Out 334 userid gender age occupation zip 10 48067 56 16 70072 25 15 55117 45 02460 25 20 55455 In 335 ratings5 Out 335 userid movieid rating timestamp 1193 978300760 661 978302109 914 978301968 3408 978300275 2355 978824291 In 336 movies5 Out 336 movieid title genres Toy Story 1995 AnimationChildrensComedy Jumanji 1995 AdventureChildrensFantasy Grumpier Old Men 1995 Comedy Romance Waiting to Exhale 1995 Comedy Drama MovieLens 1M DataSet 27 Father of the Bride Part II 1995 Comedy In 337 ratings Out 337 class pandas. core. frame. DataFrame Int64Index 1000209 entries to 1000208 Data columns userid 1000209 nonnull values movieid 1000209 nonnull values rating 1000209 nonnull values timestamp 1000209 nonnull values dtypes int644 Note that ages and occupations are coded as integers indicating groups described in the data sets README file.  Analyzing the data spread across three tables is not simple task for example suppose you wanted to compute mean ratings for particular movie by sex and age.  As you will see this is much easier to do with all of the data merged together into single table.  Using pandass merge function we first merge ratings with users then merging that result with the movies data.  pandas infers which columns to use as the merge or join keys based on overlapping names In 338 data pd. mergepd. mergeratings users movies In 339 data Out 339 class pandas. core. frame. DataFrame Int64Index 1000209 entries to 1000208 Data columns userid 1000209 nonnull values movieid 1000209 nonnull values rating 1000209 nonnull values timestamp 1000209 nonnull values gender 1000209 nonnull values age 1000209 nonnull values occupation 1000209 nonnull values zip 1000209 nonnull values title 1000209 nonnull values genres 1000209 nonnull values dtypes int646 object4 In 340 data. ixo Out 340 userid movieid rating timestamp 978824268 gender age occupation 10 zip 48067 title Toy Story 1995 genres Animation Childrens Comedy Name 28 Chapter2 Introductory Examples In this form aggregating the ratings grouped by one or more user or movie attributes is straightforward once you build some familiarity with pandas.  To get mean movie ratings for each film grouped by gender we can use the pivottable method In 341 meanratings data. pivottablerating rowstitle ere colsgender aggfuncmean In 342 meanratings5 Out 342 gender title 1000000 Duck 1971 3. 375000 2. 761905 Night Mother 1986 3. 388889 3. 352941 Til There Was You 1997 2. 675676 2. 733333 burbs The 1989 2. 793478 2. 962085 . . And Justice for All 1979 3. 828571 3. 689024 This produced another DataFrame containing mean ratings with movie totals as row labels and gender as column labels.  First Im going to filter down to movies that re ceived at least 250 ratings completely arbitrary number to do this group the data by title and use size to get Series of group sizes for each title In 343 ratings by title data. groupbytitle. size In 344 ratings by title10 Out 344 title 1000000 Duck 1971 37 Night Mother 1986 70 Til There Was You 1997 52 burbs The 1989 303 . . . And Justice for All 1979 199 1900 1994 10 Things Hate About You 1999 700 101 Dalmatians 1961 565 101 Dalmatians 1996 364 12 Angry Men 1957 616 In 345 active titles ratings by title. indexratings by title 250 In 346 active titles Out 346 Indexburbs The 1989 10 Things Hate About You 1999 101 Dalmatians 1961 . . .  Young Sherlock Holmes 1985 Zero Effect 1998 eXistenZ 1999 dtypeobject The index of titles receiving at least 250 ratings can then be used to select rows from meanratings above In 347 meanratings meanratings. ixactive titles In 348 meanratings Out 348 class pandas. core.  frame. DataFrame Index 1216 entries burbs The 1989 to eXistenZ 1999 MovieLens 1M DataSet 29 Data columns 1216 nonnull values 1216 nonnull values dtypes float642 To see the top films among female viewers we can sort by the column in descending order In 350 top female ratings meanratings. sortindexbyF ascendingFalse In 351 top female ratings10 Out 351 gender Close Shave 1995 4. 644444 4. 473795 Wrong Trousers The 1993 4. 588235 4. 478261 Sunset Blvd.  a. k. a.  Sunset Boulevard 1950 4. 572650 4. 464589 Wallace Gromit The Best of Aardman Animation 1996 4. 563107 4. 385075 Schindlers List 1993 4. 562602 4. 491415 Shawshank Redemption The 1994 4. 539075 4. 560625 Grand Day Out 1992 4. 537879 4. 293255 To Kill Mockingbird 1962 4. 536667 4. 372611 Creature Comforts 1990 4. 513889 4. 272277 Usual Suspects The 1995 4. 513317 4. 518248 Measuring rating disagreement Suppose you wanted to find the movies that are most divisive between male and female viewers.  One way is to add column to meanratings containing the difference in means then sort by that In 352 meanratingsdiff meanratingsM meanratingsF Sorting by diff gives us the movies with the greatest rating difference and which were preferred by women In 353 sorted by diff meanratings. sortindexbydiff In 354 sorted by diff15 Out 354 gender diff Dirty Dancing 1987 3. 790378 2. 959596 0. 830782 Jumpin Jack Flash 1986 3. 254717 2. 578358 0. 676359 Grease 1978 3. 975265 3. 367041 0. 608224 Little Women 1994 3. 870588 3. 321739 0. 548849 Steel Magnolias 1989 3. 901734 3. 365957 0. 535777 Anastasia 1997 3. 800000 3. 281609 0. 518391 Rocky Horror Picture Show The 1975 3. 673016 3. 160131 0. 512885 Color Purple The 1985 4. 158192 3. 659341 0. 498851 Age of Innocence The 1993 3. 827068 3. 339506 0. 487561 Free Willy 1993 2. 921348 2. 438776 0. 482573 French Kiss 1995 3. 535714 3. 056962 0. 478752 Little Shop of Horrors The 1960 3. 650000 3. 179688 0. 470312 Guys and Dolls 1955 4. 051724 3. 583333 0. 468391 Mary Poppins 1964 4. 197740 3. 730594 0. 467147 Patch Adams 1998 3. 473282 3. 008746 0. 464536 30 Chapter2 Introductory Examples Reversing the order of the rows and again slicing off the top 15 rows we get the movies preferred by men that women didnt rate as highly Reverse order of rows take first 15 rows In 355 sorted by diff115 Out355 gender diff Good The Bad and The Ugly The 1966 3. 494949 4. 221300 0. 726351 Kentucky Fried Movie The 1977 2. 878788 3. 555147 0. 676359 Dumb Dumber 1994 2. 697987 3. 336595 0. 638608 Longest Day The 1962 3. 411765 4. 031447 0. 619682 Cable Guy The 1996 2. 250000 2. 863787 0. 613787 Evil Dead II Dead By Dawn 1987 3. 297297 3. 909283 0. 611985 Hidden The 1987 3. 137931 3. 745098 0. 607167 Rocky III 1982 2. 361702 2. 943503 0. 581801 Caddyshack 1980 3. 396135 3. 969737 0. 573602 For Few Dollars More 1965 3. 409091 3. 953795 0. 544704 Porkys 1981 2. 296875 2. 836364 0. 539489 Animal House 1978 3. 628906 4. 167192 0. 538286 Exorcist The 1973 3. 537634 4. 067239 0. 529605 Fright Night 1985 2. 973684 3. 500000 0. 526316 Barb Wire 1996 1. 585366 2. 100386 0. 515020 Suppose instead you wanted the movies that elicited the most disagreement among viewers independent of gender.  Disagreement can be measured by the variance or standard deviation of the ratings Standard deviation of rating grouped by title In 356 rating stdby title data. groupbytitlerating. std Filter down to active titles In 357 rating stdby title rating stdby title. ixactive titles Order Series by value in descending order In 358 rating stdby title. orderascendingFalse 10 Out 358 title Dumb Dumber 1994 1. 321333 Blair Witch Project The 1999 1. 316368 Natural Born Killers 1994 1. 307198 Tank Girl 1995 1. 277695 Rocky Horror Picture Show The 1975 1. 260177 Eyes Wide Shut 1999 1. 259624 Evita 1996 1. 253631 Billy Madison 1995 1. 249970 Fear and Loathing in Las Vegas 1998 1. 246408 Bicentennial Man 1999 1. 245533 Name rating You may have noticed that movie genres are given as pipeseparated string.  If you wanted to do some analysis by genre more work would be required to transform the genre information into more usable form.  will revisit this data later in the book to illustrate such transformation.  MovieLens 1M DataSet 31 US Baby Names 18802010 The United States Social Security Administration SSA has made available data on the frequency of baby names from 1880 through the present.  Hadley Wickham an author of several popular packages has often made use of this data set in illustrating data manipulation in R.  In names. head10 Out name sex births year Mary 7065 1880 Anna 2604 1880 Emma 2003 1880 Elizabeth 1939 1880 Minnie 1746 1880 Margaret 1578 1880 Ida 1472 1880 Alice 1414 1880 Bertha 1320 1880 Sarah 1288 1880 There are many things you might want to do with the data set Visualize the proportion of babies given particular name your own or another name over time.  Determine the relative rank of name.  Determine the most popular names in each year or the names with largest increases or decreases.  Analyze trends in names vowels consonants length overall diversity changes in spelling first and last letters Analyze external sources of trends biblical names celebrities demographic changes Using the tools weve looked at so far most of these kinds of analyses are very straight forward so will walk you through many of them.  encourage you to download and explore the data yourself.  If you find an interesting pattern in the data would love to hear about it.  As of this writing the US Social Security Administration makes available data files one per year containing the total number of births for each sexname combination.  The raw archive of these files can be obtained here http www. ssa. govoactbabynameslimits . html In the event that this page has been moved by the time youre reading this it can most likely be located again by Internet search.  After downloading the National data file names. zip and unzipping it you will have directory containing series of files like yob1880. txt.  use the UNIX head command to look at the first 10 lines of one of the files on Windows you can use the more command or open it in text editor 32 Chapter2 Introductory Examples In 367 head 10 namesyob1880. txt MaryF 7065 AnnaF 2604 Emma 2003 Elizabeth F1939 MinnieF1746 MargaretF1578 Ida F1472 AliceF1414 Bertha F1320 Sarah F1288 As this is nicely commaseparated form it can be loaded into DataFrame with pandas. readcsv In 368 import pandas as pd In 369 names1880 pd. readcsvnamesyob1880. txt namesname sex births In 370 names1880 Out 370 class pandas. core.  frame. DataFrame Int64Index 2000 entries to 1999 Data columns name 2000 nonnull values sex 2000 nonnull values births 2000 nonnull values dtypes int641 object2 These files only contain names with at least occurrences in each year so for simplic itys sake we can use the sum of the births column by sex as the total number of births in that year In 371 names1880. groupbysex. births. sum Out 371 sex 90993 110493 Name births Since the data set is split into files by year one of the first things to do is to assemble all of the data into single DataFrame and further to add year field.  This is easy to do using pandas.  concat 2010 is the last available year right now years range1880 2011 pieces columns name sex births for year in years path namesyobd. txt year frame pd. readcsvpath namescolumns frameyear year pieces . appendframe US Baby Names 18802010 33 Concatenate everything into single DataFrame names pd. concatpieces ignore indexTrue There are couple things to note here.  First remember that concat glues the DataFrame objects together rowwise by default.  Secondly you have to pass ignore indexTrue because were not interested in preserving the original row numbers returned from readcsv.  So we now have very large DataFrame containing all of the names data Now the names DataFrame looks like In 373 names Out 373 class pandas. core.  frame. DataFrame Int64Index 1690784 entries to 1690783 Data columns name 1690784 nonnull values sex 1690784 nonnull values births 1690784 nonnull values year 1690784 nonnull values dtypes int642 object2 With this data in hand we can already start aggregating the data at the year and sex level using groupby or pivottable see Figure 24 In 374 totalbirths names. pivottablebirths rowsyear ere colssex aggfuncsum In 375 totalbirths. tail Out 375 sex year 2006 1896468 2050234 2007 1916888 2069242 2008 1883645 2032310 2009 1827643 1973359 2010 1759010 1898382 In 376 totalbirths. plottitleTotal births by sex and year Next lets insert column prop with the fraction of babies given each name relative to the total number of births.  prop value of 0. 02 would indicate that out of every 100 babies was given particular name.  Thus we group the data by year and sex then add the new column to each group def addpropgroup Integer division floors births group. births. astypefloat groupprop births births. sum return group names names. groupbyyear sex. applyaddprop 34 Chapter2 Introductory Examples se00000 Total births by sex and year 2000000 1500000 1000000 500000 ao 1900 1920 1940 1960 1980 2000 2020 year Figure 24.  Total births by sex and year Vs Remember that because births is of integer type we have to cast either the numerator or denominator to floating point to compute fraction 12 unless you are using Python 3.  The resulting complete data set now has the following columns In 378 names Out 378 class pandas. core. frame. DataFrame Int64Index 1690784 entries to 1690783 Data columns name 1690784 nonnull values sex 1690784 nonnull values births 1690784 nonnull values year 1690784 nonnull values prop 1690784 nonnull values dtypes float641 int642 object2 When performing group operation like this its often valuable to do sanity check like verifying that the prop column sums to within all the groups.  Since this is floating point data use np. allclose to check that the group sums are sufficiently close to but perhaps not exactly equal to In 379 np. allclosenames. groupbyyear sex. prop. sum Out379 True Now that this is done Im going to extract subset of the data to facilitate further analysis the top 1000 names for each sexyear combination.  This is yet another group operation def gettop1000group return group. sortindexbybirths ascendingFalse1000 US Baby Names 18802010 35 grouped names. groupbyyear sex top1000 grouped. applygettop1000 If you prefer doityourself approach you could also do pieces for year group in names. groupbyyear sex pieces.  appendgroup. sortindexbybirths ascendingFalse 1000 top1000 pd. concatpieces ignore indexTrue The resulting data set is now quite bit smaller In 382 top1000 Out 382 class pandas. core.  frame. DataFrame Int64Index 261877 entries to 261876 Data columns name 261877 nonnull values sex 261877 nonnull values births 261877 nonnull values year 261877 nonnull values prop 261877 nonnull values dtypes float641 int642 object2 Well use this Top 1000 data set in the following investigations into the data.  Analyzing Naming Trends With the full data set and Top 1000 data set in hand we can start analyzing various naming trends of interest.  Splitting the Top 1000 names into the boy and girl portions is easy to do first In 383 boys top1000top1000. sex In 384 girls top1000top1000. sex Simple time series like the number of Johns or Marys for each year can be plotted but require bit of munging to be bit more useful.  Lets form pivot table of the total number of births by year and name In 385 totalbirths top1000. pivottablebirths rowsyear colsname aggfuncsum Now this can be plotted for handful of names using DataFrames plot method In 386 totalbirths Out 386 class pandas. core. frame. DataFrame Int64Index 131 entries 1880 to 2010 Columns 6865 entries Aaden to Zuri dtypes float646865 In 387 subset totalbirthsJohn Harry Mary Marilyn In 388 subset. plotsubplotsTrue figsize12 10 gridFalse evarey of titleNumber of births per year 36 Chapter2 Introductory Examples See Figure 25 for the result.  On looking at this you might conclude that these names have grown out of favor with the American population.  But the story is actually more complicated than that as will be explored in the next section.  Number of births per year we98 80 70000 John 60000 50000 40000 30000 20000 10000 year 10000 B00 Harry 6000 4000 2000 year 80000 70000 60000 Mary 50000 40000 30000 20000 10000 year 12000 10000 Marilyn 8000 6000 4000 2000 es soe so we oe age aw year Figure 25.  few boy and girl names over time Measuring the increase in naming diversity One explanation for the decrease in plots above is that fewer parents are choosing common names for their children.  This hypothesis can be explored and confirmed in the data.  One measure is the proportion of births represented by the top 1000 most popular names which aggregate and plot by year and sex 390 table top1000. pivottableprop rowsyear awn et colssex aggfuncsum In 91 table. plottitleSum of table1000. prop by year and sex awmast yticksnp. linspace0 1. 2 13 xticksrange1880 2020 10 See Figure 26 for this plot.  So you can see that indeed there appears to be increasing name diversity decreasing total proportion in the top 1000.  Another interesting met ric is the number of distinct names taken in order of popularity from highest to lowest in the top 50 of births.  This number is bit more tricky to compute.  Lets consider just the boy names from 2010 392 df boysboys. year 2010 393 df Out 393 class pandas. core.  frame. DataFrame Int64Index 1000 entries 260877 to 261876 Data columns US Baby Names 18802010 37 name 1000 nonnull values sex 1000 nonnull values births 1000 nonnull values year 1000 nonnull values prop 1000 nonnull values dtypes float641 int642 object2 Sum of table1000. prop by year and sex OR 80 1890 1900 1910 1920 1930 1940 1950 1960 1970 1980 1990 2000 2010 year Figure 26.  Proportion of births represented in top 1000 names by sex After sorting prop in descending order we want to know how many of the most popular names it takes to reach 50.  You could write for loop to do this but vectorized NumPy way is bit more clever.  Taking the cumulative sum cumsum of prop then calling the method searchsorted returns the position in the cumulative sum at which 0. 5 would need to be inserted to keep it in sorted order In 394 propcumsum df. sortindexbyprop ascendingFalse . prop. cumsum In 395 propcumsum 10 Out 395 260877 0. 011523 260878 0. 020934 260879 0. 029959 260880 0. 038930 260881 0. 047817 260882 0. 056579 260883 0. 065155 260884 0. 073414 260885 0. 081528 260886 0. 089621 In 396 propcumsum. searchsorted0. 5 Out396 116 38 Chapter2 Introductory Examples Since arrays are zeroindexed adding to this result gives you result of 117.  By con trast in 1900 this number was much smaller In 397 df boysboys. year 1900 In 398 in1900 df. sortindexbyprop ascendingFalse . prop. cumsum In 399 in1900. searchsorted0. 5 Out 399 25 It should now be fairly straightforward to apply this operation to each yearsex com bination groupby those fields and apply function returning the count for each group def getquantilecountgroup q0. 5 group group. sortindexbyprop ascendingFalse return group. prop. cumsum. searchsortedq diversity top1000. groupbyyear sex. applygetquantilecount diversity diversity. unstacksex This resulting DataFrame diversity now has two time series one for each sex indexed by year.  This can be inspected in Python and plotted as before see Figure 27 In 401 diversity. head Out 401 sex FM year 1880 38 14 1881 38 14 1882 38 15 1883 39 15 1884 39 16 In 402 diversity. plottitleNumber of popular names in top 50 Number of popular names in top 50 250 tao 1900 1920 1940 1960 1980 2000 2020 year Figure 27.  Plot of diversity metric by year US Baby Names 18802010 39 As you can see girl names have always been more diverse than boy names and they have only become more so over time.  Further analysis of what exactly is driving the diversity like the increase of alternate spellings is left to the reader.  The Last letter Revolution In 2007 baby name researcher Laura Wattenberg pointed out on her website http www. babynamewizard. com that the distribution of boy names by final letter has changed significantly over the last 100 years.  To see this first aggregate all of the births in the full data set by year sex and final letter extract last letter from name column getlastletter lambda x1 lastletters names. name. mapgetlastletter lastletters. name lastletter table names. pivottablebirths rowslastletters colssex year aggfuncsum Then select out three representative years spanning the history and print the first few rows In 404 subtable table. reindexcolumns1910 1960 2010 levelyear In 405 subtable. head Out405 sex year 1910 1960 2010 1910 1960 2010 lastletter 108376 691247 670605 977 5204 28438 NaN 694 450 411 3912 38859 49 946 482 15476 23125 6750 3729 2607 22111 262112 44398 133569 435013 313833 28655 178823 129012 Next normalize the table by total births to compute new table containing proportion of total births for each sex ending in each letter In 406 subtable. sum Out 406 sex year 1910 396416 1960 2022062 2010 1759010 1910 194198 1960 2132588 2010 1898382 In 407 letterprop subtable subtable. sum. astypefloat With the letter proportions now in hand can make bar plots for each sex broken down by year.  See Figure 28 import matplotlib. pyplot as plt 40 Chapter Introductory Examples fig axes plt. subplots2 figsize10 letterpropM. plotkindbar rot0 axaxes0 titleMale letterpropF. plotkindbar rot0 axaxes1 titleFemale legendFalse abcdefgdhijktimnopqrstuvwxydaz lastletter Female en abcde Ghijktmnopaqrstuvwx yz lastletter Figure 28.  Proportion of boy and girl names ending in each letter As you can see boy names ending in have experienced significant growth since the 1960s.  Going back to the full table created above again normalize by year and sex and select subset of letters for the boy names finally transposing to make each column time series In 410 letterprop table table. sum. astypefloat In 411 dnyts letterprop. ixd M. T In 412 dnyts. head Out 412 year 1880 1881 1882 1883 1884 0. 083055 0. 083247 0. 085340 0. 084066 0. 086120 0. 153213 0. 153214 0. 149560 0. 151646 0. 149915 0. 075760 0. 077451 0. 077537 0. 079144 0. 080405 With this DataFrame of time series in hand can make plot of the trends over time again with its plot method see Figure 29 In 414 dnyts. plot US Baby Names 18802010 41 0. 09380 1900 1920 1940 1960 1980 2000 2020 ear Figure 29.  Proportion of boys born with names ending in dny over time Boy names that became girl names and vice versa Another fun trend is looking at boy names that were more popular with one sex earlier in the sample but have changed sexes in the present.  One example is the name Lesley or Leslie.  Going back to the top1000 dataset compute list of names occurring in the dataset starting with les1 In 415 In 416 In 417 In 418 Out 418 allnames top1000. name. unique mask np. arraylesl in x. lower for in allnames lesley like allnamesmask lesley like arrayLeslie Lesley Leslee Lesli Lesly dtypeobject From there we can filter down to just those names and sum births grouped by name to see the relative frequencies In 419 filtered top1000top1000. name. isinlesley like In 420 filtered. groupbyname. births. sum Out 420 name Leslee 1082 Lesley 35022 Lesli 929 Leslie 370429 Lesly 10067 Name births Next lets aggregate by sex and year and normalize within year 42 Chapter2 Introductory Examples In 421 table In 422 table In 423 table.  Out 423 sex year 2006 2007 2008 2009 2010 1.  1.  1.  1.  1.  NaN NaN NaN NaN NaN filtered. pivottablebirths rowsyear colssex aggfuncsum table. divtable. sum1 axis0 tail Lastly its now easy to make plot of the breakdown by sex over time Figure 210 In 425 table. plotstyleM O80 1920 1940 year 1960 1980 2000 2020 Figure 210.  Proportion of malefemale Lesleylike names over time Conclusions and The Path Ahead The examples in this chapter are rather simple but theyre here to give you bit of flavor of what sorts of things you can expect in the upcoming chapters.  The focus of this book is on tools as opposed to presenting more sophisticated analytical methods.  Mastering the techniques in this book will enable you to implement your own analyses assuming you know what you want to do in short order.  Conclusions and The Path Ahead 43 CHAPTER IPython An Interactive Computing and Development Environment Act without doing work without effort.  Think of the small as large and the few as many.  Confront the difficult while it is still easy accomplish the great task by series of small acts.  Laozi People often ask me What is your Python development environment My answer is almost always the same IPython and text editor.  You may choose to substitute an Integrated Development Environment IDE for text editor in order to take advantage of more advanced graphical tools and code completion capabilities.  Even if so strongly recommend making Python an important part of your workflow.  Some IDEs even provide Python integration so its possible to get the best of both worlds.  The Python project began in 2001 as Fernando Prezs side project to make better interactive Python interpreter.  In the subsequent 11 years it has grown into whats widely considered one of the most important tools in the modern scientific Python computing stack.  While it does not provide any computational or data analytical tools by itself IPython is designed from the ground up to maximize your productivity in both interactive computing and software development.  It encourages an executeexplore workflow instead of the typical editcompilerun workflow of many other programming languages.  It also provides very tight integration with the operating systems shell and file system.  Since much of data analysis coding involves exploration trial and error and iteration Python will in almost all cases help you get the job done faster.  Of course the Python project now encompasses great deal more than just an en hanced interactive Python shell.  It also includes rich GUI console with inline plotting webbased interactive notebook format and lightweight fast parallel computing engine.  And as with so many other tools designed for and by programmers it is highly customizable.  Ill discuss some of these features later in the chapter.  45 Since IPython has interactivity at its core some of the features in this chapter are dif ficult to fully illustrate without live console.  If this is your first time learning about IPython recommend that you follow along with the examples to get feel for how things work.  As with any keyboarddriven consolelike environment developing mus clememory for the common commands is part of the learning curve.  Va oe Many parts of this chapter for example profiling and debugging can 43 be safely omitted on first reading as they are not necessary for under standing the rest of the book.  This chapter is intended to provide standalone rich overview of the functionality provided by IPython.  Python Basics You can launch Python on the command line just like launching the regular Python interpreter except with the ipython command ipython Python 2. 7. 2 default May 27 2012 12 Type copyright credits or license for more information.  IPython 0. 12 An enhanced Interactive Python.  Introduction and overview of IPythons features.  quickref Quick reference.  help Pythons own help system.  object Details about object use object for extra details.  In a5 In Out2 You can execute arbitrary Python statements by typing them in and pressing return.  When typing just variable into Python it renders string representation of the object In 541 import numpy as np In 542 data randn for in range7 In 543 data Out 543 0. 6900018528091594 1. 0015434424937888 0. 5030873913603446 0. 6222742250596455 0. 9211686080130108 0. 726213492660829 0. 2228955458351768 46 Chapter3 IPython An Interactive Computing and Development Environment Many kinds of Python objects are formatted to be more readable or prettyprinted which is distinct from normal printing with print.  If you printed dict like the above in the standard Python interpreter it would be much less readable from numpy. random import randn data randn for in range7 print data 1. 5948255432744511 0. 10569006472787983 1. 972367135977295 0. 15455217573074576 0. 24058577449429575 1. 2904897053651216 0. 3308507317325902 IPython also provides facilities to make it easy to execute arbitrary blocks of code via somewhat glorified copyandpasting and whole Python scripts.  These will be dis cussed shortly.  Tab Completion On the surface the Python shell looks like cosmetically slightlydifferent interactive Python interpreter.  Users of Mathematica may find the enumerated input and output prompts familiar.  One of the major improvements over the standard Python shell is tab completion feature common to most interactive data analysis environments.  While entering expressions in the shell pressing Tab will search the namespace for any variables objects functions etc.  matching the characters you have typed so far In anapple 27 In anexample 42 In anTab anapple and anexample any In this example note that Python displayed both the two variables defined as well as the Python keyword and and builtin function any.  Naturally you can also complete methods and attributes on any object after typing period In In b. Tab b. append b. extend b. insert b. remove b. sort b. count b.  index b. pop b. reverse The same goes for modules In import datetime In datetime. Tab datetime. date datetime . MAXYEAR datetime.  timedelta datetime.  datetime datetime . MINYEAR datetime. tzinfo datetime. datetimeCAPI datetime. time Python Basics 47 Note that IPython by default hides methods and attributes starting with underscores such as magic methods and internal private methods ia and attributes in order to avoid cluttering the display and confusing new Python users.  These too can be tabcompleted but you must first type an underscore to see them.  If you prefer to always see such methods in tab completion you can change this setting in the Python configu ration.  Tab completion works in many contexts outside of searching the interactive namespace and completing object or module attributes.  When typing anything that looks like file path even in Python string pressing Tab will complete anything on your com puters file system matching what youve typed In bookscriptsTab bookscriptscprofexample. py bookscriptsipythonscripttest. py bookscriptsipythonbug. py bookscriptsprofmod. py In path bookscriptsTab bookscriptscprofexample. py bookscriptsipythonscripttest. py bookscriptsipythonbug. py bookscriptsprofmod. py Combined with the run command see later section this functionality will undoubt edly save you many keystrokes.  Another area where tab completion saves time is in the completion of function keyword arguments including the sign.  Introspection Using question mark before or after variable will display some general informa tion about the object In 545 Type list String Form1 Length Docstring list new empty list listiterable new list initialized from iterables items This is referred to as object introspection.  If the object is function or instance method the docstring if defined will also be shown.  Suppose wed written the following func tion def addnumbersa Add two numbers together Returns thesum type of arguments 48 Chapter3 IPython An Interactive Computing and Development Environment return Then using shows us the docstring In 547 addnumbers Type function String Formfunction addnumbers at Ox5fad848 File bookscriptsipythoninput5465473012eeb65 Definition addnumbersa Docstring Add two numbers together Returns thesum type of arguments Using will also show the functions source code if possible In 548 addnumbers Type function String Formfunction addnumbers at 0x5fad848 File bookscriptsipythoninput5465473012eeb65 Definition addnumbersa Source def addnumbersa Add two numbers together Returns thesum type of arguments return has final usage which is for searching the Python namespace in manner similar to the standard UNIX or Windows command line.  number of characters combined with the wildcard will show all names matching the wildcard expression.  For ex ample we could get list of all functions in the top level NumPy namespace containing load In 549 np. load np.  load np.  loads np.  loadtxt np. pkgload The run Command Any file can be run as Python program inside the environment of your IPython session using the run command.  Suppose you had the following simple script stored in ipy thonscripttest. py def fx return a5 Python Basics 49 b6 7. 5 result fa This can be executed by passing the file name to run In 550 run ipythonscripttest. py The script is run in an empty namespace with no imports or other variables defined so that the behavior should be identical to running the program on the command line using python script. py.  All of the variables imports functions and globals defined in the file up until an exception if any is raised will then be accessible in the Python shell In 551 Out551 7. 5 In 552 result Out552 1. 4666666666666666 If Python script expects command line arguments to be found in sys. argv these can be passed after the file path as though run on the command line.  Vs sO Should you wish to give script access to variables already defined in Ss the interactive Python namespace use run instead of plain run.  Interrupting running code Pressing CtrlC while any code is running whether script through run or long running command will cause KeyboardInterrupt to be raised.  This will cause nearly all Python programs to stop immediately except in very exceptional cases.  When piece of Python code has called into some compiled extension ta modules pressing Ctr1C will not cause the program execution to stop immediately in all cases.  In such cases you will have to either wait until control is returned to the Python interpreter or in more dire circum stances forcibly terminate the Python process via the OS task manager.  Executing Code from the Clipboard quickanddirty way to execute code in Python is via pasting from the clipboard.  This might seem fairly crude but in practice it is very useful.  For example while de veloping complex or timeconsuming application you may wish to execute script piece by piece pausing at each stage to examine the currently loaded data and results.  Or you might find code snippet on the Internet that you want to run and play around with but youd rather not create new . py file for it.  50 Chapter3 IPython An Interactive Computing and Development Environment Code snippets can be pasted from the clipboard in many cases by pressing Ctr1lShift V.  Note that it is not completely robust as this mode of pasting mimics typing each line into IPython and line breaks are treated as return.  This means that if you paste code with an indented block and there is blank line Python will think that the in dented block is over.  Once the next line in the block is executed an IndentationEr ror will be raised.  For example the following code y7 if x5 xt1 will not work if simply pasted In In y7 In if wcoie In y8 IndentationError unexpected indent If you want to paste code into IPython try the paste and cpaste magic functions.  As the error message suggests we should instead use the paste and cpaste magic functions.  paste takes whatever text is in the clipboard and executes it as single block in the shell In paste x5 y7 if x5 y8 End pasted text Depending on your platform and how you installed Python theres tSs small chance that paste will not work.  Packaged distributions like EPDFree as described in in the intro should not be problem.  cpaste is similar except that it gives you special prompt for pasting code into In cpaste Pasting code enter alone on the line to stop or use CtrlD.  2x 7y7 if Python Basics 51 With the cpaste block you have the freedom to paste as much code as you like before executing it.  You might decide to use cpaste in order to look at the pasted code before executing it.  If you accidentally paste the wrong code you can break out of the cpaste prompt by pressing Ctr1C.  Later Ill introduce the IPython HTML Notebook which brings new level of sophis tication for developing analyses blockbyblock in browserbased notebook format with executable code cells.  Python interaction with editors and IDEs Some text editors such as Emacs and vim have 3rd party extensions enabling blocks of code to be sent directly from the editor to running Python shell.  Refer to the IPython website or do an Internet search to find out more.  Some IDEs such as the PyDev plugin for Eclipse and Python Tools for Visual Studio from Microsoft and possibly others have integration with the Python terminal ap plication.  If you want to work in an IDE but dont want to give up the IPython console features this may be good option for you.  Keyboard Shortcuts IPython has many keyboard shortcuts for navigating the prompt which will be familiar to users of the Emacs text editor or the UNIX bash shell and interacting with the shells command history see later section.  Table 31 summarizes some of the most commonly used shortcuts.  See Figure 31 for an illustration of few of these such as cursor move ment.  Cb Cf In 27 avariable In 27 avari Ck Ca Ce In 27 Cu Figure 31.  Illustration of some of IPythons keyboard shortcuts 52 Chapter3 IPython An Interactive Computing and Development Environment Table 31.  Command Standard IPython Keyboard Shortcuts Description Ctrl1p or uparrow Search backward in command history for commands starting with currentlyentered text Ctrlnordownarrow Search forward in command history for commands starting with currentlyentered text Ctrlr Readlinestyle reverse history search partial matching Ctr1Shiftv Paste text from clipboard Ctrlc Interrupt currentlyexecuting code Ctrla Move cursor to beginning of line Ctrle Move cursor to end of line Ctrlk Delete text from cursor until end of line Ctrlu Discard all text on current line Ctrlf Move cursor forward one character Ctrlb Move cursor back one character Ctrl1 Clear screen Exceptions and Tracebacks If an exception is raised while runing script or executing any statement Python will by default print full call stack trace traceback with few lines of context around the position at each point in the stack.  In 553 run cho3ipythonbug. py AssertionError Traceback most recent call last homewesmcodeipythonIPythonutilspy3compat. pyc in execfilefname where 176 else 177 filename fname 178 builtin. execfilefilename where bookscriptsch03ipythonbug. py in module 13 throwsanexception 14 15 calling things bookscriptsch03ipythonbug. py in calling things 11 def calling things 12 worksfine 13 throwsanexception 14 15 calling things bookscriptsch03ipythonbug. py in throwsanexception a5 b6 asserta 10 10 11 def calling things AssertionError Python Basics 53 Having additional context by itself is big advantage over the standard Python inter preter which does not provide any additional context.  The amount of context shown can be controlled using the xmode magic command from minimal same as the stan dard Python interpreter to verbose which inlines function argument values and more.  As you will see later in the chapter you can step into the stack using the debug or pdb magics after an error has occurred for interactive postmortem debugging.  Magic Commands IPython has many special commands known as magic commands which are de signed to facilitate common tasks and enable you to easily control the behavior of the IPython system.  magic command is any command prefixed by the the percent symbol .  For example you can check the execution time of any Python statement such as matrix multiplication using the timeit magic function which will be discussed in more detail later In 554 np. random. randn100 100 In 555 timeit np. dota 10000 loops best of 69. 1 us per loop Magic commands can be viewed as command line programs to be run within the IPy thon system.  Many of them have additional command line options which can all be viewed as you might expect using In reset Resets the namespace by removing all names defined by the user.  Parameters force reset without asking for confirmation.  Soft reset Only clears your namespace leaving history intact.  References to objects may be kept.  By default without this option we do hard reset giving you new session and removing all references to objects from the current session.  Examples In in ip. userns Out8 True In reset In in ip. userns Out1 False 54 Chapter3 IPython An Interactive Computing and Development Environment Magic functions can be used by default without the percent sign as long as no variable is defined with the same name as the magic function in question.  This feature is called automagic and can be enabled or disabled using automagic.  Since IPythons documentation is easily accessible from within the system encourage you to explore all of the special commands available by typing quickref or magic.  will highlight few more of the most critical ones for being productive in interactive computing and Python development in Python.  Table 32.  Frequentlyused IPython Magic Commands Command Description quickref Display the IPython Quick Reference Card magic Display detailed documentation for all of the available magic commands debug Enter the interactive debugger at the bottom of the last exception traceback ahist Print command input and optionally output history pdb Automatically enter debugger after any exception zpaste Execute preformatted Python code from clipboard cpaste Open special prompt for manually pasting Python code to be executed mreset Delete all variables names defined in interactive namespace page OBJECT Pretty print the object and display it through pager run script.  py prun statement stime statement timeit statement Run Python script inside IPython Execute statement with cProfile and report the profiler output Report the execution time of single statement Run statement multiple times to compute an emsemble average execution time.  Useful for timing code with very short execution time Awho zwhols whos Displayvariablesdefinedininteractive namespace with varying levels ofinformation verbosity xdel variable Delete variable and attempt to clear any references to the object in the IPython internals Qtbased Rich GUI Console The IPython team has developed Qt frameworkbased GUI console designed to wed the features of the terminalonly applications with the features provided by rich text widget like embedded images multiline editing and syntax highlighting.  If you have either PyQt or PySide installed the application can be launched with inline plotting by running this on the command line ipython qtconsole pylabinline The Qt console can launch multiple IPython processes in tabs enabling you to switch between tasks.  It can also share process with the Python HTML Notebook applica tion which Ill highlight later.  IPython Basics 55 IPython File Edit View Kernel Magic Window Help For more information type helppylab.  In img plt. imreadbookscriptsch03stinkbug. png In imshowimg Cut2 matplotlib. image. AxesImage at Ox42ece50 50 100 150 200 250 300 350 Qo 100 200 300 400 In plot randn1000 . cumsum cut3 matplotlib. lines. Line2D at 0x45406d0 Figure 32.  IPython Qt Console Matplotlib Integration and Pylab Mode Part of why IPython is so widely used in scientific computing is that it is designed as companion to libraries like matplotlib and other GUI toolkits.  Dont worry if you have never used matplotlib before it will be discussed in much more detail later in this book.  If you create matplotlib plot window in the regular Python shell youll be sad to find that the GUI event loop takes control of the Python session until the plot window is closed.  That wont work for interactive data analysis and visualization so IPython has 56 Chapter3 IPython An Interactive Computing and Development Environment implemented special handling for each GUI framework so that it will work seamlessly with the shell.  The typical way to launch Python with matplotlib integration is by adding the pylab flag two dashes.  ipython pylab This will cause several things to happen.  First Python will launch with the default GUI backend integration enabled so that matplotlib plot windows can be created with no issues.  Secondly most of NumPy and matplotlib will be imported into the top level interactive namespace to produce an interactive computing environment reminiscent of MATLAB and other domainspecific scientific computing environments.  Its possi ble to do this setup by hand by using gui too try running gui to find out how.  .  svn python wos File Edt View Bookmarks Settings Help Hane Adj Close Length 252 fin spyclose plot Outl motplotlib axes AxesSubplot at 64496491G in pit.  flouret jOutl eo Gmoteletl ib flgure. Figure ot 8x489ee18 Hin spycloseplot Qut9 metplotlib.  axes Axessubplot ot BxdBaSada CiB1 exit Lf58 Drepbes ooukovn Lpythan pyl abq Puthon 2. 7. 2 1EPD 7.  12 e4bstI default ty 2611.  15 7k Si Type copyright.  credits or License for more information.  BRuthon 8. 13. dey An enhenced Interactive Python.  intreauict on at and overview of TPuthan features.  Julohrer Quick refer Pythons aun nneip sustem.  pevects Details about object.  use object for extra deta Welcome to pylab matplotiibbased Python environnent backend For nore information tune helppulab.  Ww wa 090 plotnp.  random randn 166 .  cumsun poeta Cmatplotlib. lines. Lino2D at Gx3fdsfdB ay oC BvYa C2 pit.  flouret ut2 motplotlib.  fiqure. Figure at Bx3fesdsa fin 30 from pondas.  io.  data import getdatayahoo spyclose getdatayshoot SPY JLAdj Close nm CS spyclose. plot utS motplotlib axes AxesSubplot at Gx3Fff2d9 nm pn fn 62 Figure Figure 33.  Pylab mode IPython with matplotlib windows IPython Basics 57 Using the Command History IPython maintains small ondisk database containing the text of each command that you execute.  This serves various purposes Searching completing and executing previouslyexecuted commands with mini mal typing Persisting the command history between sessions.  Logging the inputoutput history to file Searching and Reusing the Command History Being able to search and execute previous commands is for many people the most useful feature.  Since Python encourages an iterative interactive code development workflow you may often find yourself repeating the same commands such as run command or some other code snippet.  Suppose you had run In7 run firstsecondthirddatascript. py and then explored the results of the script assuming it ran successfully only to find that you made an incorrect calculation.  After figuring out the problem and modifying datascript. py you can start typing few letters of the run command then press either the Ctr1P key combination or the up arrow key.  This will search the command history for the first prior command matching the letters you typed.  Pressing either Ctr1P or up arrow multiple times will continue to search through the history.  If you pass over the command you wish to execute fear not.  You can move forward through the command history by pressing either Ctr1N or down arrow.  After doing this few times you may start pressing these keys without thinking Using Ctr1R gives you the same partial incremental searching capability provided by the readline used in UNIXstyle shells such as the bash shell.  On Windows read line functionality is emulated by IPython.  To use this press Ctr1R then type few characters contained in the input line you want to search for In acommand foox reverseisearchcom acommand foox Pressing Ctr1R will cycle through the history for each line matching the characters you ve typed.  Input and Output Variables Forgetting to assign the result of function call to variable can be very annoying.  Fortunately Python stores references to both the input the text that you type and output the object that is returned in special variables.  The previous two outputs are stored in the one underscore and two underscores variables respectively 58 Chapter3 IPython An Interactive Computing and Development Environment In 556 27 Out556 134217728 In 557 Out557 134217728 Input variables are stored in variables named like ixX where is the input line number.  For each such input variables there is corresponding output variable X.  So after input line 27 say there will be two new variables 27 for the output and i27 for the input.  In 26 foo bar In 27 foo Out27 bar In 28 i27 Out28 ufoo In 29 27 Out29 bar Since the input variables are strings that can be executed again using the Python exec keyword In 30 exec i27 Several magic functions allow you to work with the input and output history.  hist is capable of printing all or part of the input history with or without line numbers.  reset is for clearing the interactive namespace and optionally the input and output caches.  The xdel magic function is intended for removing all references to particu lar object from the Python machinery.  See the documentation for both of these magics for more details.  When working with very large data sets keep in mind that IPythons ta input and output history causes any object referenced there to not be garbage collected freeing up the memory even if you delete the vari ables from the interactive namespace using the del keyword.  In such cases careful usage of xdel and reset can help you avoid running into memory problems.  Logging the Input and Output IPython is capable of logging the entire console session including input and output.  Logging is turned on by typing logstart In logstart Activating autologging.  Current session state plus future input saved.  Filename ipythonlog. py Mode rotate Output logging False Raw input log False Using the Command History 59 Timestamping False State active IPython logging can be enabled at any time and it will record your entire session in cluding previous commands.  Thus if you are working on something and you decide you want to save everything you did you can simply enable logging.  See the docstring of logstart for more options including changing the output file path as well as the companion functions logoff logon logstate and logstop.  Interacting with the Operating System Another important feature of Python is that it provides very strong integration with the operating system shell.  This means among other things that you can perform most standard command line actions as you would in the Windows or UNIX Linux OS shell without having to exit IPython.  This includes executing shell commands changing directories and storing the results of command in Python object list or string.  There are also simple shell command aliasing and directory bookmarking features.  See Table 33 for summary of magic functions and syntax for calling shell commands.  Ill briefly visit these features in the next few sections.  Table 33.  IPython systemrelated commands Command Description cmd Execute cmd in the system shell output cmd args Run cmd and store the stdout in output walias aliasname cmd Define analias for system shell command bookmark Utilize IPythons directory bookmarking system wcd directory Change system working directory to passed directory pwd Return the current system working directory wpushd directory Place current directory on stack and change to target directory popd Change to directory popped off the top of the stack dirs Return list containing the current directory stack wdhist Print the history of visited directories env Return the system environment variables as dict Shell Commands and Aliases Starting line in Python with an exclamation point or bang tells Python to execute everything after the bang in the system shell.  This means that you can delete files using rm or del depending on your OS change directories or execute any other process.  Its even possible to start processes that take control away from IPython even another Python interpreter 60 Chapter3 Python An Interactive Computing and Development Environment In python Python 2. 7. 2 EPD 7. 12 64bit default Jul 2011 51 GCC 4. 1. 2 20080704 Red Hat 4. 1. 244 on linux2 Type packages demo or enthought for more information.  The console output of shell command can be stored in variable by assigning the escaped expression to variable.  For example on my Linuxbased machine connected to the Internet via ethernet can get my IP address as Python variable In ipinfo ifconfig etho grep inet In ipinfo0. strip Out2 inet addr192. 168. 1. 137 Bcast192. 168. 1. 255 Mask255. 255. 255. 0 The returned Python object ipinfo is actually custom list type containing various versions of the console output.  IPython can also substitute in Python values defined in the current environment when using .  To do this preface the variable name by the dollar sign In foo test In 1s foo test4. py test. py test. xml The alias magic function can define custom shortcuts for shell commands.  Asa simple example In alias 11 ls In 11 usr total 332 drwxrxrx root root 69632 20120129 bin drwxrxrx root root 4096 20100823 games drwxrxrx 123 root root 20480 20111226 include drwxrxrx 265 root root 126976 20120129 lib drwxrxrx 44 root root 69632 20111226 1ib32 lrwxrwxrwx root root 20100823 lib64 lib drwxrxrx 15 root root 4096 20111013 local drwxrxrx root root 12288 20120112 sbin drwxrxrx 387 root root 12288 20111104 share drwxrwsrx 24 root src 4096 20110717 src Multiple commands can be executed just as on the command line by separating them with semicolons In 558 alias testalias cd ch08 1s cd . .  In 559 testalias macrodata. csv spx. csv tips. csv Youll notice that Python forgets any aliases you define interactively as soon as the session is closed.  To create permanent aliases you will need to use the configuration system.  See later in the chapter.  Interacting with the Operating System 61 Directory Bookmark System IPython has simple directory bookmarking system to enable you to save aliases for common directories so that you can jump around very easily.  For example Im an avid user of Dropbox so can define bookmark to make it easy to change directories to my Dropbox In bookmark db homewesmDropbox Once Ive done this when use the cd magic can use any bookmarks Ive defined In cd db bookmarkdb homewesmDropbox homewesmDropbox If bookmark name conflicts with directory name in your current working directory you can use the flag to override and use the bookmark location.  Using the option with bookmark lists all of your bookmarks In bookmark Current bookmarks db homewesmDropbox Bookmarks unlike aliases are automatically persisted between IPython sessions.  Software Development Tools In addition to being comfortable environment for interactive computing and data exploration Python is well suited as software development environment.  In data analysis applications its important first to have correct code.  Fortunately Python has closely integrated and enhanced the builtin Python pdb debugger.  Secondly you want your code to be fast.  For this Python has easytouse code timing and profiling tools.  will give an overview of these tools in detail here.  Interactive Debugger IPythons debugger enhances pdb with tab completion syntax highlighting and context for each line in exception tracebacks.  One of the best times to debug code is right after an error has occurred.  The debug command when entered immediately after an ex ception invokes the postmortem debugger and drops you into the stack frame where the exception was raised In run cho3ipythonbug. py AssertionError Traceback most recent call last homewesmbookscriptscho3ipythonbug. py in module 13 throwsanexception 14 15 calling things homewesmbookscriptscho3ipythonbug. py in calling things 62 Chapter3 IPython An Interactive Computing and Development Environment 11 def calling things 12 works fine 13 throwsanexception 14 15 calling things homewesmbookscriptsch03ipythonbug. py in throwsanexception a5 asserta 10 10 11 def calling things AssertionError In debug homewesmbookscriptsch03ipythonbug. py9throwsanexception asserta 10 10 ipdb Once inside the debugger you can execute arbitrary Python code and explore all of the objects and data which have been kept alive by the interpreter inside each stack frame.  By default you start in the lowest level where the error occurred.  By pressing up and down you can switch between the levels of the stack trace ipdb homewesmbookscriptsch03ipythonbug. py13calling things 12 works fine 13 throwsanexception 14 Executing the pdb command makes it so that Python automatically invokes the de bugger after any exception mode that many users will find especially useful.  Its also easy to use the debugger to help develop code especially when you wish to set breakpoints or step through the execution of function or script to examine the state at each stage.  There are several ways to accomplish this.  The first is by using run with the flag which invokes the debugger before executing any code in the passed script.  You must immediately press step to enter the script In run cho3ipythonbug. py Breakpoint at homewesmbookscriptscho3ipythonbug. py1 NOTE Enter at the ipdb prompt to start your script.  string1module ipdb Call homewesmbookscriptsch03ipythonbug. py1module def works fine a5 b6 Software Development Tools 63 After this point its up to you how you want to work your way through the file.  For example in the above exception we could set breakpoint right before calling the works fine method and run the script until we reach the breakpoint by pressing continue ipdb 12 ipdb homewesmbookscriptsch03ipythonbug. py12calling things 11 def calling things 12 works fine 13 throwsanexception At this point you can step into works fine or execute works fine by pressing next to advance to the next line ipdb homewesmbookscriptsch03ipythonbug. py13calling things 12 works fine 13 throwsanexception 14 Then we could step into throwsanexception and advance to the line where the error occurs and look at the variables in the scope.  Note that debugger commands take precedence over variable names in such cases preface the variables with to examine their contents.  ipdb Call homewesmbookscriptsch03ipythonbug. py6throwsanexception def throwsanexception a5 ipdb homewesmbookscriptsch03ipythonbug. py7throwsanexception def throws anexception 700 a5 ipdb homewesmbookscriptsch03ipythonbug. py8throwsanexception a5 asserta 10 ipdb homewesmbookscriptsch03ipythonbug. py9throwsanexception asserta 10 10 ipdb ipdb 64 Chapter3 IPython An Interactive Computing and Development Environment Becoming proficient in the interactive debugger is largely matter of practice and ex perience.  See Table 34 for full catalogue of the debugger commands.  If you are used to an IDE you might find the terminaldriven debugger to be bit bewildering at first but that will improve in time.  Most of the Python IDEs have excellent GUI debuggers but it is usually significant productivity gain to remain in Python for your debugging.  Table 34.  IPython debugger commands Command help help command continue quit break number pathtofile. pynumber step next up down args debug statement 1ist statement where Action Display command list Show documentation for command Resume program execution Exit debugger without executing any more code Set breakpoint at number in current file Set breakpoint at line number in specified file Step into function call Execute current line and advance to next line at current level Move updown in function call stack Show arguments for current function Invoke statement statement in new recursive debugger Show current position and context at current level of stack Print full stack trace with context at current position Other ways to make use of the debugger There are couple of other useful ways to invoke the debugger.  The first is by using special settrace function named after pdb. settrace which is basically poor mans breakpoint.  Here are two small recipes you might want to put somewhere for your general use potentially adding them to your IPython profile as do def settrace from IPython. core. debugger import Pdb PdbcolorschemeLinux. settracesys. getframe. fback def debugf args kwargs from IPython. core. debugger import Pdb pdb PdbcolorschemeLinux return pdb. runcallf args kwargs The first function settrace is very simple.  Put settrace anywhere in your code that you want to stop and take look around for example right before an exception occurs In run cho3ipythonbug. py homewesmbookscriptsch03ipythonbug. py16calling things 15 settrace Software Development Tools 65 16 throwsanexception 17 Pressing continue will cause the code to resume normally with no harm done.  The debug function above enables you to invoke the interactive debugger easily on an arbitrary function call.  Suppose we had written function like def fx z1 tmp xty return tmp and we wished to step through its logic.  Ordinarily using would look like z3.  To instead step into pass as the first argument to debug followed by the po sitional and keyword arguments to be passed to In debugf z3 ipythoninput2F def fx aesay tmp xty return tmp ipdb find that these two simple recipes save me lot of time on daytoday basis.  Lastly the debugger can be used in conjunction with run.  By running script with run you will be dropped directly into the debugger ready to set any breakpoints and start the script In run cho3ipythonbug. py Breakpoint at homewesmbookscriptscho3ipythonbug. py1 NOTE Enter at the ipdb prompt to start your script.  string1module ipdb Adding with line number starts the debugger with breakpoint set already In run b2 ch03ipythonbug. py Breakpoint at homewesmbookscriptscho3ipythonbug. py2 NOTE Enter at the ipdb prompt to start your script.  string1module ipdb homewesmbookscriptsch03ipythonbug. py2worksfine def works fine a5 b6 ipdb 66 Chapter3 IPython An Interactive Computing and Development Environment Timing Code time and timeit For largerscale or longerrunning data analysis applications you may wish to measure the execution time of various components or of individual statements or function calls.  You may want report of which functions are taking up the most time in complex process.  Fortunately Python enables you to get this information very easily while you are developing and testing your code.  Timing code by hand using the builtin time module and its functions time. clock and time. time is often tedious and repetitive as you must write the same uninteresting boilerplate code import time start time. time for in rangeiterations some code to run here elapsed per time. time start iterations Since this is such common operation Python has two magic functions time and timeit to automate this process for you.  time runs statement once reporting the total execution time.  Suppose we had large list of strings and we wanted to compare different methods of selecting all strings starting with particular prefix.  Here is simple list of 700000 strings and two identical methods of selecting only the ones that start with foo very large list of strings strings foo foobar baz qux python Guido Van Rossum 100000 method1 for in strings if x. startswithfoo method2 for in strings if x3 foo It looks like they should be about the same performancewise right We can check for sure using time In 561 time methoda for in strings if x. startswithfoo CPU times user 0. 19 sys 0. 00 total 0. 19 Wall time 0. 19 In 562 time method2 for in strings if x3 foo CPU times user 0. 09 sys 0. 00 total 0. 09 Wall time 0. 09 The Wall time is the main number of interest.  So it looks like the first method takes more than twice as long but its not very precise measurement.  If you try timeing those statements multiple times yourself youll find that the results are somewhat variable.  To get more precise measurement use the timeit magic function.  Given an arbitrary statement it has heuristic to run statement multiple times to produce fairly accurate average runtime.  In 563 timeit for in strings if x. startswithfoo 10 loops best of 159 ms per loop Software Development Tools 67 In 564 timeit for in strings if x3 foo 10 loops best of 59. 3 ms per loop This seemingly innocuous example illustrates that it is worth understanding the per formance characteristics of the Python standard library NumPy pandas and other libraries used in this book.  In largerscale data analysis applications those milliseconds will start to add up timeit is especially useful for analyzing statements and functions with very short ex ecution times even at the level of microseconds 1le6 seconds or nanoseconds le9 seconds.  These may seem like insignificant amounts of time but of course 20 mi crosecond function invoked million times takes 15 seconds longer than micro second function.  In the above example we could very directly compare the two string operations to understand their performance characteristics In 565 foobar In 566 foo In 567 timeit x. startswithy 1000000 loops best of 267 ns per loop In 568 timeit x3 10000000 loops best of 147 ns per loop Basic Profiling prun and run Profiling code is closely related to timing code except it is concerned with determining where time is spent.  The main Python profiling tool is the cProfile module which is not specific to Python at all.  cProfile executes program or any arbitrary block of code while keeping track of how much time is spent in each function.  common way to use cProfile is on the command line running an entire program and outputting the aggregated time per function.  Suppose we had simple script which does some linear algebra in loop computing the maximum absolute eigenvalues of series of 100 100 matrices import numpy as np from numpy. linalg import eigvals def runexperiment niter100 100 results for in xrangeniter mat np. random. randnK maxeigenvalue np. abseigvalsmat . max results.  appendmaxeigenvalue return results someresults runexperiment print Largest one we saw np. maxsomeresults 68 Chapter3 Python An Interactive Computing and Development Environment Dont worry if you are not familiar with NumPy.  You can run this script through cProfile by running the following in the command line python cProfile cprofexample. py If you try that youll find that the results are outputted sorted by function name.  This makes it bit hard to get an idea of where the most time is spent so its very common to specify sort order using the flag python cProfile cumulative cprofexample. py Largest one we saw 11. 923204422 15116 function calls 14927 primitive calls in 0. 720 seconds Ordered by cumulative time ncalls tottime percall cumtime percall filename linenofunction 0. 001 0. 001 0. 721 0. 721 cprofexample. py1module 100 0. 003 0. 000 0. 586 0. 006 linalg. py702eigvals 200 0. 572 0. 003 0. 572 0. 003 numpy. linalg. lapacklite. dgeev 0. 002 0. 002 0. 075 0. 075 init. py106module 100 0. 059 0. 001 0. 059 0. 001 method randn 0. 000 0. 000 0. 044 0. 044 addnewdocs. py9module 0. 001 0. 001 0. 037 0. 019 init. py1module 0. 003 0. 002 0. 030 0. 015 init. py2module 0. 000 0. 000 0. 030 0. 030 typecheck. py3module 0. 001 0. 001 0. 021 0. 021 init. py15module 0. 013 0. 013 0. 013 0. 013 numeric. py1module 0. 000 0. 000 0. 009 0. 009 init. py6module 0. 001 0. 001 0. 008 0. 008 init. py45module 262 0. 005 0. 000 0. 007 0. 000 functionbase. py3178addnewdoc 100 0. 003 0. 000 0. 005 0. 000 linalg. py162assertFinite Only the first 15 rows of the output are shown.  Its easiest to read by scanning down the cumtime column to see how much total time was spent inside each function.  Note that if function calls some other function the clock does not stop running.  cProfile records the start and end time of each function call and uses that to produce the timing.  In addition to the above commandline usage cProfile can also be used programmat ically to profile arbitrary blocks of code without having to run new process.  Python has convenient interface to this capability using the prun command and the option to run.  prun takes the same command line options as cProfile but will profile an arbitrary Python statement instead of whole .  py file In prun cumulative runexperiment 4203 function calls in 0. 643 seconds Ordered by cumulative time List reduced from 32 to due to restriction ncalls tottime percall cumtime percall filename linenofunction 0. 000 0. 000 0. 643 0. 643 string1module 0. 001 0. 001 0. 643 0. 643 cprofexample. py4runexperiment 100 0. 003 0. 000 0. 583 0. 006 linalg. py702eigvals Software Development Tools 69 200 0. 569 0. 003 0. 569 0. 003 numpy. linalg. lapacklite. dgeev 100 0. 058 0. 001 0. 058 0. 001 method randn 100 0. 003 0. 000 0. 005 0. 000 linalg. py162assertFinite 200 0. 002 0. 000 0. 002 0. 000 method all of numpy. ndarray objects Similarly calling run cumulative cprofexample. py has the same effect as the commandline approach above except you never have to leave Python.  Profiling Function LinebyLine In some cases the information you obtain from prun or another cProfilebased profile method may not tell the whole story about functions execution time or it may be so complex that the results aggregated by function name are hard to interpret.  For this case there is small library called lineprofiler obtainable via PyPI or one of the package management tools.  It contains an Python extension enabling new magic function lprun that computes linebylineprofiling of one or more functions.  You can enable this extension by modifying your Python configuration see the Python documentation or the section on configuration later in this chapter to include the following line list of dotted module names of IPython extensions to load.  c. TerminalIPythonApp. extensions lineprofiler line profiler can be used programmatically see the full documentation but it is perhaps most powerful when used interactively in IPython.  Suppose you had module profmod with the following code doing some NumPy array operations from numpy. random import randn def addandsumx added summed added. sumaxis1 return summed def callfunction randn1000 1000 randn1000 1000 return addandsumx If we wanted to understand the performance of the addandsum function prun gives us the following In 569 run profmod In 570 randn3000 3000 In 571 randn3000 3000 In 572 prun addandsumx function calls in 0. 049 seconds Ordered by internal time ncalls tottime percall cumtime percall filename linenofunction 0. 036 0. 036 0. 046 0. 046 profmod. py3addandsum 70 Chapter3 Python An Interactive Computing and Development Environment 0. 009 0. 009 0. 009 0. 009 method sum of numpy. ndarray objects 0. 003 0. 003 0. 049 0. 049 string1module 0. 000 0. 000 0. 000 0. 000 method disable of lsprof. Profiler objects This is not especially enlightening.  With the lineprofiler Python extension activa ted anew command lprun is available.  The only difference in usage is that we must instruct lprun which function or functions we wish to profile.  The general syntax is lprun funci func2 statementtoprofile In this case we want to profile addandsum so we run In 573 lprun addandsum addandsumx Timer unit 1e06 File bookscriptsprofmod. py Function addandsum at line Total time 0. 045936 Line Hits Time Per Hit Time Line Contents def addandsumx 36510 36510. 0 79. 5 added 9425 9425. 0 20. 5 summed added. sumaxis1 1. 0 0. 0 return summed Youll probably agree this is much easier to interpret.  In this case we profiled the same function we used in the statement.  Looking at the module code above we could call call function and profile that as well as addandsum thus getting full picture of the performance of the code In 574 lprun addandsum callfunction callfunction Timer unit 1e06 File bookscriptsprofmod. py Function addandsum at line Total time 0. 005526 Line Hits Time Per Hit Time Line Contents def addandsumx 4375 4375. 0 79. 2 added 1149 1149. 0 20. 8 summed added. sumaxis1 2. 0 0. 0 return summed File bookscriptsprofmod. py Function callfunction at line Total time 0. 121016 Line Hits Time Per Hit Time Line Contents def callfunction 57169 57169. 0 47. 2 randn1000 1000 10 58304 58304. 0 48. 2 randn1000 1000 11 5543 5543. 0 4. 6 return addandsumx As general rule of thumb tend to prefer prun cProfile for macro profiling and lprun lineprofiler for micro profiling.  Its worthwhile to have good under standing of both tools.  Software Development Tools 71 The reason that you have to specify explicitly the names of the functions you want to profile with lprun is that the overhead of tracing the 418 execution time of each line is significant.  Tracing functions that are not of interest would potentially significantly alter the profile results.  Python HTML Notebook Starting in 2011 the Python team led by Brian Granger built web technologybased interactive computational document format that is commonly known as the Python Notebook.  It has grown into wonderful tool for interactive computing and an ideal medium for reproducible research and teaching.  Ive used it while writing most of the examples in the book encourage you to make use of it too.  It has JSONbased .  ipynb document format that enables easy sharing of code output and figures.  Recently in Python conferences popular approach for demonstrations has been to use the notebook and post the . ipynb files online afterward for everyone to play with.  The notebook application runs as lightweight server process on the command line.  It can be started by running ipython notebook pylabinline NotebookApp Using existing profile dir uhomewesm. configipythonprofile default NotebookApp Serving notebooks from homewesmbookscripts NotebookApp The IPython Notebook is running at http127. 0. 0. 18888 NotebookApp Use ControlC to stop this server and shut down all kernels.  On most platforms your primary web browser will automatically open up to the note book dashboard.  In some cases you may have to navigate to the listed URL.  From there you can create new notebook and start exploring.  Since you use the notebook inside web browser the server process can run anywhere.  You can even securely connect to notebooks running on cloud service providers like Amazon EC2.  As of this writing new project NotebookCloud httpnotebookcloud . appspot. com makes it easy to launch notebooks on EC2.  Tips for Productive Code Development Using IPython Writing code in way that makes it easy to develop debug and ultimately use inter actively may be paradigm shift for many users.  There are procedural details like code reloading that may require some adjustment as well as coding style concerns.  As such most of this section is more of an art than science and will require some experimentation on your part to determine way to write your Python code that is effective and productive for you.  Ultimately you want to structure your code in way that makes it easy to use iteratively and to be able to explore the results of running program or function as effortlessly as possible.  have found software designed with 72 Chapter3 Python An Interactive Computing and Development Environment BD 127. 00. 18888sa0esdoed135447b269dade4gecsi77tyy 23 Lt aw Ply Notebook NotebookEx Last saved Jul 26 106 PM File Elites Viewoo Insert Callees Kernalecs Help iz Code import numpy as np import pandas as pd print Hello world Hello world tips pd.  readcsvbookscriptsch08tips.  csv tips.  head Tita bile sex smoker daytime sie efiesroiremaeie Sinnnar2 afio3e1eevae no Suninmer3 2101 a50vale nv Sin Dever szseeaaivae no Sun inner 3. 61 Female No Sun Dinner In img plt. imreadbookscriptsch03stinkbug.  png figurefigsize4 plt.  imshow img Out4 matplotlib. image. AxesImage at O0x7f465d3428510 50 Figure 34.  Python Notebook IPython in mind to be easier to work with than code intended only to be run as as standalone commandline application.  This becomes especially important when some thing goes wrong and you have to diagnose an error in code that you or someone else might have written months or years beforehand.  Tips for Productive Code Development Using IPython 73 Reloading Module Dependencies In Python when you type import somelib the code in somelib is executed and all the variables functions and imports defined within are stored in the newly created somelib module namespace.  The next time you type import somelib you will get reference to the existing module namespace.  The potential difficulty in interactive code development in Python comes when you say run script that depends on some other module where you may have made changes.  Suppose had the following code in testscript. py import somelib result somelib. getanswerx If you were to execute run testscript. py then modify somelib. py the next time you execute run testscript. py you will still get the old version of somelib because of Pythons loadonce module system.  This behavior differs from some other data anal ysis environments like MATLAB which automatically propagate code changes.  To cope with this you have couple of options.  The first way is to use Pythons builtin reload function altering testscript. py to look like the following import somelib reloadsomelib result somelib. getanswerx This guarantees that you will get fresh copy of some lib every time you run testscript. py.  Obviously if the dependencies go deeper it might be bit tricky to be inserting usages of reload all over the place.  For this problem Python has special dreload function not magic function for deep recursive reloading of modules.  If were to run import some lib then type dreloadsomelib it will attempt to reload somelib as well as all of its dependencies.  This will not work in all cases unfortunately but when it does it beats having to restart IPython.  Code Design Tips Theres no simple recipe for this but here are some highlevel principles have found effective in my own work.  1.  Since module or package may be imported in many different places in particular program Python caches modules code the first time it is imported rather than executing the code in the module every time.  Otherwise modularity and good code organization could potentially cause inefficiency in an application.  74 Chapter3 IPython An Interactive Computing and Development Environment Keep relevant objects and data alive Its not unusual to see program written for the command line with structure some what like the following trivial example from myfunctions import def fx return gx def main y7. 5 result if name main Do you see what might be wrong with this program if we were to run it in IPython After its done none of the results or objects defined in the main function will be ac cessible in the Python shell.  better way is to have whatever code is in main execute directly in the modules global namespace orintheif name main block if you want the module to also be importable.  That way when you run the code youll be able to look at all of the variables defined in main.  Its less meaningful in this simple example but in this book well be looking at some complex data analysis prob lems involving large data sets that you will want to be able to play with in IPython.  Flat is better than nested Deeply nested code makes me think about the many layers of an onion.  When testing or debugging function how many layers of the onion must you peel back in order to reach the code of interest The idea that flat is better than nested is part of the Zen of Python and it applies generally to developing code for interactive use as well.  Making functions and classes as decoupled and modular as possible makes them easier to test if you are writing unit tests debug and use interactively.  Overcome fear of longer files If you come from Java or another such language background you may have been told to keep files short.  In many languages this is sound advice long length is usually bad code smell indicating refactoring or reorganization may be necessary.  How ever while developing code using IPython working with 10 small but interconnected files under say 100 lines each is likely to cause you more headache in general than single large file or two or three longer files.  Fewer files means fewer modules to reload and less jumping between files while editing too.  have found maintaining larger modules each with high internal cohesion to be much more useful and pythonic.  After iterating toward solution it sometimes will make sense to refactor larger files into smaller ones.  Tips for Productive Code Development Using IPython 75 Obviously dont support taking this argument to the extreme which would to be to put all of your code in single monstrous file.  Finding sensible and intuitive module and package structure for large codebase often takes bit of work but it is especially important to get right in teams.  Each module should be internally cohesive and it should be as obvious as possible where to find functions and classes responsible for each area of functionality.  Advanced Python Features Making Your Own Classes IPythonfriendly IPython makes every effort to display consolefriendly string representation of any object that you inspect.  For many objects like dicts lists and tuples the builtin pprint module is used to do the nice formatting.  In userdefined classes however you have to generate the desired string output yourself.  Suppose we had the following sim ple class class Message def initself msg self. msg msg If you wrote this you would be disappointed to discover that the default output for your class isnt very nice In 576 MessageI have secret In 577 Out577 main. Message instance at 0x60ebbd8 IPython takes the string returned by the repr magic method by doing output reprobj and prints that to the console.  Thus we can adda simple repr method to the above class to get more helpful output class Message def initself msg self. msg msg def repr self return Message self. msg In 579 MessageI have secret In 580 Out580 Message have secret 76 Chapter3 Python An Interactive Computing and Development Environment Profiles and Configuration Most aspects of the appearance colors prompt spacing between lines etc.  and be havior of the Python shell are configurable through an extensive configuration system.  Here are some of the things you can do via configuration Change the color scheme Change how the input and output prompts look or remove the blank line after Out and before the next In prompt Change how the input and output prompts look Execute an arbitrary list of Python statements.  These could be imports that you use all the time or anything else you want to happen each time you launch IPython Enable Python extensions like the lprun magic in lineprofiler Define your own magics or system aliases All of these configuration options are specified in special ipythonconfig.  py file which will be found in the . configipython directory on UNIXlike systems and HOME . ipython directory on Windows.  Where your home directory is depends on your system.  Configuration is performed based on particular profile.  When you start IPy thon normally you load up by default the default profile stored in the pro file default directory.  Thus on my Linux OS the full path to my default Python configuration file is homewesm. configipythonprofiledefaultipythonconfig. py Dll spare you the gory details of whats in this file.  Fortunately it has comments de scribing what each configuration option is for so will leave it to the reader to tinker and customize.  One additional useful feature is that its possible to have multiple pro files.  Suppose you wanted to have an alternate Python configuration tailored for particular application or project.  Creating new profile is as simple is typing something like ipython profile create secretproject Once youve done this edit the config files in the newlycreated pro filesecretproject directory then launch Python like so ipython profilesecretproject Python 2. 7. 2 EPD 7. 12 64bit default Jul 2011 51 Type copyright credits or license for more information.  IPython 0. 13 An enhanced Interactive Python.  Introduction and overview of IPythons features.  quickref Quick reference.  help Pythons own help system.  object Details about object use object for extra details.  IPython profile secretproject Advanced IPython Features 77 In As always the online Python documentation is an excellent resource for more on profiles and configuration.  Credits Parts of this chapter were derived from the wonderful documentation put together by the Python Development Team.  cant thank them enough for all of their work build ing this amazing set of tools.  78 Chapter3 Python An Interactive Computing and Development Environment CHAPTER NumPy Basics Arrays and Vectorized Computation NumPy short for Numerical Python is the fundamental package required for high performance scientific computing and data analysis.  It is the foundation on which nearly all of the higherlevel tools in this book are built.  Here are some of the things it provides ndarray fast and spaceefficient multidimensional array providing vectorized arithmetic operations and sophisticated broadcasting capabilities Standard mathematical functions for fast operations on entire arrays of data without having to write loops Tools for reading writing array data to disk and working with memorymapped files Linear algebra random number generation and Fourier transform capabilities Tools for integrating code written in and Fortran The last bullet point is also one of the most important ones from an ecosystem point of view.  Because NumPy provides an easytouse API it is very easy to pass data to external libraries written in lowlevel language and also for external libraries to return data to Python as NumPy arrays.  This feature has made Python language of choice for wrapping legacy CCFortran codebases and giving them dynamic and easy touse interface.  While NumPy by itself does not provide very much highlevel data analytical func tionality having an understanding of NumPy arrays and arrayoriented computing will help you use tools like pandas much more effectively.  If youre new to Python and just looking to get your hands dirty working with data using pandas feel free to give this chapter skim.  For more on advanced NumPy features like broadcasting see Chap ter 12.  79 For most data analysis applications the main areas of functionality Ill focus on are Fast vectorized array operations for data munging and cleaning subsetting and filtering transformation and any other kinds of computations Common array algorithms like sorting unique and set operations Efficient descriptive statistics and aggregatingsummarizing data Data alignment and relational data manipulations for merging and joining together heterogeneous data sets Expressing conditional logic as array expressions instead of loops with ifelif else branches Groupwise data manipulations aggregation transformation function applica tion.  Much more on this in Chapter While NumPy provides the computational foundation for these operations you will likely want to use pandas as your basis for most kinds of data analysis especially for structured or tabular data as it provides rich highlevel interface making most com mon data tasks very concise and simple.  pandas also provides some more domain specific functionality like time series manipulation which is not present in NumPy.  Vs eS In this chapter and throughout the book use the standard NumPy convention of always using import numpy as np.  You are of course 43 welcome to put from numpy import in your code to avoid having to write np.  but would caution you against making habit of this.  The NumPy ndarray Multidimensional Array Object One of the key features of NumPy is its Ndimensional array object or ndarray which is fast flexible container for large data sets in Python.  Arrays enable you to perform mathematical operations on whole blocks of data using similar syntax to the equivalent operations between scalar elements In data Out array 0. 9526 0. 246 0. 8856 0. 5639 0. 2379 0. 9104 In data 10 In 10 data data Out Out10 array 9. 5256 2. 4601 8. 8565 array 1. 9051 0. 492 1. 7713 5. 6385 2. 3794 9. 104 1. 1277 0. 4759 1. 8208 An ndarray is generic multidimensional container for homogeneous data that is all of the elements must be the same type.  Every array has shape tuple indicating the size of each dimension and dtype an object describing the data type of the array In 11 data. shape Out11 80 Chapter NumPy Basics Arrays and Vectorized Computation In 12 data. dtype Out12 dtypefloat64 This chapter will introduce you to the basics of using NumPy arrays and should be sufficient for following along with the rest of the book.  While its not necessary to have deep understanding of NumPy for many data analytical applications becoming pro ficient in arrayoriented programming and thinking is key step along the way to be coming scientific Python guru.  Whenever you see array NumPy array or ndarray in the text with few exceptions they all refer to the same thing the ndarray object.  Creating ndarrays The easiest way to create an array is to use the array function.  This accepts any se quencelike object including other arrays and produces new NumPy array contain ing the passed data.  For example list is good candidate for conversion In 13 data1 7. 5 In 14 arr1 np. arraydata1 In 15 arr1 Out15 array 6.  7. 5 0.  1.  Nested sequences like list of equallength lists will be converted into multidimen sional array In 16 data2 In 17 arr2 np. arraydata2 In 18 arr2 Out 18 array1 In 19 arr2. ndim Out19 In 20 arr2. shape Out20 Unless explicitly specified more on this later np.  array tries to infer good data type for the array that it creates.  The data type is stored in special dtype object for example in the above two examples we have In 21 arr1. dtype Out21 dtypefloat64 The NumPy ndarray Multidimensional Array Object 81 In 22 arr2. dtype Out22 dtypeint64 In addition to np.  array there are number of other functions for creating new arrays.  As examples zeros and ones create arrays of 0s or 1s respectively with given length or shape.  empty creates an array without initializing its values to any particular value.  To create higher dimensional array with these methods pass tuple for the shape In 23 np. zeros10 Out23 array 0.  0.  0.  0.  0.  0.  O.  O.  0.  0.  In 24 np. zeros3 Out 24 array 0.  0.  0.  0.  0.  0.  0.  0.  0.  ve we vue ooo ooo noe noe vee In 25 np. empty2 Out25 4. 94065646e324 3. 87491056e297 4. 94065646e324 array 1. 90723115e083 2. 33568637e124 4. 42786966e160 4. 94065646e324 2. 46845796e130 4. 94065646e324 5. 73293533e053 6. 70608105e012 1. 27100354e025 Its not safe to assume that np. empty will return an array of all zeros.  In ta many cases as previously shown it will return uninitialized garbage values.  arange is an arrayvalued version of the builtin Python range function In 26 np. arange15 Out26 array 10 11 12 13 14 See Table 41 for short list of standard array creation functions.  Since NumPy is focused on numerical computing the data type if not specified will in many cases be float64 floating point.  Table 41.  Array creation functions Function Description array Convert input data list tuple array or other sequence type to an ndarray either by inferring dtype or explicitly specifying dtype.  Copies the input data by default.  asarray Convert input to ndarray but do not copy if the input is already an ndarray arange Like the builtin range but returns an ndarray instead of list.  ones oneslike zeros zeroslike Produce an array of all 1s with the given shape and dtype.  ones like takes another array and produces ones array of the same shape and dtype.  Like ones and oneslike but producing arrays of 0s instead 82 Chapter NumPy Basics Arrays and Vectorized Computation Function Description empty empty like Create new arrays by allocating new memory but do not populate with any values like ones and zeros eye identity Create square Nx identity matrix 1s on the diagonal and 0s elsewhere Data Types for ndarrays The data type or dtype is special object containing the information the ndarray needs to interpret chunk of memory as particular type of data In 27 arr1 np. array1 dtypenp. float64 In 28 arr2 np. array1 dtypenp. int32 In 29 arr1. dtype In 30 arr2. dtype Out29 dtypefloat64 Out30 dtypeint32 Dtypes are part of what make NumPy so powerful and flexible.  In most cases they map directly onto an underlying machine representation which makes it easy to read and write binary streams of data to disk and also to connect to code written in lowlevel language like or Fortran.  The numerical dtypes are named the same way type name like float or int followed by number indicating the number of bits per element.  standard doubleprecision floating point value whats used under the hood in Pythons float object takes up bytes or 64 bits.  Thus this type is known in NumPy as float64.  See Table 42 for full listing of NumPys supported data types.  Vs eS Dont worry about memorizing the NumPy dtypes especially if youre new user.  Its often only necessary to care about the general kind of 43 data youre dealing with whether floating point complex integer boolean string or general Python object.  When you need more control over how data are stored in memory and on disk especially large data sets it is good to know that you have control over the storage type.  Table 42.  NumPy data types Type Type Code Description int8 uint8 i1 ul Signed and unsigned 8bit byte integer types int16 uint16 i2 u2 Signed and unsigned 16bit integer types int32 uint32 i4 u4 Signed and unsigned 32bit integer types int64 uint64 i8 u8 Signed and unsigned 32bit integer types float16 Halfprecision floating point float32 or Standard singleprecision floating point.  Compatible with float float64 or Standard doubleprecision floating point.  Compatible with double and Python float object The NumPy ndarray Multidimensional Array Object 83 Type Type Code Description float128 f16 or Extendedprecision floating point complex64 complex128 c8 c16 Complexnumbersrepresented by two 32 64 or 128 floats respectively complex256 c32 bool Boolean type storing True and False values object Python object type string Fixedlength string type byte per character.  For example to create string dtype with length 10 use S10.  unicode Fixedlength unicode type number of bytes platform specific.  Same specification semantics as string e. g.  U10.  You can explicitly convert or cast an array from one dtype to another using ndarrays astype method In 31 arr np. array1 In 32 arr. dtype Out32 dtypeint64 In 33 floatarr arr. astypenp. float64 In 34 floatarr. dtype Out34 dtypefloat64 In this example integers were cast to floating point.  If cast some floating point num bers to be of integer dtype the decimal part will be truncated In 35 arr np. array3. 7 1. 2 2. 6 0. 5 12. 9 10. 1 In 36 arr Out36 array 3. 7 1. 2 2. 6 0. 5 12. 9 10. 1 In 37 arr. astypenp. int32 Out37 array 12 10 dtypeint32 Should you have an array of strings representing numbers you can use astype to convert them to numeric form In 38 numericstrings np. array1. 25 9. 6 42 dtypenp. string In 39 numericstrings. astype float Out39 array 1. 25 9. 6 42.  If casting were to fail for some reason like string that cannot be converted to float64 TypeError will be raised.  See that was bit lazy and wrote float instead of np. float64 NumPy is smart enough to alias the Python types to the equivalent dtypes.  You can also use another arrays dtype attribute In 40 intarray np. arange10 84 Chapter NumPy Basics Arrays and Vectorized Computation In 41 calibers np. array. 22 . 270 . 357 . 380 . 44 . 50 dtypenp. float64 In 42 intarray. astypecalibers. dtype Out42 array 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.  There are shorthand type code strings you can also use to refer to dtype In 43 emptyuint32 np. empty8 dtypeu4 In 44 emptyuint32 Out 44 array 65904672 64856792 39438163 dtypeuint32 Calling astype always creates new array copy of the data even if the new dtype is the same as the old dtype.  Its worth keeping in mind that floating point numbers such as those in float64 and float32 arrays are only capable of approximating frac tional quantities.  In complex computations you may accrue some floating point error making comparisons only valid up to certain num ber of decimal places.  Operations between Arrays and Scalars Arrays are important because they enable you to express batch operations on data without writing any for loops.  This is usually called vectorization.  Any arithmetic op erations between equalsize arrays applies the operation elementwise In 45 arr np. array1.  2.  3.  4.  5.  6.  In 46 arr Out 46 array 1.  2. 5 4.  5. 5 6.  In 47 arr arr In 48 arr arr Out 47 Out 48 array 1.  4.  9.  array 0.  0.  0.  16.  25.  36.  0.  0.  0.  Arithmetic operations with scalars are as you would expect propagating the value to each element In 49 arr In 50 arr 0. 5 Out 49 Out50 array 1.  0. 5 0. 3333 array 1.  1. 4142 1. 7321 0. 25 0. 2 0. 1667 2. 2361 2. 4495 The NumPy ndarray Multidimensional Array Object 85 Operations between differently sized arrays is called broadcasting and will be discussed in more detail in Chapter 12.  Having deep understanding of broadcasting is not nec essary for most of this book.  Basic Indexing and Slicing NumbPy array indexing is rich topic as there are many ways you may want to select subset of your data or individual elements.  Onedimensional arrays are simple on the surface they act similarly to Python lists In 51 arr np. arange10 52 arr 52 array0 53 arr5 53 54 arr58 54 array5 In 55 arr58 12 56 arr 56 array 12 12 12 As you can see if you assign scalar value to slice as in arr58 12 the value is propagated or broadcasted henceforth to the entire selection.  An important first dis tinction from lists is that array slices are views on the original array.  This means that the data is not copied and any modifications to the view will be reflected in the source array In 57 arrslice arr58 In 58 arrslice1 12345 In 59 arr Out59 array 12 12345 12 In 60 arrslice 64 In 61 arr Out61 array 64 64 64 If you are new to NumPy you might be surprised by this especially if you have used other array programming languages which copy data more zealously.  As NumPy has been designed with large data use cases in mind you could imagine performance and memory problems if NumPy insisted on copying data left and right.  86 Chapter NumPy Basics Arrays and Vectorized Computation If you want copy of slice of an ndarray instead of view you will need to explicitly copy the array for example arr58. copy.  With higher dimensional arrays you have many more options.  In twodimensional array the elements at each index are no longer scalars but rather onedimensional arrays In 62 arr2d np. array1 In 63 arr2d2 Out63 array7 Thus individual elements can be accessed recursively.  But that is bit too much work so you can pass commaseparated list of indices to select individual elements.  So these are equivalent In 64 arr2do2 Out 64 In 65 arr2do Out 65 See Figure 41 for an illustration of indexing on 2D array.  axis Figure 41.  Indexing elements in NumPy array In multidimensional arrays if you omit later indices the returned object will be lower dimensional ndarray consisting of all the data along the higher dimensions.  So in the 2x 2x array arr3d In 66 arr3d np. array1 10 11 12 In 67 arr3d Out 67 array The NumPy ndarray Multidimensional Array Object 87 75 10 11 12 arr3d0 is array In 68 arr3d0 Out 68 array1 Both scalar values and arrays can be assigned to arr3d0 In 69 oldvalues arr3d0. copy In 70 arr3d0 42 In 71 arr3d Out71 array42 42 42 42 42 42 12 10 11 In 72 arr3d0 oldvalues In 73 arr3d Out 73 array 10 11 12 Similarly arr3d1 gives you all of the values whose indices start with form ing 1dimensional array In 74 arr3d1 Out74 array7 Note that in all of these cases where subsections of the array have been selected the returned arrays are views.  Indexing with slices Like onedimensional objects such as Python lists ndarrays can be sliced using the familiar syntax In 75 arr16 Out75 array 64 Higher dimensional objects give you more options as you can slice one or more axes and also mix integers.  Consider the 2D array above arr2d.  Slicing this array is bit different In 76 arr2d In 77 arr2d2 Out 76 Out 77 88 Chapter NumPy Basics Arrays and Vectorized Computation array1 array1 As you can see it has sliced along axis the first axis.  slice therefore selects range of elements along an axis.  You can pass multiple slices just like you can pass multiple indexes In 78 arr2d2 Out 78 array2 When slicing like this you always obtain array views of the same number of dimensions.  By mixing integer indexes and slices you get lower dimensional slices In 79 arr2d1 In 80 arr2d2 Out79 array4 Out80 array7 See Figure 42 for an illustration.  Note that colon by itself means to take the entire axis so you can slice only higher dimensional axes by doing In 81 arr2d Out 81 array1 Of course assigning to slice expression assigns to the whole selection In 82 arr2d2 Boolean Indexing Lets consider an example where we have some data in an array and an array of names with duplicates.  Im going to use here the randn function in numpy.  random to generate some random normally distributed data In 83 names np. arrayBob Joe Will Bob Will Joe Joe In 84 data randn7 In 85 names Out 85 arrayBob Joe Will Bob Will Joe Joe dtype S4 In 86 data Out 86 array0. 048 0. 5433 0. 2349 1. 2792 0. 268 0. 5465 0. 0939 2. 0445 0. 047 2. 026 0. 7719 0. 3103 2. 1452 0. 8799 0. 0523 0. 0672 1. 0023 0. 1698 1. 1503 1. 7289 The NumPy ndarray Multidimensional Array Object 89 0. 1913 0. 4544 0. 4519 0. 5535 0. 5994 0. 8174 0. 9297 1. 2564 Expression Shape a.  arr2 arr2 arr2 35 arr2 arr arr1 arr12 Figure 42.  Twodimensional array slicing Suppose each name corresponds to row in the data array and we wanted to select all the rows with corresponding name Bob.  Like arithmetic operations comparisons such as with arrays are also vectorized.  Thus comparing names with the string Bob yields boolean array In 87 names Bob Out87 array True False False True False False False dtypebool This boolean array can be passed when indexing the array In 88 datanames Bob Out88 array0. 048 0. 5433 0. 2349 1. 2792 2. 1452 0. 8799 0. 0523 0. 0672 The boolean array must be of the same length as the axis its indexing.  You can even mix and match boolean arrays with slices or integers or sequences of integers more on this later In 89 datanames Bob Out 89 array0. 2349 1. 2792 90 Chapter NumPy Basics Arrays and Vectorized Computation 0. 0523 0. 0672 In 90 datanames Bob Out90 array 1. 2792 0. 0672 To select everything but Bob you can either use or negate the condition using In 91 names Bob Out91 arrayFalse True True False True True True dtypebool In 92 datanames Bob Out92 array0. 268 0. 5465 0. 0939 2. 0445 0. 047 2. 026 0. 7719 0. 3103 1. 0023 0. 1698 1. 1503 1. 7289 0. 1913 0. 4544 0. 4519 0. 5535 0. 5994 0. 8174 0. 9297 1. 2564 Selecting two of the three names to combine multiple boolean conditions use boolean arithmetic operators like and and or In 93 mask names Bob names Will In 94 mask Out94 arrayTrue False True True True False False dtypebool In 95 datamask Out 95 array0. 048 0. 5433 0. 2349 1. 2792 0. 047 2. 026 0. 7719 0. 3103 2. 1452 0. 8799 0. 0523 0. 0672 1. 0023 0. 1698 1. 1503 1. 7289 Selecting data from an array by boolean indexing always creates copy of the data even if the returned array is unchanged.  The Python keywords and and or do not work with boolean arrays.  Setting values with boolean arrays works in commonsense way.  To set all of the negative values in data to we need only do In 96 datadata In 97 data Out 97 array 0.  0. 5433 0.  1. 2792 0.  0. 5465 0. 0939 0.  0.  0.  0. 7719 0. 3103 2. 1452 0. 8799 0.  0. 0672 0.  0.  1. 1503 1. 7289 0. 1913 0. 4544 0. 4519 0. 5535 0. 5994 0. 8174 The NumPy ndarray Multidimensional Array Object 91 Setting whole rows or columns using 1D boolean array is also easy 98 datanames Joe 99 data Out99 array Te Te Js 0. 5465 0. 0939 0.  7.  7.  7.  0. 1913 0. 4544 0. 4519 0. 5535 0. 5994 0. 8174 0.  O.  Fancy Indexing Fancy indexing is term adopted by NumPy to describe indexing using integer arrays.  Suppose we had array In 100 arr np. empty8 In 101 for in range8 sere arri In 102 Out102 array 0.  0.  0.  0.  1.  1.  1.  1.  2.  2.  2.  2.  35 35 35 4.  4.  55 55 55 5e5 6.  6.  6.  6.  75 Tes Ts To select out subset of the rows in particular order you can simply pass list or ndarray of integers specifying the desired order In 103 arr4 Out 103 array 4.  4.  4. 5 4.  35 35 35 0.  0.  0.  0.  6.  6.  6.  6.  Hopefully this code did what you expected Using negative indices select rows from the end In 104 arr3 Out 104 array 5.  35 Bey Be 4. 5 1.  1.  92 Chapter NumPy Basics Arrays and Vectorized Computation Passing multiple index arrays does something slightly different it selects 1D array of elements corresponding to each tuple of indices more on reshape in Chapter 12 In 105 arr np. arange32. reshape8 In 106 arr Out 106 array 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 In 107 arr1 Out107 array 23 29 10 Take moment to understand what just happened the elements 75 1and were selected.  The behavior of fancy indexing in this case is bit different from what some users might have expected myself included which is the rectangular region formed by selecting subset of the matrixs rows and columns.  Here is one way to get that In 108 arr1 Out 108 array 20 23 21 22 28 31 29 30 11 10 Another way is to use the np. ix function which converts two 1D integer arrays to an indexer that selects the square region In 109 arrnp. ix1 Out109 array 20 23 21 22 28 31 29 30 11 10 Keep in mind that fancy indexing unlike slicing always copies the data into new array.  Transposing Arrays and Swapping Axes Transposing is special form of reshaping which similarly returns view on the un derlying data without copying anything.  Arrays have the transpose method and also the special attribute In 110 arr np. arange15. reshape3 In 111 arr In 112 arr. T The NumPy ndarray Multidimensional Array Object 93 Out111 Out112 array array 10 41 11 10 11 12 13 14 12 13 14 When doing matrix computations you will do this very often like for example com puting the inner matrix product XX using np.  dot In 113 arr np. random. randn6 In 114 np. dotarr. T arr Out114 array 2. 584 1. 8753 0. 8888 1. 8753 6. 6636 0. 3884 0. 8888 0. 3884 3. 9781 For higher dimensional arrays transpose will accept tuple of axis numbers to permute the axes for extra mind bending In 115 arr np. arange16. reshape2 In 116 arr Out 116 array 10 11 12 13 14 15 In 117 arr. transpose1 Out 117 array 10 11 12 13 14 15 Simple transposing with . T is just special case of swapping axes.  ndarray has the method swapaxes which takes pair of axis numbers In 118 arr In 119 arr. swapaxes1 Out 118 Out119 array array 55 71 10 12 12 13 14 15 12 13 10 14 11 15 swapaxes similarly returns view on the data without making copy.  94 Chapter NumPy Basics Arrays and Vectorized Computation Universal Functions Fast Elementwise Array Functions universal function or ufunc is function that performs elementwise operations on data in ndarrays.  You can think of them as fast vectorized wrappers for simple functions that take one or more scalar values and produce one or more scalar results.  Many ufuncs are simple elementwise transformations like sqrt or exp In 120 arr np. arange10 In 121 np. sqrtarr Out121 array 0.  te 1. 4142 1. 7321 2.  2. 2361 2. 4495 2. 6458 2. 8284 3.  In 122 np. exparr Out122 array 1.  2. 7183 7. 3891 20. 0855 54. 5982 148. 4132 403. 4288 1096. 6332 2980. 958 8103. 0839 These are referred to as unary ufuncs.  Others such as add or maximum take arrays thus binary ufuncs and return single array as the result In 123 randn8 In 124 randn8 In 125 Out125 array 0. 0749 0. 0974 0. 2002 0. 2551 0. 4655 0. 9222 0. 446 0. 9337 In 126 Out126 array 0. 267 1. 1131 0. 3361 0. 6117 1. 2323 0. 4788 0. 4315 0. 7147 In 127 np. maximumx elementwise maximum Out127 array 0. 267 0. 0974 0. 2002 0. 6117 0. 4655 0. 9222 0. 446 0. 7147 While not common ufunc can return multiple arrays.  modf is one example vector ized version of the builtin Python divmod it returns the fractional and integral parts of floating point array In 128 arr randn7 In 129 np. modfarr Out129 array0. 6808 0. 0636 0. 386 0. 1393 0. 8806 0. 9363 0. 883 array2.  4.  3.  5.  3.  6.  Universal Functions Fast Elementwise Array Functions 95 See Table 43 and Table 44 for listing of available ufuncs.  Table 43.  Unary ufuncs Function abs fabs sqrt square exp log logio log2 logip sign ceil floor rint modf isnan isfinite isinf cos cosh sin sinh tan tanh arccos arccosh arcsin arcsinh arctan arctanh logicalnot Description Compute the absolute value elementwise for integer floating point or complex values.  Use fabs as faster alternative for noncomplexvalued data Compute the square root of each element.  Equivalent to arr 0. 5 Compute the square of each element.  Equivalent to arr Compute the exponent of each element Natural logarithm base log base 10 log base and log1 respectively Compute the sign of each element positive zero or negative Compute the ceiling of each element i. e.  the smallest integer greater than or equal to each element Compute the floor of each element i. e.  the largest integer less than or equal to each element Round elements to the nearest integer preserving the dtype Return fractional and integral parts of array as separate array Return boolean array indicating whether each value is NaN Not Number Return boolean array indicating whether each element is finite nonin nonNaN or infinite respectively Regular and hyperbolic trigonometric functions Inverse trigonometric functions Compute truth value of not elementwise.  Equivalent to arr.  Table 44.  Binary universal functions Function add subtract multiply divide floordivide power maximum max minimum fmin mod copysign Description Add corresponding elements in arrays Subtract elements in second array from first array Multiply array elements Divide or floor divide truncating the remainder Raise elements in first array to powers indicated in second array Elementwise maximum.  fmax ignores NaN Elementwise minimum.  fmin ignores NaN Elementwise modulus remainder of division Copy sign of values in second argument to values in first argument 96 Chapter NumPy Basics Arrays and Vectorized Computation Function Description greater greaterequal Perform elementwise comparison yielding boolean array.  Equivalent to infix operators ess less equal equal Is less equal equal notequal logicaland Compute elementwise truth value of logical operation.  Equivalent to infix operators logical or logical xor lx Data Processing Using Arrays Using NumPy arrays enables you to express many kinds of data processing tasks as concise array expressions that might otherwise require writing loops.  This practice of replacing explicit loops with array expressions is commonly referred to as vectoriza tion.  In general vectorized array operations will often be one or two or more orders of magnitude faster than their pure Python equivalents with the biggest impact in any kind of numerical computations.  Later in Chapter 12 will explain broadcasting powerful method for vectorizing computations.  As simple example suppose we wished to evaluate the function sqrtx2 y2 across regular grid of values.  The np. meshgrid function takes two 1D arrays and pro duces two 2D matrices corresponding to all pairs of in the two arrays In 130 points np. arange5 0. 01 1000 equally spaced points In 131 xs ys np. meshgridpoints points In 132 ys Out 132 array5 5s Se wees Se yy SSe yy M50 4. 99 4. 99 4. 99 . . .  4. 99 4. 99 4. 99 4. 98 4. 98 4. 98 . . .  4. 98 4. 98 4. 98 eey 4. 97 4. 97 4. 97 . . .  4. 97 4. 97 4. 97 4. 98 4. 98 4. 98 . . .  4. 98 4. 98 4. 98 4. 99 4. 99 4. 99 . . .  4. 99 4. 99 4. 99 Now evaluating the function is simple matter of writing the same expression you would write with two points In 134 import matplotlib. pyplot as plt In 135 np. sqrtxs ys In 136 Out 136 array 7. 0711 7. 064 7. 0569 . . .  7. 0499 7. 0569 7. 064 7. 064 7. 0569 7. 0499 . . .  7. 0428 7. 0499 7. 0569 7. 0569 7. 0499 7. 0428 . . .  7. 0357 7. 0428 7. 0499 seey 7. 0499 7. 0428 7. 0357 . . .  7. 0286 7. 0357 7. 0428 7. 0569 7. 0499 7. 0428 . . .  7. 0357 7. 0428 7. 0499 7. 064 7. 0569 7. 0499 . . .  7. 0428 7. 0499 7. 0569 Data Processing Using Arrays 97 In 137 plt. imshowz cmapplt. cm. gray plt. colorbar Out 137 matplotlib. colorbar. Colorbar instance at 0x4e46d40 In 138 plt. titleImage plot of sqrtx2 y2 for grid of values Out 138 matplotlib. text. Text at 0x4565790 See Figure 43.  Here used the matplotlib function imshow to create an image plot from 2D array of function values.  Image plot of for grid of values 200 400 600 800 200 400 600 800 Figure 43.  Plot of function evaluated on grid Expressing Conditional Logic as Array Operations The numpy. where function is vectorized version of the ternary expression if condi tion else y.  Suppose we had boolean array and two arrays of values In 140 xarr np. array1. 1 1. 2 1. 3 1. 4 1. 5 In 141 yarr np. array2. 1 2. 2 2. 3 2. 4 2. 5 In 142 cond np. arrayTrue False True True False Suppose we wanted to take value from xarr whenever the corresponding value in cond is True otherwise take the value from yarr.  list comprehension doing this might look like In 143 result if else eens for in zipxarr yarr cond In 144 result Out144 1. 1000000000000001 2. 2000000000000002 1. 3 1. 3999999999999999 2. 5 98 Chapter NumPy Basics Arrays and Vectorized Computation This has multiple problems.  First it will not be very fast for large arrays because all the work is being done in pure Python.  Secondly it will not work with multidimen sional arrays.  With np. where you can write this very concisely In 145 result np. wherecond xarr yarr In 146 result Out146 array 1. 1 2. 2 1. 3 1. 4 2. 5 The second and third arguments to np. where dont need to be arrays one or both of them can be scalars.  typical use of where in data analysis is to produce new array of values based on another array.  Suppose you had matrix of randomly generated data and you wanted to replace all positive values with and all negative values with 2.  This is very easy to do with np. where In 147 arr randn4 In 148 arr Out 148 array 0. 6372 2. 2043 1. 7904 0. 0752 1. 5926 1. 1536 0. 4413 0. 3483 0. 1798 0. 3299 0. 7827 0. 7585 0. 5857 0. 1619 1. 3583 1. 3865 In 149 np. wherearr Out149 array In 150 np. wherearr arr set only positive values to Out150 array 2.  de gy 2s 2s 1. 5926 1. 1536 2.  de 0. 1798 2.  70. 7585 2.  Ds 2.  71. 3865 The arrays passed to where can be more than just equal sizes array or scalars.  With some cleverness you can use where to express more complicated logic consider this example where have two boolean arrays cond1 and cond2 and wish to assign different value for each of the possible pairs of boolean values result for in rangen if condii and cond2i result . append0 elif cond1i result. append1 elif cond2i result. append2 else result . append3 Data Processing Using Arrays 99 While perhaps not immediately obvious this for loop can be converted into nested where expression np. wherecond1 cond2 np. wherecond1 np. wherecond2 In this particular example we can also take advantage of the fact that boolean values are treated as or in calculations so this could alternatively be expressed though bit more cryptically as an arithmetic operation result cond1 cond2 cond2 cond1 cond1 cond2 Mathematical and Statistical Methods set of mathematical functions which compute statistics about an entire array or about the data along an axis are accessible as array methods.  Aggregations often called reductions like sum mean and standard deviation std can either be used by calling the array instance method or using the top level NumPy function In 151 arr np. random. randn5 normallydistributed data In 152 arr. mean Out152 0. 062814911084854597 In 153 np. meanarr Out153 0. 062814911084854597 In 154 arr. sum Out 154 1. 2562982216970919 Functions like mean and sum take an optional axis argument which computes the statistic over the given axis resulting in an array with one fewer dimension In 155 arry. meanaxis1 Out155 array1. 2833 0. 2844 0. 6574 0. 6743 0. 0187 In 156 arr. sum0 Out 156 array3. 1003 1. 6189 1. 4044 4. 5712 Other methods like cumsum and cumprod do not aggregate instead producing an array of the intermediate results In 157 arr np. array0 In 158 arr. cumsum0 In 159 arr. cumprod1 Out158 Out159 array array ol 12 60 12 15 42 336 See Table 45 for full listing.  Well see many examples of these methods in action in later chapters.  100 Chapter NumPy Basics Arrays and Vectorized Computation Table 45.  Basic array statistical methods Method Description sum Sum of all the elements in the array or along an axis.  Zerolength arrays have sum 0.  mean Arithmetic mean.  Zerolength arrays have NaN mean.  std var Standard deviation and variance respectively with optional degrees of freedom adjust ment default denominator n.  min max Minimum and maximum.  argmin argmax Indices of minimum and maximum elements respectively.  cumsum Cumulative sum of elements starting from cumprod Cumulative product of elements starting from Methods for Boolean Arrays Boolean values are coerced to True and False in the above methods.  Thus sum is often used as means of counting True values in boolean array In 160 arr randn100 In 161 arr 0. sum Number of positive values Out161 44 There are two additional methods any and al11 useful especially for boolean arrays.  any tests whether one or more values in an array is True while all checks if every value is True In 162 bools np. arrayFalse False True False In 163 bools. any Out163 True In 164 bools. all1 Out164 False These methods also work with nonboolean arrays where nonzero elements evaluate to True.  Sorting Like Pythons builtin list type NumPy arrays can be sorted inplace using the sort method In 165 arr randn8 In 166 arr Out 166 array 0. 6903 0. 4678 0. 0968 0. 1349 0. 9879 0. 0185 1. 3147 0. 5425 In 167 arr. sort Data Processing Using Arrays 101 In 168 arr Out 168 array1. 3147 0. 5425 0. 1349 0. 0185 0. 0968 0. 4678 0. 6903 0. 9879 Multidimensional arrays can have each 1D section of values sorted inplace along an axis by passing the axis number to sort In 169 arr randn5 In 170 arr Out 170 array0. 7139 1. 6331 0. 4959 0. 8236 1. 3132 0. 1935 1. 6748 3. 0336 0. 863 0. 3161 0. 5362 2. 468 0. 9058 1. 1184 1. 0516 In 171 arr. sort1 In 172 arr Out 172 array1. 6331 0. 7139 0. 4959 1. 3132 0. 1935 0. 8236 1. 6748 0. 863 3. 0336 2. 468 0. 3161 0. 5362 1. 0516 0. 9058 1. 1184 The top level method np.  sort returns sorted copy of an array instead of modifying the array in place.  quickanddirty way to compute the quantiles of an array is to sort it and select the value at particular rank In 173 largearr randn1000 In 174 largearr. sort In 175 large arrint0. 05 lenlarge arr quantile Out175 1. 5791023260896004 For more details on using NumPys sorting methods and more advanced techniques like indirect sorts see Chapter 12.  Several other kinds of data manipulations related to sorting for example sorting table of data by one or more columns are also to be found in pandas.  Unique and Other Set Logic NumPy has some basic set operations for onedimensional ndarrays.  Probably the most commonly used one is np. unique which returns the sorted unique values in an array In 176 names np. arrayBob Joe Will Bob Will Joe Joe In 177 np. uniquenames Out177 102 Chapter NumPy Basics Arrays and Vectorized Computation arrayBob Joe Will dtype S4 In 178 ints np. array3 In 179 np. uniqueints Out179 array1 Contrast np. unique with the pure Python alternative In 180 sortedsetnames Out180 Bob Joe Will Another function np. inid tests membership of the values in one array in another returning boolean array In 181 values np. array6 In 182 np. inidvalues Out182 array True False False True True False True dtypebool See Table 46 for listing of set functions in NumPy.  Table 46.  Array set operations Method Description uniquex Compute the sorted unique elements in intersectidx Compute the sorted common elements in and unionidx Compute the sorted union of elements inidx Compute boolean array indicating whether each element of is contained in setdiffidx Set difference elements in that are not in setxoridx Set symmetric differences elements that are in either of the arrays but not both File Input and Output with Arrays NumPy is able to save and load data to and from disk either in text or binary format.  In later chapters you will learn about tools in pandas for reading tabular data into memory.  Storing Arrays on Disk in Binary Format np.  save and np.  load are the two workhorse functions for efficiently saving and loading array data on disk.  Arrays are saved by default in an uncompressed raw binary format with file extension . npy.  In 183 arr np. arange10 In 184 np. savesomearray arr File Input and Output with Arrays 103 If the file path does not already end in . npy the extension will be appended.  The array on disk can then be loaded using np.  load In 185 np. loadsomearray. npy Out185 array0 You save multiple arrays in zip archive using np. savez and passing the arrays as key word arguments In 186 np. savezarrayarchive. npz aarr barr When loading an . npz file you get back dictlike object which loads the individual arrays lazily In 187 arch np. loadarrayarchive. npz In 188 archb Out188 array0 Saving and Loading Text Files Loading text from files is fairly standard task.  The landscape of file reading and writing functions in Python can be bit confusing for newcomer so will focus mainly on the readcsv and readtable functions in pandas.  It will at times be useful to load data into vanilla NumPy arrays using np. loadtxt or the more specialized np. genfromtxt.  These functions have many options allowing you to specify different delimiters con verter functions for certain columns skipping rows and other things.  Take simple case of commaseparated file CSV like this In 191 cat array ex. txt 0. 580052 0. 1867301. 0407171. 134411 0. 194163 0. 636917 0. 9386590. 124094 0. 126410 0. 268607 0. 695724 0. 047428 1. 4844130. 004176 0. 744203 0. 005487 2. 302869 0. 200131 1. 670238 1. 881090 0. 1932301. 047233 0. 482803 0. 960334 This can be loaded into 2D array like so In 192 arr np. loadtxtarrayex. txt delimiter In 193 arr Out193 array 0. 5801 0. 1867 1. 0407 1. 1344 0. 1942 0. 6369 0. 9387 0. 1241 0. 1264 0. 2686 0. 6957 0. 0474 1. 4844 0. 0042 0. 7442 0. 0055 2. 3029 0. 2001 1. 6702 1. 8811 0. 1932 1. 0472 0. 4828 0. 9603 np. savetxt performs the inverse operation writing an array to delimited text file.  genfromtxt is similar to loadtxt but is geared for structured arrays and missing data handling see Chapter 12 for more on structured arrays.  104 Chapter NumPy Basics Arrays and Vectorized Computation For more on file reading and writing especially tabular or spreadsheet like data see the later chapters involving pandas and DataFrame objects.  Linear Algebra Linear algebra like matrix multiplication decompositions determinants and other square matrix math is an important part of any array library.  Unlike some languages like MATLAB multiplying two twodimensional arrays with is an elementwise product instead of matrix dot product.  As such there is function dot both an array method and function in the numpy namespace for matrix multiplication In 194 np. array1.  2.  3.  4.  5. 5 6.  In 195 np. array6.  23 In 196 In 197 Out196 Out197 array 1.  2.  3.  array 6.  23.  4.  5.  6.  1.  Tals 8.  9.  In 198 x. doty equivalently np. dotx Out 198 array 28.  64.  67.  181.  matrix product between 2D array and suitably sized 1D array results ina 1D array In 199 np. dotx np. ones3 Out199 array 6.  15.  numpy. linalg has standard set of matrix decompositions and things like inverse and determinant.  These are implemented under the hood using the same industrystandard Fortran libraries used in other languages like MATLAB and such as like BLAS LA PACK or possibly depending on your NumPy build the Intel MKL In 201 from numpy. linalg import inv qr In 202 randn5 In 203 mat X. T. dotX In 204 invmat Out 204 array 3. 0361 0. 1808 0. 6878 2. 8285 1. 1911 0. 1808 0. 5035 0. 1215 0. 6702 0. 0956 0. 6878 0. 1215 0. 2904 0. 8081 0. 3049 2. 8285 0. 6702 0. 8081 3. 4152 1. 1557 1. 1911 0. 0956 0. 3049 1. 1557 0. 6051 In 205 mat. dotinvmat Linear Algebra 105 Out 205 array 1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  In 206 qrmat In 207 Out 207 array 6. 9271 7. 389 6. 1227 7. 1163 4. 9215 0.  739735 0. 8671 2. 9747 5. 7402 0.  0.  10. 2681 1. 8909 1. 6079 0.  0.  0.  71. 2996 3. 3577 0.  oO.  0.  oO.  0. 5571 See Table 47 for list of some of the most commonlyused linear algebra functions.  The scientific Python community is hopeful that there may be matrix multiplication infix operator implemented someday providing syntac 12 tically nicer alternative to using np. dot.  But for now this is the way.  Table 47.  Commonlyused numpy. linalg functions Function diag dot trace det eig inv pinv qr svd solve Istsq Description Return the diagonal or offdiagonal elements of square matrix as 1D array or convert 1D array into square matrix with zeros on the offdiagonal Matrix multiplication Compute the sum of the diagonal elements Compute the matrix determinant Compute the eigenvalues and eigenvectors of square matrix Compute the inverse of square matrix Compute the MoorePenrose pseudoinverse inverse of matrix Compute the QR decomposition Compute the singular value decomposition SVD Solve the linear system Ax for where is square matrix Compute the leastsquares solution to Ax Random Number Generation The numpy. random module supplements the builtin Python random with functions for efficiently generating whole arrays of sample values from many kinds of probability 106 Chapter NumPy Basics Arrays and Vectorized Computation distributions.  For example you can get by array of samples from the standard normal distribution using normal In 208 samples np. random. normalsize4 In 209 samples Out 209 array 0. 1241 0. 3026 0. 5238 0. 0009 1. 3438 0. 7135 0. 8312 2. 3702 1. 8608 0. 8608 0. 5601 1. 2659 0. 1198 1. 0635 0. 3329 2. 3594 Pythons builtin random module by contrast only samples one value at time.  As you can see from this benchmark numpy. random is well over an order of magnitude faster for generating very large samples In 210 from random import normalvariate In 211 1000000 In 212 timeit samples normalvariate0 for in xrangeN loops best of 1. 33 per loop In 213 timeit np. random. normalsizeN 10 loops best of 57. 7 ms per loop See Table 48 for partial list of functions available in numpy. random.  Ill give some examples of leveraging these functions ability to generate large arrays of samples all at once in the next section.  Table 48.  Partial list of numpy. random functions Function Description seed Seed the random number generator permutation Return random permutation of sequence or return permuted range shuffle Randomly permute sequence in place rand Draw samples from uniform distribution randint Draw random integers from given lowtohigh range randn Draw samples from normal distribution with mean and standard deviation MATLABlike interface binomial Draw samples from binomial distribution normal Draw samples from normal Gaussian distribution beta Draw samples from beta distribution chisquare Draw samples from chisquare distribution gamma Draw samples from gamma distribution uniform Draw samples from uniform distribution Random Number Generation 107 Example Random Walks An illustrative application of utilizing array operations is in the simulation of random walks.  Lets first consider simple random walk starting at with steps of and occurring with equal probability.  pure Python way to implement single random walk with 1000 steps using the builtin random module import random position walk position steps 1000 for in xrangesteps step if random. randint0 else position step walk. appendposition See Figure 44 for an example plot of the first 100 values on one of these random walks.  10 10 15 Random walk with 11 steps 20 40 60 80 100 Figure 44.  simple random walk You might make the observation that walk is simply the cumulative sum of the random steps and could be evaluated as an array expression.  Thus use the np.  random module to draw 1000 coin flips at once set these to and and compute the cumulative sum In 215 nsteps 1000 216 draws np. random. randint0 sizensteps 217 steps np. wheredraws 218 walk steps. cumsum 108 Chapter NumPy Basics Arrays and Vectorized Computation From this we can begin to extract statistics like the minimum and maximum value along the walks trajectory In 219 walk. min In 220 walk. max Out219 Out220 31 more complicated statistic is the first crossing time the step at which the random walk reaches particular value.  Here we might want to know how long it took the random walk to get at least 10 steps away from the origin in either direction.  np. abswalk 10 gives us boolean array indicating where the walk has reached or exceeded 10 but we want the index of the first 10 or 10.  Turns out this can be com puted using argmax which returns the first index of the maximum value in the boolean array True is the maximum value In 221 np. abswalk 10. argmax Out221 37 Note that using argmax here is not always efficient because it always makes full scan of the array.  In this special case once True is observed we know it to be the maximum value.  Simulating Many Random Walks at Once If your goal was to simulate many random walks say 5000 of them you can generate all of the random walks with minor modifications to the above code.  The numpy. ran dom functions if passed 2tuple will generate 2D array of draws and we can compute the cumulative sum across the rows to compute all 5000 random walks in one shot In 222 nwalks 5000 In 223 nsteps 1000 In 224 draws np. random. randint0 sizenwalks nsteps or In 225 steps np. wheredraws In 226 walks steps. cumsum1 In 227 walks Out 227 array . . .  . . .  34 33 32 we . . .  24 25 26 . .  14 13 14 24 23 22 Now we can compute the maximum and minimum values obtained over all of the walks In 228 walks. max In 229 walks. min Out 228 138 Out229 133 Example Random Walks 109 Out of these walks lets compute the minimum crossing time to 30 or 30.  This is slightly tricky because not all 5000 of them reach 30.  We can check this using the any method In 230 hits30 np. abswalks 30. any1 In 231 hits30 Out231 arrayFalse True False . . .  False True False dtypebool In 232 hits30. sum Number that hit 30 or 30 Out232 3410 We can use this boolean array to select out the rows of walks that actually cross the absolute 30 level and call argmax across axis to get the crossing times In 233 crossing times np. abswalkshits30 30. argmax1 In 234 crossing times. mean Out234 498. 88973607038122 Feel free to experiment with other distributions for the steps other than equal sized coin flips.  You need only use different random number generation function like normal to generate normally distributed steps with some mean and standard deviation In 235 steps np. random. normalloc0 scale0. 25 sees sizenwalks nsteps 110 Chapter NumPy Basics Arrays and Vectorized Computation CHAPTER Getting Started with pandas pandas will be the primary library of interest throughout much of the rest of the book.  It contains highlevel data structures and manipulation tools designed to make data analysis fast and easy in Python.  pandas is built on top of NumPy and makes it easy to use in NumPycentric applications.  As bit of background started building pandas in early 2008 during my tenure at AQR quantitative investment management firm.  At the time had distinct set of requirements that were not welladdressed by any single tool at my disposal Data structures with labeled axes supporting automatic or explicit data alignment.  This prevents common errors resulting from misaligned data and working with ditterentlyindexed data coming from different sources.  Integrated time series functionality.  The same data structures handle both time series data and nontime series data.  Arithmetic operations and reductions like summing across an axis would pass on the metadata axis labels.  Flexible handling of missing data.  Merge and other relational operations found in popular database databases SQL based for example.  wanted to be able to do all of these things in one place preferably in language well suited to general purpose software development.  Python was good candidate lan guage for this but at that time there was not an integrated set of data structures and tools providing this functionality.  Over the last four years pandas has matured into quite large library capable of solving much broader set of data handling problems than ever anticipated but it has ex panded in its scope without compromising the simplicity and easeofuse that desired from the very beginning.  hope that after reading this book you will find it to be just as much of an indispensable tool as do.  Throughout the rest of the book use the following import conventions for pandas 111 In from pandas import Series DataFrame In import pandas as pd Thus whenever you see pd.  in code its referring to pandas.  Series and DataFrame are used so much that find it easier to import them into the local namespace.  Introduction to pandas Data Structures To get started with pandas you will need to get comfortable with its two workhorse data structures Series and DataFrame.  While they are not universal solution for every problem they provide solid easytouse basis for most applications.  Series Series is onedimensional arraylike object containing an array of data of any NumPy data type and an associated array of data labels called its index.  The simplest Series is formed from only an array of data In obj Series4 ut obj WNROOH wun Bos The string representation of Series displayed interactively shows the index on the left and the values on the right.  Since we did not specify an index for the data default one consisting of the integers through where is the length of the data is created.  You can get the array representation and index object of the Series via its values and index attributes respectively In obj. values Out6 array In obj. index Out7 Int64Index0 Often it will be desirable to create Series with an index identifying each data point In obj2 Series4 indexd wun Bos nv 112 Chapter Getting Started with pandas In 10 obj2. index Out10 Indexd dtypeobject Compared with regular NumPy array you can use values in the index when selecting single values or set of values In 11 obj2a Out11 In 12 obj2d In 13 obj2c Out 13 NumbPy array operations such as filtering with boolean array scalar multiplication or applying math functions will preserve the indexvalue link In 14 obj2 Out14 15 obj2obj2 In 16 obj2 In 17 np. expobj2 outa Out16 Out17 12 403 . 428793 14 1096.  633158 10 0. 006738 Cc 20. 085537 Another way to think about Series is as fixedlength ordered dict as it is mapping of index values to data values.  It can be substituted into many functions that expect dict In 18 in obj2 Out18 True In 19 in obj2 Out19 False Should you have data contained in Python dict you can create Series from it by passing the dict In 20 sdata Ohio 35000 Texas 71000 Oregon 16000 Utah 5000 In 21 obj3 Seriessdata In 22 obj3 Out 22 Ohio 35000 Oregon 16000 Introduction to pandas Data Structures 113 Texas 71000 Utah 5000 When only passing dict the index in the resulting Series will have the dicts keys in sorted order.  In 23 states California Ohio Oregon Texas In 24 obj4 Seriessdata indexstates In 25 obj4 Out 25 California NaN Ohio 35000 Oregon 16000 Texas 71000 In this case values found in sdata were placed in the appropriate locations but since no value for California was found it appears as NaN not number which is con sidered in pandas to mark missing or NA values.  will use the terms missing or NA to refer to missing data.  The isnul1 and notnul1 functions in pandas should be used to detect missing data In 26 pd. isnullobj4 In 27 pd. notnullobj4 Out 26 Out 27 California True California False Ohio False Ohio True Oregon False Oregon True Texas False Texas True Series also has these as instance methods In 28 obj4. isnull Out 28 California True Ohio False Oregon False Texas False discuss working with missing data in more detail later in this chapter.  critical Series feature for many applications is that it automatically aligns differently indexed data in arithmetic operations In 29 obj3 In 30 obj4 Out29 Out 30 Ohio 35000 California NaN Oregon 16000 Ohio 35000 Texas 71000 Oregon 16000 Utah 5000 Texas 71000 In 31 obj3 obj4 Out 31 California NaN Ohio 70000 Oregon 32000 114 Chapter Getting Started with pandas Texas 142000 Utah NaN Data alignment features are addressed as separate topic.  Both the Series object itself and its index have name attribute which integrates with other key areas of pandas functionality In 32 obj4. name population In 33 obj4. index. name state In 34 obj4 Out 34 state California NaN Ohio 35000 Oregon 16000 Texas 71000 Name population Seriess index can be altered in place by assignment In 35 obj. index Bob Steve Jeff Ryan In 36 obj Out 36 Bob Steve Jeff Ryan DataFrame DataFrame represents tabular spreadsheetlike data structure containing an or dered collection of columns each of which can be different value type numeric string boolean etc. .  The DataFrame has both row and column index it can be thought of as dict of Series one for all sharing the same index.  Compared with other such DataFramelike structures you may have used before like Rs data.  frame row oriented and columnoriented operations in DataFrame are treated roughly symmet rically.  Under the hood the data is stored as one or more twodimensional blocks rather than list dict or some other collection of onedimensional arrays.  The exact details of DataFrames internals are far outside the scope of this book.  While DataFrame stores the data internally in twodimensional for mat you can easily represent much higherdimensional data ina tabular format using hierarchical indexing subject of later section and key ingredient in many of the more advanced datahandling features in pan das.  Introduction to pandas Data Structures 115 There are numerous ways to construct DataFrame though one of the most common is from dict of equallength lists or NumPy arrays data state Ohio Ohio Ohio Nevada Nevada year 2000 2001 2002 2001 2002 pop 1. 5 1. 7 3. 6 2. 4 2. 9 frame DataFramedata The resulting DataFrame will have its index assigned automatically as with Series and the columns are placed in sorted order In 38 frame Out 38 pop state year 1. 5 Ohio 2000 Td Ohio 2001 3. 6 Ohio 2002 2. 4 Nevada 2001 2. 9 Nevada 2002 BWNRO If you specify sequence of columns the DataFrames columns will be exactly what you pass In 39 DataFramedata columnsyear state pop Out 39 year state pop 2000 Ohio 1. 5 2001 Ohio 1. 7 2002 Ohio 3. 6 2001 Nevada 2. 4 2002 Nevada 2. 9 As with Series if you pass column that isnt contained in data it will appear with NA values in the result In 40 frame2 DataFramedata columnsyear state pop debt ataa indexone two three four five In 41 frame2 Out 41 year state pop debt one 2000 Ohio 1. 5 NaN two 2001 Ohio 1. 7.  NaN three 2002 Ohio 3. 6 NaN four 2001 Nevada 2. 4 NaN five 2002 Nevada 2. 9 NaN In 42 frame2. columns Out42 Indexyear state pop debt dtypeobject Acolumn in DataFrame can be retrieved as Series either by dictlike notation or by attribute In 43 frame2state In 44 frame2. year Out 43 Out44 one Ohio one 2000 116 Chapter Getting Started with pandas two Ohio two 2001 three Ohio three 2002 four Nevada four 2001 five Nevada five 2002 Name state Name year Note that the returned Series have the same index as the DataFrame and their name attribute has been appropriately set.  Rows can also be retrieved by position or name by couple of methods such as the ix indexing field much more on this later In 45 frame2. ixthree Out 45 year 2002 state Ohio pop 3. 6 debt NaN Name three Columns can be modified by assignment.  For example the empty debt column could be assigned scalar value or an array of values In 46 frame2debt 16. 5 In 47 frame2 Out 47 year state pop debt one 2000 Ohio 1. 5 16. 5 two 2001 Ohio 1. 7 16. 5 three 2002 Ohio 3. 6 16. 5 four 2001 Nevada 2. 4 16. 5 five 2002 Nevada 2. 9 16. 5 In 48 frame2debt np. arange5.  In 49 frame2 Out 49 year state pop debt one 2000 Ohio 1. 5 two 2001 Ohio 1. 7 4.  three 2002 Ohio 3. 6 four 2001 Nevada 2. 4 five 2002 Nevada 2. 9 When assigning lists or arrays to column the values length must match the length of the DataFrame.  If you assign Series it will be instead conformed exactly to the DataFrames index inserting missing values in any holes In 50 val Series1. 2 1. 5 1. 7 indextwo four five In 51 frame2debt val In 52 frame2 Out 52 year state pop debt Introduction to pandas Data Structures 117 one 2000 Ohio 1. 5 NaN two 2001 Ohio 1. 7 1. 2 three 2002 Ohio 3. 6 NaN four 2001 Nevada 2. 4 1. 5 five 2002 Nevada 2. 9 1. 7 Assigning column that doesnt exist will create new column.  The del keyword will delete columns as with dict In 53 frame2eastern frame2. state Ohio In 54 frame2 Out54 year state pop debt eastern one 2000 Ohio 1. 5 NaN True two 2001 Ohio 1. 7 1. 2 True three 2002 Ohio 3. 6 NaN True four 2001 Nevada 2. 4 1. 5 False five 2002 Nevada 2. 9 1. 7 False In 55 del frame2eastern In 56 frame2. columns Out56 Indexyear state pop debt dtypeobject The column returned when indexing DataFrame is view on the un derlying data not copy.  Thus any inplace modifications to the Series will be reflected in the DataFrame.  The column can be explicitly copied using the Seriess copy method.  Another common form of data is nested dict of dicts format In 57 pop Nevada 2001 2. 4 2002 2. 9 Ohio 2000 1. 5 2001 1. 7 2002 3. 6 If passed to DataFrame it will interpret the outer dict keys as the columns and the inner keys as the row indices In 58 In 59 Out 59 Nevada 2000 2001 2002 frame3 DataFramepop frame3 Ohio 1. 5 1. 7 3. 6 NaN 2. 4 2. 9 Of course you can always transpose the result In 60 frame3. T Out 60 Nevada Ohio 2000 2001 2002 NaN 2. 4 1. 7 2. 9 ded 3. 6 118 Chapter Getting Started with pandas The keys in the inner dicts are unioned and sorted to form the index in the result.  This isnt true if an explicit index is specified In 61 DataFramepop index2001 2002 2003 Out 61 Nevada Ohio 2001 2. 4 1. 7 2002 2. 9 3. 6 2003 NaN NaN Dicts of Series are treated much in the same way In 62 pdata Ohio frame3Ohio1 were Nevada frame3 Nevada In 63 DataFramepdata Out 63 Nevada Ohio 2000 NaN 1. 5 2001 2. 4 1s7 For complete list of things you can pass the DataFrame constructor see Table 51.  If DataFrames index and columns have their name attributes set these will also be displayed In 64 frame3. index. name year frame3. columns. name state In 65 frame3 Out 65 state Nevada Ohio year 2000 NaN 1. 5 2001 2. 4 1. 7 2002 2. 9 3. 6 Like Series the values attribute returns the data contained in the DataFrame as 2D ndarray In 66 frame3. values Out 66 array nan 2. 4 2. 9 1. 5 1. 7 3. 6 If the DataFrames columns are different dtypes the dtype of the values array will be chosen to accomodate all of the columns In 67 frame2. values Out 67 array2000 Ohio 1. 5 nan 2001 Ohio 1. 7 1. 2 2002 Ohio 3. 6 nan 2001 Nevada 2. 4 2002 Nevada 2. 9 1. 5 1. 7 dtypeobject Introduction to pandas Data Structures 119 Table 51.  Possible data inputs to DataFrame constructor Type Notes 2D ndarray matrix of data passing optional row and column labels dict of arrays lists or tuples Each sequence becomes column in the DataFrame.  All sequences must be the same length.  NumPy structuredrecord array Treated as the dict of arrays case dict of Series Each value becomes column.  Indexes from each Series are unioned together to form the results row index if no explicit index is passed.  dict of dicts Each inner dict becomes column.  Keys are unioned to form the row index as in the dict of Series case.  list of dicts or Series Each item becomes row in the DataFrame.  Union of dict keys or Series indexes become the DataFrames column labels List of lists or tuples Treated as the 2D ndarray case Another DataFrame The DataFrames indexes are used unless different ones are passed NumPy MaskedArray Like the 2D ndarray case except masked values become NAmissing in the DataFrame result Index Objects pandass Index objects are responsible for holding the axis labels and other metadata like the axis name or names.  Any array or other sequence of labels used when con structing Series or DataFrame is internally converted to an Index In 68 obj Seriesrange3 indexa In 69 index obj. index In 70 index Out70 Indexa dtypeobject In 71 index1 Out71 Indexb dtypeobject Index objects are immutable and thus cant be modified by the user In 72 index1 Exception Traceback most recent call last ipythoninput72676fdeb26a68 in module index1 Userswesmcodepandaspandascoreindex. pyc in setitemself key value 302 def setitemself key value 303 Disable the setting of values.  304 raise Exceptionstrself. class object is immutable 305 306 def getitemself key Exception class pandas. core. index. Index object is immutable 120 Chapter Getting Started with pandas Immutability is important so that Index objects can be safely shared among data structures In 73 index pd. Indexnp. arange3 In 74 obj2 Series1. 5 2. 5 indexindex In 75 obj2. index is index Out75 True Table 52 has list of builtin Index classes in the library.  With some development effort Index can even be subclassed to implement specialized axis indexing function ality.  Many users will not need to know much about Index objects but they re nonetheless an important part of pandass data model.  Table 52.  Main Index objects in pandas Class Description Index The most general Index object representing axis labels in NumPy array of Python objects.  Int64Index Specialized Index for integer values.  MultiIndex Hierarchical index object representing multiple levels of indexing on single axis.  Can be thought of as similar to an array of tuples.  DatetimeIndex Stores nanosecond timestamps represented using NumPys datetime64 dtype.  PeriodIndex Specialized Index for Period data timespans.  In addition to being arraylike an Index also functions as fixedsize set In 76 frame3 Out 76 state Nevada Ohio year 2000 NaN 1. 5 2001 2. 4 1. 7 2002 2. 9 3. 6 In 77 Ohio in frame3. columns Out77 True In 78 2003 in frame3. index Out78 False Each Index has number of methods and properties for set logic and answering other common questions about the data it contains.  These are summarized in Table 53.  Introduction to pandas Data Structures 121 Table 53.  Index methods and properties Method append diff intersection union isin delete drop insert ismonotonic isunique unique Description Concatenate with additional Index objects producing new Index Compute set difference as an Index Compute set intersection Compute set union Compute boolean array indicating whether each value is contained in the passed collection Compute new Index with element at index deleted Compute new index by deleting passed values Compute new Index by inserting element at index Returns True if each element is greater than or equal to the previous element Returns True if the Index has no duplicate values Compute the array of unique values in the Index Essential Functionality In this section Ill walk you through the fundamental mechanics of interacting with the data contained in Series or DataFrame.  Upcoming chapters will delve more deeply into data analysis and manipulation topics using pandas.  This book is not intended to serve as exhaustive documentation for the pandas library instead focus on the most important features leaving the less common that is more esoteric things for you to explore on your own.  Reindexing critical method on pandas objects is reindex which means to create new object with the data conformed to new index.  Consider simple example from above In 79 obj Series4. 5 7. 2 5. 3 3. 6 indexd Calling reindex on this Series rearranges the data according to the new index intro ducing missing values if any index values were not already present 81 82 Out 82 5. 3 obj2 obj. reindexa obj2 122 Chapter Getting Started with pandas For ordered data like time series it may be desirable to do some interpolation or filling of values when reindexing.  The method option allows us to do this using method such as ffi11 which forward fills the values In 84 obj3 Seriesblue purple yellow index0 In 85 obj3. reindexrange6 methodffil1 Out 85 blue blue purple purple yellow yellow Table 54 lists available method options.  At this time interpolation more sophisticated than forward and backfilling would need to be applied after the fact.  Table 54.  reindex method interpolation options Argument Description fil or pad Fill or carry values forward bfillorbackfill Fill or carry values backward With DataFrame reindex can alter either the row index columns or both.  When passed just sequence the rows are reindexed in the result In 86 frame DataFramenp. arange9. reshape3 indexa wwe columnsOhio Texas California In 87 frame Out 87 Ohio Texas California dl Cc In 88 frame2 frame. reindexa In 89 frame2 Out 89 Essential Functionality 123 Ohio Texas California NaN NaN NaN The columns can be reindexed using the columns keyword In 90 states Texas Utah California In 91 frame. reindexcolumnsstates Out91 Texas Utah California NaN NaN NaN Both can be reindexed in one shot though interpolation will only apply rowwise axis In 92 frame. reindexindexa methodffill wwe columnsstates Out92 Texas Utah California NaN NaN NaN NaN As youll see soon reindexing can be done more succinctly by labelindexing with ix In 93 frame. ixa states Out 93 Texas Utah California NaN NaN NaN NaN Cc NaN NaN Table 55.  reindex function arguments Argument Description index New sequence to use as index.  Can be Index instance or any other sequencelike Python data structure.  An Index will be used exactly as is without any copying method Interpolation fill method see Table 54 for options.  fillvalue Substitute value to use when introducing missing data by reindexing limit When forward or backfilling maximum size gap to fill level Match simple Index on level of Multilndex otherwise select subset of copy If True always copy underlying data even if new index is equivalent to old index.  Otherwise do not copy the data when the indexes are equivalent.  124 Chapter Getting Started with pandas Dropping entries from an axis Dropping one or more entries from an axis is easy if you have an index array or list without those entries.  As that can require bit of munging and set logic the drop method will return new object with the indicated value or values deleted from an axis In 94 obj Seriesnp. arange5.  indexa In 95 newobj obj. dropc In 96 newobj Out 96 In 97 obj. dropd Out 97 With DataFrame index values can be deleted from either axis In 98 data DataFramenp. arange16. reshape4 ataa indexOhio Colorado Utah New York asa columnsone two three four In 99 data. dropColorado Ohio Out 99 one two three four Utah 10 11 New York 12 13 14 15 In 100 data. droptwo axis1 In 101 data. droptwo four axis1 Out100 Out101 one three four one three Ohio Ohio Colorado Colorado Utah 10 11 Utah 10 New York 12 14 15 New York 12 14 Indexing selection and filtering Series indexing obj. . .  works analogously to NumPy array indexing except you can use the Seriess index values instead of only integers.  Here are some examples of this In 102 obj Seriesnp. arange4.  indexa In 103 objb In 104 obj1 Out103 1. 0 Out104 1. 0 In 105 obj24 In 106 objb Out 105 Out 106 Essential Functionality 125 In 107 obj1 In 108 objobj Out 107 Out 108 Slicing with labels behaves differently than normal Python slicing in that the endpoint is inclusive In 109 objbc Out109 Cc Setting using these methods works just as you would expect In 110 objbc As youve seen above indexing into DataFrame is for retrieving one or more columns either with single value or sequence In 112 data DataFramenp. arange16. reshape4 aerosol indexOhio Colorado Utah New York sere columnsone two three four Out 113 one two three four Ohio Colorado Utah 10 11 New York 12 13 14 15 In 114 datatwo In 115 datathree one Out 114 Out 115 Ohio three one Colorado Ohio Utah Colorado New York 13 Utah 10 Name two New York 14 12 Indexing like this has few special cases.  First selecting rows by slicing or boolean array In 116 data2 In 117 datadatathree Out 116 Out117 one two three four one two three four 126 Chapter5 Getting Started with pandas Ohio Colorado Colorado Utah 10 11 New York 12 13 14 15 This might seem inconsistent to some readers but this syntax arose out of practicality and nothing more.  Another use case is in indexing with boolean DataFrame such as one produced by scalar comparison In 118 data Out 118 one two three four Ohio True True True True Colorado True False False False Utah False False False False New York False False False False In 119 datadata In 120 data Out120 one two three four Ohio Colorado Utah 10 11 New York 12 13 14 15 This is intended to make DataFrame syntactically more like an ndarray in this case.  For DataFrame labelindexing on the rows introduce the special indexing field ix.  It enables you to select subset of the rows and columns from DataFrame with NumPy like notation plus axis labels.  As mentioned earlier this is also less verbose way to do reindexing In 121 data. ixColorado two three Out121 two three Name Colorado In 122 data. ixColorado Utah Out122 four one two Colorado Utah 11 In 123 data. ix2 In 124 data. ixUtah two Out 123 Out 124 one Ohio two Colorado three 10 Utah four 11 Name two Name Utah In 125 data. ixdata. three Out 125 Essential Functionality 127 one two three Colorado Utah 10 New York 12 13 14 So there are many ways to select and rearrange the data contained in pandas object.  For DataFrame there is short summary of many of them in Table 56.  You have number of additional options when working with hierarchical indexes as youll later see.  When designing pandas felt that having to type frame col to select column was too verbose and errorprone since column selection is 18 one of the most common operations.  Thus made the design tradeoff to push all of the rich labelindexing into ix.  Table 56.  Indexing options with DataFrame Type Notes objval Select single column or sequence of columns from the DataFrame.  Special case con veniences boolean array filter rows slice slice rows or boolean DataFrame set values based on some criterion.  obj. ixval Selects single row or subset of rows from the DataFrame.  obj. ix val Selects single column of subset of columns.  obj. ixval1 val2 Select both rows and columns.  reindex method Conform one or more axes to new indexes.  xs method Select single row or column as Series by label.  icol irowmethods Select single column or row respectively as Series by integer location.  getvalue setvaluemethods Select single value by row and column label.  Arithmetic and data alignment One of the most important pandas features is the behavior of arithmetic between ob jects with different indexes.  When adding together objects if any index pairs are not the same the respective index in the result will be the union of the index pairs.  Lets look at simple example In 126 s1 Series7. 3 2. 5 3. 4 1. 5 indexa In 127 s2 Series2. 1 3. 6 1. 5 3. 1 indexa In 128 sa In 129 s2 Out 128 Out129 7. 3 2. 1 cc 2. 5 3. 6 3. 4 1. 5 128 Chapter5 Getting Started with pandas 1. 5 Adding these together yields In 130 s1 s2 Out 130 AoaAan 8g 502 1.  NaN 0. 0 NaN NaN The internal data alignment introduces NA values in the indices that dont overlap.  Missing values propagate in arithmetic computations.  In the case of DataFrame alignment is performed on both the rows and the columns In 131 df1 DataFramenp. arange9. . reshape3 columnslistbcd In 133 Out 133 Ohio Texas Colorado indexOhio Texas Colorado df2 DataFramenp. arange12. . reshape4 columnslistbde indexUtah Ohio Texas Oregon df4 In 134 df2 Out 134 bcd die Oo Utah 3455 Ohio Texas Oregon 10 11 Adding these together returns DataFrame whose index and columns are the unions of the ones in each DataFrame In 135 df1 df2 Out 135 bc dee Colorado NaN NaN NaN NaN Ohio Oregon Texas Utah NaN NaN NaN NaN NaN NaN NaN 12 NaN NaN NaN NaN NaN Arithmetic methods with fill values In arithmetic operations between differentlyindexed objects you might want to fill with special value like when an axis label is found in one object but not the other In 136 df1 DataFramenp. arange12. . reshape3 columnslistabcd In 137 df2 DataFramenp. arange20. . reshape4 columnslistabcde In 138 df1 In 139 df2 Out 138 Out 139 ab ocd cde Essential Functionality 129 001 oO 145 10 411 10 11 12 13 14 15 16 17 18 19 Adding these together results in NA values in the locations that dont overlap In 140 df1 df2 Out 140 oc dee 4.  NaN 11 13 15 NaN 18 20 22 24 NaN NaN NaN NaN NaN NaN Using the add method on df1 pass df2 and an argument to fillvalue In 141 df1. adddf2 fillvalueo Out 141 bc dee 11 13 15 18 20 22 24 14 15 16 17 18 19 WNrR OO Relatedly when reindexing Series or DataFrame you can also specify different fill value In 142 df1. reindexcolumnsdf2. columns fillvalueo Out 142 bc de 001 145 10 11 Table 57.  Flexible arithmetic methods Method Description add Method for addition sub Method for subtraction div Method for division mul Method for multiplication Operations between DataFrame and Series As with NumPy arrays arithmetic between DataFrame and Series is welldefined.  First as motivating example consider the difference between 2D array and one of its rows In 143 arr np. arange12. . reshape3 In 144 arr Out 144 array 0.  1.  2.  3.  4. 5 55 6. 5 130 Chapter5 Getting Started with pandas 8.  9.  10.  11.  In 145 arro Out145 array 0.  1.  2.  3.  In 146 arr arro Out 146 array 0.  4.  8.  This is referred to as broadcasting and is explained in more detail in Chapter 12.  Op erations between DataFrame and Series are similar of Oo vw ewe of Oo ay of oO vee In 147 frame DataFramenp. arange12. . reshape4 columnslistbde ugiea indexUtah Ohio Texas Oregon In 148 series frame. ix0 In 149 frame In 150 series Out149 Out150 die Utah Ohio Texas Name Utah Oregon 10 11 By default arithmetic between DataFrame and Series matches the index of the Series on the DataFrames columns broadcasting down the rows In 151 frame series Out151 bde Utah 00 Ohio Texas Oregon If an index value is not found in either the DataFrames columns or the Seriess index the objects will be reindexed to form the union In 152 series2 Seriesrange3 indexb In 153 frame series2 Out153 de Utah NaN NaN Ohio NaN NaN Texas NaN NaN Oregon NaN 12 NaN If you want to instead broadcast over the columns matching on the rows you have to use one of the arithmetic methods.  For example In 154 series3 framed In 155 frame In 156 series3 Essential Functionality 131 Out155 Out156 die Utah Utah Ohio Ohio Texas Texas Oregon 10 Oregon 10 11 Name In 157 frame. subseries3 axis0 Out157 bde Utah Ohio Texas Oregon The axis number that you pass is the axis to match on.  In this case we mean to match on the DataFrames row index and broadcast across.  Function application and mapping NumPy ufuncs elementwise array methods work fine with pandas objects In 158 frame DataFramenp. random. randn4 columnslistbde ore indexUtah Ohio Texas Oregon In 159 frame In 160 np. absframe Out 159 Out 160 Utah 0. 204708 0. 478943 0. 519439 Utah 0. 204708 0. 478943 0. 519439 Ohio 0. 555730 1. 965781 1. 393406 Ohio 0. 555730 1. 965781 1. 393406 Texas 0. 092908 0. 281746 0. 769023 Texas 0. 092908 0. 281746 0. 769023 Oregon 1. 246435 1. 007189 1. 296221 Oregon 1. 246435 1. 007189 1. 296221 Another frequent operation is applying function on 1D arrays to each column or row.  DataFrames apply method does exactly this In 161 lambda x. max x. min In 162 frame. applyf In 163 frame. applyf axis1 Out 162 Out 163 1. 802165 Utah 0. 998382 1. 684034 Ohio 24521517 2. 689627 Texas 0. 676115 Oregon 2. 542656 Many of the most common array statistics like sum and mean are DataFrame methods so using apply is not necessary.  The function passed to apply need not return scalar value it can also return Series with multiple values In 164 def fx soneed return Seriesx. min x. max indexmin max In 165 frame. applyf 132 Chapter5 Getting Started with pandas Out 165 min 0. 555730 0. 281746 1. 296221 max 1. 246435 1. 965781 1. 393406 Elementwise Python functions can be used too.  Suppose you wanted to compute formatted string from each floating point value in frame.  You can do this with applymap In 166 format lambda . 2f In 167 frame. applymapformat Out 167 Utah 0. 20 Ohio 0. 56 Texas 0. 09 Oregon 1. 25 0. 48 1. 97 0. 28 1. 01 0. 52 1. 39 0. 77 1. 30 The reason for the name applymap is that Series has map method for applying an ele mentwise function In 168 framee. mapformat Out 168 Utah 0. 52 Ohio 1. 39 Texas 0. 77 Oregon 1. 30 Name Sorting and ranking Sorting data set by some criterion is another important builtin operation.  To sort lexicographically by row or column index use the sortindex method which returns new sorted object In 169 obj Seriesrange4 indexd In 170 obj. sortindex Out170 With DataFrame you can sort by index on either axis In 171 frame DataFramenp. arange8. reshape2 indexthree one columnsd In 172 frame. sortindex In 173 frame. sortindexaxis1 Out172 Out173 dabe bcd one 45 67 three three one Essential Functionality 133 The data is sorted in ascending order by default but can be sorted in descending order too In 174 frame. sortindexaxis1 ascendingFalse Out174 dc three one mR To sort Series by its values use its order method In 175 obj Series4 In 176 obj. order Out 176 Any missing values are sorted to the end of the Series by default In 177 obj Series4 np. nan np. nan In 178 obj. order Out 178 NaN NaN On DataFrame you may want to sort by the values in one or more columns.  To do so pass one or more column names to the by option In 179 frame DataFrameb In 180 frame In 181 frame. sortindexbyb Out 180 Out 181 00 03 117 00 117 To sort by multiple columns pass list of names In 182 frame. sortindexbya Out182 03 12 117 134 Chapter5 Getting Started with pandas Ranking is closely related to sorting assigning ranks from one through the number of valid data points in an array.  It is similar to the indirect sort indices produced by numpy. argsort except that ties are broken according to rule.  The rank methods for Series and DataFrame are the place to look by default rank breaks ties by assigning each group the mean rank In 183 obj Series7 In 184 obj. rank Out 184 6. 5 aAuFPWNPR OO PNWAB WE Wmuoouwunne Ranks can also be assigned according to the order theyre observed in the data In 185 obj. rankmethod first Out 185 Naturally you can rank in descending order too In 186 obj. rankascendingFalse methodmax Out 186 See Table 58 fora list of tiebreaking methods available.  DataFrame can compute ranks over the rows or the columns In 187 frame DataFrameb 4. 3 sees 2. 5 In 188 frame In 189 frame. rankaxis1 Out 188 Out189 be 4. 3 2. 0 7. 0 5. 0 113 03. 0 8. 0 22 2. 0 2. 5 Essential Functionality 135 Table 58.  Tiebreaking methods with rank Method Description average Default assign the average rank to each entry in the equal group.  min Use the minimum rank for the whole group.  max Use the maximum rank for the whole group.  first Assign ranks in the order the values appear in the data.  Axis indexes with duplicate values Up until now all of the examples Ive showed you have had unique axis labels index values.  While many pandas functions like reindex require that the labels be unique its not mandatory.  Lets consider small Series with duplicate indices In 190 obj Seriesrange5 indexa 191 obj 191 PWNPRP OW WO The indexs isunique property can tell you whether its values are unique or not In 192 obj. index. is unique Out192 False Data selection is one of the main things that behaves differently with duplicates.  In dexing value with multiple entries returns Series while single entries return scalar value In 193 obja In 194 objc Out 193 Out194 The same logic extends to indexing rows in DataFrame In 195 df DataFramenp. random. randn4 indexa In 196 df Out 196 0. 274992 0. 228913 1. 352917 0. 886429 2. 001637 0. 371843 1. 669025 0. 438570 0. 539741 0. 476985 3. 248944 1. 021228 coon wy In 197 df. ixb Out197 136 Chapter5 Getting Started with pandas 1. 669025 0. 438570 0. 539741 0. 476985 3. 248944 1. 021228 Summarizing and Computing Descriptive Statistics pandas objects are equipped with set of common mathematical and statistical meth ods.  Most of these fall into the category of reductions or summary statistics methods that extract single value like the sum or mean froma Series or Series of values from the rows or columns of DataFrame.  Compared with the equivalent methods of vanilla NumbPy arrays they are all built from the ground up to exclude missing data.  Consider small DataFrame In 198 df DataFrame1. 4 np. nan 7. 1 4. 5 wnarere np. nan np. nan 0. 75 1. 3 newest indexa marry columnsone two In 199 df Out199 one two 1. 40 NaN 7. 10 4. 5 NaN NaN 0. 75 1. 3 Calling DataFrames sum method returns Series containing column sums In 200 df. sum Out200 one 9. 25 two 5. 80 Passing axis1 sums over the rows instead In 201 df. sumaxis1 Out201 1. 40 2. 60 NaN 0. 55 NA values are excluded unless the entire slice row or column in this case is NA.  This can be disabled using the skipna option In 202 df. meanaxis1 skipnaFalse Out 202 NaN 1. 300 Cc NaN 0. 275 See Table 59 for list of common options for each reduction method options.  Summarizing and Computing Descriptive Statistics 137 Table 59.  Options for reduction methods Method Description axis Axis to reduce over.  for DataFrames rows and for columns.  skipna Exclude missing values True by default.  level Reduce grouped by level if the axis is hierarchicallyindexed Multilndex.  Some methods like idxmin and idxmax return indirect statistics like the index value where the minimum or maximum values are attained In 203 df. idxmax Out 203 one two Other methods are accumulations In 204 df. cumsum Out204 one two 1. 40 NaN 8. 50 4. 5 NaN NaN 9. 25 5. 8 aq ow Another type of method is neither reduction nor an accumulation.  describe is one such example producing multiple summary statistics in one shot In 205 df. describe Out 205 one two count 3. 000000 2. 000000 mean 3. 083333 2. 900000 std 3. 493685 2. 262742 min 0. 750000 4. 500000 25 1. 075000 3. 700000 50 1. 400000 2. 900000 75 4. 250000 2. 100000 max 100000 1. 300000 On nonnumeric data describe produces alternate summary statistics In 206 obj Seriesa In 207 obj. describe Out207 count 16 unique top freq See Table 510 for full list of summary statistics and related methods.  138 Chapter5 Getting Started with pandas Table 510.  Descriptive and summary statistics Method count describe min max argmin argmax idxmin idxmax quantile sum mean median mad var std skew kurt cumsum cummin cummax cumprod diff pctchange Description Number of nonNA values Compute set of summary statistics for Series or each DataFrame column Compute minimum and maximum values Compute index locations integers at which minimum or maximum value obtained respectively Compute index values at which minimum or maximum value obtained respectively Compute sample quantile ranging from to Sum of values Mean of values Arithmetic median 50 quantile of values Mean absolute deviation from mean value Sample variance of values Sample standard deviation of values Sample skewness 3rd moment of values Sample kurtosis 4th moment of values Cumulative sum of values Cumulative minimum or maximum of values respectively Cumulative product of values Compute 1st arithmetic difference useful for time series Compute percent changes Correlation and Covariance Some summary statistics like correlation and covariance are computed from pairs of arguments.  Lets consider some DataFrames of stock prices and volumes obtained from Yahoo Finance import pandas. io. data as web all data for ticker in AAPL IBM MSFT GOOG alldataticker web. getdatayahooticker 112000 112010 price DataFrametic dataAdj Close for tic data in alldata. iteritems volume DataFrametic dataVolume for tic data in alldata. iteritems now compute percent changes of the prices In 209 returns price. pctchange In 210 returns. tail Summarizing and Computing Descriptive Statistics 139 Out210 AAPL GOOG IBM MSFT Date 20091224 0. 034339 0. 011117 0. 004420 0. 002747 20091228 0. 012294 0. 007098 0. 013282 0. 005479 20091229 0. 011861 0. 005571 0. 003474 0. 006812 20091230 0. 012147 0. 005376 0. 005468 0. 013532 20091231 0. 004300 0. 004416 0. 012609 0. 015432 The corr method of Series computes the correlation of the overlapping nonNA alignedbyindex values in two Series.  Relatedly cov computes the covariance In 211 returns. MSFT. corrreturns.  IBM Out211 0. 49609291822168838 In 212 returns. MSFT. covreturns.  IBM Out212 0. 00021600332437329015 DataFrames corr and cov methods on the other hand return full correlation or covariance matrix as DataFrame respectively In 213 returns. corr Out 213 AAPL GOOG IBM MSFT AAPL 1. 000000 0. 470660 0. 410648 0. 424550 GOOG 0. 470660 1. 000000 0. 390692 0. 443334 IBM 0. 410648 0. 390692 1. 000000 0. 496093 MSFT 0. 424550 0. 443334 0. 496093 1. 000000 In 214 returns. cov Out214 AAPL GOOG IBM MSFT AAPL 0. 001028 0. 000303 0. 000252 0. 000309 GOOG 0. 000303 0. 000580 0. 000142 0. 000205 IBM 0. 000252 0. 000142 0. 000367 0. 000216 MSFT 0. 000309 0. 000205 0. 000216 0. 000516 Using DataFrames corrwith method you can compute pairwise correlations between DataFrames columns or rows with another Series or DataFrame.  Passing Series returns Series with the correlation value computed for each column In 215 returns. corrwithreturns.  IBM Out215 AAPL 0. 410648 GOOG 0. 390692 IBM 1. 000000 MSFT 0. 496093 Passing DataFrame computes the correlations of matching column names.  Here compute correlations of percent changes with volume In 216 returns. corrwithvolume Out216 AAPL 0. 057461 GOOG 0. 062644 140 Chapter5 Getting Started with pandas IBM 0. 007900 MSFT 0. 014175 Passing axis1 does things rowwise instead.  In all cases the data points are aligned by label before computing the correlation.  Unique Values Value Counts and Membership Another class of related methods extracts information about the values contained in onedimensional Series.  To illustrate these consider this example In 217 obj Seriesc The first function is unique which gives you an array of the unique values in Series In 218 uniques obj. unique In 219 uniques Out219 arrayc dtypeobject The unique values are not necessarily returned in sorted order but could be sorted after the fact if needed uniques. sort.  Relatedly valuecounts computes Series con taining value frequencies In 220 obj. valuecounts Out220 The Series is sorted by value in descending order as convenience.  valuecounts is also available as toplevel pandas method that can be used with any array or sequence In 221 pd. valuecountsobj. values sortFalse Out221 Lastly isin is responsible for vectorized set membership and can be very useful in filtering data set down to subset of values in Series or column in DataFrame In 222 mask obj. isinb In 223 mask In 224 objmask Out 223 Out 224 True False False False False True True Aun PWNR OO CoN OW nnowe Summarizing and Computing Descriptive Statistics 141 True True See Table 511 for reference on these methods.  Table 511.  Unique value counts and binning methods Method isin unique valuecounts Description Compute boolean array indicating whether each Series value is contained in the passed sequence of values.  Compute array of unique values in Series returned in the order observed.  Return Series containing unique values as its index and frequencies as its values ordered count in descending order.  In some cases you may want to compute histogram on multiple related columns in DataFrame.  Heres an example In 225 data In 226 data Out 226 Qu1 BWNRO Pw pw Qu2 WN RW Qu3 DataFrameQui Qu2 Qu3 Passing pandas. valuecounts to this DataFrames apply function gives In 227 result data. applypd. valuecounts. fillnao In 228 result Out 228 Qu1 WPWN PR ONNO Qu2 CONNER Qu3 RPNOR Handling Missing Data Missing data is common in most data analysis applications.  One of the goals in de signing pandas was to make working with missing data as painless as possible.  For example all of the descriptive statistics on pandas objects exclude missing data as you ve seen earlier in the chapter.  142 Chapter Getting Started with pandas pandas uses the floating point value NaN Not Number to represent missing data in both floating as well as in nonfloating point arrays.  It is just used as sentinel that can be easily detected In 229 string data Seriesaardvark artichoke np. nan avocado In 230 string data In 231 string data. isnull Out 230 Out 231 aardvark False artichoke False NaN True avocado False The builtin Python None value is also treated as NA in object arrays In 232 string datao None In 233 string data. isnull Out 233 True False True False do not claim that pandass NA representation is optimal but it is simple and reason ably consistent.  Its the best solution with good allaround performance characteristics and simple API that could concoct in the absence of true NA data type or bit pattern in NumPys data types.  Ongoing development work in NumPy may change this in the future.  Table 512.  NA handling methods Argument Description dropna Filter axis labels based on whether values for each label have missing data with varying thresholds for how much missing data to tolerate.  fillna Fill in missing data with some value or using an interpolation method such as ffil1 or bfill.  isnull Return liketype object containing boolean values indicating which values are missing NA.  notnull Negation of isnu11.  Filtering Out Missing Data You have number of options for filtering out missing data.  While doing it by hand is always an option dropna can be very helpful.  On Series it returns the Series with only the nonnull data and index values In 234 from numpy import nan as NA In 235 data Series1 NA 3. 5 NA In 236 data. dropna Out 236 Handling Missing Data 143 Naturally you could have computed this yourself by boolean indexing In 237 datadata. notnull Out 237 1. 0 3. 5 7. 0 With DataFrame objects these are bit more complex.  You may want to drop rows or columns which are all NA or just those containing any NAs.  dropna by default drops any row containing missing value In 238 data DataFrame1.  6. 5 3.  1.  NA NA veeee NA NA NA NA 6. 5 3.  In 239 cleaned data. dropna In 240 data In 241 cleaned Out 240 Out241 1.  12 6. 5 6. 5 NaN NaN NaN NaN NaN NaN 6. 5 Passing howal1 will only drop rows that are all NA In 242 data. dropnahowall1 Out 242 6. 5 NaN NaN NaN 6. 5 Dropping columns in the same way is only matter of passing axis1 In 243 data4 NA In 244 data In 245 data. dropnaaxis1 howall Out 244 Out245 d.  6. 5 NaN 6. 5 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 6. 5 NaN NaN 6. 5 related way to filter out DataFrame rows tends to concern time series data.  Suppose you want to keep only rows containing certain number of observations.  You can indicate this with the thresh argument In 246 df DataFramenp. random. randn7 In 247 df. ix4 NA df. ix2 NA 144 Chapter Getting Started with pandas In 248 df Out 248 1.  0. 577087 NaN NaN 0. 523772 NaN NaN 0. 713544 NaN NaN 1. 860761 NaN 0. 560145 1. 265934 NaN 1. 063512 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 Filling in Missing Data In 249 df. dropnathresh3 Out249 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 Rather than filtering out missing data and potentially discarding other data along with it you may want to fill in the holes in any number of ways.  For most purposes the fillna method is the workhorse function to use.  Calling fillna with constant replaces missing values with that value In 250 df. fillnao Out 250 0. 577087 0. 000000 0. 000000 0. 523772 0. 000000 0. 000000 0. 713544 0. 000000 0. 000000 1. 860761 0. 000000 0. 560145 1. 265934 0. 000000 1. 063512 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 Calling fillna with dict you can use different fill value for each column In 251 df. fillna1 0. 5 Out 251 1.  0. 577087 0. 500000 NaN 0. 523772 0. 500000 NaN 0. 713544 0. 500000 NaN 1. 860761 0. 500000 0. 560145 1. 265934 0. 500000 1. 063512 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 fillna returns new object but you can modify the existing object in place always returns reference to In 252 In 253 df Out 253 0. 577087 0. 000000 0. 000000 0. 523772 0. 000000 0. 000000 0. 713544 0. 000000 0. 000000 1. 860761 0. 000000 0. 560145 the filled object df. fillna0 inplaceTrue Handling Missing Data 145 1. 265934 0. 000000 1. 063512 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 The same interpolation methods available for reindexing can be used with fillna In 254 In 255 df.  In 256 df Out 256 0. 286350 0. 331286 0. 246674 1. 327195 0. 022185 0. 862580 In 257 df.  Out257 0. 286350 0. 331286 0. 246674 1. 327195 0. 022185 0. 862580 With fillna you can do lots of other things with little creativity.  For example you df DataFramenp. random. randn6 ix2 NA df. ix4 NA 0. 377984 0. 753887 1. 349742 0. 069877 NaN 1. 004812 NaN 1. 549106 NaN NaN NaN NaN fillnamethod fill 0. 377984 0. 753887 349742 0. 069877 349742 1. 004812 349742 1. 549106 349742 1. 549106 349742 1. 549106 PRPPRPRB In 258 df. fillnamethodffill limit2 Out 258 UBPWNPR OO 0. 286350 0. 331286 0. 246674 1. 327195 0. 022185 0. 862580 might pass the mean or median value of Series In 259 data Series1.  NA 3. 5 NA In 260 data.  fillnadata. mean Out260 1. 000000 3. 833333 3. 500000 3. 833333 7. 000000 See Table 513 for reference on fillna.  Table 513.  fillna function arguments Argument Description value method axis inplace limit Scalar value or dictlike object to use to fill missing values 0. 377984 0. 753887 1. 349742 0. 069877 1. 349742 1. 004812 1. 349742 1. 549106 NaN 1. 549106 NaN 1. 549106 Interpolation by default i11 iffunction called with no other arguments Axis to fill on default axis0 Modify the calling object without producing copy For forward and backward filling maximum number of consecutive periods to fill 146 Chapter5 Getting Started with pandas Hierarchical Indexing Hierarchical indexing is an important feature of pandas enabling you to have multiple two or more index levels on an axis.  Somewhat abstractly it provides way for you to work with higher dimensional data in lower dimensional form.  Lets start with simple example create Series with list of lists or arrays as the index In 261 data Seriesnp. random. randn10 eee indexa wore In 262 data Out 262 ail 0. 670216 0. 852965 0. 955869 0. 023493 2. 304234 0. 652469 1. 218302 1. 332610 1. 074623 0. 723642 What youre seeing is prettified view of Series with MultiIndex as its index.  The gaps in the index display mean use the label directly above In 263 data. index Out 263 MultiIndex With hierarchicallyindexed object socalled partial indexing is possible enabling you to concisely select subsets of the data In 264 datab Out264 0. 023493 2. 304234 0. 652469 In 265 databc In 266 data. ixb Out 265 Out 266 0. 023493 0. 023493 2. 304234 2. 304234 0. 652469 0. 652469 1. 218302 1. 074623 1. 332610 0. 723642 Selection is even possible in some cases from an inner level In 267 data Out 267 0. 852965 Hierarchical Indexing 147 2. 304234 1. 332610 1. 074623 Hierarchical indexing plays critical role in reshaping data and groupbased operations like forming pivot table.  For example this data could be rearranged into DataFrame using its unstack method In 268 data. unstack Out 268 0. 670216 0. 852965 0. 955869 0. 023493 2. 304234 0. 652469 Cc 1. 218302 1. 332610 NaN NaN 1. 074623 0. 723642 The inverse operation of unstack is stack In 269 data. unstack. stack Out269 ai 0. 670216 0. 852965 0. 955869 0. 023493 2. 304234 0. 652469 1. 218302 1. 332610 1. 074623 0. 723642 WNN PWN PW DY stack and unstack will be explored in more detail in Chapter 7.  With DataFrame either axis can have hierarchical index In 270 frame DataFramenp. arange12. reshape4 sees indexa scone ad columnsOhio Ohio Colorado scone ad Green Red Green In 271 frame Out 271 Ohio Colorado Green Red Green ai bi 10 11 The hierarchical levels can have names as strings or any Python objects.  If so these will show up in the console output dont confuse the index names with the axis labels In 272 frame. index. names key1 key2 In 273 frame. columns. names state color In 274 frame 148 Chapter Getting Started with pandas Out 274 state Ohio Colorado color Green Red Green key1 key2 10 11 With partial column indexing you can similarly select groups of columns In 275 frameOhio Out275 color Green Red key1 key2 10 MultilIndex can be created by itself and then reused the columns in the above Data Frame with level names could be created like this MultilIndex. fromarraysOhio Ohio Colorado Green Red Green namesstate color Reordering and Sorting Levels At times you will need to rearrange the order of the levels on an axis or sort the data by the values in one specific level.  The swaplevel takes two level numbers or names and returns new object with the levels interchanged but the data is otherwise unaltered In 276 frame. swaplevelkey1 key2 Out 276 state Ohio Colorado color Green Red Green key2 key1 10 11 sortlevel on the other hand sorts the data stably using only the values in single level.  When swapping levels its not uncommon to also use sortlevel so that the result is lexicographically sorted In 277 frame. sortlevel1 In 278 frame. swaplevel0 1. sortlevel0o Out 277 Out278 state Ohio Colorado state Ohio Colorado color Green Red Green color Green Red Green key1 key2 key2 key1 10 11 10 11 Hierarchical Indexing 149 Data selection performance is much better on hierarchically indexed objects if the index is lexicographically sorted starting with the outer 12 most level that is the result of calling sortlevel0 or sortindex.  Summary Statistics by Level Many descriptive and summary statistics on DataFrame and Series have level option in which you can specify the level you want to sum by on particular axis.  Consider the above DataFrame we can sum by level on either the rows or columns like so In 279 frame. sumlevelkey2 Out 279 state Ohio Colorado color Green Red Green key2 10 12 14 16 In 280 frame. sumlevelcolor axis1 Out 280 color Green Red key1 key2 14 20 10 Under the hood this utilizes pandass groupby machinery which will be discussed in more detail later in the book.  Using DataFrames Columns Its not unusual to want to use one or more columns from DataFrame as the row index alternatively you may wish to move the row index into the DataFrames col umns.  Heres an example DataFrame acmnned one one one two two two two acmnned In 281 frame DataFramea range7 range7 In one one one two two two two Aun PWNR OO WNRONR OQ 150 Chapter5 Getting Started with pandas DataFrames setindex function will create new DataFrame using one or more of its columns as the index In 283 frame2 frame. setindexc In 284 frame2 Out 284 ot anu PWNPR RPNWHU ON By default the columns are removed from the DataFrame though you can leave them in In 285 frame. setindexc dropFalse Out 285 one one one one twoO0 two two two two resetindex on the other hand does the opposite of setindex the hierarchical index levels are are moved into the columns In 286 frame2. resetindex Out 286 one one one two two two two Au RPWNPR OC WNHRONrFR OQ DAuRPWNPR OO PNWHRUDN OT Other pandas Topics Here are some additional topics that may be of use to you in your data travels.  Integer Indexing Working with pandas objects indexed by integers is something that often trips up new users due to some differences with indexing semantics on builtin Python data Other pandas Topics 151 structures like lists and tuples.  For example you would not expect the following code to generate an error ser Seriesnp. arange3.  ser1 In this case pandas could fall back on integer indexing but theres not safe and general way that know of to do this without introducing subtle bugs.  Here we have an index containing but inferring what the user wants labelbased indexing or positionbased is difficult In 288 ser Out 288 On the other hand with noninteger index there is no potential for ambiguity In 289 ser2 Seriesnp. arange3.  indexa In 290 ser21 Out290 2. 0 To keep things consistent if you have an axis index containing indexers data selection with integers will always be labeloriented.  This includes slicing with ix too In 291 ser. ix1 Out291 In cases where you need reliable positionbased indexing regardless of the index type you can use the igetvalue method from Series and irow and icol methods from Da taFrame In 292 ser3 Seriesrange3 index5 In 293 ser3. igetvalue2 Out293 In 294 frame DataFramenp. arange6. reshape3 index2 In 295 frame. irow0 Out295 1.  Name Panel Data While not major topic of this book pandas has Panel data structure which you can think of as threedimensional analogue of DataFrame.  Much of the development focus of pandas has been in tabular data manipulations as these are easier to reason about 152 Chapter5 Getting Started with pandas and hierarchical indexing makes using truly Ndimensional arrays unnecessary in lot of cases.  To create Panel you can use dict of DataFrame objects or threedimensional ndarray import pandas. io. data as web pdata pd. Paneldictstk web. getdatayahoostk 112009 612012 for stk in AAPL GOOG MSFT DELL Each item the analogue of columns in DataFrame in the Panel is DataFrame In 297 pdata Out 297 class pandas. core. panel. Panel Dimensions items 861 major minor Items AAPL to MSFT Major axis 20090102 00 to 20120601 00 Minor axis Open to Adj Close In 298 pdata pdata. swapaxesitems minor In 299 pdataAdj Close Out 299 class pandas. core.  frame. DataFrame DatetimeIndex 861 entries 20090102 00 to 20120601 00 Data columns AAPL 861 nonnull values DELL 861 nonnull values GOOG 861 nonnull values MSFT 861 nonnull values dtypes float644 ixbased label indexing generalizes to three dimensions so we can select all data at particular date or range of dates like so In 300 pdata. ix 612012 Out 300 Open High Low Close Volume Adj Close AAPL 569. 16 572. 65 560. 52 560. 99 18606700 560. 99 DELL 12. 15 12. 30 12. 05 12. 07 19396700 12. 07 GOOG 571. 79 572. 65 568. 35 570. 98 3057900 570. 98 MSFT 28. 76 28. 96 28. 44 28. 45 56634300 28. 45 In 301 pdata. ixAdj Close 5222012 Out 301 AAPL DELL GOOG MSFT Date 20120522 556. 97 15. 08 600. 80 29. 76 20120523 570. 56 12. 49 609. 46 29. 11 20120524 565. 32 12. 45 603. 66 29. 07 20120525 562. 29 12. 46 591. 53 29. 06 20120529 572. 27 12. 66 594. 34 29. 56 20120530 579. 17 12. 56 588. 23 29. 34 Other pandas Topics 153 20120531 577. 73 12. 33 580. 86 29. 19 20120601 560. 99 12. 07 570. 98 28. 45 An alternate way to represent panel data especially for fitting statistical models is in stacked DataFrame form In 302 stacked pdata. ix 5302012 . toframe In 303 stacked Out 303 Open High Low Close Volume Adj Close major minor 20120530 AAPL 569. 20 579. 99 566. 56 579. 17 18908200 579. 17 DELL 12. 59 12. 70 12. 46 12. 56 19787800 12. 56 GOOG 588. 16 591. 90 583. 53 588. 23 1906700 588. 23 MSFT 29. 35 29. 48 29. 12 29. 34 41585500 29. 34 20120531 AAPL 580. 74 581. 50 571. 46 577. 73 17559800 577. 73 DELL 12. 53 12. 54 12. 33 12. 33 19955500 12. 33 GOOG 588. 72 590. 00 579. 00 580. 86 2968300 580. 86 MSFT 29. 30 29. 42 28. 94 29. 19 39134000 29. 19 20120601 AAPL 569. 16 572. 65 560. 52 560. 99 18606700 560. 99 DELL 12. 15 12. 30 12. 05 12. 07 19396700 12. 07 GOOG 571. 79 572. 65 568. 35 570. 98 3057900 570. 98 MSFT 28. 76 28. 96 28. 44 28. 45 56634300 28. 45 DataFrame has related topanel method the inverse of toframe In 304 stacked. topanel Out 304 class pandas. core. panel. Panel Dimensions items major minor Items Open to Adj Close Major axis 20120530 00 to 20120601 00 Minor axis AAPL to MSFT 154 Chapter5 Getting Started with pandas CHAPTER Data Loading Storage and File Formats The tools in this book are of little use if you cant easily import and export data in Python.  Im going to be focused on input and output with pandas objects though there are of course numerous tools in other libraries to aid in this process.  NumPy for ex ample features lowlevel but extremely fast binary data loading and storage including support for memorymapped array.  See Chapter 12 for more on those.  Input and output typically falls into few main categories reading text files and other more efficient ondisk formats loading data from databases and interacting with net work sources like web APIs.  Reading and Writing Data in Text Format Python has become beloved language for text and file munging due to its simple syntax for interacting with files intuitive data structures and convenient features like tuple packing and unpacking.  pandas features number of functions for reading tabular data as DataFrame object.  Table 61 has summary of all of them though readcsv and readtable are likely the ones youll use the most.  Table 61.  Parsing functions in pandas Function Description readcsv Load delimited data from file URL or filelike object.  Use comma as default delimiter readtable Load delimited data from file URL or filelike object.  Use tab as default delimiter readfwf Read data in fixedwidth column format that is no delimiters readclipboard Versionofreadtablethatreads data fromthe clipboard.  Useful for converting tables from web pages 155 Pll give an overview of the mechanics of these functions which are meant to convert text data into DataFrame.  The options for these functions fall into few categories Indexing can treat one or more columns as the returned DataFrame and whether to get column names from the file the user or not at all.  Type inference and data conversion this includes the userdefined value conver sions and custom list of missing value markers.  Datetime parsing includes combining capability including combining date and time information spread over multiple columns into single column in the result.  Iterating support for iterating over chunks of very large files.  Unclean data issues skipping rows or footer comments or other minor things like numeric data with thousands separated by commas.  Type inference is one of the more important features of these functions that means you dont have to specify which columns are numeric integer boolean or string.  Handling dates and other custom types requires bit more effort though.  Lets start with small commaseparated CSV text file In 846 cat ch06ex1. csv abcdmessage 1234hello 5678world 9101112 foo Since this is commadelimited we can use readcsv to read it into DataFrame In 847 df pd. readcsvch06ex1. csv message hello world 10 11 12 foo We could also have used readtable and specifying the delimiter In 849 pd. readtablecho6ex1. csv sep Out 849 message hello world 10 11 12 foo sO Here used the Unix cat shell command to print the raw contents of the file to the screen.  If youre on Windows you can use type instead S48 of cat to achieve the same effect.  156 Chapter6 Data Loading Storage and File Formats file will not always have header row.  Consider this file In 850 cat ch06ex2. csv 1234hello 5678world 9101112f00 To read this in you have couple of options.  You can allow pandas to assign default column names or you can specify names yourself In 851 pd. readcsvcho6ex2. csv headerNone Out 851 X. 1 X. 2 X. 3 X. 4 X. 5 hello world 10 11 12 foo bc.  message hello world 10 11 12 foo Suppose you wanted the message column to be the index of the returned DataFrame.  You can either indicate you want the column at index or named message using the indexcol argument In 853 names message In 854 pd. readcsvcho6ex2. csv namesnames indexcolmessage Out 854 boc message hello world foo 10 11 12 In the event that you want to form hierarchical index from multiple columns just pass list of column numbers or names In 855 cat cho6csvmindex. csv key1 key2 value1 value2 onea12 oneb34 onec56 oned78 twoa910 twob1112 twoc1314 twod1516 In 856 parsed pd. readcsvch06csvmindex. csv indexcolkey1 key2 In 857 parsed Out 857 Reading and Writing Data in Text Format 157 value1 value2 key1 key2 one two 10 11 12 13 14 15 16 In some cases table might not have fixed delimiter using whitespace or some other pattern to separate fields.  In these cases you can pass regular expression as delimiter for readtable.  Consider text file that looks like this In 858 listopencho6ex3. txt Out 858 Cn aaa 0. 264438 1. 026059 0. 619500n bbb 0. 927272 0. 302904 0. 032399n ccc 0. 264273 0. 386314 0. 217601n ddd 0. 871858 0. 348382 1. 100491n While you could do some munging by hand in this case fields are separated by variable amount of whitespace.  This can be expressed by the regular expression so we have then In 859 result pd. readtablecho6ex3. txt seps In 860 result Out 860 aaa 0. 264438 1. 026059 0. 619500 bbb 0. 927272 0. 302904 0. 032399 ccc 0. 264273 0. 386314 0. 217601 ddd 0. 871858 0. 348382 1. 100491 Because there was one fewer column name than the number of data rows readtable infers that the first column should be the DataFrames index in this special case.  The parser functions have many additional arguments to help you handle the wide variety of exception file formats that occur see Table 62.  For example you can skip the first third and fourth rows of file with skiprows In 861 cat cho6ex4. csv hey abcdmessage just wanted to make things more difficult for you who reads CSV files with computers anyway 1234hello 5678world 9101112 foo In 862 pd. readcsvch06ex4. csv skiprows0 Out 862 message 158 Chapter6 Data Loading Storage and File Formats 01 hello world 10 11 12 foo Handling missing values is an important and frequently nuanced part of the file parsing process.  Missing data is usually either not present empty string or marked by some sentinel value.  By default pandas uses set of commonly occurring sentinels such as NA 1. IND and NULL In 863 cat ch06ex5. csv something abcdmessage one1234NA two568world three9101112 foo In 864 result pd. readcsvch06ex5. csv In 865 result Out 865 something message one NaN two 6NaN world three 10 11 12 foo In 866 pd. isnullresult Out 866 something message False False False False False True False False False True False False False False False False False False The navalues option can take either list or set of strings to consider missing values In 867 result pd. readcsvch06ex5. csv navaluesNULL In 868 result Out 868 something message one NaN two 6NaN world three 10 11 12 foo Different NA sentinels can be specified for each column in dict In 869 sentinels message foo NA something two In 870 pd. readcsvcho6ex5. csv navaluessentinels Out 870 something message one NaN NaN 6NaN world three 10 11 12 NaN Reading and Writing Data in Text Format 159 Table 62.  readcsv readtable function arguments Argument Description path String indicating filesystem location URL or filelike object sepordelimiter Character sequence or regular expression to use to split fields in each row header Row number to use as column names.  Defaults to first row but should be None if there is no header row indexcol Column numbers or names to use as the row index in the result.  Can be single namenumber or list of them for hierarchical index names List of column names for result combine with headerNone skiprows Number of rows at beginning of file to ignore or list of row numbers starting from to skip navalues Sequence of values to replace with NA comment Character or characters to split comments off the end of lines parsedates keepdatecol Attemptto parse data to datetime False by default.  If True will attempt to parse all columns.  Otherwise can specify list of column numbers or name to parse.  If element of list is tuple or list will combine multiple columns together and parse to date for example if datetime split across two columns If joining columns to parse date keep the joined columns.  Default False converters Dict containing column number of name mapping to functions.  Forexample foo would apply the function to all values in the foo column dayfirst When parsing potentially ambiguous dates treat as international format e. g.  762012 June dateparser 2012.  Default False Function to use to parse dates nrows Number of rows to read from beginning of file iterator Return TextParser object for reading file piecemeal chunksize For iteration size of file chunks skipfooter Number of lines to ignore at end of file verbose Print various parser output information like the number of missing values placed in nonnumeric columns encoding Text encoding for unicode.  For example utf8 for UTF8 encoded text squeeze If the parsed data only contains one column return Series thousands Separator for thousands e. g.  or.  Reading Text Files in Pieces When processing very large files or figuring out the right set of arguments to correctly process large file you may only want to read ina small piece of file or iterate through smaller chunks of the file.  In 871 result pd. readcsvch06ex6. csv In 872 result Out 872 160 Chapter6 Data Loading Storage and File Formats class pandas. core.  frame. DataFrame Int64Index 10000 entries to 9999 Data columns one 10000 nonnull values two 10000 nonnull values three 10000 nonnull values four 10000 nonnull values key 10000 nonnull values dtypes float644 object1 If you want to only read out small number of rows avoiding reading the entire file specify that with nrows In 873 pd. readcsvch06ex6. csv nrows5 Out 873 one two three four key 0. 467976 0. 038649 0. 295344 1. 824726 0. 358893 1. 404453 0. 704965 0. 200638 0. 501840 0. 659254 0. 421691 0. 057688 0. 204886 1. 074134 1. 388361 0. 982404 0. 354628 0. 133116 0. 283763 0. 837063 RBDAAaAWr To read out file in pieces specify chunksize as number of rows In 874 chunker pd. readcsvch06ex6. csv chunksize1000 In 875 chunker Out875 pandas. io. parsers. TextParser at 0x8398150 The TextParser object returned by readcsv allows you to iterate over the parts of the file according to the chunksize.  For example we can iterate over ex6. csv aggregating the value counts in the key column like so chunker pd. readcsvch06ex6. csv chunksize1000 tot Series for piece in chunker tot tot. addpiecekey. valuecounts fillvalue0 tot tot. orderascendingFalse We have then In 877 tot10 Out 877 368 364 346 343 340 338 337 335 334 330 maAmUYzoorxnm Reading and Writing Data in Text Format 161 TextParser is also equipped with getchunk method which enables you to read pieces of an arbitrary size.  Writing Data Out to Text Format Data can also be exported to delimited format.  Lets consider one of the CSV files read above In 878 data pd. readcsvch06ex5. csv In 879 data Out 879 something message one NaN two 6NaN world three 10 11 12 foo Using DataFrames tocsv method we can write the data out toa commaseparated file In 880 data. tocsvcho6out. csv In 881 cat cho6out. csv somethingabcdmessage 0one123. 04 two568world 2three91011. 012 foo Other delimiters can be used of course writing to sys. stdout so it just prints the text result In 882 data. tocsvsys. stdout sep something abcdmessage Oone123. 04 1two56 8world 2three91011. 012 foo Missing values appear as empty strings in the output.  You might want to denote them by some other sentinel value In 883 data. tocsvsys. stdout narepNULL somethingabcdmessage 0one123. 04NULL 1two56NULL8world 2three91011. 012 foo With no other options specified both the row and column labels are written.  Both of these can be disabled In 884 data. tocsvsys. stdout indexFalse headerFalse one123. 04 two568world three91011. 012 foo You can also write only subset of the columns and in an order of your choosing 162 Chapter6 Data Loading Storage and File Formats 885 data. tocsvsys. stdout indexFalse colsa abc 123. 0 56 91011. 0 Series also has tocsv method In 886 dates pd. daterange112000 periods7 In 887 ts Seriesnp. arange7 indexdates In 888 ts. tocsvch06tseries. csv In 889 cat cho6tseries. csv 20000101 000 20000102 001 20000103 002 20000104 00 20000105 004 20000106 005 20000107 006 With bit of wrangling no header first column as index you can read CSV version of Series with readcsv but there is also fromcsv convenience method that makes it bit simpler 890 Series. fromcsvch06tseries. csv parsedatesTrue Out 890 20000101 20000102 20000103 20000104 20000105 20000106 20000107 aun PWN See the docstrings for tocsv and fromcsv in Python for more information.  Manually Working with Delimited Formats Most forms of tabular data can be loaded from disk using functions like pan das. read table.  In some cases however some manual processing may be necessary.  Its not uncommon to receive file with one or more malformed lines that trip up read Save To illustrate the basic tools consider small CSV file 891 cat chO06ex7. csv se bm Mc myn nye mgm Te For any file with singlecharacter delimiter you can use Pythons builtin csv module.  To use it pass any open file or filelike object to csv.  reader Reading and Writing Data in Text Format 163 import csv opench06ex7. csv reader csv. readerf Iterating through the reader like file yields tuples of values in each like with any quote characters removed In 893 for line in reader averse 33 print line From there its up to you to do the wrangling necessary to put the data in the form that you need it.  For example In 894 lines listcsv. readeropench06ex7. csv In 895 header values lineso0 lines1 In 896 datadict for in zipheader zipvalues In 897 datadict Out897 bs cs CSV files come in many different flavors.  Defining new format with different de limiter string quoting convention or line terminator is done by defining simple sub class of csv. Dialect class mydialectcsv. Dialect lineterminator delimiter quotechar reader csv. readerf dialectmydialect Individual CSV dialect parameters can also be given as keywords to csv.  reader without having to define subclass reader csv. readerf delimiter The possible options attributes of csv. Dialect and what they do can be found in Table 63.  Table 63.  CSV dialect options Argument Description delimiter Onecharacter string to separate fields.  Defaults to .  lineterminator Line terminator for writing defaults to rn .  Reader ignores this and recognizes crossplatform line terminators.  quotechar Quote character for fields with special characters like delimiter.  Default is .  quoting Quoting convention.  Options include csv. QUOTEALL quote all fields csv. QUOTEMINIMAL only fields with special characters like the delimiter 164 Chapter6 Data Loading Storage and File Formats Argument Description csv. QUOTENONNUMERIC and csv. QUOTENON no quoting.  See Pythons documentation for full details.  Defaults to QUOTEMINIMAL.  skipinitialspace Ignore whitespace after each delimiter.  Default False.  doublequote How to handle quoting character inside field.  If True itis doubled.  See online documentation for full detail and behavior.  escapechar String to escape the delimiter if quoting is set to csv.  QUOTENONE.  Disabled by default For files with more complicated or fixed multicharacter delimiters you ase will not be able to use the csv module.  In those cases youll have to do 12 the line splitting and other cleanup using strings split method or the regular expression method re.  split.  To write delimited files manually you can use csv. writer.  It accepts an open writable file object and the same dialect and format options as csv.  reader with openmydata. csv as writer csv. writerf dialectmydialect writer. writerowone two three writer. writerow1 writer. writerow4 writer. writerow7 JSON Data JSON short for JavaScript Object Notation has become one of the standard formats for sending data by HTTP request between web browsers and other applications.  It is much more flexible data format than tabular text form like CSV.  Here is an example obj name Wes places lived United States Spain Germany pet null siblings name Scott age 25 pet Zuko name Katie age 33 pet Cisco JSON is very nearly valid Python code with the exception of its null value null and some other nuances such as disallowing trailing commas at the end of lists.  The basic types are objects dicts arrays lists strings numbers booleans and nulls.  All of the keys in an object must be strings.  There are several Python libraries for reading and writing JSON data.  Ill use json here as it is built into the Python standard library.  To convert JSON string to Python form use json.  loads In 899 import json Reading and Writing Data in Text Format 165 In 900 result json.  loadsobj In 901 result Out 901 uname uWes upet None uplaceslived uUnited States uSpain uGermany usiblings uage 25 uname uScott upet uZuko uage 33 uname uKatie upet uCisco json. dumps on the other hand converts Python object back to JSON In 902 asjson json. dumpsresult How you convert JSON object or list of objects to DataFrame or some other data structure for analysis will be up to you.  Conveniently you can passa list of JSON objects to the DataFrame constructor and select subset of the data fields In 903 siblings DataFrameresultsiblings columnsname age In 904 siblings Out 904 name age Scott 25 Katie 33 For an extended example of reading and manipulating JSON data including nested records see the USDA Food Database example in the next chapter.  Va sO An effort is underway to add fast native JSON export tojson and .  decoding fromjson to pandas.  This was not ready at the time of writ ek ing.  XML and HTML Web Scraping Python has many libraries for reading and writing data in the ubiquitous HTML and XML formats.  lxml httplxml. de is one that has consistently strong performance in parsing very large files.  Ixml has multiple programmer interfaces first Ill show using 1xml. html for HTML then parse some XML using lxml. objectify.  Many websites make data available in HTML tables for viewing in browser but not downloadable as an easily machinereadable format like JSON HTML or XML.  no ticed that this was the case with Yahoo Finances stock options data.  If you arent familiar with this data options are derivative contracts giving you the right to buy call option or sell put option companys stock at some particular price the strike between now and some fixed point in the future the expiry.  People trade both call and put options across many strikes and expiries this data can all be found together in tables on Yahoo Finance.  166 Chapter6 Data Loading Storage and File Formats To get started find the URL you want to extract data from open it with urllib2 and parse the stream with lxml like so from lxml. html import parse from urllib2 import urlopen parsed parseurlopenhttpfinance. yahoo. comqopsAAPLOptions doc parsed. getroot Using this object you can extract all HTML tags of particular type such as table tags containing the data of interest.  As simple motivating example suppose you wanted to get list of every URL linked to in the document links are tags in HTML.  Using the document roots findall method along with an XPath means of expressing queries on the document In 906 links doc. findall. a In 907 links Out 907 Element at 0x6c488fo Element at 0x6c48950 Element at 0x6c489b0 Element at 0x6c48a10 Element at 0x6c48a70 But these are objects representing HTML elements to get the URL and link text you have to use each elements get method for the URL and textcontent method for the display text In 908 Ink links28 In 909 Ink Out909 Element at Ox6c48ddo In 910 1nk. gethref Out910 httpbiz. yahoo. comspecial. htm1 In 911 1Ink. textcontent Out911 Special Editions Thus getting list of all URLs in the document is matter of writing this list compre hension In 912 urls 1nk. gethref for Ink in doc. findall. a In 913 urls10 Out 913 http info. yahoo. comprivacyusyahoofinancedetails. html http info. yahoo. comrelevantads http docs. yahoo. cominfoterms httpdocs. yahoo. cominfocopyrightcopyright. html httphelp. yahoo. com1usyahoofinanceformsindex. html http help. yahoo. com1usyahoofinancequotesfitadelay. html http help. yahoo. com1usyahoofinancequotesfitadelay. html Reading and Writing Data in Text Format 167 http www. capitaliq. com http www. csidata. com http www. morningstar. com Now finding the right tables in the document can be matter of trial and error some websites make it easier by giving table of interest an id attribute.  determined that these were the two tables containing the call data and put data respectively tables doc. findall. table calls tables9 puts tables13 Each table has header row followed by each of the data rows In 915 rows calls. findall. tr For the header as well as the data rows we want to extract the text from each cell in the case of the header these are th cells and td cells for the data def unpackrow kindtd elts row. findall. s kind return val. textcontent for val in elts Thus we obtain In 917 unpackrows0 kindth Out917 Strike Symbol Last Chg Bid Ask Vol Open Int In 918 unpackrows1 kindtd Out 918 295. 00 AAPL120818C00295000 310. 40 0. 00 289. 80 290. 80 169 Now its matter of combining all of these steps together to convert this data into DataFrame.  Since the numerical data is still in string format we want to convert some but perhaps not all of the columns to floating point format.  You could do this by hand but luckily pandas has class TextParser that is used internally in the readcsv and other parsing functions to do the appropriate automatic type conversion from pandas. io. parsers import TextParser def parseoptions datatable rows table. findall. tr header unpackrows0 kindth data unpackr for in rows1 return TextParserdata namesheader. getchunk Finally we invoke this parsing function on the lxml table objects and get DataFrame results 168 Chapter6 Data Loading Storage and File Formats In 920 calldata parse options datacalls In 921 putdata parse options dataputs In 922 calldata10 Out 922 Strike Symbol Last Chg Bid Ask Vol Open Int 295 AAPL120818C00295000 310. 40 0. 0 289. 80 290. 80 169 300 AAPL120818C00300000 277. 10 1. 7 284. 80 285. 60 478 305 AAPL120818C00305000 300. 97 0. 0 279. 80 280. 80 10 316 310 AAPL120818C00310000 267. 05 0. 0 274. 80 275. 65 239 315 AAPL120818C00315000 296. 54 0. 0 269. 80 270. 80 22 88 320 AAPL120818C00320000 291. 63 0. 0 264. 80 265. 80 96 173 325 AAPL120818C00325000 261. 34 0. 0 259. 80 260. 80 NA 108 330 AAPL120818C00330000 230. 25 0. 0 254. 80 255. 80 NA 21 335 AAPL120818C00335000 266. 03 0. 0 249. 80 250. 65 46 340 AAPL120818C00340000 272. 58 0. 0 244. 80 245. 80 30 Parsing XML with Ixml. objectify XML extensible markup language is another common structured data format sup porting hierarchical nested data with metadata.  The files that generate the book you are reading actually form series of large XML documents.  Above showed the lxml library and its xml.  html interface.  Here show an alternate interface thats convenient for XML data 1xml. objectify.  The New York Metropolitan Transportation Authority MTA publishes number of data series about its bus and train services httpwww. mta. infodevelopersdownload html.  Here well look at the performance data which is contained in set of XML files.  Each train or bus service has different file like Performance MNR. xml for the Metro North Railroad containing monthly data as series of XML records that look like this INDICATOR INDICATORSEQ373889INDICATORSEQ PARENTSEQPARENTSEQ AGENCYNAMEMetroNorth RailroadAGENCYNAME INDICATORNAMEEscalator AvailabilityINDICATORNAME DESCRIPTIONPercent of the time that escalators are operational systemwide.  The availability rate is based on physical observations performed the morning of regular business days only.  This is new indicator the agency began reporting in 2009. DESCRIPTION PERIODYEAR2011PERIODYEAR PERIODMONTH12PERIODMONTH CATEGORYService IndicatorsCATEGORY FREQUENCYMFREQUENCY DESIREDCHANGEUDESIREDCHANGE INDICATORUNITINDICATORUNIT DECIMALPLACES1DECIMALPLACES YTDTARGET97. 00YTDTARGET YTDACTUALYTDACTUAL MONTHLYTARGET97. 00MONTHLYTARGET MONTHLYACTUALMONTHLYACTUAL INDICATOR Reading and Writing Data in Text Format 169 Using 1xml. objectify we parse the file and get reference to the root node of the XML file with getroot from lxml import objectify path PerformanceMNR. xml parsed objectify. parseopenpath root parsed. getroot root.  INDICATOR return generator yielding each INDICATOR XML element.  For each record we can populate dict of tag names like YTDACTUAL to data values excluding few tags data skip fields PARENTSEQ INDICATOR SEQ DESIRED CHANGE DECIMAL PLACES for elt in root.  INDICATOR eldata for child in elt. getchildren if child. tag in skip fields continue eldatachild. tag child. pyval data. appendeldata Lastly convert this list of dicts into DataFrame In 927 perf DataFramedata In 928 perf Out928 class pandas. core. frame. DataFrame Int64Index 648 entries to 647 Data columns AGENCYNAME 648 nonnull values CATEGORY 648 nonnull values DESCRIPTION 648 nonnull values FREQUENCY 648 nonnull values INDICATORNAME 648 nonnull values INDICATORUNIT 648 nonnull values MONTHLYACTUAL 648 nonnull values MONTHLY TARGET 648 nonnull values PERIODMONTH 648 nonnull values PERIODYEAR 648 nonnull values YTDACTUAL 648 nonnull values YTDTARGET 648 nonnull values dtypes int642 object10 XML data can get much more complicated than this example.  Each tag can have met adata too.  Consider an HTML link tag which is also valid XML from StringIO import StringI0 tag hrefhttpwww. google. comGooglea root objectify. parseStringI0tag . getroot 170 Chapter6 Data Loading Storage and File Formats You can now access any of the fields like href in the tag or the link text In 930 root Out930 Element at Ox88bd4bo In 931 root. gethref Out931 httpwww. google. com In 932 root. text Out932 Google Binary Data Formats One of the easiest ways to store data efficiently in binary format is using Pythons built in pickle serialization.  Conveniently pandas objects all have save method which writes the data to disk as pickle In 933 frame pd. readcsvch06ex1. csv In 934 frame Out 934 message hello world 10 11 12 foo In 935 frame. savecho6framepickle You read the data back into Python with pandas. load another pickle convenience function In 936 pd. loadcho6framepickle Out936 bc.  message hello world 10 11 12 foo pickle is only recommended as shortterm storage format.  The prob lem is that it is hard to guarantee that the format will be stable over time an object pickled today may not unpickle with later version ofa library.  Ihave made every effort to ensure that this does not occur with pandas but at some point in the future it may be necessary to break the pickle format.  Using HDF5 Format There are number of tools that facilitate efficiently reading and writing large amounts of scientific data in binary format on disk.  popular industrygrade library for this is HDF5 which is library with interfaces in many other languages like Java Python and MATLAB.  The HDF in HDF5 stands for hierarchical data format.  Each HDF5 Binary Data Formats 171 file contains an internal file systemlike node structure enabling you to store multiple datasets and supporting metadata.  Compared with simpler formats HDF5 supports onthefly compression with variety of compressors enabling data with repeated pat terns to be stored more efficiently.  For very large datasets that dont fit into memory HDFS5 is good choice as you can efficiently read and write small sections of much larger arrays.  There are not one but two interfaces to the HDF5 library in Python PyTables and h5py each of which takes different approach to the problem.  h5py provides direct but highlevel interface to the HDF5 API while PyTables abstracts many of the details of HDFS5 to provide multiple flexible data containers table indexing querying capability and some support for outofcore computations.  pandas has minimal dictlike HDFStore class which uses PyTables to store pandas objects In 937 store pd. HDFStoremydata. hs In 938 storeobj1 frame In 939 storeobj1col framea In 940 store Out940 class pandas. io. pytables. HDFStore File path mydata. h5 obj1 DataFrame obj1col Series Objects contained in the HDF5 file can be retrieved in dictlike fashion In 941 storeobj1 Out 941 message o1 hello world 10 11 12 foo If you work with huge quantities of data would encourage you to explore PyTables and h5py to see how they can suit your needs.  Since many data analysis problems are 1Obound rather than CPUbound using tool like HDF5 can massively accelerate your applications.  HDF5 is not database.  It is best suited for writeonce readmany da tea tasets.  While data can be added to file at any time if multiple writers do so simultaneously the file can become corrupted.  Reading Microsoft Excel Files pandas also supports reading tabular data stored in Excel 2003 and higher files using the ExcelFile class.  Interally ExcelFile uses the xlrd and openpyxl packages so you 172 Chapter6 Data Loading Storage and File Formats may have to install them first.  To use ExcelFile create an instance by passing path to an xls or x1sx file xlsfile pd. ExcelFiledata. xls Data stored in sheet can then be read into DataFrame using parse table xlsfile. parseSheet1 Interacting with HTML and Web APIs Many websites have public APIs providing data feeds via JSON or some other format.  There are number of ways to access these APIs from Python one easytouse method that recommend is the requests package httpdocs. pythonrequests. org.  To search for the words python pandas on Twitter we can make an HTTP GET request like so In 944 import requests In 945 url httpsearch. twitter. comsearch. jsonqpython20pandas In 946 resp requests. geturl In 947 resp Out947 Response 200 The Response objects text attribute contains the content of the GET query.  Many web APIs will return JSON string that must be loaded into Python object In 948 import json In 949 data json. loadsresp. text In 950 data. keys Out950 unextpage ucompletedin umaxidstr usinceid str urefreshurl uresults usinceid uresults per page uquery umaxid upage The results field in the response contains list of tweets each of which is represented as Python dict that looks like ucreatedat uMon 25 Jun 2012 33 0000 ufromuser uwesmckinn ufromuserid 115494880 ufromuserid str u115494880 ufromusername uWes McKinney ugeo None Interacting with HTML and Web APIs 173 uid 217313849177686018 uidstr u217313849177686018 uiso language code upt umetadata uresulttype urecent usource ua hrefhttptwitter. comweba utext uLunchtime pandasfu httpt. coSI70xZZQ pydata utouser None utouserid utouserid str uO utousername None We can then make list of the tweet fields of interest then pass the results list to Da taFrame In 951 tweetfields createdat fromuser id text In 952 tweets DataFramedataresults columnstweetfields In 953 tweets Out 953 class pandas. core.  frame. DataFrame Int64Index 15 entries to 14 Data columns createdat 15 nonnull values fromuser 15 nonnull values id 15 nonnull values text 15 nonnull values dtypes int641 object3 Each row in the DataFrame now has the extracted data from each tweet In 121 tweets. ix7 Out121 createdat Thu 23 Jul 2012 00 0000 fromuser deblike id 227419585803059201 text pandas powerful Python data analysis toolkit Name With bit of elbow grease you can create some higherlevel interfaces to common web APIs that return DataFrame objects for easy analysis.  Interacting with Databases In many applications data rarely comes from text files that being fairly inefficient way to store large amounts of data.  SQLbased relational databases such as SQL Server PostgreSQL and MySQL are in wide use and many alternative nonSQL socalled NoSQL databases have become quite popular.  The choice of database is usually de pendent on the performance data integrity and scalability needs of an application.  Loading data from SQL into DataFrame is fairly straightforward and pandas has some functions to simplify the process.  As an example Ill use an inmemory SQLite database using Pythons builtin sqlite3 driver 174 Chapter6 Data Loading Storage and File Formats import sqlite3 query CREATE TABLE test VARCHAR20 VARCHAR20 REAL INTEGER con sqlite3. connectmemory con. executequery con. commit Then insert few rows of data data Atlanta Georgia 1. 25 Tallahassee Florida 2. 6 Sacramento California 1. 7 stmt INSERT INTO test VALUES con. executemanystmt data con. commit Most Python SQL drivers PyODBC psycopg2 MySQLdb pymssal etc.  return list of tuples when selecting data from table In 956 cursor con. executeselect from test In 957 rows cursor. fetchall In 958 rows Out 958 uAtlanta uGeorgia 1. 25 uTallahassee uFlorida 2. 6 uSacramento uCalifornia 1. 7 You can pass the list of tuples to the DataFrame constructor but you also need the column names contained in the cursors description attribute In 959 cursor. description Out959 None None None None None None None None None None None None None None None None None None None None None None None None In 960 DataFramerows columnszipcursor. description0 Out 960 Atlanta Georgia 1. 25 Tallahassee Florida 2. 60 Sacramento California 1. 70 This is quite bit of munging that youd rather not repeat each time you query the database.  pandas has readframe function in its pandas. io. sql module that simplifies the process.  Just pass the select statement and the connection object Interacting with Databases 175 In 961 import pandas. io. sql as sql In 962 sql. readframeselect from test con Out 962 Atlanta Georgia 1. 25 Tallahassee Florida 2. 60 Sacramento California 1. 70 Storing and Loading Data in MongoDB NoSQIL databases take many different forms.  Some are simple dictlike keyvalue stores like BerkeleyDB or Tokyo Cabinet while others are documentbased with dictlike object being the basic unit of storage.  Ive chosen MongoDB httpmongodb. org for my example.  started MongoDB instance locally on my machine and connect to it on the default port using pymongo the official driver for MongoDB import pymongo con pymongo. Connectionlocalhost port27017 Documents stored in MongoDB are found in collections inside databases.  Each running instance of the MongoDB server can have multiple databases and each database can have multiple collections.  Suppose wanted to store the Twitter API data from earlier in the chapter.  First can access the currently empty tweets collection tweets con. db. tweets Then load the list of tweets and write each of them to the collection using tweets. save which writes the Python dict to MongoDB import requests json url httpsearch. twitter. comsearch.  jsonqpython20pandas data json. loadsrequests. geturl. text for tweet in dataresults tweets.  savetweet Now if wanted to get all of my tweets if any from the collection can query the collection with the following syntax cursor tweets. findfromuser wesmckinn The cursor returned is an iterator that yields each document as dict.  As above can convert this into DataFrame optionally extracting subset of the data fields in each tweet tweetfields createdat fromuser id text result DataFramelistcursor columnstweetfields 176 Chapter6 Data Loading Storage and File Formats CHAPTER Data Wrangling Clean Transform Merge Reshape Much of the programming work in data analysis and modeling is spent on data prep aration loading cleaning transforming and rearranging.  Sometimes the way that data is stored in files or databases is not the way you need it for data processing application.  Many people choose to do ad hoc processing of data from one form to another using general purpose programming like Python Perl or Java or UNIX text processing tools like sed or awk.  Fortunately pandas along with the Python standard library pro vide you with highlevel flexible and highperformance set of core manipulations and algorithms to enable you to wrangle data into the right form without much trouble.  If you identify type of data manipulation that isnt anywhere in this book or elsewhere in the pandas library feel free to suggest it on the mailing list or GitHub site.  Indeed much of the design and implementation of pandas has been driven by the needs of real world applications.  Combining and Merging Data Sets Data contained in pandas objects can be combined together in number of builtin ways pandas. merge connects rows in DataFrames based on one or more keys.  This will be familiar to users of SQL or other relational databases as it implements database join operations.  pandas. concat glues or stacks together objects along an axis.  combine first instance method enables splicing together overlapping data to fill in missing values in one object with values from another.  will address each of these and give number of examples.  Theyll be utilized in ex amples throughout the rest of the book.  177 Databasestyle DataFrame Merges Merge or join operations combine data sets by linking rows using one or more keys.  These operations are central to relational databases.  The merge function in pandas is the main entry point for using these algorithms on your data.  Lets start with simple example In 15 dfa DataFramekey In 16 df2 In 17 df1 Out17 data1 key aAuPWNPR Du PWN PR orTovuonve Ss data1 range7 DataFramekey data2 range3 In 18 df2 Out 18 data2 key This is an example of manytoone merge situation the data in df1 has multiple rows labeled and whereas df2 has only one row for each value in the key column.  Calling merge with these objects we obtain In 19 pd. mergedf1 df2 data1 key data2 Out19 PRROOO Note that didnt specify which column to join on.  If not specified merge uses the overlapping column names as the keys.  Its good practice to specify explicitly though In 20 pd. mergedf1 df2 onkey data1 key data2 Out20 cTrooo wy PRROOO If the column names are different in each object you can specify them separately In 21 df3 DataFramelkey data1 range7 178 Chapter7 Data Wrangling Clean Transform Merge Reshape In 22 df4 DataFramerkey scone data2 range3 In 23 pd. mergedf3 df4 leftonlkey rightonrkey Out 23 data1 lkey data2 rkey You probably noticed that the and values and associated data are missing from the result.  By default merge does an inner join the keys in the result are the intersec tion.  Other possible options are left right and outer.  The outer join takes the union of the keys combining the effect of applying both left and right joins In 24 pd. mergedf1 df2 howouter Out24 datai key data2 an NaN NaN Manytomany merges have welldefined though not necessarily intuitive behavior.  Heres an example In 25 dfa DataFramekey asiae data1 range6 In 26 df2 DataFramekey asiae data2 range5 In 27 df1 In 28 df2 Out 27 Out 28 data1 key data2 key 3.  2C In 29 pd. mergedf1 df2 onkey howleft Out29 data1 key data2 Combining and Merging DataSets 179 FPwoO ON OU BWN WuUuMrPRPOOH SL qoonooTo csc Swrwrwrn mw Manytomany joins form the Cartesian product of the rows.  Since there were rows in the left DataFrame and in the right one there are rows in the result.  The join method only affects the distinct key values appearing in the result In 30 pd. mergedf1 df2 howinner Out 30 data1 key data2 WO CONAUBWNF OO UUrPRPOOL.  HN ooo oof WY WRPRWRPWRPN ON To merge with multiple keys pass list of column names In 31 left DataFramekey1 foo foo bar key2 one two one lval In 32 right DataFramekey1 foo foo bar bar key2 one one one two rval In 33 pd. mergeleft right onkey1 key2 howouter Out 33 key1 key2 lval rval bar one bar two NaN foo one foo one foo two NaN To determine which key combinations will appear in the result depending on the choice of merge method think of the multiple keys as forming an array of tuples to be used as single join key even though its not actually implemented that way.  When joining columnsoncolumns the indexes on the passed Data ta Frame objects are discarded.  180 Chapter7 Data Wrangling Clean Transform Merge Reshape last issue to consider in merge operations is the treatment of overlapping column names.  While you can address the overlap manually see the later section on renaming axis labels merge has suffixes option for specifying strings to append to overlapping names in the left and right DataFrame objects In 34 pd. mergeleft right onkey1 Out 34 key1 key2x lval key2y rval bar bar foo foo foo foo MW BPWNP OO one one one two one one one one two one two one In 35 pd. mergeleft right onkey1 suffixesleft right Out 35 key1 key2left lval key2right rval bar bar foo foo foo foo MW BPWNP OO one one one two one one one one two one two one See Table 71 for an argument reference on merge.  Joining on index is the subject of the next section.  Table 71.  merge function arguments Argument left right how on lefton righton leftindex rightindex sort suffixes copy Description DataFrame to be merged on the left side DataFrame to be merged on the right side Oneofinner outer left orright. inner by default Column names to join on.  Must be found in both DataFrame objects.  If not specified and no other join keys given will use the intersection of the column names in left and right as the join keys Columns in left DataFrame to use as join keys Analogous to Lefton for left DataFrame Use row index in Left as its join key or keys if Multilndex Analogous to leftindex Sort merged data lexicographically by join keys True by default.  Disable to get better performance in some cases on large datasets Tuple of string values to append to column names in case of overlap defaults to y. For example if data in both DataFrame objects would appear as datax and datay inresult IfFalse avoid copying data into resulting data structure in some exceptional cases.  By default always copies Combining and Merging DataSets 181 Merging on Index In some cases the merge key or keys in DataFrame will be found in its index.  In this case you can pass leftindexTrue or rightindexTrue or both to indicate that the index should be used as the merge key In 36 left1 DataFramekey wwe value range6 In 37 right1 DataFramegroup val 3. 5 indexa In 38 left In 39 right1 Out 38 Out 39 key value group val 3. 5 7. 0 UWPWNP nrwvo es MWPWN PO In 40 pd. mergeleft1 right1 leftonkey rightindexTrue Out 40 key value group val 3. 5 3. 5 3. 5 7. 0 7. 0 Since the default merge method is to intersect the join keys you can instead form the union of them with an outer join In 41 pd. mergeleft1 right1 leftonkey rightindexTrue howouter Out 41 key value group val 3. 5 3. 5 30a 3. 5 7. 0 7. 0 NaN With hierarchicallyindexed data things are bit more complicated In 42 lefth DataFramekey1 Ohio Ohio Ohio Nevada Nevada aera key2 2000 2001 2002 2001 2002 mare data np. arange5.  In 43 righth DataFramenp. arange12. reshape6 aera indexNevada Nevada Ohio Ohio Ohio Ohio aera 2001 2000 2000 2000 2001 2002 mare columnsevent1 event2 In 44 lefth In 45 righth Out 44 Out 45 182 Chapter7 Data Wrangling Clean Transform Merge Reshape BWNRO key1 key2 event1 event2 Ohio 2000 Nevada 2001 Ohio 2001 2000 Ohio 2002 Ohio 2000 Nevada 2001 2000 Nevada 2002 2001 2002 10 11 In this case you have to indicate multiple columns to merge on as list pay attention to the handling of duplicate index values In 46 pd. mer Out 46 data NROOW key1 Nevada Ohio Ohio Ohio Ohio pd. mer Out 47 data NaN key1 Nevada Nevada Nevada Ohio Ohio Ohio Ohio gelefth righth leftonkey1 key2 rightindexTrue key2 event1 event2 2001 2000 2000 2001 2002 10 11 gelefth righth leftonkey1 key2 rightindexTrue howouter key2 event1 event2 2000 2001 2002 NaN NaN 2000 2000 2001 2002 10 11 Using the indexes of both sides of the merge is also not an issue In 48 In 50 left2 right2 left2 Out50 Ohio In 52 Nevada Out52 Ohio NaN NaN onaAnwd Nevada NaN NaN DataFrame1.  2.  3.  4.  5.  indexa columnsOhio Nevada DataFrame7.  8.  9.  10.  11.  12.  13 14 indexb columnsMissouri Alabama In 51 right2 Out 51 Missouri Alabama 10 11 12 13 14 pd. mergeleft2 right2 howouter leftindexTrue rightindexTrue Missouri Alabama NaN NaN 10 11 12 13 14 Combining and Merging DataSets 183 DataFrame has more convenient join instance for merging by index.  It can also be used to combine together many DataFrame objects having the same or similar indexes but nonoverlapping columns.  In the prior example we could have written In 53 left2. joinright2 howouter Out 53 Ohio Nevada Missouri Alabama NaN NaN NaN NaN Cc 10 NaN NaN 11 12 13 14 In part for legacy reasons much earlier versions of pandas DataFrames join method performs left join on the join keys.  It also supports joining the index of the passed DataFrame on one of the columns of the calling DataFrame In 54 lefta. joinright1 onkey Out 54 key value group val oO 3. 5 7. 0 3. 5 3. 5 7. 0 oC NaN Lastly for simple indexonindex merges you can pass list of DataFrames to join as an alternative to using the more general concat function described below In 55 another DataFrame7.  8.  9.  10.  11.  12.  16.  17.  sores indexa columnsNew York Oregon In 56 left2. joinright2 another Out 56 Ohio Nevada Missouri Alabama New York Oregon NaN NaN 10 10 13 14 11 12 In 57 left2. joinright2 another howouter Out 57 Ohio Nevada Missouri Alabama New York Oregon NaN NaN NaN NaN NaN NaN 10 10 NaN NaN 11 12 NaN NaN 13 14 11 12 NaN NaN NaN NaN 16 17 184 Chapter7 Data Wrangling Clean Transform Merge Reshape Concatenating Along an Axis Another kind of data combination operation is alternatively referred to as concatena tion binding or stacking.  NumPy has concatenate function for doing this with raw NumPy arrays In 58 arr np. arange12. reshape3 In 59 arr Out 59 array 10 11 of Oo .  In 60 np. concatenatearr arr axis1 Out 60 array Ts 10 11 10 11 In the context of pandas objects such as Series and DataFrame having labeled axes enable you to further generalize array concatenation.  In particular you have number of additional things to think about If the objects are indexed differently on the other axes should the collection of axes be unioned or intersected Do the groups need to be identifiable in the resulting object Does the concatenation axis matter at all The concat function in pandas provides consistent way to address each of these con cerns.  Ill give number of examples to illustrate how it works.  Suppose we have three Series with no index overlap In 61 s1 Series0 indexa In 62 s2 Series2 indexc In 63 s3 Series5 indexf Calling concat with these object in list glues together the values and indexes In 64 pd. concats1 s2 s3 Out 64 manoanse Du PWN PR Combining and Merging DataSets 185 By default concat works along axis0 producing another Series.  If you pass axis1 the result will instead be DataFrame axis1 is the columns In 65 pd. concats1 s2 s3 axis1 Out 65 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN manApmnDanaey In this case there is no overlap on the other axis which as you can see is the sorted union the outer join of the indexes.  You can instead intersect them by passing joininner In 66 s4 pd. concats1 s3 In 67 pd. concats1 s4 axis1 In 68 pd. concats1 s4 axis1 joininner Out 67 Out 68 01 a5 bo4 ow NaN NaN You can even specify the axes to be used on the other axes with joinaxes In 69 pd. concats1 s4 axis1 joinaxesa Out 69 NaN NaN bo1 65 NaN NaN One issue is that the concatenated pieces are not identifiable in the result.  Suppose instead you wanted to create hierarchical index on the concatenation axis.  To do this use the keys argument In 70 result pd. concats1 s1 s3 keysone two three In 71 result Out71 one two three Much more on the unstack function later In 72 result. unstack Out72 186 Chapter7 Data Wrangling Clean Transform Merge Reshape one NaN NaN two NaN NaN three NaN NaN In the case of combining Series along axis1 the keys become the DataFrame column headers In 73 pd. concats1 s2 s3 axis1 keysone two three Out73 one two three NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN The same logic extends to DataFrame objects In 74 df1 DataFramenp. arange6. reshape3 indexa wwe columnsone two In 75 df2 DataFrame5 np. arange4. reshape2 indexa wwe columnsthree four In 76 pd. concatdf1 df2 axis1 keyslevel1 level2 Out 76 level1 level2 one two three four NaN NaN If you pass dict of objects instead of list the dicts keys will be used for the keys option In 77 pd. concatlevel1 df1 level2 df2 axis1 Out77 level1 level2 one two three four NaN NaN There are couple of additional arguments governing how the hierarchical index is created see Table 72 In 78 pd. concatdf1 df2 axis1 keyslevel1 level2 were namesupper lower Out 78 upper level1 level2 lower one two three four NaN NaN Cc Combining and Merging DataSets 187 last consideration concerns DataFrames in which the row index is not meaningful in the context of the analysis In 79 dfa1 DataFramenp. random. randn3 columnsa In 80 df2 DataFramenp. random. randn2 columnsb In 81 dfa In 82 df2 Out 81 Out 82 0. 204708 0. 478943 0. 519439 0. 555730 0. 274992 0. 228913 1. 352917 1. 965781 1. 393406 0. 092908 0. 281746 0. 886429 2. 001637 0. 371843 0. 769023 246435 1. 007189 1. 296221 In this case you can pass ignoreindexTrue 83 pd. concatdf1 df2 ignore indexTrue Out 83 BWNRO 0. 204708 0. 478943 0. 519439 0. 555730 1. 965781 1. 393406 0. 092908 0. 281746 0. 769023 1. 246435 1. 007189 1. 296221 1. 352917 0. 274992 NaN 0. 228913 0. 371843 0. 886429 NaN 2. 001637 Table 72.  concat function arguments Argument objs axis join joinaxes keys levels names verifyintegrity ignore index Description List or dict of pandas objects to be concatenated.  The only required argument Axis to concatenate along defaults to Oneofinner outer defaultingto outer whetherto intersection inner orunion outer together indexes along the other axes Specific indexes to use for the other n1 axes instead of performing unionintersection logic Values to associate with objects being concatenated forming hierarchical index along the concatenation axis.  Can either be list or array of arbitrary values an array of tuples ora list of arrays if multiple level arrays passed in levels Specific indexes to use as hierarchical index level or levels if keys passed Names for created hierarchical levels if keys and or levels passed Check new axis in concatenated object for duplicates and raise exception if so.  By default False allows duplicates Do not preserve indexes along concatenation axis instead producing new rangetotallength index Combining Data with Overlap Another data combination situation cant be expressed as either merge or concate nation operation.  You may have two datasets whose indexes overlap in full or part.  As motivating example consider NumPys where function which expressed vectorized ifelse 188 Chapter7 Data Wrangling Clean Transform Merge Reshape Hi eo aS Seriesnp. nan 2. 5 np. nan 3. 5 4. 5 np. nan ccoseve indexf co uw oa Seriesnp. arangelena dtypenp. float64 saree indexf In 86 b1 np. nan In 87 In 88 In 89 np. wherepd. isnulla Out 87 Out 88 Out 89 NaN 0. 0 205 205 NaN 2. 0 Cc 3. 5 Cc Cc 3. 5 4. 5 4. 5 NaN NaN NaN Series has combine first method which performs the equivalent of this operation plus data alignment In 90 b2. combinefirsta2 Out90 NaN 4. 5 3. 0 2. 0 1. 0 0. 0 With DataFrames combine first naturally does the same thing column by column so you can think of it as patching missing data in the calling object with data from the object you pass In 91 df1 DataFramea 1.  np. nan 5.  np. nan weeat np. nan 2.  np. nan 6.  sates range2 18 DataFramea 5.  4.  np. nan 3.  7.  sates np. nan 3.  4.  6.  8.  df1. combinefirstdf2 10 14 NaN BWNPRO Reshaping and Pivoting There are number of fundamental operations for rearranging tabular data.  These are alternatingly referred to as reshape or pivot operations.  Reshaping and Pivoting 189 Reshaping with Hierarchical Indexing Hierarchical indexing provides consistent way to rearrange data in DataFrame.  There are two primary actions stack this rotates or pivots from the columns in the data to the rows unstack this pivots from the rows into the columns ll illustrate these operations through series of examples.  Consider small DataFrame with string arrays as row and column indexes In 94 data DataFramenp. arange6. reshape2 wwe indexpd. IndexOhio Colorado namestate wwe columnspd. Indexone two three namenumber In 95 data Out 95 number one two three state Ohio Colorado Using the stack method on this data pivots the columns into the rows producing Series In 96 result data. stack In 97 result Out 97 state number Ohio one two 1.  three Colorado one two three Froma hierarchicallyindexed Series you can rearrange the data back into DataFrame with unstack In 98 result. unstack Out 98 number one two three state Ohio Colorado By default the innermost level is unstacked same with stack.  You can unstack dif ferent level by passing level number or name In 99 result. unstack0 In 100 result. unstackstate Out 99 Out100 state Ohio Colorado state Ohio Colorado number number one one 190 Chapter7 Data Wrangling Clean Transform Merge Reshape two three two three Unstacking might introduce missing data if all of the values in the level arent found in each of the subgroups In 101 In 102 In 103 In 104 Out104 one two NaN Na s1 Series0 indexa s2 Series4 indexc data2 pd. concats1 s2 keysone two data2. unstack bcdeoe NaN N45 Stacking filters out missing data by default so the operation is easily invertible In 105 data2. unstack. stack In 106 data2. unstack. stackdropnaFalse Out 105 Out106 one one Cc two NaN two NaN NaN When unstacking in DataFrame the level unstacked becomes the lowest level in the result In 107 df DataFrameleft result right result sere columnspd. Indexleft right nameside In 108 df Out 108 side left right state number Ohio one two three Colorado one two three 10 In 109 df. unstackstate In 110 df. unstackstate. stackside Out109 Out110 side left right state Ohio Colorado state Ohio Colorado Ohio Colorado number side number one left one right two two left Reshaping and Pivoting 191 three 10 right three left right 10 Pivoting long to wide Format common way to store multiple time series in databases and CSV is in socalled long or stacked format code to create this DataFrame omitted for brevity In 116 ldata10 Out 116 date item value 19590331 00 realgdp 2710. 349 19590331 00 infl 0. 000 19590331 00 unemp 5. 800 19590630 00 realgdp 2778. 801 19590630 00 infl 2. 340 19590630 00 unemp 5. 100 19590930 00 realgdp 2775488 19590930 00 infl 2. 740 19590930 00 unemp 5. 300 19591231 00 realgdp 2785. 204 Data is frequently stored this way in relational databases like MySQL as fixed schema column names and data types allows the number of distinct values in the item column to increase or decrease as data is added or deleted in the table.  In the above example date and item would usually be the primary keys in relational database parlance offering both relational integrity and easier joins and programmatic queries in many cases.  The downside of course is that the data may not be easy to work with in long format you might prefer to have DataFrame containing one column per distinct item value indexed by timestamps in the date column.  DataFrames pivot method per forms exactly this transformation In 117 pivoted ldata. pivotdate item value In 118 pivoted. head Out 118 item infl realgdp unemp date 19590331 0. 00 2710. 349 19590630 2. 34 2778. 801 19590930 2. 74 2775. 488 19591231 0. 27 2785. 204 19600331 2. 31 2847. 699 uuwnuwuwnw DWP OC The first two values passed are the columns to be used as the row and column index and finally an optional value column to fill the DataFrame.  Suppose you had two value columns that you wanted to reshape simultaneously In 119 ldatavalue2 np. random. randnlenldata In 120 ldata10 Out120 192 Chapter7 Data Wrangling Clean Transform Merge Reshape 19590331 19590331 19590331 19590630 19590630 19590630 19590930 19590930 19590930 19591231 WO ONADAUBPWNPF OO 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ate item 00 realgdp 00 infl 00 unemp 00 realgdp 00 infl 00 unemp 00 realgdp 200 infl 00 unemp va 2710.  0.  5.  2778.  00 realgdp 2785.  lue 349 1.  000 0O.  800 801 0.  340 3.  100 1.  488 0.  740 0.  300 0.  204 0.  value2 669025 438570 539741 476985 248944 021228 577087 124121 302614 523772 By omitting the last argument you obtain DataFrame with hierarchical columns In 121 pivoted ldata. pivotdate item In 122 pivoted5 Out122 item date 19590331 19590630 19590930 19591231 19600331 val in 0.  2.  2.  0.  2.  ue fl 00 34 74 27 31 realgdp unemp 2710. 349 2778. 801 2775. 488 2785 . 204 2847 . 699 In 123 pivotedvalue5 Out 123 item date 19590331 19590630 19590930 19591231 19600331 inf 0. 0 2. 34 2. 74 0. 2 2. 3 al wuuwww uw realgdp unemp 2710. 349 2778. 801 2775488 2785. 204 2847. 699 uuMnuoow NOW PR OC NOW PR OC ooOowo value2 infl 438570 248944 124121 000940 831154 realgdp 1. 669025 0. 476985 0. 577087 0. 523772 0. 713544 0.  1.  0.  1.  unemp 539741 021228 302614 343810 370232 Note that pivot is just shortcut for creating hierarchical index using setindex and reshaping with unstack In 124 unstacked ldata. setindexdate item. unstackitem In 125 unstacked7 Out125 item date 19590331 19590630 19590930 19591231 19600331 19600630 19600930 val in NONONNO ue fl 00 34 . 74 27 31 14 70 realgdp unemp 2710. 349 2778. 801 2775. 488 2785 . 204 2847 . 699 2834. 390 2839. 022 Vuunuwuuwnwoww DNN AW FE CO value2 infl 438570 248944 124121 000940 831154 860757 119827 realgdp 1. 669025 0. 476985 0. 577087 0. 523772 0. 713544 1. 860761 1. 265934 unemp 539741 021228 302614 343810 370232 560145 063512 Reshaping and Pivoting 193 Data Transformation So far in this chapter weve been concerned with rearranging data.  Filtering cleaning and other tranformations are another class of important operations.  Removing Duplicates Duplicate rows may be found in DataFrame for any number of reasons.  Here is an example In 126 data DataFrameki one two eee k2 In 127 data Out 127 k1 k2 one one one two two two two Aun PWNR OO PPWWNP PRB The DataFrame method duplicated returns boolean Series indicating whether each row is duplicate or not In 128 data. duplicated Out 128 False True False False True False True Relatedly drop duplicates returns DataFrame where the duplicated array is True In 129 data. dropduplicates Out 129 k1 k2 one one two two mwn PWN PR Both of these methods by default consider all of the columns alternatively you can specify any subset of them to detect duplicates.  Suppose we had an additional column of values and wanted to filter duplicates only based on the k1 column In 130 datav1 range7 In 131 data. dropduplicatesk1 194 Chapter7 Data Wrangling Clean Transform Merge Reshape Out 131 kit k2 vi one two duplicated and dropduplicates by default keep the first observed value combination.  Passing takelastTrue will return the last one In 132 data. dropduplicatesk1 k2 take lastTrue Out 13 kt one one two two DPN EF k2 v1 ll Transforming Data Using Function or Mapping For many data sets you may wish to perform some transformation based on the values in an array Series or column ina DataFrame.  Consider the following hypothetical data collected about some kinds of meat In 133 data In 134 data Out 13 CON DU BPWNPRP food bacon pulled pork bacon Pastrami corned beef Bacon pastrami honey ham nova lox DataFramefood bacon pulled pork bacon Pastrami ounces Aww on an oooouwunoocjoe corned beef Bacon pastrami honey ham nova lox ounces 12 7. 5 Suppose you wanted to add column indicating the type of animal that each food came from.  Lets write down mapping of each distinct meat type to the kind of animal meattoanimal bacon pig pulled pork pig eh te pastrami cow corned beef cow honey ham pig nova lox salmon Data Transformation 195 The map method on Series accepts function or dictlike object containing mapping but here we have small problem in that some of the meats above are capitalized and others are not.  Thus we also need to convert each value to lower case In 136 dataanimal datafood. mapstr. lower. mapmeattoanimal In 137 data Out 137 food ounces animal bacon 4. 0 pig pulled pork 3. 0 pig bacon 12. 0 pig Pastrami 6. 0 cow corned beef 7. 5 cow Bacon 8. 0 pig pastrami 3. 0 cow honey ham 5. 0 pig nova lox 6. 0 salmon We could also have passed function that does all the work In 138 datafood. maplambda meattoanimalx. lower Out 138 pig pig pig cow cow pig cow pig salmon Name food Using map is convenient way to perform elementwise transformations and other data cleaningrelated operations.  Replacing Values Filling in missing data with the fillna method can be thought of as special case of more general value replacement.  While map as youve seen above can be used to modify subset of values in an object replace provides simpler and more flexible way to do so.  Lets consider this Series In 139 data Series1.  999.  2.  999.  1000.  3.  In 140 data Out 140 999 999 1000 196 Chapter7 Data Wrangling Clean Transform Merge Reshape The 999 values might be sentinel values for missing data.  To replace these with NA values that pandas understands we can use replace producing new Series In 141 data. replace999 np. nan Out 141 NaN NaN 1000 If you want to replace multiple values at once you instead pass list then the substitute value In 142 data. replace999 1000 np. nan Out 142 NaN NaN NaN UWPWNP OO To use different replacement for each value pass list of substitutes In 143 data. replace999 1000 np. nan Out 143 NaN NaN UWPWNPRP OO The argument passed can also be dict In 144 data. replace999 np. nan 1000 Out144 NaN NaN UWPWNPRP OO Renaming Axis Indexes Like values in Series axis labels can be similarly transformed by function or mapping of some form to produce new differently labeled objects.  The axes can also be modified in place without creating new data structure.  Heres simple example In 145 data DataFramenp. arange12. reshape3 awrmeet indexOhio Colorado New York wea et columnsone two three four Data Transformation 197 Like Series the axis indexes have map method In 146 data. index. mapstr. upper Out146 arrayOHIO COLORADO NEW YORK dtypeobject You can assign to index modifying the DataFrame in place In 147 data. index data. index. mapstr. upper In 148 data Out 148 one two three four OHIO COLORADO NEW YORK 10 11 If you want to create transformed version of data set without modifying the original useful method is rename In 149 data. renameindexstr. title columnsstr. upper Out149 ONE TWO THREE FOUR Ohio Colorado New York 10 11 Notably rename can be used in conjunction with dictlike object providing new values for subset of the axis labels In 150 data. renameindexOHIO INDIANA sees columnsthree peekaboo Out 150 one two peekaboo four INDIANA COLORADO NEW YORK 10 11 rename saves having to copy the DataFrame manually and assign to its index and col umns attributes.  Should you wish to modify data set in place pass inplaceTrue Always returns reference to DataFrame In 151 data. renameindexOHIO INDIANA inplaceTrue In 152 data Out 152 one two three four INDIANA COLORADO NEW YORK 10 11 198 Chapter7 Data Wrangling Clean Transform Merge Reshape Discretization and Binning Continuous data is often discretized or otherwised separated into bins for analysis.  Suppose you have data about group of people in study and you want to group them into discrete age buckets In 153 ages 20 22 25 27 21 23 37 31 61 45 41 32 Lets divide these into bins of 18 to 25 26 to 35 35 to 60 and finally 60 and older.  To do so you have to use cut function in pandas In 154 bins 18 25 35 60 100 In 155 cats pd. cutages bins In 156 cats Out 156 Categorical array18 25 18 25 18 25 25 35 18 25 18 25 35 60 25 35 60 100 35 60 35 60 25 35 dtypeobject Levels Index18 25 25 35 35 60 60 100 dtypeobject The object pandas returns is special Categorical object.  You can treat it like an array of strings indicating the bin name internally it contains levels array indicating the distinct category names along with labeling for the ages data in the labels attribute In 157 cats. labels Out157 array0 In 158 cats. levels Out158 Index18 25 25 35 35 60 60 100 dtypeobject In 159 pd. valuecountscats Out159 18 25 35 60 25 35 60 100 Consistent with mathematical notation for intervals parenthesis means that the side is open while the square bracket means it is closed inclusive.  Which side is closed can be changed by passing rightFalse In 160 pd. cutages 18 26 36 61 100 rightFalse Out160 Categorical array18 26 18 26 18 26 26 36 18 26 18 26 36 61 26 36 61 100 36 61 36 61 26 36 dtypeobject Levels Index18 26 26 36 36 61 61 100 dtypeobject You can also pass your own bin names by passing list or array to the labels option In 161 groupnames Youth YoungAdult MiddleAged Senior In 162 pd. cutages bins labelsgroupnames Out162 Data Transformation 199 Categorical arrayYouth Youth Youth YoungAdult Youth Youth MiddleAged YoungAdult Senior MiddleAged MiddleAged YoungAdult dtypeobject Levels IndexYouth YoungAdult MiddleAged Senior dtypeobject If you pass cut integer number of bins instead of explicit bin edges it will compute equallength bins based on the minimum and maximum values in the data.  Consider the case of some uniformly distributed data chopped into fourths In 163 data np. random. rand20 In 164 pd. cutdata precision2 Out 164 Categorical array0. 45 0. 67 0. 23 0. 45 0. 0037 0. 23 0. 45 0. 67 0. 67 0. 9 0. 45 0. 67 0. 67 0. 9 0. 23 0. 45 0. 23 0. 45 0. 67 0. 9 0. 67 0. 9 0. 67 0. 9 0. 23 0. 45 0. 23 0. 45 0. 23 0. 45 0. 67 0. 9 0. 0037 0. 23 0. 0037 0. 23 0. 23 0. 45 0. 23 0. 45 dtypeobject Levels Index0. 0037 0. 23 0. 23 0. 45 0. 45 0. 67 0. 67 0. 9 dtypeobject closely related function qcut bins the data based on sample quantiles.  Depending on the distribution of the data using cut will not usually result in each bin having the same number of data points.  Since qcut uses sample quantiles instead by definition you will obtain roughly equalsize bins In 165 data np. random. randn1000 Normally distributed In 166 cats pd. qcutdata Cut into quartiles In 167 cats Out 167 Categorical array0. 022 0. 641 3. 745 0. 635 0. 641 3. 26 . . .  0. 635 0. 022 0. 641 3. 26 0. 635 0. 022 dtypeobject Levels Index3. 745 0. 635 0. 635 0. 022 0. 022 0. 641 0. 641 3. 26 dtypeobject In 168 pd. valuecountscats Out168 3. 745 0. 635 250 0. 641 3. 26 250 0. 635 0. 022 250 0. 022 0. 641 250 Similar to cut you can pass your own quantiles numbers between and inclusive In 169 pd. qcutdata 0. 1 0. 5 0. 9 1.  Out169 Categorical array0. 022 1. 302 1. 266 0. 022 0. 022 1. 302 . . .  1. 266 0. 022 0. 022 1. 302 1. 266 0. 022 dtypeobject Levels Index3. 745 1. 266 1. 266 0. 022 0. 022 1. 302 1. 302 3. 26 dtypeobject 200 Chapter7 Data Wrangling Clean Transform Merge Reshape Well return to cut and qcut later in the chapter on aggregation and group operations as these discretization functions are especially useful for quantile and group analysis.  Detecting and Filtering Outliers Filtering or transforming outliers is largely matter of applying array operations.  Con sider DataFrame with some normally distributed data In 170 np. random. seed12345 In 171 data DataFramenp. random. randn1000 In 172 data. describe Out 172 count 1000. 000000 1000. 000000 1000. 000000 1000. 000000 mean 0. 067684 0. 067924 0. 025598 0. 002298 std 0. 998035 0. 992106 1. 006835 0. 996794 min 3. 428254 3. 548824 3. 184377 3. 745356 25 0. 774890 0. 591841 0. 641675 0. 644144 50 0. 116401 0. 101143 0. 002073 0. 013611 75 0. 616366 0. 780282 0. 680391 0. 654328 max 3. 366626 2. 653656 3. 260383 3. 927528 Suppose you wanted to find values in one of the columns exceeding three in magnitude In 173 col data3 In 174 colnp. abscol Out174 97 3. 927528 305 3. 399312 400 3. 745356 Name To select all rows having value exceeding or you can use the any method on boolean DataFrame In 175 datanp. absdata 3. any1 Out175 0. 539741 0. 476985 3. 248944 1. 021228 97 0. 774363 0. 552936 0. 106061 3. 927528 102 0. 655054 0. 565230 176873 0. 959533 305 2. 315555 0. 457246 0. 025907 3. 399312 324 0. 050188 1. 951312 3. 260383 0. 963301 400 0. 146326 0. 508391 0. 196713 3. 745356 499 0. 293333 0. 242459 3. 056990 1. 918403 523 3. 428254 0. 296336 0. 439938 0. 867165 586 0. 275144 1. 179227 3. 184377 1. 369891 808 0. 362528 3. 548824 1. 553205 2. 186301 900 3. 366626 2. 372214 0. 851010 1. 332846 OoOWwWow Values can just as easily be set based on these criteria.  Here is code to cap values outside the interval to DataTransformation 201 In 176 datanp. absdata np. signdata In 177 data. describe Out177 count 1000. 000000 1000. 000000 1000. 000000 1000. 000000 mean 0. 067623 0. 068473 0. 025153 0. 002081 std 0. 995485 0. 990253 1. 003977 0. 989736 min 3. 000000 3. 000000 3. 000000 3. 000000 25 0. 774890 0. 591841 0. 641675 0. 644144 50 0. 116401 0. 101143 0. 002073 0. 013611 75 0. 616366 0. 780282 0. 680391 0. 654328 max 3. 000000 2. 653656 3. 000000 3. 000000 The ufunc np. sign returns an array of and depending on the sign of the values.  Permutation and Random Sampling Permuting randomly reordering Series or the rows ina DataFrame is easy to do using the numpy. random.  permutation function.  Calling permutation with the length of the axis you want to permute produces an array of integers indicating the new ordering In 178 df DataFramenp. arange5 4. reshape5 In 179 sampler np. random. permutation5 In 180 sampler Out180 array1 That array can then be used in ixbased indexing or the take function In 181 df In 182 df. takesampler Out 181 Out 182 Oo Oo Oo 8600 d.  10 11 10 11 12 13 14 15 12 13 14 15 16 17 18 19 16 17 18 19 To select random subset without replacement one way is to slice off the first ele ments of the array returned by permutation where is the desired subset size.  There are much more efficient samplingwithoutreplacement algorithms but this is an easy strategy that uses readily available tools In 183 df. takenp. random. permutationlendf3 Out 183 12 13 14 15 16 17 18 19 To generate sample with replacement the fastest way is to use np.  random.  randint to draw random integers 202 Chapter7 Data Wrangling Clean Transform Merge Reshape In 184 In 185 In 186 Out 186 In 187 In 188 Out 188 bag np. array5 sampler np. random. randint0 lenbag size10 sampler array4 draws bag. takesampler draws array Computing IndicatorDummy Variables Another type of transformation for statistical modeling or machine learning applica tions is converting categorical variable into dummy or indicator matrix.  If column in DataFrame has distinct values you would derive matrix or DataFrame containing columns containing all 1s and 0s.  pandas has getdummies function for doing this though devising one yourself is not difficult.  Lets return to an earlier ex ample DataFrame In 189 df DataFramekey In Out190 001 1041 01 oorooon data1 range6 190 pd. getdummiesdf key In some cases you may want to add prefix to the columns in the indicator DataFrame which can then be merged with the other data.  getdummies has prefix argument for doing just this In 191 In 192 In 193 data1 UWPPWN PO MW PWN PR dummies pd. getdummiesdfkey prefixkey dfwithdummy dfdata1. joindummies df withdummy Out 193 keya keyb key RPOOOR Data Transformation 203 If row in DataFrame belongs to multiple categories things are bit more compli cated.  Lets return to the MovieLens 1M dataset from earlier in the book In 194 mnames movieid title genres In 195 movies pd. readtablech02movielensmovies. dat sep sranee headerNone namesmnames In 196 movies 10 Out 196 movieid title genres Toy Story 1995 AnimationChildrensComedy Jumanji 1995 AdventureChildrensFantasy Grumpier Old Men 1995 Comedy Romance Waiting to Exhale 1995 Comedy Drama Father of the Bride Part II 1995 Comedy Heat 1995 ActionCrimeThriller Sabrina 1995 Comedy Romance Tom and Huck 1995 Adventure Childrens Sudden Death 1995 Action 10 GoldenEye 1995 Action Adventure Thriller Adding indicator variables for each genre requires little bit of wrangling.  First we extract the list of unique genres in the dataset using nice set. union trick In 197 genre iter setx. split for in movies. genres In 198 genres sortedset. uniongenreiter Now one way to construct the indicator DataFrame is to start with DataFrame of all Zeros In 199 dummies DataFramenp. zeroslenmovies lengenres columnsgenres Now iterate through each movie and set entries in each row of dummies to In 200 for gen in enumeratemovies. genres satay 62 dummies. ixi gen. split Then as above you can combine this with movies In 201 movies windic movies.  joindummies. addprefixGenre In 202 movieswindic. ix0 Out202 movieid title Toy Story 1995 genres AnimationChildrens Comedy GenreAction GenreAdventure GenreAnimation GenreChildrens GenreComedy GenreCrime GenreDocumentary GenreDrama GenreFantasy oooorRrRRO 204 Chapter7 Data Wrangling Clean Transform Merge Reshape GenreFilmNoir GenreHorror GenreMusical GenreMystery GenreRomance GenreSciFi GenreThriller GenreWar GenreWestern Name oooooo 0o00 For much larger data this method of constructing indicator variables with multiple membership is not especially speedy.  lowerlevel func ia tion leveraging the internals of the DataFrame could certainly be writ ten.  useful recipe for statistical applications is to combine getdummies with discretiza tion function like cut In 204 values np. random. rand10 In 205 values Out 205 array 0. 9296 0. 3164 0. 1839 0. 2046 0. 5677 0. 5955 0. 9645 0. 6532 0. 7489 0. 6536 In 206 bins 0. 2 0. 4 0. 6 0. 8 In 207 pd. getdummiespd. cutvalues bins Out 207 0. 2 0. 2 0. 4 0. 4 0. 6 0. 6 0. 8 0. 8 WON ADU BWNF OO oooooorRoR oooorRRrRO OOO PRPRPOOGOOOCOCOOCOO ooorROOCOCOCOOR String Manipulation Python has long been popular data munging language in part due to its easeofuse for string and text processing.  Most text operations are made simple with the string objects builtin methods.  For more complex pattern matching and text manipulations regular expressions may be needed.  pandas adds to the mix by enabling you to apply string and regular expressions concisely on whole arrays of data additionally handling the annoyance of missing data.  String Manipulation 205 String Object Methods In many string munging and scripting applications builtin string methods are suffi cient.  As an example commaseparated string can be broken into pieces with split In 208 val ab guido In 209 val. split Out209 guido split is often combined with strip to trim whitespace including newlines In 210 pieces x. strip for in val. split In 211 pieces Out211 guido These substrings could be concatenated together with twocolon delimiter using ad dition In 212 first second third pieces In 213 first second third Out213 abguido But this isnt practical generic method.  faster and more Pythonic way is to pass list or tuple to the join method on the string In 214 . joinpieces Out214 abguido Other methods are concerned with locating substrings.  Using Pythons in keyword is the best way to detect substring though index and find can also be used In 215 guido in val Out215 True In 216 val. index In 217 val. find Out216 Out217 Note the difference between find and index is that index raises an exception if the string isnt found versus returning In 218 val. index ValueError Traceback most recent call last ipythoninput218280f8b2856ce in module val. index ValueError substring not found Relatedly count returns the number of occurrences of particular substring In 219 val. count Out219 replace will substitute occurrences of one pattern for another.  This is commonly used to delete patterns too by passing an empty string 206 Chapter7 Data Wrangling Clean Transform Merge Reshape In 220 val. replace In 221 val. replace Out220 ab guido Out221 ab guido Regular expressions can also be used with many of these operations as youll see below.  Table 73.  Python builtin string methods Argument count endswith startswith join index find rfind replace strip rstrip lstrip split lower upper ljust rjust Description Return the number of nonoverlapping occurrences of substring in the string.  Returns True if string ends with suffix starts with prefix.  Use string as delimiter for concatenating sequence of other strings.  Return position of first character in substring if found in the string.  Raises ValueEr ror if not found.  Return position of first character of first occurrence of substring in the string.  Like index but returns if not found.  Return position of first character of ast occurrence of substring in the string.  Returns if not found.  Replace occurrences of string with another string.  Trim whitespace including newlines equivalent to x.  strip andrstrip 1strip respectively for each element.  Break string into list of substrings using passed delimiter.  Convert alphabet characters to lowercase or uppercase respectively.  Left justify or right justify respectively.  Pad opposite side of string with spaces or some other fill character to return string with minimum width.  Regular expressions Regular expressions provide flexible way to search or match string patterns in text.  single expression commonly called regex is string formed according to the regular expression language.  Pythons builtin re module is responsible for applying regular expressions to strings Ill give number of examples of its use here.  Vs The art of writing regular expressions could be chapter of its own and 43 thus is outside the books scope.  There are many excellent tutorials and 43 references on the internet such as Zed Shaws Learn Regex The Hard Way httpregex. learncodethehardway. orgbook.  The re module functions fall into three categories pattern matching substitution and splitting.  Naturally these are all related regex describes pattern to locate in the text which can then be used for many purposes.  Lets look at simple example suppose wanted to split string with variable number of whitespace characters tabs spaces and newlines.  The regex describing one or more whitespace characters is String Manipulation 207 In 222 import re In 223 text foo bart baz tqux In 224 re. splits text Out224 foo bar baz qux When you call re. splits text the regular expression is first compiled then its split method is called on the passed text.  You can compile the regex yourself with re. compile forming reusable regex object In 225 regex re. compiles In 226 regex. splittext Out226 foo bar baz qux If instead you wanted to get list of all patterns matching the regex you can use the findall method In 227 regex.  findalltext Out227 nM At SO To avoid unwanted escaping with in regular expression use raw string literals like rCx instead of the equivalent Cx.  Creating regex object with re. compile is highly recommended if you intend to apply the same expression to many strings doing so will save CPU cycles.  match and search are closely related to findall.  While findall returns all matches in string search returns only the first match.  More rigidly match only matches at the beginning of the string.  As less trivial example lets consider block of text and regular expression capable of identifying most email addresses text Dave davegoogle. com Steve stevegmail. com Rob robgmail. com Ryan ryanyahoo. com pattern rAZ09. AZ09. . AZ24 re.  IGNORECASE makes the regex caseinsensitive regex re. compilepattern flagsre. IGNORECASE Using findal1 on the text produces list of the email addresses In 229 regex.  findalltext Out229 davegoogle. com stevegmail. com robgmail. com ryanyahoo. com search returns special match object for the first email address in the text.  For the above regex the match object can only tell us the start and end position of the pattern in the string 208 Chapter7 Data Wrangling Clean Transform Merge Reshape In 230 regex. searchtext In 231 Out231 sre. SREMatch at 0x10a05de00 In 232 textm. startm. end Out232 davegoogle. com regex. match returns None as it only will match if the pattern occurs at the start of the string In 233 print regex. matchtext None Relatedly sub will return new string with occurrences of the pattern replaced by the new string In 234 print regex. subREDACTED text Dave REDACTED Steve REDACTED Rob REDACTED Ryan REDACTED Suppose you wanted to find email addresses and simultaneously segment each address into its components username domain name and domain suffix.  To do this put parentheses around the parts of the pattern to segment In 235 pattern rAZ09. AZ09. . AZ24 In 236 regex re. compilepattern flagsre. IGNORECASE match object produced by this modified regex returns tuple of the pattern compo nents with its groups method In 237 regex. matchwesmbright. net In 238 m. groups Out238 wesm bright net findall returns list of tuples when the pattern has groups In 239 regex.  findalltext Out 239 dave google com steve gmail com rob gmail com ryan yahoo com sub also has access to groups in each match using special symbols like etc.  In 240 print regex. subrUsername Domain Suffix text Dave Username dave Domain google Suffix com Steve Username steve Domain gmail Suffix com Rob Username rob Domain gmail Suffix com Ryan Username ryan Domain yahoo Suffix com String Manipulation 209 There is much more to regular expressions in Python most of which is outside the books scope.  To give you flavor one variation on the above email regex gives names to the match groups regex re. compiler PusernameAZ09.  PdomainAZ09.  Na PsuffixAZ24 flagsre.  IGNORECASE re. VERBOSE The match object produced by such regex can produce handy dict with the specified group names In 242 regex. matchwesmbright. net In 243 m. groupdict Out243 domain bright suffix net username wesm Table 74.  Regular expression methods Argument Description findall finditer Return all nonoverlapping matching patterns ina string.  Findal1 returns list of all patterns while finditer returns them one by one from an iterator.  match Match pattern at start of string and optionally segment pattern components into groups.  If the pattern matches returns match object otherwise None.  search Scan string for match to pattern returning match object if so.  Unlike match the match can be anywhere in the string as opposed to only at the beginning.  split Break string into pieces at each occurrence of pattern.  sub subn Replace all sub or first occurrences subn of pattern in string with replacement expression.  Use symbols . . .  toreferto match group elements in the re placement string.  Vectorized string functions in pandas Cleaning up messy data set for analysis often requires lot of string munging and regularization.  To complicate matters column containing strings will sometimes have missing data In 244 data Dave davegoogle. com Steve stevegmail. com weeee Rob robgmail. com Wes np. nan In 245 data Seriesdata In 246 data In 247 data. isnull Out 246 Out247 Dave davegoogle. com Dave False Rob robgmail. com Rob False Steve stevegmail. com Steve False Wes NaN Wes True 210 Chapter7 Data Wrangling Clean Transform Merge Reshape String and regular expression methods can be applied passing lambda or other func tion to each value using data. map but it will fail on the NA.  To cope with this Series has concise methods for string operations that skip NA values.  These are accessed through Seriess str attribute for example we could check whether each email address has gmail in it with str. contains In 248 data. str. containsgmail Out 248 Dave False Rob True Steve True Wes NaN Regular expressions can be used too along with any re options like IGNORECASE In 249 pattern Out249 AZ09. AZ09. . AZ24 In 250 data. str. findallpattern flagsre. IGNORECASE Out 250 Dave dave google com Rob rob gmail com Steve steve gmail com Wes NaN There are couple of ways to do vectorized element retrieval.  Either use str. get or index into the str attribute In 251 matches data. str. matchpattern flagsre. IGNORECASE In 252 matches Out 252 Dave dave google com Rob rob gmail com Steve steve gmail com Wes NaN In 253 matches. str. get1 In 254 matches. str0 Out253 Out254 Dave google Dave dave Rob gmail Rob rob Steve gmail Steve steve Wes NaN Wes NaN You can similarly slice strings using this syntax In 255 data. str5 Out255 Dave dave Rob robg Steve steve Wes NaN String Manipulation 211 Table 75.  Vectorized string methods Method Description cat Concatenate strings elementwise with optional delimiter contains Return boolean array if each string contains patternregex count Count occurrences of pattern endswith startswith Equivalent to x.  endswithpattern orx. startswithpattern for each el ement.  findall Compute list of all occurrences of patternregex for each string get Index into each element retrieve ith element join Join strings in each element of the Series with passed separator len Compute length of each string lower upper Convert cases equivalent to x.  lower or x.  upper for each element.  match Use re. match with the passed regular expression on each element returning matched groups as list.  pad Add whitespace to left right or both sides of strings center Equivalent to padsideboth repeat Duplicate values for examples.  str. repeat equivalenttox foreachstring.  replace Replace occurrences of patternregex with some other string slice Slice each string in the Series.  split Split strings on delimiter or regular expression strip rstrip lstrip Trim whitespace including newlines equivalent to x.  strip andrstrip 1strip respectively for each element.  Example USDA Food Database The US Department of Agriculture makes available database of food nutrient infor mation.  Ashley Williams an English hacker has made available version of this da taba se in JSON format httpashleyw. co. ukprojectfoodnutrientdatabase.  The re cords look like this id 21441 description KENTUCKY FRIED CHICKEN Fried Chicken EXTRA CRISPY Wing meat and skin with breading tags KFC manufacturer Kentucky Fried Chicken group Fast Foods portions amount unit wing with skin grams 68. 0 212 Chapter7 Data Wrangling Clean Transform Merge Reshape nutrients value 20. 8 units description Protein group Composition Each food has number of identifying attributes along with two lists of nutrients and portion sizes.  Having the data in this form is not particularly amenable for analysis so we need to do some work to wrangle the data into better form.  After downloading and extracting the data from the link above you can load it into Python with any JSON library of your choosing.  Ill use the builtin Python json mod ule In 256 import json In 257 db json. loadopencho7foods20111003. json In 258 lendb Out258 6636 Each entry in db is dict containing all the data for single food.  The nutrients field is list of dicts one for each nutrient In 259 db0. keys In 260 dbonutrients Out 259 Out260 uportions udescription uProtein udescription ugroup uComposition utags uunits ug unutrients uvalue 25. 18 ugroup uid umanufacturer In 261 nutrients DataFramedbonutrients In 262 nutrients7 Out 262 description group units value Protein Composition 25. 18 Total lipid fat Composition 29. 20 Carbohydrate by difference Composition 3. 06 Ash Other 3. 28 Energy Energy kcal 376. 00 Water Composition 39. 28 Energy Energy kJ 1573. 00 Example USDA Food Database 213 When converting list of dicts toa DataFrame we can specify list of fields to extract.  Well take the food names group id and manufacturer In 263 infokeys description group id manufacturer In 264 info DataFramedb columnsinfo keys In 265 info5 Out 265 description group id manufacturer Cheese caraway Dairy and Egg Products 1008 Cheese cheddar Dairy and Egg Products 1009 Cheese edam Dairy and Egg Products 1018 Cheese feta Dairy and Egg Products 1019 Cheese mozzarella part skim milk Dairy and Egg Products 1028 In 266 info Out 266 class pandas. core. frame. DataFrame Int64Index 6636 entries to 6635 Data columns description 6636 nonnull values group 6636 nonnull values id 6636 nonnull values manufacturer 5195 nonnull values dtypes int641 object3 You can see the distribution of food groups with valuecounts In 267 pd. valuecountsinfo. group10 Out 267 Vegetables and Vegetable Products 812 Beef Products 618 Baked Products 496 Breakfast Cereals 403 Legumes and Legume Products 365 Fast Foods 365 Lamb Veal and Game Products 345 Sweets 341 Pork Products 328 Fruits and Fruit Juices 328 Now to do some analysis on all of the nutrient data its easiest to assemble the nutrients for each food into single large table.  To do so we need to take several steps.  First Ill convert each list of food nutrients to DataFrame add column for the food id and append the DataFrame to list.  Then these can be concatenated together with concat nutrients for rec in db fnuts DataFramerec nutrients fnutsid recid nutrients. appendfnuts nutrients pd. concatnutrients ignoreindexTrue 214 Chapter7 Data Wrangling Clean Transform Merge Reshape If all goes well nutrients should look like this In 269 nutrients Out 269 class pandas. core. frame. DataFrame Int64Index 389355 entries to 389354 Data columns description 389355 nonnull values group 389355 nonnull values units 389355 nonnull values value 389355 nonnull values id 389355 nonnull values dtypes float641 int641 object3 noticed that for whatever reason there are duplicates in this DataFrame so it makes things easier to drop them In 270 nutrients. duplicated. sum Out270 14179 In 271 nutrients nutrients. dropduplicates Since group and description is in both DataFrame objects we can rename them to make it clear what is what In 272 colmapping description food weeee group fgroup In 273 info info. renamecolumnscolmapping copyFalse In 274 info Out 274 class pandas. core.  frame. DataFrame Int64Index 6636 entries to 6635 Data columns food 6636 nonnull values fgroup 6636 nonnull values id 6636 nonnull values manufacturer 5195 nonnull values dtypes int641 object3 In 275 colmapping description nutrient wees group nutgroup In 276 nutrients nutrients. renamecolumnscolmapping copyFalse In 277 nutrients Out 277 class pandas. core. frame. DataFrame Int64Index 375176 entries to 389354 Data columns nutrient 375176 nonnull values nutgroup 375176 nonnull values units 375176 nonnull values value 375176 nonnull values Example USDA Food Database 215 id 375176 nonnull values dtypes float641 int641 object3 With all of this done were ready to merge info with nutrients In 278 ndata pd. mergenutrients info onid howouter In 279 ndata Out 279 class pandas. core. frame. DataFrame Int64Index 375176 entries to 375175 Data columns nutrient 375176 nonnull values nutgroup 375176 nonnull values units 375176 nonnull values value 375176 nonnull values id 375176 nonnull values food 375176 nonnull values fgroup 375176 nonnull values manufacturer 293054 nonnull values dtypes float641 int641 object6 In 280 ndata. ix30000 Out 280 nutrient Folic acid nutgroup Vitamins units mcg value id 5658 food Ostrich top loin cooked fgroup Poultry Products manufacturer Name 30000 The tools that you need to slice and dice aggregate and visualize this dataset will be explored in detail in the next two chapters so after you get handle on those methods you might return to this dataset.  For example we could plot of median values by food group and nutrient type see Figure 71 In 281 result ndata. groupbynutrient fgroupvalue. quantile0. 5 In 282 resultZinc Zn. order. plotkindbarh With little cleverness you can find which food is most dense in each nutrient bynutrient ndata. groupbynutgroup nutrient getmaximum lambda x. xsx. value. idxmax getminimum lambda x. xsx. value. idxmin maxfoods bynutrient. applygetmaximumvalue food make the food little smaller maxfoods. food maxfoods. food. str50 216 Chapter7 Data Wrangling Clean Transform Merge Reshape Beef Products Lamb Veal and Game Products Nut and Seed Products Breakfast Cereals Spices and Herbs Poultry Products Pork Products Sausages and Luncheon Meats Snacks Dairy and Egg Products Fast Foods Legumes and Legume Products Cereal Grains and Pasta fgroup Ethnic Foods Restaurant Foods Finfish and Shellfish Products Baked Products Meals Entrees and Sidedishes Baby Foods Sweets Vegetables and Vegetable Products Soups Sauces and Gravies Fruits and Fruit Juices Beverages Fats and Oils Figure 71.  Median Zinc values by nutrient group The resulting DataFrame is bit too large to display in the book here is just the Amino Acids nutrient group In 284 maxfoods. ixAmino Acidsfood Out 284 nutrient Alanine Gelatins dry powder unsweetened Arginine Seeds sesame flour lowfat Aspartic acid Soy protein isolate Cystine Seeds cottonseed flour low fat glandless Glutamic acid Soy protein isolate Glycine Gelatins dry powder unsweetened Histidine Whale beluga meat dried Alaska Native Hydroxyproline KENTUCKY FRIED CHICKEN Fried Chicken ORIGINAL Isoleucine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Leucine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Lysine Seal bearded Oogruk meat dried Alaska Nativ Methionine Fish cod Atlantic dried and salted Phenylalanine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Proline Gelatins dry powder unsweetened Serine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Threonine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Tryptophan Sea lion Steller meat with fat Alaska Native Tyrosine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Valine Soy protein isolate PROTEIN TECHNOLOGIES INTERNA Name food Example USDA Food Database 217 CHAPTER Plotting and Visualization Making plots and static or interactive visualizations is one of the most important tasks in data analysis.  It may be part of the exploratory process for example helping iden tify outliers needed data transformations or coming up with ideas for models.  For others building an interactive visualization for the web using toolkit like d3. js http d3js. org may be the end goal.  Python has many visualization tools see the end of this chapter but Ill be mainly focused on matplotlib hitpmatplotlib. sourceforge net.  matplotlib is primarily 2D desktop plotting package designed for creating publica tionquality plots.  The project was started by John Hunter in 2002 to enable MAT LABlike plotting interface in Python.  He Fernando Prez of IPython and others have collaborated for many years since then to make Python combined with matplotlib very functional and productive environment for scientific computing.  When used in tandem with GUI toolkit for example within IPython matplotlib has interactive features like zooming and panning.  It supports many different GUI backends on all operating systems and additionally can export graphics to all of the common vector and raster graphics formats PDF SVG JPG PNG BMP GIF etc.  have used it to produce almost all of the graphics outside of diagrams in this book.  matplotlib has number of addon toolkits such as mplot3d for 3D plots and basemap for mapping and projections.  will give an example using basemap to plot data on map and to read shapefiles at the end of the chapter.  To follow along with the code examples in the chapter make sure you have started IPython in Pylab mode ipython pylab or enabled GUI event loop integration with the gui magic.  Brief matplotlib API Primer There are several ways to interact with matplotlib.  The most common is through pylab mode in Python by running ipython pylab.  This launches Python configured to be able to support the matplotlib GUI backend of your choice Tk wxPython PyQt Mac 219 SPY daily RSI 14 70 overbought 70 ot 30 30 oversold 22May2012 0130. 16 H132. 02 L129. 95 C131. 97 V177. 8M Chg1. 81 os ow aad Figure 81.  more complex matplotlib financial plot OS native GTK.  For most users the default backend will be sufficient.  Pylab mode also imports large set of modules and functions into Python to provide more MAT LABlike interface.  You can test that everything is working by making simple plot plot np. arange10 If everything is set up right new window should pop up with line plot.  You can close it by using the mouse or entering close.  Matplotlib API functions like plot and close are all in the matplotlib. pyplot module which is typically imported by conven tion as import matplotlib. pyplot as plt While the pandas plotting functions described later deal with many of the mundane details of making plots should you wish to customize them beyond the function op tions provided you will need to learn bit about the matplotlib API.  ee There is not enough room in the book to give comprehensive treatment 4s to the breadth and depth of functionality in matplotlib.  It should be 43 enough to teach you the ropes to get up and running.  The matplotlib gallery and documentation are the best resource for becoming plotting guru and using advanced features.  Figures and Subplots Plots in matplotlib reside within Figure object.  You can create new figure with plt.  figure In 13 fig plt. figure 220 Chapter8 Plotting and Visualization If you are in pylab mode in IPython new empty window should pop up.  plt. fig ure has number of options notably figsize will guarantee the figure has certain size and aspect ratio if saved to disk.  Figures in matplotlib also support numbering scheme for example plt. figure2 that mimics MATLAB.  You can get reference to the active figure using plt. gcf.  You cant make plot with blank figure.  You have to create one or more subplots using addsubplot In 14 ax1 fig. addsubplot2 This means that the figure should be and were selecting the first of subplots numbered from 1.  If you create the next two subplots youll end up with figure that looks like Figure 82.  In 15 ax2 fig. addsubplot2 In 16 ax3 fig. addsubplot2 1. 0 0. 87 0. 6F 0. 4 0. 2 0. 85 0. 2 0. 4 0. 6 0. 8 1. 0 1. 0 0. 8F 0. 6F 0. 44 0. 2 085 0. 2 0. 4 0. 6 0. 8 1. 0 Figure 82.  An empty matplotlib Figure with subplots When you issue plotting command like plt. plot1. 5 3. 5 1. 6 matplotlib draws on the last figure and subplot used creating one if necessary thus hiding the figure and subplot creation.  Thus if we run the following command youll get some thing like Figure 83 In 17 from numpy. random import randn In 18 plt. plotrandn50. cumsum The is astyle option instructing matplotlib to plot black dashed line.  The objects returned by fig. addsubplot above are AxesSubplot objects on which you can directly plot on the other empty subplots by calling each ones instance methods see Figure 84 Brief matplotlib API Primer 221 mn v7 4K ow .  6F nll SO Na Okv .  9h 4t v7 10 20 30 40 50 10 15 20 25 30 35 Figure 84.  Figure after additional plots In 19 axi1. histrandn100 bins20 colork alpha0. 3 In 20 ax2. scatternp. arange30 np. arange30 randn30 You can find comprehensive catalogue of plot types in the matplotlib documentation.  Since creating figure with multiple subplots according to particular layout is such common task there is convenience method plt. subplots that creates new figure and returns NumPy array containing the created subplot objects 222 Chapter8 Plotting and Visualization In 22 fig axes plt. subplots2 In 23 axes Out 23 arrayAxes0. 1250. 5363640. 227941x0.  363636 Axes 0. 398529 0. 536364 0. 227941Xx0.  363636 Axes 0. 672059 0. 536364 0. 227941x0.  363636 Axes0. 1250. 10. 227941x0.  363636 Axes 0. 398529 0. 130. 227941x0.  363636 Axes 0. 6720590. 10. 227941x0. 363636 dtypeobject This is very useful as the axes array can be easily indexed like twodimensional array for example axes0 1.  You can also indicate that subplots should have the same or axis using sharex and sharey respectively.  This is especially useful when comparing data on the same scale otherwise matplotlib autoscales plot limits independently.  See Table 81 for more on this method.  Table 81.  pyplot. subplots options Argument Description nrows Number of rows of subplots ncols Number of columns of subplots sharex All subplots should use the same Xaxis ticks adjusting the x1 im will affect all subplots sharey All subplots should use the same Yaxis ticks adjusting the y1im will affect all subplots subplotkw Dict of keywords passed to addsubp1ot call used to create each subplot.  fig kw Additional keywords to subplots are used when creating the figure such as plt. subplots2 figsize8 Adjusting the spacing around subplots By default matplotlib leaves certain amount of padding around the outside of the subplots and spacing between subplots.  This spacing is all specified relative to the height and width of the plot so that if you resize the plot either programmatically or manually using the GUI window the plot will dynamically adjust itself.  The spacing can be most easily changed using the subplots adjust Figure method also available as toplevel function subplots adjustleftNone bottomNone rightNone topNone wspaceNone hspaceNone wspace and hspace controls the percent of the figure width and figure height respec tively to use as spacing between subplots.  Here is small example where shrink the spacing all the way to zero see Figure 85 fig axes plt. subplots2 sharexTrue shareyTrue for in range2 for in range2 axesi j. histrandn500 bins50 colork alpha0. 5 plt. subplotsadjustwspace0 hspace0 ABrief matplotlib API Primer 223 40 35F 30 25r 20 15 10 SF 40 35 30 25 20 15 10 Figure 85.  Figure with no intersubplot spacing You may notice that the axis labels overlap.  matplotlib doesnt check whether the labels overlap so in case like this you would need to fix the labels yourself by specifying explicit tick locations and tick labels.  More on this in the coming sections.  Colors Markers and Line Styles Matplotlibs main plot function accepts arrays of and coordinates and optionally string abbreviation indicating color and line style.  For example to plot versus with green dashes you would execute ax. plotx This way of specifying both color and linestyle in string is provided as convenience in practice if you were creating plots programmatically you might prefer not to have to munge strings together to create plots with the desired style.  The same plot could also have been expressed more explicitly as ax. plotx linestyle colorg There are number of color abbreviations provided for commonlyused colors but any color on the spectrum can be used by specifying its RGB value for example CECE CE.  You can see the full set of linestyles by looking at the docstring for plot.  Line plots can additionally have markers to highlight the actual data points.  Since mat plotlib creates continuous line plot interpolating between points it can occasionally be unclear where the points lie.  The marker can be part of the style string which must have color followed by marker type and line style see Figure 86 In 28 plt. plotrandn30. cumsum ko 224 Chapter8 Plotting and Visualization 1. 0 0. 5 0. 0 0. 57 1. 0 1. 5 ry 2. 0F 2. 5 3. 0F 3. 5p 10 15 30 Figure 86.  Line plot with markers example This could also have been written more explicitly as plotrandn30. cumsum colork linestyledashed markero For line plots you will notice that subsequent points are linearly interpolated by de fault.  This can be altered with the drawstyle option In 30 data randn30. cumsum In 31 plt. plotdata labelDefault Out 31 In 32 Out 32 In 33 matplotlib. lines. Line2D at 0x461cddo plt. plotdata drawstylestepspost labelstepspost matplotlib. lines. Line2D at 0x461f350 plt. legendlocbest Ticks Labels and Legends For most kinds of plot decorations there are two main ways to do things using the procedural pyplot interface which will be very familiar to MATLAB users and the more objectoriented native matplotlib API.  The pyplot interface designed for interactive use consists of methods like xlim xticks and xticklabels.  These control the plot range tick locations and tick labels respectively.  They can be used in two ways Called with no arguments returns the current parameter value.  For example plt. xlim returns the current axis plotting range ABrief matplotlib API Primer 225 10 Default stepspost 10 a5 20 25 30 Figure 87.  Line plot with different drawstyle options Called with parameters sets the parameter value.  So plt. xlim0 10 sets the axis range to to 10 All such methods act on the active or most recentlycreated AxesSubplot.  Each of them corresponds to two methods on the subplot object itself in the case of xlim these are ax. getxlim and ax. setxlim.  prefer to use the subplot instance methods myself in the interest of being explicit and especially when working with multiple subplots but you can certainly use whichever you find more convenient.  Setting the title axis labels ticks and ticklabels To illustrate customizing the axes Ill create simple figure and plot of random walk see Figure 88 In 34 fig plt. figure ax fig. addsubplot1 In 35 ax. plotrandn1000 . cumsum To change the axis ticks its easiest to use setxticks and setxticklabels.  The former instructs matplotlib where to place the ticks along the data range by default these locations will also be the labels.  But we can set any other values as the labels using setxticklabels In 36 ticks ax. setxticks0 250 500 750 1000 In 37 labels ax. setxticklabelsone two three four five aweal rotation30 fontsizesmall Lastly setxlabel gives name to the axis and settitle the subplot title 226 Chapter Plotting and Visualization 40 30 20 10 205 200 400 600 800 1000 Figure 88.  Simple plot for illustrating xticks In 38 ax. settitleMy first matplotlib plot Out38 matplotlib. text. Text at 0x79190912850 In 39 ax. setxlabelStages See Figure 89 for the resulting figure.  Modifying the axis consists of the same process substituting for in the above.  My first matplotlib plot 40 OS ente or ae Stages Figure 89.  Simple plot for illustrating xticks ABrief matplotlib API Primer 227 30 20 10 hw yl it hy Vy ey 10 20 30 40 505 200 400 600 800 1000 Figure 810.  Simple plot with lines and legend Adding legends Legends are another critical element for identifying plot elements.  There are couple of ways to add one.  The easiest is to pass the label argument when adding each piece of the plot In 40 fig plt. figure ax fig. addsubplot1 In 41 ax. plotrandn1000. cumsum labelone Out41 matplotlib. lines. Line2D at 0x4720a90 In 42 ax. plotrandn1000. cumsum labeltwo Out42 matplotlib. lines. Line2D at 0x4720f90 In 43 ax. plotrandn1000. cumsum k.  labelthree Out43 matplotlib. lines. Line2D at 0x4723550 Once youve done this you can either call ax.  legend or plt.  legend to automatically create legend In 44 ax. legendlocbest See Figure 810.  The loc tells matplotlib where to place the plot.  If you arent picky best is good option as it will choose location that is most out of the way.  To exclude one or more elements from the legend pass no label or labelnolegend.  Annotations and Drawing on Subplot In addition to the standard plot types you may wish to draw your own plot annotations which could consist of text arrows or other shapes.  228 Chapter Plotting and Visualization Annotations and text can be added using the text arrow and annotate functions.  text draws text at given coordinates on the plot with optional custom styling ax. textx Hello world familymonospace fontsize10 Annotations can draw both text and arrows arranged appropriately.  As an example lets plot the closing SP 500 index price since 2007 obtained from Yahoo Finance and annotate it with some of the important dates from the 20082009 financial crisis.  See Figure 811 for the result from datetime import datetime fig plt. figure ax fig. addsubplot1 data pd. readcsvch08spx. csv indexcol0 parsedatesTrue spx dataSPX spx. plotaxax stylek crisis data datetime2007 10 11 Peak of bull market datetime2008 12 Bear Stearns Fails datetime2008 15 Lehman Bankruptcy for date label in crisis data ax. annotatelabel xydate spx. asofdate 50 xytextdate spx. asofdate 200 arrowpropsdictfacecolorblack horizontalalignmentleft verticalalignmenttop Zoom in on 20072010 ax. setxlim112007 112011 ax. setylim600 1800 ax. settitleImportant dates in 20082009 financial crisis See the online matplotlib gallery for many more annotation examples to learn from.  Drawing shapes requires some more care.  matplotlib has objects that represent many common shapes referred to as patches.  Some of these like Rectangle and Circle are found in matplotlib. pyplot but the full set is located in matplotlib. patches.  To add shape to plot you create the patch object shp and add it to subplot by calling ax. addpatchshp see Figure 812 fig plt. figure ax fig. addsubplot1 rect plt. Rectangle0. 2 0. 75 0. 4 0. 15 colork alpha0. 3 circ plt. Circle0. 7 0. 2 0. 15 colorb alpha0. 3 pgon plt. Polygon0. 15 0. 15 0. 35 0. 4 0. 2 0. 6 colorg alpha0. 5 ABrief matplotlib API Primer 229 ax. addpatchrect ax. addpatchcirc ax. addpatchpgon 1800 1600 1400F 1200 1000 Bit once mnmnemdnomcnmad emma flim rise fascresee 3S 08 iS oo oe oe oY eo oy ge .  yt yo ee .  RW ge Figure 811.  Important dates in 20082009 financial crisis 0. 67 0. 4 0. 2 085 0. 2 0. 4 0. 6 0. 8 1. 0 Figure 812.  Figure composed from different patches If you look at the implementation of many familiar plot types you will see that they are assembled from patches.  230 Chapter8 Plotting and Visualization Saving Plots to File The active figure can be saved to file using plt. savefig.  This method is equivalent to the figure objects savefig instance method.  For example to save an SVG version of figure you need only type plt. savefigfigpath. svg The file type is inferred from the file extension.  So if you used . pdf instead you would get PDF.  There are couple of important options that use frequently for publishing graphics dpi which controls the dotsperinch resolution and bboxinches which can trim the whitespace around the actual figure.  To get the same plot as PNG above with minimal whitespace around the plot and at 400 DPI you would do plt. savefigfigpath. png dpi400 bboxinchestight savefig doesnt have to write to disk it can also write to any filelike object such as StringI0 from io import StringIO buffer StringI0 plt. savefig buffer plotdata buffer. getvalue For example this is useful for serving dynamicallygenerated images over the web.  Table 82.  Figure. savefig options Argument Description fname String containing filepath or Python filelike object.  The figure format is inferred from the file extension e. g.  .  pdf for PDF or .  png for PNG.  dpi The figure resolution in dots per inch defaults to 100 out of the box but can be configured facecolor edge The color of the figure background outside of the subplots.  white by default color format The explicit file format to use png pdf svg ps eps . . .  bboxinches The portion of the figure to save.  If tight is passed will attempt to trim the empty space around the figure matplotlib Configuration matplotlib comes configured with color schemes and defaults that are geared primarily toward preparing figures for publication.  Fortunately nearly all of the default behavior can be customized via an extensive set of global parameters governing figure size sub plot spacing colors font sizes grid styles and so on.  There are two main ways to interact with the matplotlib configuration system.  The first is programmatically from Python using the rc method.  For example to set the global default figure size to be 10 10 you could enter plt. rcfigure figsize10 10 Brief matplotlib API Primer 231 The first argument to rc is the component you wish to customize such as figure axes xtick ytick grid legend or many others.  After that can follow sequence of keyword arguments indicating the new parameters.  An easy way to write down the options in your program is as dict fontoptions family monospace weight bold size small plt. rcfont fontoptions For more extensive customization and to see list of all the options matplotlib comes with configuration file matplotlibrc in the matplotlibmp1data directory.  If you cus tomize this file and place it in your home directory titled . matplotlibrc it will be loaded each time you use matplotlib.  Plotting Functions in pandas As youve seen matplotlib is actually fairly lowlevel tool.  You assemble plot from its base components the data display the type of plot line bar box scatter contour etc.  legend title tick labels and other annotations.  Part of the reason for this is that in many cases the data needed to make complete plot is spread across many objects.  In pandas we have row labels column labels and possibly grouping information.  This means that many kinds of fullyformed plots that would ordinarily require lot of matplotlib code can be expressed in one or two concise statements.  Therefore pandas has an increasing number of highlevel plotting methods for creating standard visual izations that take advantage of how data is organized in DataFrame objects.  As of this writing the plotting functionality in pandas is undergoing tea quite bit of work.  As part of the 2012 Google Summer of Code pro gram student is working full time to add features and to make the interface more consistent and usable.  Thus its possible that this code may fall outofdate faster than the other things in this book.  The online pandas documentation will be the best resource in that event.  Line Plots Series and DataFrame each have plot method for making many different plot types.  By default they make line plots see Figure 813 In 55 Seriesnp. random. randn10. cumsum indexnp. arange0 100 10 In 56 s. plot The Series objects index is passed to matplotlib for plotting on the axis though this can be disabled by passing useindexFalse.  The axis ticks and limits can be adjusted using the xticks and xlim options and axis respectively using yticks and ylim.  See 232 Chapter Plotting and Visualization 10 20 30 40 50 60 70 80 90 Figure 813.  Simple Series plot example Table 83 fora full listing of plot options.  Ill comment ona few more of them through out this section and leave the rest to you to explore.  Most of pandass plotting methods accept an optional ax parameter which can be matplotlib subplot object.  This gives you more flexible placement of subplots in grid layout.  There will be more on this in the later section on the matplotlib API.  DataFrames plot method plots each of its columns as different line on the same subplot creating legend automatically see Figure 814 In 57 df DataFramenp. random. randn10 4. cumsum0 aiaa columnsA asa indexnp. arange0 100 10 sO Additional keyword arguments to plot are passed through to the re spective matplotlib plotting function so you can further customize 43 these plots by learning more about the matplotlib API.  Table 83.  Series. plot method arguments Argument Description label Label for plot legend ax matplotlib subplot object to plot on.  If nothing passed uses active matplotlib subplot style Style string like ko to be passed to matplotlib.  alpha The plot fill opacity from to Plotting Functions in pandas 233 10 20 30 40 50 60 70 80 90 Figure 814.  Simple DataFrame plot example Argument Description kind Canbeline bar barh kde logy Use logarithmic scaling on the axis useindex Use the object index for tick labels rot Rotation of tick labels through 360 xticks Values to use for axis ticks yticks Values to use for axis ticks xlim axis limits e. g.  10 ylim axis limits grid Display axis grid on by default DataFrame has number of options allowing some flexibility with how the columns are handled for example whether to plot them all on the same subplot or to create separate subplots.  See Table 84 for more on these.  Table 84.  DataFramespecific plot arguments Argument Description subplots Plot each DataFrame column in separate subplot sharex If subplotsTrue share the same axis linking ticks and limits sharey If subplotsTrue share the same axis figsize Size of figure to create as tuple 234 Chapter Plotting and Visualization Argument Description title Plot title as string legend Add subplot legend True by default sortcolumns Plot columns in alphabetical order by default uses existing column order Vs For time series plotting see Chapter 10.  Bar Plots Making bar plots instead of line plots is as simple as passing kindbar for vertical bars or kindbarh for horizontal bars.  In this case the Series or DataFrame index will be used as the bar or barh ticks see Figure 815 In 59 fig axes plt. subplots2 In 60 data Seriesnp. random. rand16 indexlistabcdefghijklmnop In 61 data. plotkindbar axaxes0 colork alpha0. 7 Out61 matplotlib. axes. AxesSubplot at 0x4ee7750 In 62 data. plotkindbarh axaxes1 colork alpha0. 7 For more on the plt. subplots function and matplotlib axes and figures see the later section in this chapter.  With DataFrame bar plots group the values in each row together in group in bars side by side for each value.  See Figure 816 In 63 df DataFramenp. random. rand6 aera indexone two three four five six mare columnspd. IndexA nameGenus In 64 df Out 64 Genus one 0. 301686 0. 156333 0. 371943 0. 270731 two 0. 750589 0. 525587 0. 689429 0. 358974 three 0. 381504 0. 667707 0. 473772 0. 632528 four 0. 942408 0. 180186 0. 708284 0. 641783 five 0. 840278 0. 909589 0. 010041 0. 653207 six 0. 062854 0. 589813 0. 811318 0. 060217 In 65 df. plotkind bar Plotting Functions in pandas 235 oO 9oNA0ET X33500 oO 0. 2 0. 4 0. 6 0. 8 1. 0 Figure 815.  Horizonal and vertical bar plot example Note that the name Genus on the DataFrames columns is used to title the legend.  Stacked bar plots are created from DataFrame by passing stackedTrue resulting in the value in each row being stacked together see Figure 817 In 67 df. plotkindbarh stackedTrue alpha0. 5 Vs useful recipe for bar plots as seen in an earlier chapter is to visualize Seriess value frequency using valuecounts s. valuecounts ne plot kindbar Returning to the tipping data set used earlier in the book suppose we wanted to make stacked bar plot showing the percentage of data points for each party size on each day.  load the data using readcsv and make crosstabulation by day and party size In 68 tips pd. readcsvcho8tips. csv In 69 partycounts pd. crosstabtips. day tips. size In 70 partycounts Out70 size 45 day Fri 16 00 Sat 53 18 13 Sun oO 39 15 18 Thur 48 236 Chapter8 Plotting and Visualization Not many and 6person parties In 71 partycounts partycounts. ix 25 0. 0 one two three four five SIX Figure 816.  DataFrame bar plot example six five four three two 0. 0 0. 5 1. 0 1. 5 2. 0 2. 5 Figure 817.  DataFrame stacked bar plot example Then normalize so that each row sums to have to cast to float to avoid integer division issues on Python 2. 7 and make the plot see Figure 818 Normalize to sum to In 72 partypcts partycounts. divpartycounts. sum1. astypefloat axis0 Plotting Functions in pandas 237 In 73 partypcts Out 73 size day Fri 0. 888889 0. 055556 0. 055556 0. 000000 Sat 0. 623529 0. 211765 0. 152941 0. 011765 Sun 0. 520000 0. 200000 0. 240000 0. 040000 Thur 0. 827586 0. 068966 0. 086207 0. 017241 In 74 partypcts. plotkindbar stackedTrue 1. 0 0. 8 0. 6 0. 4 0. 2 0. 0 Fri Sat Sun Thur day Figure 818.  Fraction of parties by size on each day So you can see that party sizes appear to increase on the weekend in this data set.  Histograms and Density Plots histogram with which you may be wellacquainted is kind of bar plot that gives discretized display of value frequency.  The data points are split into discrete evenly spaced bins and the number of data points in each bin is plotted.  Using the tipping data from before we can make histogram of tip percentages of the total bill using the hist method on the Series see Figure 819 In 76 tipstippct tipstip tipstotalbill In 77 tipstippct. histbins50 238 Chapter Plotting and Visualization 0. 1 0. 2 0. 3 Figure 819.  Histogram of tip percentages related plot type is density plot which is formed by computing an estimate of continuous probability distribution that might have generated the observed data.  usual procedure is to approximate this distribution as mixture of kernels that is simpler distributions like the normal Gaussian distribution.  Thus density plots are also known as KDE kernel density estimate plots.  Using plot with kindkde makes density plot using the standard mixtureofnormals KDE see Figure 820 In 79 tipstippct. plotkindkde These two plot types are often plotted together the histogram in normalized form to give binned density with kernel density estimate plotted on top.  As an example consider bimodal distribution consisting of draws from two different standard normal distributions see Figure 821 In 81 comp1 np. random. normal0 size200 N0 In 82 comp2 np. random. normal10 size200 N10 In 83 values Seriesnp. concatenatecomp1 comp2 In 84 values. histbins100 alpha0. 3 colork normedTrue Out84 matplotlib. axes. AxesSubplot at 0x5cd2350 In 85 values. plotkindkde stylek Scatter Plots Scatter plots are useful way of examining the relationship between two onedimen sional data series.  matplotlib has scatter plotting method that is the workhorse of Plotting Functions in pandas 239 oa 0. 2 0. 0 0. 2 0. 4 0. 6 0. 8 1. 0 1. 2 Figure 820.  Density plot of tip percentages 0. 30 Density oO BR ur 0. 10 0. 05 08070 10 15 20 25 Figure 821.  Normalized histogram of normal mixture with density estimate making these kinds of plots.  To give an example load the macrodata dataset from the statsmodels project select few variables then compute log differences In 86 macro pd. readcsvch08macrodata. csv In 87 data macrocpi mi tbilrate unemp In 88 trans data np. logdata. diff. dropna 240 Chapter8 Plotting and Visualization In 89 trans data5 Out 89 cpi 198 0. 007904 199 0. 021979 200 0. 002340 201 0. 008419 202 0. 008894 Its easy to plot simple scatter plot using plt. scatter see Figure 822 mi tbilrate unemp 0. 045361 0. 396881 0. 105361 0. 066753 2. 277267 0. 139762 0. 010286 0. 606136 0. 160343 0. 037461 0. 200671 0. 127339 0. 012202 0. 405465 0. 042560 In 91 plt. scattertrans datam1 transdataunemp Out91 matplotlib. collections. PathCollection at 0x43c31d0 In 92 plt. titleChanges in log vs.  log m1 unemp Changes in log m1 vs.  log unemp 0. 25 .  0. 20 0. 15 ar .  .  .  0. 10 oo ym eo o.  .  0. 05 wow 1s oe of Pee Pom 088 0. 00 00 come cam C00 000 08 Oo ee oe aA ed age ee 0. 05 om fo gee .  0. 10 .  019 04 0. 02 0. 00 0. 02 0. 04 0. 06 0. 08 Figure 822.  simple scatter plot In exploratory data analysis its helpful to be able to look at all the scatter plots among group of variables this is known as pairs plot or scatter plot matrix.  Making such plot from scratch is bit of work so pandas has scattermatrix function for creating one from DataFrame.  It also supports placing histograms or density plots of each variable along the diagonal.  See Figure 823 for the resulting plot In 93 pd. scattermatrixtrans data diagonalkde colork alpha0. 3 Plotting Maps Visualizing Haiti Earthquake Crisis Data Ushahidi is nonprofit software company that enables crowdsourcing of information related to natural disasters and geopolitical events via text message.  Many of these data sets are then published on their website for analysis and visualization.  downloaded Plotting Maps Visualizing Haiti Earthquake Crisis Data 241 Scatter plot matrix of statsmodels macro data ml 1. 0 tbilrate tbilrate Figure 823.  Scatter plot matrix of statsmodels macro data the data collected during the 2010 Haiti earthquake crisis and aftermath and Ill show you how prepared the data for analysis and visualization using pandas and other tools we have looked at thus far.  After downloading the CSV file from the above link we can load it into DataFrame using read csv In 94 data pd. readcsvcho8Haiti. csv In 95 data Out95 class pandas. core. frame. DataFrame Int64Index 3593 entries to 3592 Data columns Serial 3593 nonnull values INCIDENT TITLE 3593 nonnull values INCIDENT DATE 3593 nonnull values LOCATION 3593 nonnull values DESCRIPTION 3593 nonnull values CATEGORY 3587 nonnull values LATITUDE 3593 nonnull values LONGITUDE 3593 nonnull values APPROVED 3593 nonnull values VERIFIED 3593 nonnull values dtypes float642 int641 object7 242 Chapter8 Plotting and Visualization Its easy now to tinker with this data set to see what kinds of things we might want to do with it.  Each row represents report sent from someones mobile phone indicating an emergency or some other problem.  Each has an associated timestamp and location as latitude and longitude In 96 dataINCIDENT DATE LATITUDE LONGITUDE10 Out 96 INCIDENT DATE LATITUDE LONGITUDE 05072010 18. 233333 72. 533333 28062010 50. 226029 5. 729886 24062010 22. 278381 114. 174287 20062010 44. 407062 8. 933989 18052010 18. 571084 72. 334671 26042010 18. 593707 72. 310079 26042010 18. 482800 73. 638800 26042010 18. 415000 73. 195000 15032010 18. 517443 72. 236841 15032010 18. 547790 72. 410010 Ww ONAUBWNF OO The CATEGORY field contains commaseparated list of codes indicating the type of message In 97 dataCATEGORY Out 97 1.  Urgences Emergency 3.  Public Health 1.  Urgences Emergency 2.  Urgences logistiques 2.  Urgences logistiques Vital Lines 8.  Autre 1.  Urgences Emergency 1.  Urgences Emergency 5e.  Communication lines down Name CATEGORY If you notice above in the data summary some of the categories are missing so we might want to drop these data points.  Additionally calling describe shows that there are some aberrant locations In 98 data. describe Out 98 Serial LATITUDE LONGITUDE count 3593. 000000 3593. 000000 3593. 000000 mean 2080. 277484 18. 611495 72. 322680 std 1171. 100360 0. 738572 3. 650776 min 4. 000000 18. 041313 74. 452757 25 1074. 000000 18. 524070 72. 417500 50 2163 . 000000 18. 539269 72. 335000 75 3088 . 000000 18. 561820 72. 293570 max 4052. 000000 50. 226029 114. 174287 Cleaning the bad locations and removing the missing categories is now fairly simple In 99 data datadata. LATITUDE 18 data. LATITUDE 20 eormeat data. LONGITUDE 75 data. LONGITUDE 70 were data. CATEGORY. notnull Plotting Maps Visualizing Haiti Earthquake Crisis Data 243 Now we might want to do some analysis or visualization of this data by category but each category field may have multiple categories.  Additionally each category is given as code plus an English and possibly also French code name.  Thus little bit of wrangling is required to get the data into more agreeable form.  First wrote these two functions to get list of all the categories and to split each category into code and an English name def tocatlistcatstr stripped x. strip for in catstr. split return for in stripped if def getallcategoriescatseries catsets settocatlistx for in catseries return sortedset. unioncatsets def getenglishcat code names cat. split.  if in names names names. split return code names. strip You can test out that the getenglish function does what you expect In 101 getenglish2.  Urgences logistiques Vital Lines Out101 Vital Lines Now make dict mapping code to name because well use the codes for analysis.  Well use this later when adorning plots note the use of generator expression in lieu of list comprehension In 102 allcats getallcategoriesdata. CATEGORY Generator expression In 103 englishmapping dictgetenglishx for in all cats In 104 english mapping2a Out104 Food Shortage In 105 english mapping 6c Out105 Earthquake and aftershocks There are many ways to go about augmenting the data set to be able to easily select records by category.  One way is to add indicator or dummy columns one for each category.  To do that first extract the unique category codes and construct DataFrame of zeros having those as its columns and the same index as data def getcodeseq return x. split. 0 for in seq if allcodes getcodeallcats codeindex pd. Indexnp. uniqueallcodes dummy frame DataFramenp. zeroslendata lencodeindex indexdata. index columnscodeindex If all goes well dummy frame should look something like this 244 Chapter Plotting and Visualization In 107 dummy frame. ix Out 107 class pandas. core.  frame. DataFrame Int64Index 3569 entries to 3592 Data columns 3569 nonnull values ta 3569 nonnull values 1b 3569 nonnull values 1c 3569 nonnull values 1d 3569 nonnull values 3569 nonnull values dtypes float646 As you recall the trick is then to set the appropriate entries of each row to lastly joining this with data for row cat in zipdata. index data. CATEGORY codes getcodetocatlistcat dummy frame. ixrow codes data data.  joindummyframe. addprefixcategory data finally now has new columns like In 109 data. ix Out109 class pandas. core.  frame. DataFrame Int64Index 3569 entries to 3592 Data columns category 3569 nonnull values category 1a 3569 nonnull values category 1b 3569 nonnull values category 1c 3569 nonnull values category 1d 3569 nonnull values dtypes float645 Lets make some plots As this is spatial data wed like to plot the data by category on map of Haiti.  The basemap toolkit httpmatplotlib. github. combasemap an addon to matplotlib enables plotting 2D data on maps in Python.  basemap provides many different globe projections and means for transforming projecting latitude and lon gitude coordinates on the globe onto twodimensional matplotlib plot.  After some trial and error and using the above data as guideline wrote this function which draws simple black and white map of Haiti from mpltoolkits. basemap import Basemap import matplotlib. pyplot as plt def basichaitimapaxNone lllat17. 25 urlat20. 25 lllon75 urlon71 create polar stereographic Basemap instance.  Basemapaxax projectionstere lonourlon lllon latourlat lllat llcrnrlatlllat urcrnrlaturlat llcrnrlonlllon urcrnrlonurlon Plotting Maps Visualizing Haiti Earthquake Crisis Data 245 resolutionf draw coastlines state and country boundaries edge of map.  m. drawcoastlines m. drawstates m. drawcountries return The idea now is that the returned Basemap object knows how to transform coordinates onto the canvas.  wrote the following code to plot the data observations for number of report categories.  For each category filter down the data set to the coordinates labeled by that category plot Basemap on the appropriate subplot transform the co ordinates then plot the points using the Basemaps plot method fig axes plt. subplotsnrows2 ncols2 figsize12 10 fig. subplotsadjusthspace0. 05 wspace0. 05 toplot 2a 3c 7a lllat17. 25 urlat20. 25 lllon75 urlon71 for code ax in ziptoplot axes. flat basichaitimapax lllatlllat urlaturlat lllon1llon urlonurlon catdata datadatacategory code compute map proj coordinates.  mcatdata. LONGITUDE catdata. LATITUDE m. plotx k.  alpha0. 5 ax. settitles code english mappingcode The resulting figure can be seen in Figure 824.  It seems from the plot that most of the data is concentrated around the most populous city PortauPrince.  basemap allows you to overlap additional map data which comes from what are called shapefiles.  first downloaded shapefile with roads in Portau Prince see httpcegrp. cga. harvard. edushaitiqresourcesdata.  The Basemap object conveniently has readshapefile method so that after extracting the road data archive added just the following lines to my code shapefile path cho8PortAuPrince RoadsPortAuPrinceRoads m. readshapefileshapefilepath roads After little more trial and error with the latitude and longitude boundaries was able to make Figure 825 for the Food shortage category.  246 Chapter Plotting and Visualization 2a Food Shortage Emergency Figure 824.  Haiti crisis data for categories Food shortages reported in PortauPrince Figure 825.  Food shortage reports in PortauPrince during the Haiti earthquake crisis Python Visualization Tool Ecosystem As is common with open source there are plethora of options for creating graphics in Python too many to list.  In addition to open source there are numerous commercial libraries with Python bindings.  Python Visualization Tool Ecosystem 247 In this chapter and throughout the book have been primarily concerned with mat plotlib as it is the most widely used plotting tool in Python.  While its an important part of the scientific Python ecosystem matplotlib has plenty of shortcomings when it comes to the creation and display of statistical graphics.  MATLAB users will likely find matplotlib familiar while users especially users of the excellent ggplot2 and trel lis packages may be somewhat disappointed at least as of this writing.  It is possible to make beautiful plots for display on the web in matplotlib but doing so often requires significant effort as the library is designed for the printed page.  Aesthetics aside it is sufficient for most needs.  In pandas along with the other developers have sought to build convenient user interface that makes it easier to make most kinds of plots com monplace in data analysis.  There are number of other visualization tools in wide use.  list few of them here and encourage you to explore the ecosystem.  Chaco Chaco httpcode. enthought. comchaco developed by Enthought is plotting tool kit suitable both for static plotting and interactive visualizations.  It is especially well suited for expressing complex visualizations with data interrelationships.  Compared with matplotlib Chaco has much better support for interacting with plot elements and rendering is very fast making it good choice for building interactive GUI applications.  Figure 826.  Chaco example plot 248 Chapter Plotting and Visualization mayavi The mayavi project developed by Prabhu Ramachandran Gal Varoquaux and others is 3D graphics toolkit built on the open source graphics library VTK.  mayavi like matplotlib integrates with Python so that it is easy to use interactively.  The plots can be panned rotated and zoomed using the mouse and keyboard.  used mayavi to make one of the illustrations of broadcasting in Chapter 12.  While dont show any mayaviusing code here there is plenty of documentation and examples available on line.  In many cases believe it is good alternative to technology like WebGL though the graphics are harder to share in interactive form.  Other Packages Of course there are numerous other visualization libraries and applications available in Python PyQwt Veusz gnuplotpy biggles and others.  have seen PyQwt put to good use in GUI applications built using the Qt application framework using PyQt.  While many of these libraries continue to be under active development some of them are part of much larger applications have noted in the last few years general trend toward webbased technologies and away from desktop graphics.  Ill say few more words about this in the next section.  The Future of Visualization Tools Visualizations built on web technologies that is JavaScriptbased appear to be the inevitable future.  Doubtlessly you have used many different kinds of static or interactive visualizations built in Flash or JavaScript over the years.  New toolkits such as d3. js and its numerous offshoot projects for building such displays are appearing all the time.  In contrast development in non webbased visualization has slowed significantly in recent years.  This holds true of Python as well as other data analysis and statistical computing environments like R.  The development challenge then will be in building tighter integration between data analysis and preparation tools such as pandas and the web browser.  am hopeful that this will become fruitful point of collaboration between Python and nonPython users as well.  Python Visualization Tool Ecosystem 249 CHAPTER Data Aggregation and Group Operations Categorizing data set and applying function to each group whether an aggregation or transformation is often critical component of data analysis workflow.  After loading merging and preparing data set familiar task is to compute group statistics or possibly pivot tables for reporting or visualization purposes.  pandas provides flex ible and highperformance groupby facility enabling you to slice and dice and sum marize data sets in natural way.  One reason for the popularity of relational databases and SQL which stands for structured query language is the ease with which data can be joined filtered trans formed and aggregated.  However query languages like SQL are rather limited in the kinds of group operations that can be performed.  As you will see with the expressive ness and power of Python and pandas we can perform much more complex grouped operations by utilizing any function that accepts pandas object or NumPy array.  In this chapter you will learn how to Split pandas object into pieces using one or more keys in the form of functions arrays or DataFrame column names Computing group summary statistics like count mean or standard deviation or userdefined function Apply varying set of functions to each column of DataFrame Apply withingroup transformations or other manipulations like normalization linear regression rank or subset selection Compute pivot tables and crosstabulations Perform quantile analysis and other dataderived group analyses 251 Aggregation of time series data special use case of groupby is referred to as resampling in this book and will receive separate treatment in 4l8 Chapter 10.  GroupBy Mechanics Hadley Wickham an author of many popular packages for the programming lan guage coined the term splitapplycombine for talking about group operations and think thats good description of the process.  In the first stage of the process data contained in pandas object whether Series DataFrame or otherwise is split into groups based on one or more keys that you provide.  The splitting is performed on particular axis of an object.  For example DataFrame can be grouped on its rows axis0 or its columns axis1.  Once this is done function is applied to each group producing new value.  Finally the results of all those function applications are com bined into result object.  The form of the resulting object will usually depend on whats being done to the data.  See Figure 91 for mockup of simple group aggregation.  Split Apply Combine Qa.  Taal Figure 91.  Illustration of group aggregation Each grouping key can take many forms and the keys do not have to be all of the same type list or array of values that is the same length as the axis being grouped value indicating column name in DataFrame 252 Chapter9 Data Aggregation and Group Operations dict or Series giving correspondence between the values on the axis being grouped and the group names function to be invoked on the axis index or the individual labels in the index Note that the latter three methods are all just shortcuts for producing an array of values to be used to split up the object.  Dont worry if this all seems very abstract.  Throughout this chapter will give many examples of all of these methods.  To get started here is very simple small tabular dataset as DataFrame In 13 df DataFramekey1 scorned key2 one two one two one semen data1 np. random. randn5 semen data2 np. random. randn5 In 14 df Out 14 data1 data2 key1 key2 0. 204708 1. 393406 one 0. 478943 0. 092908 two 0. 519439 0. 281746 one 0. 555730 0. 769023 two 1. 965781 1. 246435 one Suppose you wanted to compute the mean of the data1 column using the groups labels from key1.  There are number of ways to do this.  One is to access data1 and call groupby with the column Series at key1 In 15 grouped dfdata1. groupbydfkey1 In 16 grouped Out16 pandas. core. groupby. SeriesGroupBy at 0x2d78b10 This grouped variable is now GroupBy object.  It has not actually computed anything yet except for some intermediate data about the group key dfkey1 .  The idea is that this object has all of the information needed to then apply some operation to each of the groups.  For example to compute group means we can call the GroupBys mean method In 17 grouped. mean Out 17 key1 0. 746672 0. 537585 Later Ill explain more about whats going on when you call . mean.  The important thing here is that the data Series has been aggregated according to the group key producing new Series that is now indexed by the unique values in the key1 column.  The result index has the name key1 because the DataFrame column dfkey1 did.  If instead we had passed multiple arrays as list we get something different In 18 means dfdata1. groupbydfkey1 dfkey2. mean GroupBy Mechanics 253 In 19 means Out19 key1 key2 one 0. 880536 two 0. 478943 one 0. 519439 two 0. 555730 In this case we grouped the data using two keys and the resulting Series now has hierarchical index consisting of the unique pairs of keys observed In 20 means. unstack Out20 key2 one two key1 0. 880536 0. 478943 0. 519439 0. 555730 In these examples the group keys are all Series though they could be any arrays of the right length In 21 states np. arrayOhio California California Ohio Ohio In 22 years np. array2005 2005 2006 2005 2006 In 23 dfdata1. groupbystates years. mean Out 23 California 2005 0. 478943 2006 0. 519439 Ohio 2005 0. 380219 2006 1. 965781 Frequently the grouping information to be found in the same DataFrame as the data you want to work on.  In that case you can pass column names whether those are strings numbers or other Python objects as the group keys In 24 df. groupbykey1. mean Out 24 data1 data2 key1 0. 746672 0. 910916 0. 537585 0. 525384 In 25 df. groupbykey1 key2. mean Out 25 data1 data2 key1 key2 one 0. 880536 1. 319920 two 0. 478943 0. 092908 one 0. 519439 0. 281746 two 0. 555730 0. 769023 You may have noticed in the first case df. groupbykey1. mean that there is no key2 column in the result.  Because dfkey2 is not numeric data it is said to be nuisance column which is therefore excluded from the result.  By default all of the 254 Chapter9 Data Aggregation and Group Operations numeric columns are aggregated though it is possible to filter down to subset as youll see soon.  Regardless of the objective in using groupby generally useful GroupBy method is size which return Series containing group sizes In 26 df. groupbykey1 key2. size Out 26 key1 key2 one two one two As of this writing any missing values in group key will be excluded ta from the result.  Its possible and in fact quite likely that by the time you are reading this there will be an option to include the NA group in the result.  Iterating Over Groups The GroupBy object supports iteration generating sequence of 2tuples containing the group name along with the chunk of data.  Consider the following small example data set In 27 for name group in df. groupbykey1 wera print name were print group data1 data2 key1 key2 0. 204708 1. 393406 one 0. 478943 0. 092908 two 1. 965781 1. 246435 one data1 data2 key1 key2 0. 519439 0. 281746 one 0. 555730 0. 769023 two In the case of multiple keys the first element in the tuple will be tuple of key values In 28 for k1 k2 group in df. groupbykey1 key2 awaat print ki k2 awaat print group data1 data2 key1 key2 0. 204708 1. 393406 one 1. 965781 1. 246435 one two data1 data2 key1 key2 0. 478943 0. 092908 two one data1 data2 key1 key2 GroupBy Mechanics 255 0. 519439 0. 281746 one two data1 data2 key1 key2 0. 55573 0. 769023 two Of course you can choose to do whatever you want with the pieces of data.  recipe you may find useful is computing dict of the data pieces as oneliner In 29 pieces dictlistdf. groupbykey1 In 30 piecesb Out 30 data1 data2 key1 key2 0. 519439 0. 281746 one 0. 555730 0. 769023 two By default groupby groups on axis0 but you can group on any of the other axes.  For example we could group the columns of our example df here by dtype like so In 31 df. dtypes Out 31 data1 float64 data2 float64 key1 object key2 object In 32 grouped df. groupbydf. dtypes axis1 In 33 dictlist grouped Out 33 dtypefloat64 data1 data2 0. 204708 1. 393406 0. 478943 0. 092908 0. 519439 0. 281746 0. 555730 0. 769023 1. 965781 1. 246435 dtypeobject key1 key2 one two one two one Selecting Column or Subset of Columns Indexing GroupBy object created from DataFrame with column name or array of column names has the effect of selecting those columns for aggregation.  This means that df. groupbykey1data1 df. groupbykey1data2 are syntactic sugar for dfdata1. groupbydf key1 dfdata2. groupbydfkey1 256 Chapter9 Data Aggregation and Group Operations Especially for large data sets it may be desirable to aggregate only few columns.  For example in the above data set to compute means for just the data2 column and get the result as DataFrame we could write In 34 df. groupbykey1 key2data2. mean Out 34 data2 key1 key2 one 1. 319920 two 0. 092908 one 0. 281746 two 0. 769023 The object returned by this indexing operation is grouped DataFrame if list or array is passed and grouped Series is just single column name that is passed as scalar In 35 sgrouped df. groupbykey1 key2data2 In 36 sgrouped Out36 pandas. core. groupby. SeriesGroupBy at 0x2e215d0 In 37 sgrouped. mean Out 37 key1 key2 one 1. 319920 two 0. 092908 one 0. 281746 two 0. 769023 Name data2 Grouping with Dicts and Series Grouping information may exist in form other than an array.  Lets consider another example DataFrame In 38 people DataFramenp. random. randn5 weeat columnsa wewat indexJoe Steve Wes Jim Travis In 39 people. ix23 np. nan Add few NA values In 40 people Out 40 Joe 1. 007189 1. 296221 0. 274992 0. 228913 1. 352917 Steve 0. 886429 2. 001637 0. 371843 1. 669025 0. 438570 Wes 0. 539741 NaN NaN 1. 021228 0. 577087 Jim 0. 124121 0. 302614 0. 523772 0. 000940 1. 343810 Travis 0. 713544 0. 831154 2. 370232 1. 860761 0. 860757 Now suppose havea group correspondence for the columns and want to sum together the columns by group In 41 mapping red red blue ates blue red orange GroupBy Mechanics 257 Now you could easily construct an array from this dict to pass to groupby but instead we can just pass the dict In 42 bycolumn people. groupbymapping axis1 In 43 bycolumn. sum Out 43 blue red Joe 0. 503905 1. 063885 Steve 1. 297183 1. 553778 Wes 1. 021228 1. 116829 Jim 0. 524712 1. 770545 Travis 4. 230992 2. 405455 The same functionality holds for Series which can be viewed as fixed size mapping.  When used Series as group keys in the above examples pandas does in fact inspect each Series to ensure that its index is aligned with the axis its grouping In 44 mapseries Seriesmapping In 45 mapseries Out 45 red red blue blue red orange In 46 people. groupbymap series axis1. count Out 46 blue red Joe Steve Wes Jim Travis Grouping with Functions Using Python functions in what can be fairly creative ways is more abstract way of defining group mapping compared with dict or Series.  Any function passed as group key will be called once per index value with the return values being used as the group names.  More concretely consider the example DataFrame from the previous section which has peoples first names as index values.  Suppose you wanted to group by the length of the names you could compute an array of string lengths but instead you can just pass the len function In 47 people. groupbylen . sum Out 47 0. 591569 0. 993608 0. 798764 0. 791374 2. 119639 258 Chapter9 Data Aggregation and Group Operations 0. 886429 2. 001637 0. 371843 1. 669025 0. 438570 0. 713544 0. 831154 2. 370232 1. 860761 0. 860757 Mixing functions with arrays dicts or Series is not problem as everything gets con verted to arrays internally In 48 keylist one one one two two In 49 people. groupbylen keylist. min Out 49 one 0. 539741 1. 296221 0. 274992 1. 021228 0. 577087 two 0. 124121 0. 302614 0. 523772 0. 000940 1. 343810 one 0. 886429 2. 001637 0. 371843 1. 669025 0. 438570 two 0. 713544 0. 831154 2. 370232 1. 860761 0. 860757 Grouping by Index Levels final convenience for hierarchicallyindexed data sets is the ability to aggregate using one of the levels of an axis index.  To do this pass the level number or name using the level keyword In 50 columns pd. MultiIndex. fromarraysUS US US JP JP scone namescty tenor In 51 hierdf DataFramenp. random. randn4 columnscolumns In 52 hierdf Out 52 cty US JP tenor 0. 560145 1. 265934 0. 119827 1. 063512 0. 332883 2. 359419 0. 199543 1. 541996 0. 970736 1. 307030 0. 286350 0. 377984 0. 753887 0. 331286 1. 349742 0. 069877 0. 246674 0. 011862 1. 004812 1. 327195 In 53 hierdf. groupbylevelcty axis1. count Out 53 cty JP US Data Aggregation By aggregation am generally referring to any data transformation that produces scalar values from arrays.  In the examples above have used several of them such as mean count min and sum.  You may wonder what is going on when you invoke mean on GroupBy object.  Many common aggregations such as those found in Table 91 have optimized implementations that compute the statistics on the dataset in place.  How ever you are not limited to only this set of methods.  You can use aggregations of your Data Aggregation 259 own devising and additionally call any method that is also defined on the grouped object.  For example as you recall quantile computes sample quantiles of Series or DataFrames columns In 54 df Out 54 data1 data2 key1 key2 0. 204708 1. 393406 0. 478943 0. 092908 0. 519439 0. 281746 0. 555730 0. 769023 1. 965781 1. 246435 one two one two one roT ow In 55 grouped df. groupbykey1 In 56 grouped data1. quantile0o. 9 Out 56 key1 1. 668413 0. 523068 While quantile is not explicitly implemented for GroupBy it is Series method and thus available for use.  Internally GroupBy efficiently slices up the Series calls piece.  quantile0. 9 foreach piece then assembles those results together into the result object.  To use your own aggregation functions pass any function that aggregates an array to the aggregate or agg method In 57 def peaktopeakarr ees return arr. max arr. min In 58 grouped. aggpeaktopeak Out 58 key1 data1 data2 2. 170488 1. 300498 0. 036292 0. 487276 Youll notice that some methods like describe also work even though they are not aggregations strictly speaking In 59 grouped. describe Out 59 key1 data1 count 3. 000000 mean 0. 746672 std 1. 109736 min 0. 204708 25 0. 137118 50 0. 478943 RPOOOOW data2 000000 910916 712217 092908 669671 246435 1.  Note that quantile performs linear interpolation if there is no value at exactly the passed percentile.  260 Chapter9 Data Aggregation and Group Operations 75 1. 222362 1. 319920 max 1. 965781 1. 393406 count 2. 000000 2. 000000 mean 0. 537585 0. 525384 std 0. 025662 0. 344556 min 0. 555730 0. 281746 25 0. 546657 0. 403565 50 0. 537585 0. 525384 75 0. 528512 0. 647203 max 0. 519439 0. 769023 will explain in more detail what has happened here in the next major section on group wise operations and transformations.  Vs sO You may notice that custom aggregation functions are much slower than 43 the optimized functions found in Table 91.  This is because there is Vs 48 significant overhead function calls data rearrangement in construct ing the intermediate group data chunks.  Table 91.  Optimized groupby methods Functionname Description count Number of nonNA values in the group sum Sum of nonNA values mean Mean of nonNA values median Arithmetic median of nonNA values std var Unbiased denominator standard deviation and variance min max Minimum and maximum of nonNA values prod Product of nonNA values first last First and last nonNA values To illustrate some more advanced aggregation features Ill use less trivial dataset dataset on restaurant tipping.  obtained it from the reshape2 package it was origi nally found in Bryant Smiths 1995 text on business statistics and found in the books GitHub repository.  After loading it with readcsv add tipping percentage column tippct.  In 60 tips pd. readcsvcho8tips. csv Add tip percentage of total bill In 61 tipstippct tipstip tipstotalbill In 62 tips6 Out 62 total bill tip sex smoker day time size tippct 16. 99 1. 01 Female No Sun Dinner 0. 059447 10. 34 1. 66 Male No Sun Dinner 0. 160542 Data Aggregation 261 21. 01 23. 68 24. 59 25. 29 Mm PWN Columnwise and Multiple Function Application As youve seen above aggregating Series or all of the columns of DataFrame is matter of using aggregate with the desired function or calling method like mean or std.  However you may want to aggregate using different function depending on the column or multiple functions at once.  Fortunately this is straightforward to do which Pl illustrate through number of examples.  First Ill group the tips by sex and smoker In 63 grouped tips. groupbysex smoker Note that for descriptive statistics like those in Table 91 you can pass the name of the 3. 61 Fe function as string Male No Male No male No Male No Sun Sun Sun Sun Dinner Dinner Dinner Dinner In 64 grouped pct groupedtippct In 65 groupedpct. aggmean Out 65 sex smoker Female No Yes Male No Yes Name tippct If you pass list of functions or function names instead you get back DataFrame with 0. 156 0. 182 0. 160 0. 152 921 150 669 771 column names taken from the functions In 66 groupedpct. aggmean Out 66 sex smoker Female No Yes Male No Yes You dont need to accept the names that GroupBy gives to the columns notably lambda functions have the name lambda which make them hard to identify you can see for yourself by looking at functions name attribute.  As such if you pass list of name function tuples the first element of each tuple will be used as the DataFrame column names you can think of list of 2tuples as an ordered mapping mean 0. 156921 0. 182150 0. 160669 0. 152771 std peaktopeak 0. 036421 0. 071595 0. 041849 0. 090588 0. 195876 0. 360233 0. 220186 0. 674707 FRNW std peaktopeak 0. 166587 0. 139780 0. 146808 0. 186240 In 67 groupedpct. aggfoo mean bar np. std Out 67 sex smoker Female No Yes foo 0. 156921 0. 182150 bar 0. 036421 0. 071595 262 Chapter9 Data Aggregation and Group Operations Male No 0. 160669 0. 041849 Yes 0. 152771 0. 090588 With DataFrame you have more options as you can specify list of functions to apply to all of the columns or different functions per column.  To start suppose we wanted to compute the same three statistics for the tippct and totalbill columns In 68 functions count mean max In 69 result groupedtippct totalbill. aggfunctions In 70 result Out70 tippct totalbill count mean max count mean max sex smoker Female No 54 0. 156921 0. 252672 54 18. 105185 35. 83 Yes 33 0. 182150 0. 416667 33 17. 977879 44. 30 Male No 97 0. 160669 0. 291990 97 19. 791237 48. 33 Yes 60 0. 152771 0. 710345 60 22. 284500 50. 81 As you can see the resulting DataFrame has hierarchical columns the same as you would get aggregating each column separately and using concat to glue the results together using the column names as the keys argument In 71 resulttippct Out71 count mean max sex smoker Female No 54 0. 156921 0. 252672 Yes 33 0. 182150 0. 416667 Male No 97 0. 160669 0. 291990 Yes 60 0. 152771 0. 710345 As above list of tuples with custom names can be passed In 72 ftuples Durchschnitt mean Abweichung np. var In 73 groupedtippct totalbill. aggftuples Out 73 tippct totalbill Durchschnitt Abweichung Durchschnitt Abweichung sex smoker Female No 0. 156921 0. 001327 18. 105185 53. 092422 Yes 0. 182150 0. 005126 17. 977879 84. 451517 Male No 0. 160669 0. 001751 19. 791237 76. 152961 Yes 0. 152771 0. 008206 22. 284500 98 . 244673 Now suppose you wanted to apply potentially different functions to one or more of the columns.  The trick is to pass dict to agg that contains mapping of column names to any of the function specifications listed so far In 74 grouped. aggtip np. max size sum Out 74 size tip sex smoker Data Aggregation 263 Female No 140 5. 2 Yes 74 6. 5 Male No 263 9. 0 Yes 150 10. 0 In 75 grouped. aggtippct min max mean std cconee size sum Out 75 tippct size min max mean std sum sex smoker Female No 0. 056797 0. 252672 0. 156921 0. 036421 140 Yes 0. 056433 0. 416667 0. 182150 0. 071595 74 Male No 0. 071804 0. 291990 0. 160669 0. 041849 263 Yes 0. 035638 0. 710345 0. 152771 0. 090588 150 DataFrame will have hierarchical columns only if multiple functions are applied to at least one column.  Returning Aggregated Data in unindexed Form In all of the examples up until now the aggregated data comes back with an index potentially hierarchical composed from the unique group key combinations observed.  Since this isnt always desirable you can disable this behavior in most cases by passing asindexFalse to groupby In 76 tips. groupbysex smoker asindexFalse . mean Out76 sex smoker total bill tip size tippct Female No 18. 105185 2. 773519 2. 592593 0. 156921 Female Yes 17. 977879 2. 931515 2. 242424 0. 182150 Male No 19. 791237 3. 113402 2. 711340 0. 160669 Male Yes 22. 284500 3. 051167 2. 500000 0. 152771 Of course its always possible to obtain the result in this format by calling resetindex on the result.  Using groupby in this way is generally less flexible results with hier tS archical columns for example are not currently implemented as the form of the result would have to be somewhat arbitrary.  Groupwise Operations and Transformations Aggregation is only one kind of group operation.  It is special case in the more general class of data transformations that is it accepts functions that reduce onedimensional array to scalar value.  In this section will introduce you to the transform and apply methods which will enable you to do many other kinds of group operations.  Suppose instead we wanted to add column to DataFrame containing group means for each index.  One way to do this is to aggregate then merge 264 Chapter9 Data Aggregation and Group Operations In 77 df Out77 data1 data2 key1 key2 0. 204708 1. 393406 one 0. 478943 0. 092908 two 0. 519439 0. 281746 one 0. 555730 0. 769023 two 1. 965781 1. 246435 one In 78 kimeans df. groupbykey1. mean. addprefixmean In 79 k1means Out 79 meandata1 meandata2 key1 0. 746672 0. 910916 0. 537585 0. 525384 In 80 pd. mergedf kimeans leftonkey1 rightindexTrue Out 80 data1 data2 key1 key2 meandata1 meandata2 0. 204708 1. 393406 one 0. 746672 0. 910916 0. 478943 0. 092908 two 0. 746672 0. 910916 1. 965781 1. 246435 one 0. 746672 0. 910916 0. 519439 0. 281746 one 0. 537585 0. 525384 0. 555730 0. 769023 two 0. 537585 0. 525384 cow Ww This works but is somewhat inflexible.  You can think of the operation as transforming the two data columns using the np. mean function.  Lets look back at the people Data Frame from earlier in the chapter and use the transform method on GroupBy In 81 key one two one two one In 82 people. groupbykey . mean Out 82 one 0. 082032 1. 063687 1. 047620 0. 884358 0. 028309 two 0. 505275 0. 849512 0. 075965 0. 834983 0. 452620 In 83 people. groupbykey. transformnp. mean Out 83 Joe 0. 082032 1. 063687 1. 047620 0. 884358 0. 028309 Steve 0. 505275 0. 849512 0. 075965 0. 834983 0. 452620 Wes 0. 082032 1. 063687 1. 047620 0. 884358 0. 028309 Jim 0. 505275 0. 849512 0. 075965 0. 834983 0. 452620 Travis 0. 082032 1. 063687 1. 047620 0. 884358 0. 028309 As you may guess transform applies function to each group then places the results in the appropriate locations.  If each group produces scalar value it will be propagated broadcasted.  Suppose instead you wanted to subtract the mean value from each group.  To do this create demeaning function and pass it to transform In 84 def demeanarr sores return arr arr. mean Groupwise Operations and Transformations 265 In 85 demeaned people. groupbykey . transformdemean In 86 demeaned Out 86 Cc Joe 1. 089221 0. 232534 1. 322612 1. 113271 1. 381226 Steve 0. 381154 1. 152125 0. 447807 0. 834043 0. 891190 Wes 0. 457709 NaN NaN 0. 136869 0. 548778 Jim 0. 381154 1. 152125 0. 447807 0. 834043 0. 891190 Travis 0. 631512 0. 232534 1. 322612 0. 976402 0. 832448 You can check that demeaned now has zero group means In 87 demeaned. groupbykey . mean Out 87 be one 00 two ooa oon As youll see in the next section group demeaning can be achieved using apply also.  Apply General splitapplycombine Like aggregate transform is more specialized function having rigid requirements the passed function must either produce scalar value to be broadcasted like np. mean or transformed array of the same size.  The most general purpose GroupBy method is apply which is the subject of the rest of this section.  As in Figure 91 apply splits the object being manipulated into pieces invokes the passed function on each piece then attempts to concatenate the pieces together.  Returning to the tipping data set above suppose you wanted to select the top five tippct values by group.  First its straightforward to write function that selects the rows with the largest values in particular column In 88 def topdf n5 columntip pct scone return df. sortindexbycolumnn In 89 toptips n6 Out 89 total bill tip sex smoker day time size tippct 109 14. 31 4. 00 Female Yes Sat Dinner 0. 279525 183 23. 17 6. 50 Male Yes Sun Dinner 0. 280535 232 11. 61 3. 39 Male No Sat Dinner 0. 291990 67 3. 07 1. 00 Female Yes Sat Dinner 0. 325733 178 9. 60 4. 00 Female Yes Sun Dinner 0. 416667 172 7. 25 5. 15 Male Yes Sun Dinner 0. 710345 Now if we group by smoker say and call apply with this function we get the following In 90 tips. groupbysmoker. applytop Out 90 total bill tip sex smoker day time size tippct smoker 266 Chapter9 Data Aggregation and Group Operations No 88 24. 71 5. 85 Male No Thur Lunch 0. 236746 185 20. 69 5. 00 Male No Sun Dinner 0. 241663 51 10. 29 2. 60 Female No Sun Dinner 0. 252672 149 7. 51 2. 00 Male No Thur Lunch 0. 266312 232 11. 61 3. 39 Male No Sat Dinner 0. 291990 Yes 109 14. 31 4. 00 Female Yes Sat Dinner 0. 279525 183 23. 17 6. 50 Male Yes Sun Dinner 0. 280535 67 3. 07 1. 00 Female Yes Sat Dinner 0. 325733 178 9. 60 4. 00 Female Yes Sun Dinner 0. 416667 172 7. 25 5. 15 Male Yes Sun Dinner 0. 710345 What has happened here The top function is called on each piece of the DataFrame then the results are glued together using pandas. concat labeling the pieces with the group names.  The result therefore has hierarchical index whose inner level contains index values from the original DataFrame.  If you pass function to apply that takes other arguments or keywords you can pass these after the function In 91 tips. groupbysmoker day. applytop n1 columntotalbill Out91 total bill tip sex smoker day time size tippct smoker day No Fri 94 22. 75 3. 25 Female No Fri Dinner 0. 142857 Sat 212 48. 33 9. 00 Male No Sat Dinner 0. 186220 Sun 156 48. 17 5. 00 Male No Sun Dinner 0. 103799 Thur 142 41. 19 5. 00 Male No Thur Lunch 0. 121389 Yes Fri 95 40. 17.  4. 73 Male Yes Fri Dinner 0. 117750 Sat 170 50. 81 10. 00 Male Yes Sat Dinner 0. 196812 Sun 182 45. 35 3. 50 Male Yes Sun Dinner 0. 077178 Thur 197 43. 11 5. 00 Female Yes Thur Lunch 0. 115982 sO Beyond these basic usage mechanics getting the most out of apply is largely matter of creativity.  What occurs inside the function passed is up to you it only needs to return pandas object or scalar value.  The rest of this chapter will mainly consist of examples showing you how to solve various problems using groupby.  You may recall above called describe on GroupBy object In 92 result tips. groupbysmokertippct. describe In 93 result Out 93 smoker No count 151. 000000 mean 0. 159328 std 0. 039910 min 0. 056797 25 0. 136906 50 0. 155625 75 0. 185014 max 0. 291990 Groupwise Operations and Transformations 267 Yes count 93 . 000000 mean 0. 163196 std 0. 085119 min 0. 035638 25 0. 106771 50 0. 153846 75 0. 195059 max 0. 710345 In 94 result. unstacksmoker Out94 smoker No Yes count 151. 000000 93. 000000 mean 0. 159328 0. 163196 std 0. 039910 0. 085119 min 0. 056797 0. 035638 25 0. 136906 0. 106771 50 0. 155625 0. 153846 75 0. 185014 0. 195059 max 0. 291990 0. 710345 Inside GroupBy when you invoke method like describe it is actually just shortcut for lambda x. describe grouped.  applyf Suppressing the group keys In the examples above you see that the resulting object has hierarchical index formed from the group keys along with the indexes of each piece of the original object.  This can be disabled by passing groupkeysFalse to groupby In 95 tips. groupbysmoker groupkeysFalse. applytop Out 95 total bill tip sex smoker day time size tippct 88 24. 71 5. 85 Male No Thur Lunch 0. 236746 185 20. 69 5. 00 Male No Sun Dinner 0. 241663 51 10. 29 2. 60 Female No Sun Dinner 0. 252672 149 7. 51 2. 00 Male No Thur Lunch 0. 266312 232 11. 61 3. 39 Male No Sat Dinner 0. 291990 109 14. 31 4. 00 Female Yes Sat Dinner 0. 279525 183 23. 17 6. 50 Male Yes Sun Dinner 0. 280535 67 3. 07 1. 00 Female Yes Sat Dinner 0. 325733 178 9. 60 4. 00 Female Yes Sun Dinner 0. 416667 172 7. 25 5. 15 Male Yes Sun Dinner 0. 710345 Quantile and Bucket Analysis As you may recall from Chapter pandas has some tools in particular cut and qcut for slicing data up into buckets with bins of your choosing or by sample quantiles.  Combining these functions with groupby it becomes very simple to perform bucket or 268 Chapter Data Aggregation and Group Operations quantile analysis on data set.  Consider simple random data set and an equallength bucket categorization using cut In 96 frame DataFramedata1 np. random. randn1000 data2 np. random. randn1000 In 97 factor In 98 factor10 Out 98 Categorical pd. cutframe. data1 array1. 23 0. 489 2. 956 1. 23 1. 23 0. 489 0. 489 2. 208 1. 23 0. 489 0. 489 2. 208 1. 23 0. 489 1. 23 0. 489 0. 489 2. 208 0. 489 2. 208 dtypeobject Levels Index2. 956 1. 23 1. 23 0. 489 0. 489 2. 208 2. 208 3. 928 dtypeobject The Factor object returned by cut can be passed directly to groupby.  So we could com pute set of statistics for the data2 column like so In 99 def getstatsgroup return min group. min max group. max count group. count mean group. mean In 100 grouped frame. data2. groupbyfactor In 101 grouped. applygetstats . unstack Out101 data1 count 1. 23 0. 489 2. 956 1. 23 0. 489 2. 208 2. 208 3. 928 598 95 297 10 max min 3. 260383 0. 002051 2. 989741 1. 670835 0. 039521 3. 399312 2. 954439 0. 081822 3. 745356 1. 765640 0. 024750 1. 929776 These were equallength buckets to compute equalsize buckets based on sample quantiles use qcut.  Ill pass labelsFalse to just get quantile numbers.  Return quantile numbers grouping pd. qcutframe. data1 10 labelsFalse In 102 In 103 In 104 grouped frame. data2. groupbygrouping grouped. applygetstats. unstack Out104 count 100 100 100 100 100 100 100 100 100 100 WO ONDUNBRWNPRO NNNNNNWNN PB max 670835 628441 527939 260383 074345 184810 458842 954439 735527 377020 mean 049902 030989 067179 065713 111653 052130 021489 026459 103406 220122 3.  950098 ei 315555 ei 223506 3.  3.  064111 .  min 399312 925113 047939 989741 056990 745356 Groupwise Operations and Transformations 269 Example Filling Missing Values with Groupspecific Values When cleaning up missing data in some cases you will filter out data observations using dropna but in others you may want to impute fill in the NA values using fixed value or some value derived from the data.  fillna is the right tool to use for example here fill in NA values with the mean In 105 In 106 Seriesnp. random. randn6 s2 np. nan In 107 Out107 NaN 0. 125921 NaN 3.  0. 884475 NaN 0. 227290 ut 108 0. 261035 0. 125921 0. 261035 0. 884475 0. 261035 0. 227290 MWUPPWNP OOH 108 s. fillnas. mean Suppose you need the fill value to vary by group.  As you may guess you need only group the data and use app1y with function that calls fillna on each data chunk.  Here is some sample data on some US states divided into eastern and western states In 109 states Ohio New York Vermont Florida wcwmned Oregon Nevada California Idaho In 110 groupkey East West In 111 data Seriesnp. random. randn8 indexstates In 112 dataVermont Nevada Idaho np. nan In 113 data Out 113 Ohio 0. 922264 New York 2. 153545 Vermont NaN Florida 0. 375842 Oregon 0. 329939 Nevada NaN California 1. 105913 Idaho NaN In 114 data. groupbygroupkey. mean Out114 270 Chapter Data Aggregation and Group Operations East 0. 535707 West 0. 717926 We can fill the NA values using the group means like so In 115 fillmean lambda g. fillnag. mean In 116 data. groupbygroupkey. applyfillmean Out 116 Ohio 0. 922264 New York 2. 153545 Vermont 0. 535707 Florida 0. 375842 Oregon 0. 329939 Nevada 0. 717926 California 1. 105913 Idaho 0. 717926 In another case you might have predefined fill values in your code that vary by group.  Since the groups have name attribute set internally we can use that In 117 fillvalues East 0. 5 West In 118 fillfunc lambda g. fillnafillvaluesg. name In 119 data. groupbygroupkey. applyfillfunc Out119 Ohio 0. 922264 New York 2. 153545 Vermont 0. 500000 Florida 0. 375842 Oregon 0. 329939 Nevada 1. 000000 California 1. 105913 Idaho 1. 000000 Example Random Sampling and Permutation Suppose you wanted to draw random sample with or without replacement from large dataset for Monte Carlo simulation purposes or some other application.  There are anumber of ways to perform the draws some are much more efficient than others.  One way is to select the first elements of np. random. permutationN where is the size of your complete dataset and the desired sample size.  As more fun example heres way to construct deck of Englishstyle playing cards Hearts Spades Clubs Diamonds suits card val range1 11 10 basenames range2 11 cards for suit in cards. extendstrnum suit for num in basenames deck Seriescardval indexcards Groupwise Operations and Transformations 271 So now we have Series of length 52 whose index contains card names and values are the ones used in blackjack and other games to keep things simple just let the ace be In 121 deck13 Out121 AH 2H 3H 4H 5H 6H 7H 8H 9H 10H 10 JH 10 KH 10 QH 10 Now based on what said above drawing hand of cards from the desk could be written as In 122 def drawdeck n5 marry return deck. takenp. random. permutationlendeckn drawdeck Suppose you wanted two random cards from each suit.  Because the suit is the last character of each card name we can group based on this and use apply In 124 getsuit lambda card card1 last letter is suit In 125 deck. groupbygetsuit. applydraw n2 Out 125 Cc 2c 3C KD 10 8D KH 10 3H 28 45 alternatively In 126 deck. groupbygetsuit group keysFalse. applydraw n2 Out 126 KC 10 JC 10 AD 272 Chapter9 Data Aggregation and Group Operations 5D 5H 6H iS KS ON OUMN BR Example Group Weighted Average and Correlation Under the splitapplycombine paradigm of groupby operations between columns in DataFrame or two Series such group weighted average become routine affair.  As an example take this dataset containing group keys values and some weights In 127 df DataFramecategory ugiea data np. random. randn8 were st weights np. random. rand8 In 128 df Out 128 category data weights 1. 561587 0. 957515 1. 219984 0. 347267 0. 482239 0. 581362 0. 315667 0. 217091 0. 047852 0. 894406 0. 454145 0. 918564 0. 556774 0. 277825 0. 253321 0. 955905 The group weighted average by category would then be In 129 grouped df. groupbycategory In 130 getwavg lambda np. averagegdata weightsg weights In 131 grouped. applygetwavg Out 131 category 0. 811643 0. 122262 As less trivial example consider data set from Yahoo Finance containing end of day prices for few stocks and the SP 500 index the SPX ticker In 132 closepx pd. readcsvcho9stockpx. csv parsedatesTrue indexcol0 In 133 closepx Out 133 class pandas. core. frame. DataFrame DatetimeIndex 2214 entries 20030102 00 to 20111014 00 Data columns AAPL 2214 nonnull values MSFT 2214 nonnull values XOM 2214 nonnull values SPX 2214 nonnull values dtypes float644 Groupwise Operations and Transformations 273 In 134 close px4 Out 134 AAPL MSFT XOM SPX 20111011 400. 29 27. 00 76. 27 1195. 54 20111012 402. 19 26. 96 77. 16 1207. 25 20111013 408. 43 27. 18 76. 37 1203. 66 20111014 422. 00 27. 27 78. 11 1224. 58 One task of interest might be to compute DataFrame consisting of the yearly corre lations of daily returns computed from percent changes with SPX.  Here is one way to do it In 135 rets closepx. pctchange . dropna In 136 spxcorr lambda x. corrwithxSPX In 137 byyear rets. groupbylambda x. year In 138 byyear. applyspxcorr Out 138 AAPL MSFT XOM SPX 2003 0. 541124 0. 745174 0. 661265 al 2004 0. 374283 0. 588531 0. 557742 al 2005 0. 467540 0. 562374 0. 631010 al 2006 0. 428267 0. 406126 0. 518514 al 2007 0. 508118 0. 658770 0. 786264 al 2008 0. 681434 0. 804626 0. 828303 2009 0. 707103 0. 654902 0. 797921 2010 0. 710105 0. 730118 0. 839057 al 2011 0. 691931 0. 800996 0. 859975 There is of course nothing to stop you from computing intercolumn correlations Annual correlation of Apple with Microsoft In 139 byyear. applylambda gAAPL. corrgMSFT Out 139 2003 0. 480868 2004 0. 259024 2005 0. 300093 2006 0. 161735 2007 0. 417738 2008 0. 611901 2009 0. 432738 2010 0. 571946 2011 0. 581987 Example Groupwise Linear Regression In the same vein as the previous example you can use groupby to perform more complex groupwise statistical analysis as long as the function returns pandas object or scalar value.  For example can define the following regress function using the statsmo dels econometrics library which executes an ordinary least squares OLS regression on each chunk of data 274 Chapter Data Aggregation and Group Operations import statsmodels. api as sm def regressdata yvar xvars datayvar dataxvars Xintercept 1.  result sm. OLSY X. fit return result. params Now to run yearly linear regression of AAPL on SPX returns execute In 141 byyear. applyregress AAPL SPX Out 141 2003 2004 2005 2006 2007 2008 2009 2010 2011 Pivot Tables and CrossTabulation CORCORRBRRBRER SPX 195406 363463 766415 645496 198761 968016 879103 052608 806605 intercept 0. 000710 004201 003246 000080 003438 0. 001110 0. 002954 0. 001261 0. 001514 0.  0.  0.  0.  pivot table is data summarization tool frequently found in spreadsheet programs and other data analysis software.  It aggregates table of data by one or more keys arranging the data in rectangle with some of the group keys along the rows and some along the columns.  Pivot tables in Python with pandas are made possible using the groupby facility described in this chapter combined with reshape operations utilizing hierarchical indexing.  DataFrame has pivottable method and additionally there is toplevel pandas. pivottable function.  In addition to providing convenience inter face to groupby pivottable also can add partial totals also known as margins.  Returning to the tipping data set suppose wanted to compute table of group means the default pivottable aggregation type arranged by sex and smoker on the rows In 142 tips. pivottablerowssex smoker Out 142 sex smoker Female No Yes Male No Yes size 2. 592593 2. 242424 2. 711340 2. 500000 tip 2. 773519 2. 931515 3. 113402 3. 051167 tippct total bill 0. 156921 0. 182150 0. 160669 0. 152771 18. 105185 17. 977879 19. 791237 22. 284500 This could have been easily produced using groupby.  Now suppose we want to aggre gate only tippct and size and additionally group by day.  Ill put smoker in the table columns and day in the rows In 143 tips. pivottable Out 143 tippct size rowssex day colssmoker Pivot Tables and CrossTabulation 275 tippct size smoker No Yes No Yes sex day Female Fri 0. 165296 0. 209129 2. 500000 2. 000000 Sat 0. 147993 0. 163817 2. 307692 2. 200000 Sun 0. 165710 0. 237075 3. 071429 2. 500000 Thur 0. 155971 0. 163073 2. 480000 2. 428571 Male Fri 0. 138005 0. 144730 2. 000000 2. 125000 Sat 0. 162132 0. 139067 2. 656250 2. 629630 Sun 0. 158291 0. 173964 2. 883721 2. 600000 Thur 0. 165706 0. 164417 2. 500000 2. 300000 This table could be augmented to include partial totals by passing marginsTrue.  This has the effect of adding A11 row and column labels with corresponding values being the group statistics for all the data within single tier.  In this below example the All values are means without taking into account smoker vs.  nonsmoker the All columns or any of the two levels of grouping on the rows the All row In 144 tips. pivottabletippct size rowssex day awe colssmoker marginsTrue Out144 size tippct smoker No Yes All No Yes All sex day Female Fri 2. 500000 2. 000000 2. 111111 0. 165296 0. 209129 0. 199388 Sat 2. 307692 2. 200000 2. 250000 0. 147993 0. 163817 0. 156470 Sun 3. 071429 2. 500000 2. 944444 0. 165710 0. 237075 0. 181569 Thur 2. 480000 2. 428571 2. 468750 0. 155971 0. 163073 0. 157525 Male Fri 2. 000000 2. 125000 2. 100000 0. 138005 0. 144730 0. 143385 Sat 2. 656250 2. 629630 2. 644068 0. 162132 0. 139067 0. 151577 Sun 2. 883721 2. 600000 2. 810345 0. 158291 0. 173964 0. 162344 Thur 2. 500000 2. 300000 2. 433333 0. 165706 0. 164417 0. 165276 All 2. 668874 2. 408602 2. 569672 0. 159328 0. 163196 0. 160803 To use different aggregation function pass it to aggfunc.  For example count or len will give you crosstabulation count or frequency of group sizes In 145 tips. pivottabletip pct rowssex smoker colsday eveteie aggfunclen marginsTrue Out145 day Fri Sat Sun Thur All sex smoker Female No 13 14 25 54 Yes 15 33 Male No 32 43 20 97 Yes 27 15 10 60 All 19 87 76 62 244 If some combinations are empty or otherwise NA you may wish to pass fillvalue In 146 tips. pivottablesize rowstime sex smoker mere ye colsday aggfuncsum fillvalue0 Out 146 day Fri Sat Sun Thur time sex smoker Dinner Female No 30 43 276 Chapter9 Data Aggregation and Group Operations Yes 33 10 Male No 85 124 Yes 12 ji.  39 Lunch Female No 60 Yes 17 Male No 50 Yes 23 See Table 92 for summary of pivottable methods.  Table 92.  pivottable options Functionname Description values Column name or names to aggregate.  By default aggregates all numeric columns rows Column names or other group keys to group on the rows of the resulting pivot table cols Column names or other group keys to group on the columns of the resulting pivot table aggfunc Aggregation function or list of functions mean by default.  Can be any function valid in groupby context fillvalue Replace missing values in result table margins Add rowcolumn subtotals and grand total False by default CrossTabulations Crosstab crosstabulation or crosstab for short is special case of pivot table that computes group frequencies.  Here is canonical example taken from the Wikipedia page on cross tabulation In 150 data Out 150 Sample Gender Handedness Female Righthanded Male Lefthanded Female Righthanded Male Righthanded Male Lefthanded Male Righthanded Female Righthanded Female Lefthanded Male Righthanded Female Righthanded WO CONAUBWNF OO CWO ON DU BWNPR BR As part of some survey analysis we might want to summarize this data by gender and handedness.  You could use pivottable to do this but the pandas. crosstab function is very convenient In 151 pd. crosstabdata. Gender data. Handedness marginsTrue Out151 Handedness Lefthanded Righthanded All Gender Female Male All Pivot Tables and CrossTabulation 277 The first two arguments to crosstab can each either be an array or Series or list of arrays.  As in the tips data In 152 pd. crosstabtips. time tips. day tips. smoker marginsTrue Out 152 smoker No Yes All time day Dinner Fri 12 Sat 45 42 87 Sun 57 19 76 Thur Lunch Fri Thur 44 17 61 All 151 93 244 Example 2012 Federal Election Commission Database The US Federal Election Commission publishes data on contributions to political cam paigns.  This includes contributor names occupation and employer address and con tribution amount.  An interesting dataset is from the 2012 US presidential election httpwww. fec. govdisclosurepPDownload. do.  As of this writing June 2012 the full dataset for all states is 150 megabyte CSV file P00000001ALL. csv which can be loaded with pandas. readcsv In 13 fec pd. readcsvcho9P00000001ALL. csv In 14 fec Out14 class pandas. core. frame. DataFrame Int64Index 1001731 entries to 1001730 Data columns cmteid 1001731 nonnull values candid 1001731 nonnull values candnm 1001731 nonnull values contbrnm 1001731 nonnull values contbrcity 1001716 nonnull values contbrst 1001727 nonnull values contbrzip 1001620 nonnull values contbremployer 994314 nonnull values contbroccupation 994433 nonnull values contbreceiptamt 1001731 nonnull values contbreceiptdt 1001731 nonnull values receiptdesc 14166 nonnull values memocd 92482 nonnull values memotext 97770 nonnull values formtp 1001731 nonnull values filenum 1001731 nonnull values dtypes float641 int641 object14 sample record in the DataFrame looks like this In 15 fec. ix123456 Out15 cmteid 00431445 278 Chapter9 Data Aggregation and Group Operations candid P80003338 candnm Obama Barack contbrnm ELLMAN IRA contbrcity TEMPE contbrst AZ contbrzip 852816719 contbremployer ARIZONA STATE UNIVERSITY contbroccupation PROFESSOR contbreceiptamt 50 contbreceiptdt 01DEC11 receiptdesc NaN memocd NaN memotext NaN formtp SA17A filenum 772372 Name 123456 You can probably think of many ways to start slicing and dicing this data to extract informative statistics about donors and patterns in the campaign contributions.  Ill spend the next several pages showing you number of different analyses that apply techniques you have learned about so far.  You can see that there are no political party affiliations in the data so this would be useful to add.  You can get list of all the unique political candidates using unique note that NumPy suppresses the quotes around the strings in the output In 16 uniquecands fec. candnm. unique In 17 uniquecands Out17 arrayBachmann Michelle Romney Mitt Obama Barack Roemer Charles E.  Buddy III Pawlenty Timothy Johnson Gary Earl Paul Ron Santorum Rick Cain Herman Gingrich Newt McCotter Thaddeus Huntsman Jon Perry Rick dtypeobject In 18 uniquecands2 Out18 Obama Barack An easy way to indicate party affiliation is using dict2 parties Bachmann Michelle Republican Cain Herman Republican Gingrich Newt Republican Huntsman Jon Republican Johnson Gary Earl Republican McCotter Thaddeus Republican Obama Barack Democrat Paul Ron Republican Pawlenty Timothy Republican Perry Rick Republican Roemer Charles E.  Buddy III Republican 2.  This makes the simplifying assumption that Gary Johnson is Republican even though he later became the Libertarian party candidate.  Example 2012 Federal Election Commission Database 279 Romney Mitt Republican Santorum Rick Republican Now using this mapping and the map method on Series objects you can compute an array of political parties from the candidate names In 20 fec. candnm12343461 Out20 123456 Obama Barack 123457 Obama Barack 123458 Obama Barack 123459 Obama Barack 123460 Obama Barack Name candnm In 21 fec. candnm12343461. mapparties Out21 123456 Democrat 123457 Democrat 123458 Democrat 123459 Democrat 123460 Democrat Name candnm Add it as column In 22 fecparty fec. candnm. mapparties In 23 fecparty. valuecounts Out 23 Democrat 593746 Republican 407985 couple of data preparation points.  First this data includes both contributions and refunds negative contribution amount In 24 fec. contbreceiptamt 0. valuecounts Out24 True 991475 False 10256 To simplify the analysis Ill restrict the data set to positive contributions In 25 fec fecfec. contbreceiptamt Since Barack Obama and Mitt Romney are the main two candidates Ill also prepare subset that just has contributions to their campaigns In 26 fecmrbo fecfec. candnm. isinObama Barack Romney Mitt Donation Statistics by Occupation and Employer Donations by occupation is another oftstudied statistic.  For example lawyers attor neys tend to donate more money to Democrats while business executives tend to donate more to Republicans.  You have no reason to believe me you can see for yourself in the data.  First the total number of donations by occupation is easy 280 Chapter Data Aggregation and Group Operations In 27 fec. contbroccupation. valuecounts10 Out 27 RETIRED 233990 INFORMATION REQUESTED 35107 ATTORNEY 34286 HOMEMAKER 29931 PHYSICIAN 23432 INFORMATION REQUESTED PER BEST EFFORTS 21138 ENGINEER 14334 TEACHER 13990 CONSULTANT 13273 PROFESSOR 12555 You will notice by looking at the occupations that many refer to the same basic job type or there are several variants of the same thing.  Here is code snippet illustrates technique for cleaning up few of them by mapping from one occupation to another note the trick of using dict. get to allow occupations with no mapping to pass through occmapping INFORMATION REQUESTED PER BEST EFFORTS NOT PROVIDED INFORMATION REQUESTED NOT PROVIDED INFORMATION REQUESTED BEST EFFORTS NOT PROVIDED C. E. 0.  CEO If no mapping provided return lambda occmapping. getx fec. contbroccupation fec. contbroccupation. mapf Pll also do the same thing for employers empmapping INFORMATION REQUESTED PER BEST EFFORTS NOT PROVIDED INFORMATION REQUESTED NOT PROVIDED SELF SELFEMPLOYED SELF EMPLOYED SELFEMPLOYED If no mapping provided return lambda empmapping. getx fec. contbremployer fec. contbremployer. mapf Now you can use pivottable to aggregate the data by party and occupation then filter down to the subset that donated at least million overall In 34 byoccupation fec. pivottablecontbreceiptamt meee rowscontbroccupation meee colsparty aggfuncsum In 35 over2mm by occupationbyoccupation. sum1 2000000 In 36 over2mm Out 36 party Democrat Republican contbroccupation Example 2012 Federal Election Commission Database 281 ATTORNEY 11141982. 97 7477194. 430000 CEO 2074974. 79 4211040. 520000 CONSULTANT 2459912. 71 2544725. 450000 ENGINEER 951525. 55 1818373. 700000 EXECUTIVE 1355161. 05 4138850. 090000 HOMEMAKER 4248875. 80 13634275. 780000 INVESTOR 884133. 00 2431768. 920000 LAWYER 3160478 . 87 391224. 320000 MANAGER 762883. 22 1444532. 370000 NOT PROVIDED 4866973. 96 20565473. 010000 OWNER 1001567. 36 2408286. 920000 PHYSICIAN 3735124. 94 3594320. 240000 PRESIDENT 1878509. 95 4720923. 760000 PROFESSOR 2165071. 08 296702 . 730000 REAL ESTATE 528902. 09 1625902. 250000 RETIRED 25305116. 38 23561244. 489999 SELFEMPLOYED 672393. 40 1640252. 540000 It can be easier to look at this data graphically as bar plot barh means horizontal bar plot see Figure 92 In 38 over2mm. plotkindbarh SELFEMPLOYED PHYSICIAN OWNER NOT PROVIDED MANAGER LAWYER bgp 25200 ch nena nena ne cee ne neat snc ne cece nese secncnesbesenesesesesnesssecees INVESTOR Vv party Mg Democrat HB Republican 0. 0 0. 5 1. 0 15 2. 0 25 3. 0 le7 Figure 92.  Total donations by party for top occupations You might be interested in the top donor occupations or top companies donating to Obama and Romney.  To do this you can group by candidate name and use variant of the top method from earlier in the chapter def gettopamountsgroup key n5 totals group. groupbykeycontbreceiptamt. sum Order totals by key in descending order return totals. orderascendingFalsen 282 Chapter Data Aggregation and Group Operations Then aggregated by occupation and employer In 40 grouped fecmrbo. groupbycandnm In 41 grouped. applygettopamounts contbroccupation n7 Out 41 candnm contbroccupation Obama Barack RETIRED 25305116. 38 ATTORNEY 11141982. 97 NOT PROVIDED 4866973 . 96 HOMEMAKER 4248875 . 80 PHYSICIAN 3735124. 94 LAWYER 3160478 . 87 CONSULTANT 2459912. 71 Romney Mitt RETIRED 11508473. 59 NOT PROVIDED 11396894. 84 HOMEMAKER 8147446. 22 ATTORNEY 5364718 . 82 PRESIDENT 2491244. 89 EXECUTIVE 2300947 . 03 C. E. 0.  1968386. 11 Name contbreceiptamt In 42 grouped. applygettopamounts contbremployer n10 Out 42 candnm contbremployer Obama Barack RETIRED 22694358. 85 SELFEMPLOYED 18626807 . 16 NOT EMPLOYED 8586308.  70 NOT PROVIDED 5053480. 37 HOMEMAKER 2605408 . 54 STUDENT 318831. 45 VOLUNTEER 257104. 00 MICROSOFT 215585. 36 SIDLEY AUSTIN LLP 168254. 00 REFUSED 149516. 07 Romney Mitt NOT PROVIDED 12059527. 24 RETIRED 11506225. 71 HOMEMAKER 8147196. 22 SELFEMPLOYED 7414115 . 22 STUDENT 496490. 94 CREDIT SUISSE 281150. 00 MORGAN STANLEY 267266. 00 GOLDMAN SACH CO.  238250. 00 BARCLAYS CAPITAL 162750. 00 H. 1. G.  CAPITAL 139500. 00 Name contbreceiptamt Bucketing Donation Amounts useful way to analyze this data is to use the cut function to discretize the contributor amounts into buckets by contribution size In 43 bins np. array0 10 100 1000 10000 100000 1000000 10000000 Example 2012 Federal Election Commission Database 283 In 44 labels pd. cutfecmrbo. contbreceiptamt bins In 45 labels Out 45 Categoricalcontbreceiptamt array10 100 100 1000 100 1000 . . .  10 10 100 100 1000 dtypeobject Levels array0 10 10 100 100 1000 1000 10000 10000 100000 100000 1000000 1000000 10000000 dtypeobject We can then group the data for Obama and Romney by name and bin label to get histogram by donation size In 46 grouped fecmrbo. groupbycandnm labels In 47 grouped. size. unstack0 Out 47 candnm Obama Barack Romney Mitt contbreceiptamt 493 77 10 40070 3681 10 100 372280 31853 100 1000 153991 43357 1000 10000 22284 26186 10000 100000 100000 1000000 NaN 1000000 10000000 NaN This data shows that Obama has received significantly larger number of small don ations than Romney.  You can also sum the contribution amounts and normalize within buckets to visualize percentage of total donations of each size by candidate In 48 bucketsums grouped. contbreceiptamt. sum. unstack0 In 49 bucketsums Out 49 candnm Obama Barack Romney Mitt contbreceiptamt 318. 24 77. 00 10 337267. 62 29819. 66 10 100 20288981. 41 1987783 . 76 100 1000 54798531. 46 22363381. 69 1000 10000 51753705. 67 63942145. 42 10000 100000 59100. 00 12700. 00 100000 1000000 1490683 . 08 NaN 1000000 10000000 7148839. 76 NaN In 50 normedsums bucketsums. divbucketsums. sumaxis1 axis0 In 51 normedsums Out51 candnm Obama Barack Romney Mitt contbreceiptamt 0. 805182 0. 194818 10 0. 918767 0. 081233 10 100 0. 910769 0. 089231 284 Chapter9 Data Aggregation and Group Operations 100 1000 0. 710176 0. 289824 1000 10000 0. 447326 0. 552674 10000 100000 0. 823120 0. 176880 100000 1000000 1. 000000 NaN 1000000 10000000 1. 000000 NaN In 52 normedsums2. plotkindbarh stackedTrue excluded the two largest bins as these are not donations by individuals.  See Fig ure 93 for the resulting figure.  candnm 10000 100000 gag Obama Barack HH Romney Mitt 1000 10000 100 1000 UO 10 100 10 Figure 93.  Percentage of total donations received by candidates for each donation size There are of course many refinements and improvements of this analysis.  For example you could aggregate donations by donor name and zip code to adjust for donors who gave many small amounts versus one or more large donations.  encourage you to download it and explore it yourself.  Donation Statistics by State Aggregating the data by candidate and state is routine affair In 53 grouped fecmrbo. groupbycandnm contbrst In 54 totals grouped. contbreceiptamt. sum. unstack0. fillnao In 55 totals totalstotals. sum1 100000 In 56 totals10 Out 56 candnm Obama Barack Romney Mitt contbrst Example 2012 Federal Election Commission Database 285 AK 281840. 15 86204. 24 AL 543123. 48 527303. 51 AR 359247. 28 105556. 00 AZ 1506476. 98 1888436. 23 CA 23824984. 24 11237636. 60 co 2132429. 49 1506714. 12 cT 2068291. 26 3499475. 45 DC 4373538. 80 1025137. 50 DE 336669. 14 82712. 00 FL 7318178 . 58 8338458. 81 If you divide each row by the total contribution amount you get the relative percentage of total donations by state for each candidate In 57 percent totals. divtotals. sum1 axis0 In 58 percent10 Out 58 candnm Obama Barack Romney Mitt contbrst AK 0. 765778 0. 234222 AL 0. 507390 0. 492610 AR 0. 772902 0. 227098 AZ 0. 443745 0. 556255 CA 0. 679498 0. 320502 co 0. 585970 0. 414030 CT 0. 371476 0. 628524 DC 0. 810113 0. 189887 DE 0. 802776 0. 197224 FL 0. 467417 0. 532583 thought it would be interesting to look at this data plotted on map using ideas from Chapter 8.  After locating shape file for the state boundaries httpnationalatlas. gov atlasftp. htmlopenChapterschpbound and learning bit more about matplotlib and its basemap toolkit was aided by blog posting from Thomas Lecocq3 ended up with the following code for plotting these relative percentages from mpltoolkits. basemap import Basemap cm import hnumpy as np from matplotlib import rcParams from matplotlib. collections import LineCollection import matplotlib. pyplot as plt from shapelib import ShapeFile import dbflib obama percentObama Barack fig plt. figurefigsize12 12 ax fig. addaxes0. 10. 10. 80. 8 lllat 21 urlat 53 lllon 118 urlon 62 3.  httpwww. geophysique. be20110127matplotlibbasemaptutorial07shapefilesunleached 286 Chapter9 Data Aggregation and Group Operations Basemapaxax projectionstere lonourlon lllon latourlat lllat licrnrlatlllat urcrnrlaturlat llcrnrlonlllon urcrnrlonurlon resolution1 m. drawcoastlines m.  drawcountries shp ShapeFile. . statesstatesp020 dbf dbflib. open. . statesstatesp020 for npoly in rangeshp. info0 Draw colored polygons on the map shpsegs shpobject shp. readobjectnpoly verts shpobject. vertices rings lenverts for ring in rangerings lons lats zipvertsring mlons lats shpsegs. appendzipxy if ring shapedict dbf. readrecordnpoly name shapedictSTATE lines LineCollectionshpsegsantialiaseds1 statetocode dict e. g.  ALASKA AK omitted try per obamastatetocodename. upper except KeyError continue lines. setfacecolorsk lines. setalpha0. 75 per Shrink the percentage bit lines. setedgecolorsk lines. setlinewidth0. 3 ax. addcollectionlines plt. show See Figure 94 for the result.  Example 2012 Federal Election Commission Database 287 Figure 94.  US map aggregated donation statistics overlay darker means more Democratic 288 Chapter9 Data Aggregation and Group Operations CHAPTER 10 Time Series Time series data is an important form of structured data in many different fields such as finance economics ecology neuroscience or physics.  Anything that is observed or measured at many points in time forms time series.  Many time series are fixed fre quency which is to say that data points occur at regular intervals according to some rule such as every 15 seconds every minutes or once per month.  Time series can also be irregular without fixed unit or time or offset between units.  How you mark and refer to time series data depends on the application and you may have one of the following Timestamps specific instants in time Fixed periods such as the month January 2007 or the full year 2010 Intervals of time indicated by start and end timestamp.  Periods can be thought of as special cases of intervals Experiment or elapsed time each timestamp is measure of time relative to particular start time.  For example the diameter of cookie baking each second since being placed in the oven In this chapter am mainly concerned with time series in the first categories though many of the techniques can be applied to experimental time series where the index may be an integer or floating point number indicating elapsed time from the start of the experiment.  The simplest and most widely used kind of time series are those indexed by timestamp.  pandas provides standard set of time series tools and data algorithms.  With this you can efficiently work with very large time series and easily slice and dice aggregate and resample irregular and fixed frequency time series.  As you might guess many of these tools are especially useful for financial and economics applications but you could cer tainly use them to analyze server log data too.  289 Some of the features and code in particular period logic presented in this chapter were derived from the now defunct scikits. timeseries li Date and Time Data Types and Tools The Python standard library includes data types for date and time data as well as calendarrelated functionality.  The datetime time and calendar modules are the main places to start.  The datetime. datetime type or simply datetime is widely used In 317 from datetime import datetime In 318 now datetime. now In 319 now Out319 datetime. datetime2012 17 21 832092 In 320 now. year now. month now. day Out320 2012 datetime stores both the date and time down to the microsecond.  datetime. time delta represents the temporal difference between two datetime objects In 321 In 322 Out 322 In 323 Out 323 delta datetime2011 datetime2008 24 15 delta datetime. timedelta926 56700 In 324 delta. seconds Out324 56700 delta. days 926 You can add or subtract timedelta or multiple thereof to datetime object to yield new shifted object In 325 In 326 In 327 Out 327 In 328 Out 328 from datetime import timedelta start datetime2011 start timedelta12 datetime. datetime2011 19 start timedelta12 datetime. datetime2010 12 14 The data types in the datetime module are summarized in Table 101.  While this chap ter is mainly concerned with the data types in pandas and higher level time series ma nipulation you will undoubtedly encounter the datetimebased types in many other places in Python the wild.  290 Chapter 10 Time Series Table 101.  Types in datetime module Type Description date Store calendar date year month day using the Gregorian calendar.  time Store time of day as hours minutes seconds and microseconds datetime Stores both date and time timedelta Represents the difference between two datetime values as days seconds and micro seconds Converting between string and datetime datetime objects and pandas Timestamp objects which Ill introduce later can be for matted as strings using str or the strftime method passing format specification In 329 stamp datetime2011 In 330 strstamp In 331 stamp. strftimeYmd Out330 20110103 00 Out 331 20110103 See Table 102 for complete list of the format codes.  These same format codes can be used to convert strings to dates using datetime.  strptime In 332 value 20110103 In 333 datetime. strptimevalue Ymd Out333 datetime. datetime2011 In 334 datestrs 762011 862011 In 335 datetime. strptimex mdY for in datestrs Out335 datetime. datetime2011 datetime. datetime2011 datetime. strptime is the best way to parse date with known format.  However it can be bit annoying to have to write format spec each time especially for common date formats.  In this case you can use the parser. parse method in the third party dateutil package In 336 from dateutil. parser import parse In 337 parse20110103 Out337 datetime. datetime2011 dateutil is capable of parsing almost any humanintelligible date representation In 338 parseJan 31 1997 PM Out 338 datetime. datetime1997 31 22 45 In international locales day appearing before month is very common so you can pass dayfirstTrue to indicate this In 339 parse6122011 dayfirstTrue Out339 datetime. datetime2011 12 Date and Time Data Types and Tools 291 pandas is generally oriented toward working with arrays of dates whether used as an axis index or column in DataFrame.  The todatetime method parses many different kinds of date representations.  Standard date formats like ISO8601 can be parsed very qui Ita NaT ckly.  In 340 datestrs Out340 762011 862011 In 341 pd. todatetimedatestrs Out 341 class pandas. tseries. index. DatetimeIndex 20110706 00 20110806 00 Length Freq None Timezone None lso handles values that should be considered missing None empty string etc.  In 342 idx pd. todatetimedatestrs None In 343 idx Out 343 class pandas. tseries. index. DatetimeIndex 20110706 00 . . .  NaT Length Freq None Timezone None In 344 idx2 Out344 NaT In 345 pd. isnullidx Out345 arrayFalse False True dtypebool Not Time is pandass NA value for timestamp data.  nize some strings as dates that you might prefer that it didnt like 42 will be parsed as the year 2042 with todays calendar date.  dateutil. parser is useful but not perfect tool.  Notably it will recog Table 102.  Datetime format specification ISO C89 compatible Type Description 4digit year ay 2digit year 2digit month 01 12 2digit day 01 31 Hour 24hour clock 00 23 Hour 12hour clock 01 12 MI 2digit minute 00 59 Second 00 61 seconds 60 61 account for leap seconds Weekday as integer Sunday 292 Chapter 10 Time Series Type Description aU Week number of the year 00 53.  Sunday is considered the first day of the week and days before the first Sunday of the year are week 0.  ZW Week number of the year 00 53.  Monday is considered the first day of the week and days before the first Monday of the year are week 0.  UTC time zone offset as HHMM or HHMM empty if time zone naive Shortcut for md for example 2012418 Shortcut for 4mdy for example 041812 datetime objects also have number of localespecific formatting options for systems in other countries or languages.  For example the abbreviated month names will be different on German or French systems compared with English systems.  Table 103.  Localespecific date formatting Type Description wa Abbreviated weekday name aN Full weekday name Abbreviated month name 4B Full month name Full date and time for example Tue 01 May 2012 57 PM zp Locale equivalent of AM or PM mx Localeappropriate formatted date e. g.  in US May 2012 yields 05012012 Localeappropriate time e. g.  12 PM Time Series Basics The most basic kind of time series object in pandas is Series indexed by timestamps which is often represented external to pandas as Python strings or datetime objects In 346 from datetime import datetime In 347 dates datetime2011 datetime2011 datetime2011 ore datetime2011 datetime2011 10 datetime2011 12 In 348 ts Seriesnp. random. randn6 indexdates In 349 ts Out 349 20110102 0. 690002 20110105 1. 001543 20110107 0. 503087 20110108 0. 622274 Time Series Basics 293 20110110 0. 921169 20110112 0. 726213 Under the hood these datetime objects have been put in DatetimeIndex and the variable ts is now of type TimeSeries In 350 typets Out350 pandas. core. series. TimeSeries In 351 ts. index Out 351 class pandas. tseries. index. DatetimeIndex 20110102 00 . . .  20110112 00 Length Freq None Timezone None Va Its not necessary to use the TimeSeries constructor explicitly when 43 creating Series with DatetimeIndex pandas knows that the object is ja time series.  Like other Series arithmetic operations between differentlyindexed time series auto matically align on the dates In 352 ts ts2 Out 352 20110102 1. 380004 20110105 NaN 20110107 1. 006175 20110108 NaN 20110110 1. 842337 20110112 NaN pandas stores timestamps using NumPys datetime64 data type at the nanosecond res olution In 353 ts. index. dtype Out353 dtypedatetime64ns Scalar values from DatetimeIndex are pandas Timestamp objects In 354 stamp ts. indexo In 355 stamp Out355 Timestamp 20110102 00 Timestamp can be substituted anywhere you would use datetime object.  Addition ally it can store frequency information if any and understands how to do time zone conversions and other kinds of manipulations.  More on both of these things later.  Indexing Selection Subsetting TimeSeries is subclass of Series and thus behaves in the same way with regard to indexing and selecting data based on label 294 Chapter 10 Time Series In 356 stamp ts. index2 In 357 tsstamp Out357 0. 50308739136034464 As convenience you can also pass string that is interpretable as date In 358 ts1102011 Out 358 0. 92116860801301081 In 359 ts20110110 Out 359 0. 92116860801301081 For longer time series year or only year and month can be passed to easily select slices of data In 360 longer ts In 361 longer ts Out 361 20000101 20000102 20000103 20000104 20020923 20020924 20020925 20020926 0. 222896 051316 1. 157719 0. 816707 0. 395813 0. 180737 1. 337508 0. 416584 Freq Length 1000 In 362 longerts2001 Out 362 20010101 20010102 20010103 20010104 20011228 20011229 20011230 20011231 1. 499503 0. 545154 0. 400823 1. 946230 1. 568139 0. 900887 0. 652346 0. 871600 Freq Length 365 Series np. random. randn1000 indexpd. daterange112000 periods1000 Out 363 20010501 20010502 20010503 20010504 20010528 20010529 20010530 20010531 1.  0.  In 363 longerts200105 662014 189203 093597 539164 683066 950313 400710 126072 Freq Length 31 Slicing with dates works just like with regular Series In 364 tsdatetime2011 Out 364 20110107 20110108 20110110 20110112 0. 503087 0. 622274 0. 921169 0. 726213 Because most time series data is ordered chronologically you can slice with timestamps not contained in time series to perform range query In 365 ts Out 365 20110102 0. 690002 In 366 ts1620111112011 Out 366 20110107 0. 503087 Time Series Basics 295 20110105 1. 001543 20110108 0. 622274 20110107 0. 503087 20110110 0. 921169 20110108 0. 622274 20110110 0. 921169 20110112 0. 726213 As before you can pass either string date datetime or Timestamp.  Remember that slicing in this manner produces views on the source time series just like slicing NumPy arrays.  There is an equivalent instance method truncate which slices TimeSeries be tween two dates In 367 ts. truncateafter192011 Out 367 20110102 0. 690002 20110105 1. 001543 20110107 0. 503087 20110108 0. 622274 All of the above holds true for DataFrame as well indexing on its rows In 368 dates pd. daterange112000 periods100 freqWWED In 369 long df DataFramenp. random. randn100 mae indexdates satay 22 columnsColorado Texas New York Ohio In 370 long df. ix52001 Out 370 Colorado Texas New York Ohio 20010502 0. 943479 0. 349366 0. 530412 0. 508724 20010509 0. 230643 0. 065569 0. 248717 0. 587136 20010516 1. 022324 1. 060661 0. 954768 0. 511824 20010523 1. 387680 0. 767902 1. 164490 1. 527070 20010530 0. 287542 0. 715359 0. 345805 0. 470886 Time Series with Duplicate Indices In some applications there may be multiple data observations falling on particular timestamp.  Here is an example In 371 dates pd. DatetimeIndex112000 122000 122000 122000 wee es 132000 In 372 dupts Seriesnp. arange5 indexdates In 373 dupts Out 373 20000101 20000102 20000102 20000102 20000103 WNrR OO We can tell that the index is not unique by checking its isunique property 296 Chapter 10 Time Series In 374 dupts. index. is unique Out374 False Indexing into this time series will now either produce scalar values or slices depending on whether timestamp is duplicated In 375 dupts132000 not duplicated Out375 In 376 dup ts122000 duplicated Out 376 20000102 20000102 20000102 Suppose you wanted to aggregate the data having nonunique timestamps.  One way to do this is to use groupby and pass levelo the only level of indexing In 377 grouped dup ts. groupbylevel0 In 378 grouped. mean In 379 grouped. count Out 378 Out 379 20000101 20000101 1.  20000102 20000102 20000103 20000103 1.  Date Ranges Frequencies and Shifting Generic time series in pandas are assumed to be irregular that is they have no fixed frequency.  For many applications this is sufficient.  However its often desirable to work relative to fixed frequency such as daily monthly or every 15 minutes even if that means introducing missing values into time series.  Fortunately pandas has full suite of standard time series frequencies and tools for resampling inferring frequencies and generating fixed frequency date ranges.  For example in the example time series con verting it to be fixed daily frequency can be accomplished by calling resample In 380 ts In 381 ts. resampleD Out 380 Out 381 20110102 0. 690002 20110102 0. 690002 20110105 1. 001543 20110103 NaN 20110107 0. 503087 20110104 NaN 20110108 0. 622274 20110105 1. 001543 20110110 0. 921169 20110106 NaN 20110112 0. 726213 20110107 0. 503087 20110108 0. 622274 20110109 NaN 20110110 0. 921169 20110111 NaN 20110112 0. 726213 Freq Conversion between frequencies or resampling is big enough topic to have its own section later.  Here Ill show you how to use the base frequencies and multiples thereof.  Date Ranges Frequencies and Shifting 297 Generating Date Ranges While used it previously without explanation you may have guessed that pan das. daterange is responsible for generating DatetimeIndex with an indicated length according to particular frequency In 382 index pd. daterange412012 612012 In 383 index Out 383 class pandas. tseries. index. DatetimeIndex 20120401 00 . . .  20120601 00 Length 62 Freq Timezone None By default daterange generates daily timestamps.  If you pass only start or end date you must pass number of periods to generate In 384 pd. daterangestart412012 periods20 Out 384 class pandas. tseries. index. DatetimeIndex 20120401 00 . . .  20120420 00 Length 20 Freq Timezone None In 385 pd. daterangeend612012 periods20 Out 385 class pandas. tseries. index. DatetimeIndex 20120513 00 . . .  20120601 00 Length 20 Freq Timezone None The start and end dates define strict boundaries for the generated date index.  For ex ample if you wanted date index containing the last business day of each month you would pass the BM frequency business end of month and only dates falling on or inside the date interval will be included In 386 pd. daterange112000 1212000 freqBM Out 386 class pandas. tseries. index. DatetimeIndex 20000131 00 . . .  20001130 00 Length 11 Freq BM Timezone None daterange by default preserves the time if any of the start or end timestamp In 387 pd. daterange522012 31 periods5 Out 387 class pandas. tseries. index. DatetimeIndex 20120502 31 . . .  20120506 31 Length Freq Timezone None Sometimes you will have start or end dates with time information but want to generate set of timestamps normalized to midnight as convention.  To do this there is normalize option In 388 pd. daterange522012 31 periods5 normalizeTrue Out 388 class pandas. tseries. index. DatetimeIndex 298 Chapter 10 Time Series 20120502 00 . . .  20120506 00 Length Freq Timezone None Frequencies and Date Offsets Frequencies in pandas are composed of base frequency and multiplier.  Base fre quencies are typically referred to by string alias like for monthly or for hourly.  For each base frequency there is an object defined generally referred to as date off set.  For example hourly frequency can be represented with the Hour class In 389 from pandas. tseries. offsets import Hour Minute In 390 hour Hour In 391 hour Out391 Hour You can define multiple of an offset by passing an integer In 392 fourhours Hour4 In 393 fourhours Out 393 Hours In most applications you would never need to explicitly create one of these objects instead using string alias like or 4H.  Putting an integer before the base frequency creates multiple In 394 pd. daterange112000 132000 freq4h Out 394 class pandas. tseries. index. DatetimeIndex 20000101 00 . . .  20000103 00 Length 18 Freq 4H Timezone None Many offsets can be combined together by addition In 395 Hour2 Minute30 Out395 150 Minutes Similarly you can pass frequency strings like 2h30min which will effectively be parsed to the same expression In 396 pd. daterange112000 periods10 freq1h30min Out 396 class pandas. tseries. index. DatetimeIndex 20000101 00 . . .  20000101 00 Length 10 Freq 90T Timezone None Some frequencies describe points in time that are not evenly spaced.  For example calendar month end and BM last businessweekday of month depend on the number of days in month and in the latter case whether the month ends ona weekend or not.  For lack of better term call these anchored offsets.  See Table 104 fora listing of frequency codes and date offset classes available in pandas.  Date Ranges Frequencies and Shifting 299 Table 104.  Base Time Series Frequencies Alias Tormin Lorms BM MS BMS WMON WTUE . . .  WOM1MON WOM2MON . . .  QJAN QFEB . . .  BOJAN BOFEB . . .  QSJAN QSFEB . . .  BOSJAN BOSFEB . . .  AJAN AFEB . . .  BAJAN BAFEB . . .  ASJAN ASFEB . . .  BASJAN BASFEB . . .  Offset Type Day BusinessDay Hour Minute Second Milli Micro MonthEnd BusinessMonthEnd MonthBegin BusinessMonthBegin Week WeekOfMonth QuarterEnd BusinessQuarterEnd QuarterBegin BusinessQuarterBegin YearEnd BusinessYearEnd YearBegin BusinessYearBegin Users can define their own custom frequency classes to provide date logic not available in pandas though the full details of that are outside 4S the scope of this book.  Description Calendar daily Business daily Hourly Minutely Secondly Millisecond 11000th of second Microsecond 11000000th of second Last calendar day of month Last business day weekday of month First calendar day of month First weekday of month Weekly on given day of week MON TUE WED THU FRI SAT or SUN.  Generate weekly dates in the first second third or fourth week of the month.  For example WOM 3FRI for the 3rd Friday of each month.  Quarterly dates anchored on last calendar day of each month for year ending in indicated month JAN FEB MAR APR MAY JUN JUL AUG SEP OCT NOV or DEC.  Quarterly dates anchored on last weekday day of each month for year ending in indicated month Quarterly dates anchored on first calendar day of each month for year ending in indicated month Quarterly dates anchored on first weekday day of each month for year ending in indicated month Annual dates anchored on last calendar day of given month JAN FEB MAR APR MAY JUN JUL AUG SEP OCT NOV or DEC.  Annual dates anchored on last weekday of given month Annual dates anchored on first day of given month Annual dates anchored on first weekday of given month 300 Chapter 10 Time Series Week of month dates One useful frequency class is week of month starting with WOM.  This enables you to get dates like the third Friday of each month In 397 rng pd. daterange112012 912012 freqWOM3FRI In 398 listxrng Out 398 Timestamp 20120120 00 Timestamp 20120217 00 Timestamp 20120316 00 Timestamp 20120420 00 Timestamp 20120518 00 Timestamp 20120615 00 Timestamp 20120720 00 Timestamp 20120817 00 Traders of US equity options will recognize these dates as the standard dates of monthly expiry.  Shifting Leading and Lagging Data Shifting refers to moving data backward and forward through time.  Both Series and DataFrame have shift method for doing naive shifts forward or backward leaving the index unmodified In 399 ts Seriesnp. random. randn4 aaa indexpd. daterange112000 periods4 freqM In 400 ts In 401 ts. shift2 In 402 ts. shift2 Out 400 Out401 Out 402 20000131 0. 575283 20000131 NaN 20000131 1. 814582 20000229 0. 304205 20000229 NaN 20000229 1. 634858 20000331 1. 814582 20000331 0. 575283 20000331 NaN 20000430 1. 634858 20000430 0. 304205 20000430 NaN Freq Freq Freq common use of shift is computing percent changes in time series or multiple time series as DataFrame columns.  This is expressed as ts ts. shift1 Because naive shifts leave the index unmodified some data is discarded.  Thus if the frequency is known it can be passed to shift to advance the timestamps instead of simply the data In 403 ts. shift2 freqM Out 403 20000331 0. 575283 20000430 0. 304205 20000531 1. 814582 20000630 1. 634858 Freq Date Ranges Frequencies and Shifting 301 Other frequencies can be passed too giving you lot of flexibility in how to lead and lag the data In 404 ts. shift3 freqD In 405 ts. shift1 freq3D Out 404 Out405 20000203 0. 575283 20000203 0. 575283 20000303 0. 304205 20000303 0. 304205 20000403 1. 814582 20000403 1. 814582 20000503 1. 634858 20000503 1. 634858 In 406 ts. shift1 freq90T Out 406 20000131 00 0. 575283 20000229 00 0. 304205 20000331 00 1. 814582 20000430 00 1. 634858 Shifting dates with offsets The pandas date offsets can also be used with datetime or Timestamp objects In 407 In 408 In 409 Out 409 from pandas. tseries. offsets import Day MonthEnd now datetime2011 11 17 now Day datetime. datetime2011 11 20 If you add an anchored offset like MonthEnd the first increment will roll forward date to the next date according to the frequency rule In 410 Out 410 In 411 Out 411 now MonthEnd datetime. datetime2011 11 30 now MonthEnd2 datetime. datetime2011 12 31 Anchored offsets can explicitly roll dates forward or backward using their rollfor ward and roll In 412 back methods respectively offset MonthEnd offset. rollforwardnow datetime. datetime2011 11 30 offset. rollbacknow datetime. datetime2011 10 31 clever use of date offsets is to use these methods with groupby In 415 In 416 Out 416 20000131 ts Seriesnp. random. randn20 indexpd. daterange1152000 periods20 freq4d ts. groupbyoffset. rollforward . mean 0. 448874 302 Chapter 10 Time Series 20000229 0. 683663 20000331 0. 251920 Ofcourse an easier and faster way to do this is using resample much more on this later In 417 ts. resampleM howmean Out 417 20000131 0. 448874 20000229 0. 683663 20000331 0. 251920 Freq Time Zone Handling Working with time zones is generally considered one of the most unpleasant parts of time series manipulation.  In particular daylight savings time DST transitions are common source of complication.  As such many time series users choose to work with time series in coordinated universal time or UTC which is the successor to Greenwich Mean Time and is the current international standard.  Time zones are expressed as offsets from UTC for example New York is four hours behind UTC during daylight savings time and hours the rest of the year.  In Python time zone information comes from the 3rd party pytz library which exposes the Olson database compilation of world time zone information.  This is especially important for historical data because the DST transition dates and even UTC offsets have been changed numerous times depending on the whims of local governments.  In the United Statesthe DST transition times have been changed many times since 1900 For detailed information about pytz library youll need to look at that librarys docu mentation.  As far as this book is concerned pandas wraps pytzs functionality so you can ignore its API outside of the time zone names.  Time zone names can be found interactively and in the docs In 418 import pytz In 419 pytz. commontimezones5 Out419 USEastern USHawaii USMountain USPacific UTC To get time zone object from pytz use pytz. timezone In 420 tz pytz. timezoneUSEastern In 421 tz Out421 DstTzInfo USEastern EST1 day 00 STD Methods in pandas will accept either time zone names or these objects.  recommend just using the names.  Time Zone Handling 303 Localization and Conversion By default time series in pandas are time zone naive.  Consider the following time series rng pd. daterange392012 930 periods6 freqD ts Seriesnp. random. randnlenrng indexrng The indexs tz field is None In 423 printts. index. tz None Date ranges can be generated with time zone set In 424 pd. daterange392012 930 periods10 freqD tzUTC Out 424 class pandas. tseries. index. DatetimeIndex 20120309 00 . . .  20120318 00 Length 10 Freq Timezone UTC Conversion from naive to localized is handled by the tzlocalize method In 425 tsutc ts. tzlocalizeUTC In 426 tsutc Out 426 20120309 00 0. 414615 20120310 00 0. 427185 20120311 00 19172557 20120312 00 0. 351572 20120313 00 1. 454593 20120314 00 2. 043319 Freq In 427 tsutc. index Out 427 class pandas. tseries. index. DatetimeIndex 20120309 00 . . .  20120314 00 Length Freq Timezone UTC Once time series has been localized to particular time zone it can be converted to another time zone using tzconvert In 428 tsutc. tzconvertUSEastern Out 428 20120309 00 0. 414615 20120310 00 0. 427185 20120311 00 1. 172557 20120312 00 0. 351572 20120313 00 1. 454593 20120314 00 2. 043319 Freq In the case of the above time series which straddles DST transition in the USEastern time zone we could localize to EST and convert to say UTC or Berlin time In 429 tseastern ts. tzlocalizeUSEastern 304 Chapter 10 Time Series In 430 tseastern. tzconvertUTC Out 430 20120309 00 0. 414615 20120310 00 0. 427185 20120311 00 1. 172557 20120312 00 0. 351572 20120313 00 1. 454593 20120314 00 2. 043319 Freq In 431 tseastern. tzconvertEuropeBerlin Out 431 20120309 00 0. 414615 20120310 00 0. 427185 20120311 00 1. 172557 20120312 00 0. 351572 20120313 00 1. 454593 20120314 00 2. 043319 Freq tzlocalize and tzconvert are also instance methods on DatetimeIndex In 432 ts. index. tzlocalizeAsiaShanghai Out 432 class pandas. tseries. index. DatetimeIndex 20120309 00 . . .  20120314 00 Length Freq Timezone AsiaShanghai Localizing naive timestamps also checks for ambiguous or nonexistent ta times around daylight savings time transitions.  Operations with Time Zoneaware Timestamp Objects Similar to time series and date ranges individual Timestamp objects similarly can be localized from naive to time zoneaware and converted from one time zone to another In 433 stamp pd. Timestamp20110312 In 434 stamputc stamp. tzlocalizeutc In 435 stamputc. tzconvertUSEastern Out435 Timestamp 20110311 000500 EST tzUSEastern You can also pass time zone when creating the Timestamp In 436 stampmoscow pd. Timestamp20110312 tzEuropeMoscow In 437 stampmoscow Out437 Timestamp 20110312 000300 MSK tzEuropeMoscow Time zoneaware Timestamp objects internally store UTC timestamp value as nano seconds since the UNIX epoch January 1970 this UTC value is invariant between time zone conversions Time Zone Handling 305 In 438 stamputc. value Out438 1299902400000000000 In 439 stamputc. tzconvertUSEastern. value Out 439 1299902400000000000 When performing time arithmetic using pandass DateOffset objects daylight savings time transitions are respected where possible 30 minutes before DST transition In 440 from pandas. tseries. offsets import Hour In 441 stamp pd. Timestamp20120312 tzUSEastern In 442 stamp Out442 Timestamp 20120312 000400 EDT tzUSEastern In 443 stamp Hour Out443 Timestamp 20120312 000400 EDT tzUSEastern 90 minutes before DST transition In 444 stamp pd. Timestamp20121104 tzUSEastern In 445 stamp Out445 Timestamp 20121104 000400 EDT tzUSEastern In 446 stamp Hour Out446 Timestamp 20121104 000500 EST tzUSEastern Operations between Different Time Zones If two time series with different time zones are combined the result will be UTC.  Since the timestamps are stored under the hood in UTC this is straightforward operation and requires no conversion to happen In 447 rng pd. daterange372012 930 periods10 freqB In 448 ts Seriesnp. random. randnlenrng indexrng In 449 ts Out 449 20120307 00 1. 749309 20120308 00 0. 387235 20120309 00 0. 208074 20120312 00 1. 221957 20120313 00 0. 067460 20120314 00 0. 229005 20120315 00 0. 576234 20120316 00 0. 816895 20120319 00 0. 772192 20120320 00 1. 333576 Freq In 450 tsa ts7. tzlocalizeEuropeLondon 306 Chapter 10 Time Series In 451 ts2 ts12. tzconvertEuropeMoscow In 452 result ts1 ts2 In 453 result. index Out 453 class pandas. tseries. index. DatetimeIndex 20120307 00 . . .  20120315 00 Length Freq Timezone UTC Periods and Period Arithmetic Periods represent time spans like days months quarters or years.  The Period class represents this data type requiring string or integer and frequency from the above table In 454 pd. Period2007 freqADEC In 455 Out455 Period2007 ADEC In this case the Period object represents the full timespan from January 2007 to December 31 2007 inclusive.  Conveniently adding and subtracting integers from pe riods has the effect of shifting by their frequency In 456 In 457 Out456 Period2012 ADEC Out457 Period2005 ADEC If two periods have the same frequency their difference is the number of units between them In 458 pd. Period2014 freqADEC Out458 Regular ranges of periods can be constructed using the periodrange function In 459 rng pd. periodrange112000 6302000 freqM In 460 rng Out 460 class pandas. tseries. period. PeriodIndex freq 200001 . . .  200006 length The PeriodIndex class stores sequence of periods and can serve as an axis index in any pandas data structure In 461 Seriesnp. random. randn6 indexrng Out 461 200001 0. 309119 200002 0. 028558 200003 1. 129605 200004 0. 374173 200005 0. 011401 Periods and Period Arithmetic 307 200006 0. 272924 Freq If you have an array of strings you can also appeal to the PeriodIndex class itself In 462 values 200103 200202 200301 In 463 index pd. PeriodIndexvalues freqQDEC In 464 index Out 464 class pandas. tseries. period. PeriodIndex freq QDEC 200103 . . .  200301 length Period Frequency Conversion Periods and PeriodIndex objects can be converted to another frequency using their asfreq method.  As an example suppose we had an annual period and wanted to convert it into monthly period either at the start or end of the year.  This is fairly straightfor ward In 465 pd. Period2007 freqADEC In 466 p. asfreqM howstart In 467 p. asfreqM howend Out466 Period200701 Out467 Period200712 You can think of Period2007 ADEC as being cursor pointing to span of time subdivided by monthly periods.  See Figure 101 for an illustration of this.  For fiscal year ending on month other than December the monthly subperiods belonging are different In 468 pd. Period2007 freqAJUN In 469 p. asfreqM start In 470 p. asfreqM end Out469 Period200607 Out470 Period200706 When converting from high to low frequency the superperiod will be determined de pending on where the subperiod belongs.  For example in AJUN frequency the month Aug2007 is actually part of the 2008 period In 471 pd. Period200708 In 472 p. asfreqAJUN Out472 Period2008 AJUN Whole PeriodIndex objects or TimeSeries can be similarly converted with the same semantics In 473 rng pd. periodrange2006 2009 freqADEC In 474 ts Seriesnp. random. randnlenrng indexrng In 475 ts 308 Chapter 10 Time Series Out475 2006 0. 601544 2007 0. 574265 2008 0. 194115 2009 0. 202225 Freq ADEC In 476 ts. asfreqM howstart In 477 ts. asfreqB howend Out 476 Out 477 200601 0. 601544 20061229 0. 601544 200701 0. 574265 20071231 0. 574265 200801 0. 194115 20081231 0. 194115 200901 0. 202225 20091231 0. 202225 Freq Freq Period201106 an tr ay Aen Se or ec Period2011 ADEC Figure 101.  Period frequency conversion illustration Quarterly Period Frequencies Quarterly data is standard in accounting finance and other fields.  Much quarterly data is reported relative to fiscal year end typically the last calendar or business day of one of the 12 months of the year.  As such the period 201204 has different meaning de pending on fiscal year end.  pandas supports all 12 possible quarterly frequencies as JAN through QDEC In 478 pd. Period201204 freqQJAN In 479 Out479 Period201204 QJAN In the case of fiscal year ending in January 201204 runs from November through Jan uary which you can check by converting to daily frequency.  See Figure 102 for an illustration In 480 p. asfreqD start In 481 p. asfreqD end Out480 Period20111101 Out481 Period20120131 Periods and Period Arithmetic 309 Thus its possible to do period arithmetic very easily for example to get the timestamp at 4PM on the 2nd to last business day of the quarter you could do In 482 p4pm p. asfreqB 1. asfreqT 16 60 In 483 p4pm Out483 Period20120130 In 484 p4pm. totimestamp Out 484 Timestamp 20120130 00 Year 2012 JAN FeB MAR APR MAY JUN JUL AUG seP oct Nov DEC QDEC QSEP QFEB 201204 201301 201302 201303 Figure 102.  Different quarterly frequency conventions Generating quarterly ranges works as you would expect using periodrange.  Arithmetic is identical too In 485 rng pd. periodrange201103 201204 freqQJAN In 486 ts Seriesnp. arangelenrng indexrng In 487 ts Out 487 201103 201104 201201 201202 201203 201204 Freq QJAN In 488 newrng rng. asfreqB 1. asfreqT 16 60 In 489 ts. index newrng. to timestamp In 490 ts Out 490 20101028 00 20110128 00 20110428 00 20110728 00 20111028 00 20120130 00 UWPWN PO 310 Chapter 10 Time Series Converting Timestamps to Periods and Back Series and DataFrame objects indexed by timestamps can be converted to periods using the toperiod method In 491 rng pd. daterange112000 periods3 freqM In 492 ts Seriesrandn3 indexrng In 493 pts ts. toperiod In 494 ts Out 494 20000131 0. 505124 20000229 2. 954439 20000331 2. 630247 Freq In 495 pts Out495 200001 0. 505124 200002 2. 954439 200003 2. 630247 Freq Since periods always refer to nonoverlapping timespans timestamp can only belong to single period for given frequency.  While the frequency of the new PeriodIndex is inferred from the timestamps by default you can specify any frequency you want.  There is also no problem with having duplicate periods in the result In 496 rng pd. daterange1292000 periods6 freqD In 497 ts2 Seriesrandn6 indexrng In 498 ts2. toperiodM Out 498 200001 0. 352453 200001 0. 477808 200001 0. 161594 200002 1. 686833 200002 0. 821965 200002 0. 667406 Freq To convert back to timestamps use totimestamp In 499 pts ts. toperiod In 500 pts Out 500 200001 0. 505124 200002 2. 954439 200003 2. 630247 Freq In 501 pts. totimestamphowend Out501 20000131 0. 505124 20000229 2. 954439 20000331 2. 630247 Freq Periods and Period Arithmetic 311 Creating PeriodIndex from Arrays Fixed frequency data sets are sometimes stored with timespan information spread across multiple columns.  For example in this macroeconomic data set the year and quarter are in different columns In 502 data pd. readcsvch08macrodata. csv In 503 data. year In 504 data. quarter Out 503 Out504 1959 1959 1959 1959 199 2008 199 200 2009 200 201 2009 201 202 2009 202 Name year Length 203 Name quarter Length 203 By passing these arrays to PeriodIndex with frequency they can be combined to form an index for the DataFrame In 505 index pd. PeriodIndexyeardata. year quarterdata. quarter freqQDEC In 506 index Out 506 class pandas. tseries. period. PeriodIndex freq QDEC 195901 . . .  200903 length 203 In 507 data. index index In 508 data. infl Out 508 195901 0. 00 195902 2. 34 195903 2. 74 195904 0. 27 200804 8. 79 200901 0. 94 200902 3. 37 200903 3. 56 Freq QDEC Name infl Length 203 Resampling and Frequency Conversion Resampling refers to the process of converting time series from one frequency to another.  Aggregating higher frequency data to lower frequency is called downsam pling while converting lower frequency to higher frequency is called upsampling.  Not 312 Chapter 10 Time Series all resampling falls into either of these categories for example converting WWED weekly on Wednesday to WFRI is neither upsampling nor downstampling.  pandas objects are equipped with resample method which is the workhorse function for all frequency conversion In 509 rng pd. daterange112000 periods100 freqD In 510 ts In 511 ts.  Out511 20000131 20000229 20000331 20000430 Freq In 512 ts.  Out 512 200001 200002 200003 200004 Freq ooooo Seriesrandnlenrng indexrng resampleM howmean 0. 170876 0. 165020 0. 095451 0. 363566 resampleM howmean kindperiod 170876 165020 095451 363566 resample is flexible and highperformance method that can be used to process very large time series.  Ill illustrate its semantics and use through series of examples.  Table 105.  Resample method arguments Argument Description freq String or DateOffset indicating desired resampled frequency e. g.  Smin or Sec ond15 howmean Function name or array function producing aggregated value for example mean ohlc np. max.  Defaults to mean.  Other common values first last median ohlc max min.  axis0 Axis to resample on default axis0 fi11methodNone How to interpolate when upsampling as in fi11 or bfil1.  By default does no closedright labelright loffsetNone limitNone interpolation.  In downsampling which end of each interval is closed inclusive right or left.  Defaults to right In downsampling how to label the aggregated result with the right or left bin edge.  For example the 930 to 935 5minute interval could be labeled 30 or 935.  Defaults to right or 935 in this example.  Time adjustment to the bin labels such as 1s Second1 to shift the aggregate labels one second earlier When forward or backward filling the maximum number of periods to fill Resampling and Frequency Conversion 313 Argument Description kindNone Aggregate to periods period or timestamps timestamp defaults to kind of index the time series has conventionNone When resampling periods the convention start or end for converting the low frequency period to high frequency.  Defaults to end Downsampling Aggregating data to regular lower frequency is pretty normal time series task.  The data youre aggregating doesnt need to be fixed frequently the desired frequency de fines bin edges that are used to slice the time series into pieces to aggregate.  For example to convert to monthly or BM the data need to be chopped up into one month intervals.  Each interval is said to be halfopen data point can only belong to one interval and the union of the intervals must make up the whole time frame.  There are couple things to think about when using resample to downsample data Which side of each interval is closed How to label each aggregated bin either with the start of the interval or the end To illustrate lets look at some oneminute data In 513 rng pd. daterange112000 periods12 freqT In 514 ts Seriesnp. arange12 indexrng In 515 ts Out515 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 20000101 00 Freq COON DURBPWNR OO Be Bp Suppose you wanted to aggregate this data into fiveminute chunks or bars by taking the sum of each group In 516 ts. resample5min howsum Out 516 20000101 00 20000101 00 45 20000101 00 40 20000101 00 11 Freq 5T 314 Chapter 10 Time Series The frequency you pass defines bin edges in fiveminute increments.  By default the right bin edge is inclusive so the value is included in the to inter val. 1 Passing closedleft changes the interval to be closed on the left In 517 ts. resample5min howsum closedleft Out517 20000101 00 10 20000101 00 35 20000101 00 21 Freq 5T As you can see the resulting time series is labeled by the timestamps from the right side of each bin.  By passing labelleft you can label them with the left bin edge In 518 ts. resample5min howsum closedleft labelleft Out 518 20000101 00 10 20000101 00 35 20000101 00 21 Freq 5T See Figure 103 for an illustration of minutely data being resampled to fiveminute.  closed tert OO 901 502 905 504 905 closedright 300 901 502 905 504 985 labelleft labelright Figure 103.  5minute resampling illustration of closed label conventions Lastly you might want to shift the result index by some amount say subtracting one second from the right edge to make it more clear which interval the timestamp refers to.  To do this pass string or date offset to loffset In 519 ts. resample5min howsum loffset1s Out 519 19991231 59 20000101 59 15 20000101 59 40 20000101 59 11 Freq 5T 1.  The choice of closedright labelright as the default might seem bit odd to some users.  In practice the choice is somewhat arbitrary for some target frequencies closedleft is preferable while for others closedright makes more sense.  The important thing is that you keep in mind exactly how you are segmenting the data.  Resampling and Frequency Conversion 315 This also could have been accomplished by calling the shift method on the result without the loffset.  OpenHighLowClose OHLC resampling In finance an ubiquitous way to aggregate time series is to compute four values for each bucket the first open last close maximum high and minimal low values.  By passing howohlc you will obtain DataFrame having columns containing these four aggregates which are efficiently computed in single sweep of the data In 520 ts. resample5min howohlc Out 520 open high low close 20000101 00 20000101 00 20000101 00 10 10 20000101 00 11 11 11 11 Resampling with GroupBy An alternate way to downsample is to use pandass groupby functionality.  For example you can group by month or weekday by passing function that accesses those fields on the time seriess index In 521 rng pd. daterange112000 periods100 freqD In 522 ts Seriesnp. arange100 indexrng In 523 ts. groupbylambda x. month. mean Out 523 15 45 75 95 524 ts. groupbylambda x. weekday . mean 01 47. 5 48. 5 49. 5 50. 5 51. 5 49. 0 50. 0 Upsampling and Interpolation When converting from low frequency toa higher frequency no aggregation is needed.  Lets consider DataFrame with some weekly data In 525 frame DataFramenp. random. randn2 wommsed indexpd. daterange112000 periods2 freqWWED scone ad columnsColorado Texas New York Ohio 316 Chapter 10 Time Series In 526 frame5 Out 526 Colorado Texas New York Ohio 20000105 0. 609657 0. 268837 0. 195592 0. 85979 20000112 0. 263206 1. 141350 0. 101937 0. 07666 When resampling this to daily frequency by default missing values are introduced In 527 dfdaily frame. resampleD In 528 dfdaily Out 528 Colorado Texas New York Ohio 20000105 0. 609657 0. 268837 0. 195592 0. 85979 20000106 NaN NaN NaN NaN 20000107 NaN NaN NaN NaN 20000108 NaN NaN NaN NaN 20000109 NaN NaN NaN NaN 20000110 NaN NaN NaN NaN 20000111 NaN NaN NaN NaN 20000112 0. 263206 1. 141350 0. 101937 0. 07666 Suppose you wanted to fill forward each weekly value on the nonWednesdays.  The same filling or interpolation methods available in the fillna and reindex methods are available for resampling In 529 frame. resampleD fillmethodffil1 Out529 Colorado Texas New York Ohio 20000105 0. 609657 0. 268837 0. 195592 0. 85979 20000106 0. 609657 0. 268837 0. 195592 0. 85979 20000107 0. 609657 0. 268837 0. 195592 0. 85979 20000108 0. 609657 0. 268837 0. 195592 0. 85979 20000109 0. 609657 0. 268837 0. 195592 0. 85979 20000110 0. 609657 0. 268837 0. 195592 0. 85979 20000111 0. 609657 0. 268837 0. 195592 0. 85979 20000112 0. 263206 1. 141350 0. 101937 0. 07666 You can similarly choose to only fill certain number of periods forward to limit how far to continue using an observed value In 530 frame. resampleD fillmethodffill limit2 Out530 Colorado Texas New York Ohio 20000105 0. 609657 0. 268837 0. 195592 0. 85979 20000106 0. 609657 0. 268837 0. 195592 0. 85979 20000107 0. 609657 0. 268837 0. 195592 0. 85979 20000108 NaN NaN NaN NaN 20000109 NaN NaN NaN NaN 20000110 NaN NaN NaN NaN 20000111 NaN NaN NaN NaN 20000112 0. 263206 1. 141350 0. 101937 0. 07666 Notably the new date index need not overlap with the old one at all Resampling and Frequency Conversion 317 In 531 frame. resampleWTHU fillmethodffill Out 531 Colorado Texas New York Ohio 20000106 0. 609657 0. 268837 0. 195592 0. 85979 20000113 0. 263206 1. 141350 0. 101937 0. 07666 Resampling with Periods Resampling data indexed by periods is reasonably straightforward and works as you would hope In 532 frame DataFramenp. random. randn24 wees indexpd. periodrange12000 122001 freqM sere columnsColorado Texas New York Ohio In 533 frame5 Out 533 Colorado Texas New York Ohio 200001 0. 120837 1. 076607 0. 434200 0. 056432 200002 0. 378890 0. 047831 0. 341626 1. 567920 200003 0. 047619 0. 821825 0. 179330 0. 166675 200004 0. 333219 0. 544615 0. 653635 2. 311026 200005 1. 612270 0. 806614 0. 557884 0. 580201 In 534 annualframe frame. resampleADEC howmean In 535 annualframe Out535 Colorado Texas New York Ohio 2000 0. 352070 0. 553642 0. 196642 0. 094099 2001 0. 158207 0. 042967 0. 360755 0. 184687 Upsampling is more nuanced as you must make decision about which end of the timespan in the new frequency to place the values before resampling just like the asfreq method.  The convention argument defaults to end but can also be start QDEC Quarterly year ending in December In 536 annualframe. resampleQDEC fillmethodffil1 Out 536 Colorado Texas New York Ohio 200004 0. 352070 0. 553642 0. 196642 0. 094099 200101 0. 352070 0. 553642 0. 196642 0. 094099 200102 0. 352070 0. 553642 0. 196642 0. 094099 200103 0. 352070 0. 553642 0. 196642 0. 094099 200104 0. 158207 0. 042967 0. 360755 0. 184687 In 537 annualframe. resampleQDEC fillmethodffill conventionstart Out 537 Colorado Texas New York Ohio 200001 0. 352070 0. 553642 0. 196642 0. 094099 200002 0. 352070 0. 553642 0. 196642 0. 094099 200003 0. 352070 0. 553642 0. 196642 0. 094099 200004 0. 352070 0. 553642 0. 196642 0. 094099 200101 0. 158207 0. 042967 0. 360755 0. 184687 318 Chapter 10 Time Series Since periods refer to timespans the rules about upsampling and downsampling are more rigid Indownsampling the target frequency must be subperiod of the source frequency.  Inupsampling the target frequency must be superperiod of the source frequency.  If these rules are not satisfied an exception will be raised.  This mainly affects the quar terly annual and weekly frequencies for example the timespans defined by QMAR only line up with AMAR AJUN ASEP and ADEC In 538 annualframe. resampleQMAR fi11methodffil11 Out 538 Colorado Texas New York Ohio 200103 0. 352070 0. 553642 0. 196642 0. 094099 200104 0. 352070 0. 553642 0. 196642 0. 094099 200201 0. 352070 0. 553642 0. 196642 0. 094099 200202 0. 352070 0. 553642 0. 196642 0. 094099 200203 0. 158207 0. 042967 0. 360755 0. 184687 Time Series Plotting Plots with pandas time series have improved date formatting compared with matplotlib out of the box.  As an example downloaded some stock price data on few common US stock from Yahoo Finance In 539 closepxall pd. readcsvcho9stockpx. csv parsedatesTrue indexcol0 In 540 close px close pxallAAPL MSFT XOM In 541 close px close px. resampleB fillmethodffil1 In 542 closepx Out542 class pandas. core. frame. DataFrame DatetimeIndex 2292 entries 20030102 00 to 20111014 00 Freq Data columns AAPL 2292 nonnull values MSFT 2292 nonnull values XOM 2292 nonnull values dtypes float643 Calling plot on one of the columns grenerates simple plot seen in Figure 104.  In 544 closepxAAPL. plot When called on DataFrame as you would expect all of the time series are drawn on single subplot with legend indicating which is which.  Pll plot only the year 2009 data so you can see how both months and years are formatted on the axis see Figure 105.  In 546 closepx. ix2009. plot Time Series Plotting 319 2004 2005 2006 2007 2008 2009 2010 2011 Figure 104.  AAPL Daily Price 250 200 150 Figure 105.  Stock Prices in 2009 In 548 closepxAAPL. ix012011 032011. plot Quarterly frequency data is also more nicely formatted with quarterly markers some thing that would be quite bit more work to do by hand.  See Figure 107.  In 550 applq close pxAAPL. resampleQDEC fillmethodffill In 551 applq. ix2009. plot last feature of time series plotting in pandas is that by rightclicking and dragging to zoom in and out the dates will be dynamically expanded or contracted and reformat ting depending on the timespan contained in the plot view.  This is of course only true when using matplotlib in interactive mode.  Moving Window Functions common class of array transformations intended for time series operations are sta tistics and other functions evaluated over sliding window or with exponentially de 320 Chapter 10 Time Series 365 360F 355 one 350 345 a9 ivrvceenrseninvann 325 Jan Feb Mar 2011 Figure 106.  Apple Daily Price in 1201132011 5O7 Q2 Q3 Q4 Ql Q2 Q3 Q4 Ql Q2 Q3 Q4 2009 2010 2011 Figure 107.  Apple Quarterly Price 20092011 caying weights.  call these moving window functions even though it includes functions without fixedlength window like exponentiallyweighted moving average.  Like other statistical functions these also automatically exclude missing data.  rolling mean is one of the simplest such functions.  It takes TimeSeries or DataFrame along with window expressed as number of periods In 555 close px. AAPL. plot Out555 matplotlib. axes. AxesSubplot at 0x1099b3990 In 556 pd. rolling meanclosepx. AAPL 250. plot See Figure 108 for the plot.  By default functions like rolling mean require the indicated number of nonNA observations.  This behavior can be changed to account for missing data and in particular the fact that you will have fewer than window periods of data at the beginning of the time series see Figure 109 Moving Window Functions 321 In 558 applstd250 pd. rolling stdclosepx. AAPL 250 minperiods10 In 559 applstd250512 Out559 20030109 NaN 20030110 NaN 20030113 NaN 20030114 NaN 20030115 0. 077496 20030116 0. 074760 20030117 0. 112368 Freq In 560 applstd250. plot 100 2004 2005 2006 2007 2008 2009 2010 2011 Figure 108.  Apple Price with 250day MA 40 35 pe BO veo eceesceseesdess eee seeees tees efevessestsstessiesbosissseseseen feoocuersss ved 25 BO evvesereneeeee 15 10 2004 2005 2006 2007 2008 2009 2010 2011 Figure 109.  Apple 250day daily return standard deviation To compute an expanding window mean you can see that an expanding window is just special case where the window is the length of the time series but only one or more periods is required to compute value 322 Chapter 10 Time Series Define expanding mean in terms of rolling mean In 561 expanding mean lambda rolling meanx lenx minperiods1 Calling rolling mean and friends on DataFrame applies the transformation to each column see Figure 1010 In 563 pd. rolling meanclose px 60. plotlogyTrue 10 10 10 10 2004 2005 2006 2007 2008 2009 2010 2011 Figure 1010.  Stocks Prices 60day MA log Yaxis See Table 106 for listing of related functions in pandas.  Table 106.  Moving window and exponentiallyweighted functions Function rolling count rolling sum rolling mean rolling median rolling var rolling std rolling skew rolling kurt rolling min rolling max rolling quantile rolling corr rolling cov rolling apply ewma ewmvar ewmstd ewmcorr ewmcov Description Returns number of nonNA observations in each trailing window.  Moving window sum.  Moving window mean.  Moving window median.  Moving window variance and standard deviation respectively.  Uses denom inator.  Moving window skewness 3rd moment and kurtosis 4th moment respectively.  Moving window minimum and maximum.  Moving window score at percentilesample quantile.  Moving window correlation and covariance.  Apply generic array function over moving window.  Exponentiallyweighted moving average.  Exponentiallyweighted moving variance and standard deviation.  Exponentiallyweighted moving correlation and covariance.  Moving Window Functions 323 bottleneck Python library by Keith Goodman provides an alternate implementation of NaNfriendly moving window functions and may be 12 worth looking at depending on your application.  Exponentiallyweighted functions An alternative to using static window size with equallyweighted observations is to specify constant decay factor to give more weight to more recent observations.  In mathematical terms if ma is the moving average result at time and is the time series in question each value in the result is computed as ma ma where is the decay factor.  There are couple of ways to specify the decay factor popular one is using span which makes the result comparable to simple moving window function with window size equal to the span.  Since an exponentiallyweighted statistic places more weight on more recent observa tions it adapts faster to changes compared with the equalweighted version.  Heres an example comparing 60day moving average of Apples stock price with an EW moving average with span60 see Figure 1011 fig axes plt. subplotsnrows2 ncols1 sharexTrue shareyTrue figsize12 aaplpx closepx. AAPL20052009 ma60 pd. rolling meanaaplpx 60 minperiods50 ewma60 pd. ewmaaaplpx span60 aaplpx. plotstylek axaxes0 ma60. plotstylek axaxes0 aaplpx. plotstylek axaxes1 ewma60. plotstylek axaxes1 axes0. settitleSimple MA axes1. settitleExponentiallyweighted MA Binary Moving Window Functions Some statistical operators like correlation and covariance need to operate on two time series.  As an example financial analysts are often interested in stocks correlation to benchmark index like the SP 500.  We can compute that by computing the percent changes and using rolling corr see Figure 1012 In 569 spxpx closepxallSPX In 570 spxrets spxpx spxpx. shift1 In 571 returns closepx. pctchange In 572 corr pd. rolling corrreturns. AAPL spxrets 125 minperiods100 324 Chapter 10 Time Series Simple MA 250 Bos 2006 2007 2008 2009 Exponentiallyweighted MA Bos 2006 2007 2008 2009 Figure 1011.  Simple moving average versus exponentiallyweighted 0. 9 0. 8 0. 7 0. 5 0. 4 0. 3 0. 2 0. 1 ts js 2004 2005 2006 2007 2008 2009 2010 2011 Figure 1012.  Sixmonth AAPL return correlation to SP 500 In 573 corr. plot Suppose you wanted to compute the correlation of the SP 500 index with many stocks at once.  Writing loop and creating new DataFrame would be easy but maybe get repetitive so if you pass TimeSeries and DataFrame function like rolling corr will compute the correlation of the TimeSeries spxrets in this case with each column in the DataFrame.  See Figure 1013 for the plot of the result In 575 corr pd. rolling corrreturns spxrets 125 minperiods100 In 576 corr. plot Moving Window Functions 325 2004 2005 2006 2007 2008 2009 2010 2011 Figure 1013.  Sixmonth return correlations to SP 500 95 BG sisseonemint rie ae 2004 2005 2006 2007 2008 2009 2010 2011 Figure 1014.  Percentile rank of AAPL return over year window UserDefined Moving Window Functions The rolling apply function provides means to apply an array function of your own devising over moving window.  The only requirement is that the function produce single value reduction from each piece of the array.  For example while we can compute sample quantiles using rolling quantile we might be interested in the per centile rank of particular value over the sample.  The scipy. stats. percentileof score function does just this In 578 from scipy. stats import percentileofscore In 579 scoreat2percent lambda percentileofscorex 0. 02 In 580 result pd. rolling applyreturns. AAPL 250 scoreat2percent In 581 result. plot 326 Chapter 10 Time Series Performance and Memory Usage Notes Timestamps and periods are represented as 64bit integers using NumPys date time64 dtype.  This means that for each data point there is an associated bytes of memory per timestamp.  Thus time series with million float64 data points has memory footprint of approximately 16 megabytes.  Since pandas makes every effort to share indexes among time series creating views on existing time series do not cause any more memory to be used.  Additionally indexes for lower frequencies daily and up are stored in central cache so that any fixedfrequency index is view on the date cache.  Thus if you have large collection of lowfrequency time series the memory footprint of the indexes will not be as significant.  Performancewise pandas has been highly optimized for data alignment operations the behindthescenes work of differently indexed ts1 ts2 and resampling.  Here is an example of aggregating 1OMM data points to OHLC In 582 rng pd. daterange112000 periods10000000 freq10ms In 583 ts Seriesnp. random. randnlenrng indexrng In 584 ts Out 584 20000101 00 1. 402235 20000101 00. 010000 2. 424667 20000101 00. 020000 1. 956042 20000101 00. 030000 0. 897339 20000102 39. 960000 0. 495530 20000102 39. 970000 0. 574766 20000102 39. 980000 1. 348374 20000102 39. 990000 0. 665034 Freq 10L Length 10000000 In 585 ts. resample15min howohlc Out 585 class pandas. core. frame. DataFrame DatetimeIndex 113 entries 20000101 00 to 20000102 00 Freq 15T Data columns open 113.  nonnull values high 113 nonnull values low 113.  nonnull values close 113.  nonnull values dtypes float644 In 586 timeit ts. resample15min howohlc 10 loops best of 61. 1 ms per loop The runtime may depend slightly on the relative size of the aggregated result higher frequency aggregates unsurprisingly take longer to compute In 587 rng pd. daterange112000 periods10000000 freq1s Performance and Memory Usage Notes 327 In 588 ts Seriesnp. random. randnlenrng indexrng In 589 timeit ts. resample15s howohlc loops best of 88. 2 ms per loop Its possible that by the time you read this the performance of these algorithms may be even further improved.  As an example there are currently no optimizations for conversions between regular frequencies but that would be fairly straightforward to do.  328 Chapter 10 Time Series CHAPTER 11 Financial and Economic Data Applications The use of Python in the financial industry has been increasing rapidly since 2005 led largely by the maturation of libraries like NumPy and pandas and the availability of skilled Python programmers.  Institutions have found that Python is wellsuited both as an interactive analysis environment as well as enabling robust systems to be devel oped often in fraction of the time it would have taken in Java or C.  Python is also an ideal glue layer it is easy to build Python interfaces to legacy libraries built in or C.  While the field of financial analysis is broad enough to fill an entire book hope to show you how the tools in this book can be applied to number of specific problems in finance.  As with other research and analysis domains too much programming effort is often spent wrangling data rather than solving the core modeling and research prob lems.  personally got started building pandas in 2008 while grappling with inadequate data tools.  In these examples Ill use the term crosssection to refer to data at fixed point in time.  For example the closing prices of all the stocks in the SP 500 index on particular date form crosssection.  Crosssectional data at multiple points in time over multiple data items for example prices together with volume form panel.  Panel data can either be represented as hierarchicallyindexed DataFrame or using the threedimen sional Panel pandas object.  Data Munging Topics Many helpful data munging tools for financial applications are spread across the earlier chapters.  Here Ill highlight number of topics as they relate to this problem domain.  329 Time Series and CrossSection Alignment One of the most timeconsuming issues in working with financial data is the socalled data alignment problem.  Two related time series may have indexes that dont line up perfectly or two DataFrame objects might have columns or row labels that dont match.  Users of MATLAB and other matrixprogramming languages often invest significant effort in wrangling data into perfectly aligned forms.  In my experience having to align data by hand and worse having to verify that data is aligned is far too rigid and tedious way to work.  It is also rife with potential for bugs due to combining misaligned data.  pandas take an alternate approach by automatically aligning data in arithmetic opera tions.  In practice this grants immense freedom and enhances your productivity.  As an example lets consider couple of DataFrames containing time series of stock prices and volume In 16 prices Out 16 AAPL JNJ SPX XOM 20110906 379. 74 64. 64 1165. 24 71. 15 20110907 383. 93 65. 43 1198. 62 73. 65 20110908 384. 14 64. 95 1185. 90 72. 82 20110909 377. 48 63. 64 1154. 23 71. 01 20110912 379. 94 63. 59 1162. 27 71. 84 20110913 384. 62 63. 61 1172. 87 71. 65 20110914 389. 30 63. 73 1188. 68 72. 64 In 17 volume Out17 AAPL INI XOM 20110906 18173500 15848300 25416300 20110907 12492000 10759700 23108400 20110908 14839800 15551500 22434800 20110909 20171900 17008200 27969100 20110912 16697300 13448200 26205800 Suppose you wanted to compute volumeweighted average price using all available data and making the simplifying assumption that the volume data is subset of the price data.  Since pandas aligns the data automatically in arithmetic and excludes missing data in functions like sum we can express this concisely as In 18 prices volume Out 18 AAPL JNJ SPX XOM 20110906 6901204890 1024434112 NaN 1808369745 20110907 4796053560 704007171 NaN 1701933660 20110908 5700560772 1010069925 NaN 1633702136 20110909 7614488812 1082401848 NaN 1986085791 20110912 6343972162 855171038 NaN 1882624672 20110913 NaN NaN NaN NaN 20110914 NaN NaN NaN NaN In 19 vwap prices volume. sum volume. sum 330 Chapter 11 Financial and Economic Data Applications In 20 vwap In 21 vwap. dropna Out20 Out 21 AAPL 380. 655181 AAPL 380. 655181 INI 64. 394769 INI 64. 394769 SPX NaN XOM 72. . 024288 XOM 72. . 024288 Since SPX wasnt found in volume you can choose to explicitly discard that at any point.  Should you wish to align by hand you can use DataFrames align method which returns tuple of reindexed versions of the two objects In 22 prices. alignvolume joininner Out 22 AAPL 20110906 379. 74 20110907 383. 93 20110908 384. 14 20110909 377. 48 20110912 379. 94 AAP 18173500 12492000 14839800 20171900 16697300 20110906 20110907 20110908 20110909 20110912 INI 64. 64 65. 43 64. 95 63. 64 63. 59 15848300 10759700 15551500 17008200 13448200 XOM 71. 15 73. 65 72. 82 71. 01 71. 84 JNJ XOM 25416300 23108400 22434800 27969100 26205800 Another indispensable feature is constructing DataFrame from collection of poten tially differently indexed Series In 23 s1 Seriesrange3 indexa In 24 s2 Seriesrange4 indexd In 25 s3 Seriesrange3 indexf In 26 DataFrameone s1 two s2 three s3 Out 26 one three two NaN NaN NaN NaN NaN NaN NaN oO NaN As you have seen earlier you can of course specify explicitly the index of the result discarding the rest of the data In 27 DataFrameone s1 two s2 three s3 indexlistface Out 27 one three two NaN NaN NaN Cc NaN NaN Data Munging Topics 331 Operations with Time Series of Different Frequencies Economic time series are often of annual quarterly monthly daily or some other more specialized frequency.  Some are completely irregular for example earnings revisions for stock may arrive at any time.  The two main tools for frequency conversion and realignment are the resample and reindex methods.  resample converts data to fixed frequency while reindex conforms data to new index.  Both support optional inter polation such as forward filling logic.  Lets consider small weekly time series In 28 ts1 In 29 ts1 Out 29 20120613 20120620 20120627 Freq WWED 1s 0.  0.  Series np. random. randn3 indexpd. daterange2012613 periods3 freqWWED 124801 469004 117439 If you resample this to business daily MondayFriday frequency you get holes on the days where there is no data In 30 ts1. resampleB Out 30 20120613 20120614 20120615 20120618 20120619 20120620 20120621 20120622 20120625 20120626 20120627 Freq 21 0.  0.  124801 NaN NaN NaN NaN 469004 NaN NaN NaN NaN 117439 Of course using ffill as the fillmethod forward fills values in those gaps.  This is common practice with lower frequency data as you compute time series of values on each timestamp having the latest valid or as of value In 31 ts1. resampleB fillmethodffil1 Out 31 20120613 20120614 20120615 20120618 20120619 20120620 20120621 20120622 20120625 20120626 124801 1.  1.  124801 1.  469004 469004 469004 469004 469004 124801 124801 124801 332 Chapter 11 Financial and Economic Data Applications 20120627 0. 117439 Freq In practice upsampling lower frequency data to higher regular frequency is fine solution but in the more general irregular time series case it may be poor fit.  Consider an irregularly sampled time series from the same general time period In 32 dates pd. DatetimeIndex2012612 2012617 2012618 semen 2012621 2012622 2012629 In 33 ts2 Seriesnp. random. randn6 indexdates In 34 ts2 Out 34 20120612 0. 449429 20120617 0. 459648 20120618 0. 172531 20120621 0. 835938 20120622 0. 594779 20120629 0. 027197 If you wanted to add the as of values in ts1 forward filling to ts2.  One option would be to resample both to regular frequency then add but if you want to maintain the date index in ts2 using reindex is more precise solution In 35 ts1. reindexts2. index methodffill Out 35 20120612 NaN 20120617 1. 124801 20120618 1. 124801 20120621 0. 469004 20120622 0. 469004 20120629 0. 117439 In 36 ts2 ts1. reindexts2. index methodffill Out 36 20120612 NaN 20120617 0. 665153 20120618 1. 297332 20120621 1. 304942 20120622 0. 125775 20120629 0. 090242 Using periods instead of timestamps Periods representing time spans provide an alternate means of working with different frequency time series especially financial or economic series with annual or quarterly frequency having particular reporting convention.  For example company might announce its quarterly earnings with fiscal year ending in June thus having QJUN fre quency.  Consider pair of macroeconomic time series related to GDP and inflation In 37 gdp Series1. 78 1. 94 2. 08 2. 01 2. 15 2. 31 2. 46 ssorme indexpd. periodrange198402 periods7 freqQSEP Data Munging Topics 333 In 38 infl Series0. 025 0. 045 0. 037 0. 04 wowed indexpd.  period range1982 periods4 freqADEC In 39 gdp In 40 infl Out 39 Out 40 198402 1. 78 1982 0. 025 198403 1. 94 1983 0. 045 198404 2. 08 1984 0. 037 198501 2. 01 1985 0. 040 198502 2. 15 Freq ADEC 198503 2. 31 198504 2. 46 Freq QSEP Unlike time series with timestamps operations between differentfrequency time series indexed by periods are not possible without explicit conversions.  In this case if we know that infl values were observed at the end of each year we can then convert to QSEP to get the right periods in that frequency In 41 inflq infl. asfreqQSEP howend In 42 inflq Out 42 198301 0. 025 198401 0. 045 198501 0. 037 198601 0. 040 Freq QSEP That time series can then be reindexed with forwardfilling to match gdp In 43 inflq. reindexgdp. index methodffil1 Out 43 198402 0. 045 198403 0. 045 198404 0. 045 198501 0. 037 198502 0. 037 198503 0. 037 198504 0. 037 Freq QSEP Time of Day and as of Data Selection Suppose you have long time series containing intraday market data and you want to extract the prices at particular time of day on each day of the data.  What if the data are irregular such that observations do not fall exactly on the desired time In practice this task can make for errorprone data munging if you are not careful.  Here is an example for illustration purposes Make an intraday date range and time series In 44 rng pd. daterange20120601 20120601 freqT Make 5day series of 930 values 334 Chapter 11 Financial and Economic Data Applications In 45 rng rng. appendrng pd. offsets. BDayi for in range1 In 46 ts Seriesnp. arangelenrng dtypefloat indexrng In 47 ts Out 47 20120601 20120601 20120601 20120601 20120606 20120606 20120606 20120606 Length 156 09 09 09 09 152 152 152 152 30 31 32 33 56 57 58 59 00 00 00 00 00 00 00 00 WNrR OO 1556 1557 1558 1559 Indexing with Python datetime. time object will extract values at those times In 48 from datetime import time In 49 tstime10 Out49 20120601 00 20120604 00 20120605 00 20120606 00 30 420 810 1200 Under the hood this uses an instance method attime available on individual time series and DataFrame objects alike In 50 ts. attimetime10 Out50 20120601 00 20120604 00 20120605 00 20120606 00 30 420 810 1200 You can select values between two times using the related betweentime method In 51 ts. betweentimetime10 time10 Out51 20120601 20120601 20120604 20120604 20120605 20120605 20120606 20120606 10 10 10 10 10 10 10 10 00 01 00 01 00 01 00 01 00 00 00 00 00 00 00 00 30 31 420 421 810 811 1200 1201 As mentioned above it might be the case that no data actually fall exactly at time like 10 AM but you might want to know the last known value at 10 AM Set most of the time series randomly to NA In 53 indexer np. sortnp. random. permutationlents700 Data Munging Topics 335 In 54 irrts ts. copy In 55 irrtsindexer np. nan In 56 irrts20120601 20120601 Out 56 20120601 00 20 20120601 00 NaN 20120601 00 22 20120601 00 23 20120601 00 NaN 20120601 00 25 20120601 00 NaN 20120601 00 NaN 20120601 00 NaN 20120601 00 NaN 20120601 00 NaN By passing an array of timestamps to the asof method you will obtain an array of the last valid nonNA values at or before each timestamp.  So we construct date range at 10 AM for each day and pass that to asof In 57 selection pd. daterange20120601 periods4 freqB In 58 irrts. asofselection Out 58 20120601 00 25 20120604 00 420 20120605 00 810 20120606 00 1197 Freq Splicing Together Data Sources In Chapter described number of strategies for merging together two related data sets.  In financial or economic context there are few widely occurring use cases Switching from one data source time series or collection of time series to another at specific point in time Patching missing values in time series at the beginning middle or end using another time series Completely replacing the data for subset of symbols countries asset tickers and so on In the first case switching from one set of time series to another at specific instant it is matter of splicing together two TimeSeries or DataFrame objects using pandas. con cat In 59 data1 DataFramenp. ones6 dtypefloat ataa columnsa wana indexpd. daterange6122012 periods6 336 Chapter 11 Financial and Economic Data Applications In 60 data2 DataFramenp. ones6 dtypefloat ccoseve columnsa scoswie indexpd. daterange6132012 periods6 In 61 spliced pd. concatdata1. ix20120614 data2. ix20120615 In 62 spliced Out 62 abe 20120612 11 20120613 20120614 20120615 20120616 20120617 20120618 Suppose in similar example that data1 was missing time series present in data2 In 63 data2 DataFramenp. ones6 dtypefloat acerece columnsa sores indexpd. daterange6132012 periods6 In 64 spliced pd. concatdata1. ix20120614 data2. ix20120615 In 65 spliced Out 65 bce 20120612 NaN 20120613 NaN 20120614 NaN 20120615 20120616 20120617 20120618 Using combine first you can bring in data from before the splice point to extend the history for item In 66 spliced filled spliced. combinefirstdata2 In 67 splicedfilled Out 67 20120612 20120613 20120614 20120615 20120616 20120617 20120618 Na NNNNRPRP PRD NNNNRPRP RPO NNNNRPRPRP OT NNNNNNZQ Since data2 does not have any values for 20120612 no values are filled on that day.  DataFrame has related method update for performing inplace updates.  You have to pass overwriteFalse to make it only fill the holes Data Munging Topics 337 In 68 spliced. updatedata2 overwriteFalse In 69 spliced Out 69 20120612 20120613 20120614 20120615 20120616 20120617 20120618 NNNNRPR PRD To replace the da but sometimes it In 70 cpsp In 71 cpsp In 72 cpsp Out72 20120612 20120613 20120614 20120615 20120616 20120617 20120618 NaN NNNNRPRP PRO NNNNRPRPRPO NNNNNNZQ ta for subset of symbols you can use any of the above techniques simpler to just set the columns directly with DataFrame indexing liced spliced.  copy liceda dataia liced NNNNBPBBR OS ZrPrrPRPRBREO NNNNNDN 2D mw Return Indexes and Cumulative Returns In financial context returns usually refer to percent changes in the price of an asset.  Lets consider price data for Apple in 2011 and 2012 In 73 impor In 74 price In 75 price Out75 Date 20120723 20120724 20120725 20120726 20120727 pandas. io. data as web web. getdatayahooAAPL 20110101Adj Close 603. 83 600. 92 574. 97 574. 88 585. 16 Name Adj Close For Apple which has no dividends computing the cumulative percent return between two points in time requires computing only the percent change in the price In 76 price Out76 0. 072 20111003 price2011301 399874037388123 338 Chapter 11 Financial and Economic Data Applications For other stocks with dividend payouts computing how much money you make from holding stock can be more complicated.  The adjusted close values used here have been adjusted for splits and dividends however.  In all cases its quite common to derive return index which is time series indicating the value of unit investment one dollar say.  Many assumptions can underlie the return index for example some will choose to reinvest profit and others not.  In the case of Apple we can compute simple return index using cumprod In 77 returns pri In 78 retindex In 79 retindexo In 80 retindex Out 80 Date 20110103 20110104 20110105 20110106 20120724 20120725 20120726 20120727 Length 396 PRPRPRB PRPRPRB 000000 005219 013442 012623 823346 744607 744334 775526 ce. pctchange returns. cumprod Set first value to With return index in hand computing cumulative returns at particular resolution is simple In 81 mreturns retindex. resampleBM howlast. pctchange In 82 mreturns2012 Out 82 Date 20120131 20120229 20120330 20120430 20120531 20120629 20120731 Freq BM 127111 188311 105284 0.  0.  010853 001986 025969 010702 Of course in this simple case no dividends or other adjustments to take into account these could have been computed from the daily percent changed by resampling with aggregation here to periods In 83 mrets returns. resampleM howprod kindperiod In 84 mrets2012 Out 84 Date Data Munging Topics 339 201201 0. 127111 201202 0. 188311 201203 0. 105284 201204 0. 025969 201205 0. 010702 201206 0. 010853 201207 0. 001986 Freq If you had dividend dates and percentages including them in the total return per day would look like returnsdividenddates dividendpcts Group Transforms and Analysis In Chapter you learned the basics of computing group statistics and applying your own transformations to groups in dataset.  Lets consider collection of hypothetical stock portfolios.  first randomly generate broad universe of 2000 tickers import random random. seed0 import string 1000 def randsn choices string. asciiuppercase return . joinrandom. choicechoices for in xrangen tickers np. arrayrands5 for in xrangeN then create DataFrame containing columns representing hypothetical but random portfolios for subset of tickers 500 df DataFrameMomentum np. random. randnM 200 0. 03 Value np. random. randnM 200 0. 08 ShortInterest np. random. randnM 200 0. 02 indextickersM Next lets create random industry classification for the tickers.  To keep things simple Pl just keep it to industries storing the mapping in Series indnames np. arrayFINANCIAL TECH sampler np. random. randint0 lenindnames industries Seriesindnamessampler indextickers name industry Now we can group by industries and carry out group aggregation and transformations In 90 byindustry df. groupbyindustries In 91 byindustry. mean Out91 Momentum ShortInterest Value 340 Chapter 11 Financial and Economic Data Applications industry FINANCIAL 0. 029485 0. 020739 0. 079929 TECH 0. 030407 0. 019609 0. 080113 In 92 byindustry. describe Out92 Momentum ShortInterest Value industry FINANCIAL count 246. 000000 246. 000000 246. 000000 mean 0. 029485 0. 020739 0. 079929 std 0. 004802 0. 004986 0. 004548 min 0. 017210 0. 036997 0. 067025 25 0. 026263 0. 024138 0. 076638 50 0. 029261 0. 020833 0. 079804 75 0. 032806 0. 017345 0. 082718 max 0. 045884 0. 006322 0. 093334 TECH count 254. 000000 254. 000000 254. 000000 mean 0. 030407 0. 019609 0. 080113 std 0. 005303 0. 005074 0. 004886 min 0. 016778 0. 032682 0. 065253 25 0. 026456 0. 022779 0. 076737 50 0. 030650 0. 019829 0. 080296 15 0. 033602 0. 016923 0. 083353 max 0. 049638 0. 003698 0. 093081 By defining transformation functions its easy to transform these portfolios by industry.  For example standardizing within industry is widely used in equity portfolio construc tion WithinIndustry Standardize def zscoregroup return group group. mean group. std dfstand byindustry. applyzscore You can verify that each industry has mean and standard deviation In 94 dfstand. groupbyindustries. aggmean std Out 94 Momentum ShortInterest Value mean std mean std mean std industry FINANCIAL TECH Other builtin kinds of transformations like rank can be used more concisely Withinindustry rank descending In 95 indrank byindustry. rankascendingFalse In 96 indrank. groupbyindustries. aggmin max Out 96 Momentum ShortInterest Value min max min max min max industry FINANCIAL 246 246 246 TECH 254 254 254 Group Transforms and Analysis 341 In quantitative equity rank and standardize is common sequence of transforms.  You could do this by chaining together rank and zscore like so Industry rank and standardize In 97 byindustry. applylambda zscorex. rank Out 97 class pandas. core. frame. DataFrame Index 500 entries VTKGN to PTDQE Data columns Momentum 500 nonnull values ShortInterest 500 nonnull values Value 500 nonnull values dtypes float643 Group Factor Exposures Factor analysis is technique in quantitative portfolio management.  Portfolio holdings and performance profit and less are decomposed using one or more factors risk fac tors are one example represented as portfolio of weights.  For example stock prices comovement with benchmark like SP 500 index is known as its beta common risk factor.  Lets consider contrived example of portfolio constructed from ran domlygenerated factors usually called the factor loadings and some weights from numpy. random import rand faci fac2 fac3 np. random. rand3 1000 tickersubset tickers. takenp. random. permutationN 1000 Weighted sum of factors plus noise port Series0. 7 faci 1. 2 fac2 0. 3 fac3 rand1000 indextickersubset factors DataFramef1 faci f2 fac2 f3 fac3 indextickersubset Vector correlations between each factor and the portfolio may not indicate too much In 99 factors. corrwithport Out99 0. 402377 0. 680980 0. 168083 The standard way to compute the factor exposures is by least squares regression using pandas. ols with factors as the explanatory variables we can compute exposures over the entire set of tickers In 100 pd. olsyport xfactors. beta Out100 il 0. 761789 1. 208760 0. 289865 intercept 0. 484477 342 Chapter 11 Financial and Economic Data Applications As you can see the original factor weights can nearly be recovered since there was not too much additional random noise added to the portfolio.  Using groupby you can com pute exposures industry by industry.  To do so write function like so def betaexposurechunk factorsNone return pd. olsychunk xfactors. beta Then group by industries and apply that function passing the DataFrame of factor loadings In 102 byind port. groupbyindustries In 103 exposures byind. applybetaexposure factorsfactors In 104 exposures. unstack Out104 f1 f2 intercept industry FINANCIAL 0. 790329 1. 182970 0. 275624 0. 455569 TECH 0. 740857 1. 232882 0. 303811 0. 508188 Decile and Quartile Analysis Analyzing data based on sample quantiles is another important tool for financial ana lysts.  For example the performance of stock portfolio could be broken down into quartiles four equalsized chunks based on each stocks pricetoearnings.  Using pan das. qcut combined with groupby makes quantile analysis reasonably straightforward.  As an example lets consider simple trend following or momentum strategy trading the SP 500 index via the SPY exchangetraded fund.  You can download the price history from Yahoo Finance In 105 import pandas. io. data as web In 106 data web. getdatayahooSPY 20060101 In 107 data Out107 class pandas. core.  frame. DataFrame DatetimeIndex 1655 entries 20060103 00 to 20120727 00 Data columns Open 1655 nonnull values High 1655 nonnull values Low 1655 nonnull values Close 1655 nonnull values Volume 1655 nonnull values Adj Close 1655 nonnull values dtypes float645 int641 Now well compute daily returns and function for transforming the returns into trend signal formed from lagged moving sum px dataAdj Close returns px. pctchange Group Transforms and Analysis 343 def toindexrets index rets. cumprod firstloc maxindex. notnull. argmax index. valuesfirstloc return index def trendsignalrets lookback lag signal pd. rolling sumrets lookback minperiodslookback return signal. shiftlag Using this function we can naively create and test trading strategy that trades this momentum signal every Friday In 109 signal trendsignalreturns 100 In 110 trade friday signal. resampleWFRI. resampleB fillmethodffill1 In 111 traderets trade friday. shift1 returns We can then convert the strategy returns to return index and plot them see Fig ure 111 In 112 toindextraderets. plot 1. 12 1. 10b 1. 08 rf 1. 06 1. 04 1. 02 .  1. 00 tel 0. 98 2007 2008 2009 2010 2011 2012 Date Figure 111.  SPY momentum strategy return index Suppose you wanted to decompose the strategy performance into more and less volatile periods of trading.  Trailing oneyear annualized standard deviation is simple measure of volatility and we can compute Sharpe ratios to assess the rewardtorisk ratio in various volatility regimes vol pd. rolling stdreturns 250 minperiods200 np. sqrt250 344 Chapter 11 Financial and Economic Data Applications def sharperets ann250 return rets. mean rets. std np. sqrtann Now dividing vol into quartiles with qcut and aggregating with sharpe we obtain In 114 traderets. groupbypd. qcutvol 4. aggsharpe Out114 0. 0955 0. 16 0. 490051 0. 16 0. 188 0. 482788 0. 188 0. 231 0. 731199 0. 231 0. 457 0. 570500 These results show that the strategy performed the best during the period when the volatility was the highest.  More Example Applications Here is small set of additional examples.  Signal Frontier Analysis In this section Ill describe simplified crosssectional momentum portfolio and show how you might explore grid of model parameterizations.  First Ill load historical prices for portfolio of financial and technology stocks names AAPL GOOG MSFT DELL GS MS BAC def getpxstock start end return web. getdatayahoostock start endAdj Close px DataFramen getpxn 112009 612012 for in names We can easily plot the cumulative returns of each stock see Figure 112 In 117 px px. asfreqB. fillnamethod pad In 118 rets px. pctchange In 119 rets. cumprod 1. plot For the portfolio construction well compute momentum over certain lookback then rank in descending order and standardize def calcmomprice lookback lag momret price. shiftlag. pctchangelookback ranks momret. rankaxis1 ascendingFalse demeaned ranks ranks. meanaxis1 return demeaned demeaned. stdaxis1 With this transform function in hand we can set up strategy backtesting function that computes portfolio for particular lookback and holding period days between trading returning the overall Sharpe ratio compound lambda x. prod daily sr lambda x. mean x. std More Example Applications 345 def stratsrprices lb hold Compute portfolio weights freq dB hold port calcmomprices 1b lag1 daily rets prices. pctchange Compute portfolio returns port port. shift1. resamplefreq howfirst returns daily rets. resamplefreq howcompound portrets port returns. sumaxis1 return daily srportrets np. sqrt252 hold Figure 112.  Cumulative returns for each of the stocks When called with the prices and parameter combination this function returns scalar value In 122 stratsrpx 70 30 Out 122 0. 27421582756800583 From there you can evaluate the stratsr function over grid of parameters storing them as you go in defaultdict and finally putting the results in DataFrame from collections import defaultdict lookbacks range20 90 holdings range20 90 dd defaultdictdict for lb in lookbacks for hold in holdings dd1bhold stratsrpx 1b hold 346 Chapter 11 Financial and Economic Data Applications ddf DataFramedd ddf. index. name Holding Period ddf. columns. name Lookback Period To visualize the results and get an idea of whats going on here is function that uses matplotlib to produce heatmap with some adornments import matplotlib. pyplot as plt def heatmapdf cmapplt. cm. grayr fig plt. figure ax fig. addsubplot111 axim ax. imshowdf. values cmapcmap interpolationnearest ax ax ax . setxlabeldf. columns. name ax.  ax.  ax.  . setyticksnp. arangelendf. index . setyticklabelslistdf. index setxticksnp. arangelendf. columns setxticklabelslistdf. columns setylabeldf. index. name plt. colorbaraxim Calling this function on the backtest results we get Figure 113 In 125 heatmapddf 1. 00 0. 75 0. 50 45 0. 25 oD 0. 00 3S 55 60 0. 25 0. 50 0. 75 20 25 30 35 40 45 50 55 60 65 70 75 80 85 Lookback Period Figure 113.  Heatmap of momentum strategy Sharpe ratio higher is better over various lookbacks and holding periods Future Contract Rolling future is an ubiquitous form of derivative contract it is an agreement to take delivery of certain asset such as oil gold or shares of the FTSE 100 index on particular date.  In practice modeling and trading futures contracts on equities currencies More Example Applications 347 commodities bonds and other asset classes is complicated by the timelimited nature of each contract.  For example at any given time for type of future say silver or copper futures multiple contracts with different expiration dates may be traded.  In many cases the future contract expiring next the near contract will be the most liquid highest volume and lowest bidask spread.  For the purposes of modeling and forecasting it can be much easier to work with continuous return index indicating the profit and loss associated with always holding the near contract.  Transitioning from an expiring contract to the next or far contract is referred to as rolling.  Computing continuous future series from the individual con tract data is not necessarily straightforward exercise and typically requires deeper understanding of the market and how the instruments are traded.  For example in practice when and how quickly would you trade out of an expiring contract and into the next contract Here describe one such process.  First Ill use scaled prices for the SPY exchangetraded fund as proxy for the SP 500 index In 127 import pandas. io. data as web Approximate price of SP 500 index In 128 px web. getdatayahooSPYAdj Close 10 In 129 px Out 129 Date 20110801 1261. 0 20110802 1228. 8 20110803 1235. 5 20120725 1339. 6 20120726 1361. 7 20120727 1386. 8 Name Adj Close Length 251 Now little bit of setup.  put couple of SP 500 future contracts and expiry dates in Series from datetime import datetime expiry ESU2 datetime2012 21 ESZ2 datetime2012 12 21 expiry Seriesexpiry . order expiry then looks like In 131 expiry Out 131 ESU2 20120921 00 ESZ2 20121221 00 348 Chapter 11 Financial and Economic Data Applications Then use the Yahoo Finance prices along with random walk and some noise to simulate the two contracts into the future np. random.  seed 12347 200 walk np. random. randint0 200 sizeN 100 0. 25 perturb np. random. randint0 20 sizeN 10 0. 25 walk walk. cumsum rng pd. daterangepx. index0 periodslenpx freqB near np. concatenatepx. values px. values1 walk far np. concatenatepx. values px. values1 walk perturb prices DataFrameESU2 near ESZ2 far indexrng prices then has two time series for the contracts that differ from each other by arandom amount In 133 prices. tail Out 133 ESU2 ESZ2 20130416 1416. 05 1417. 80 20130417 1402. 30 1404. 55 20130418 1410. 30 1412. 05 20130419 1426. 80 1426. 05 20130422 1406. 80 1404. 55 One way to splice time series together into single continuous series is to construct weighting matrix.  Active contracts would have weight of until the expiry date ap proaches.  At that point you have to decide on roll convention.  Here is function that computes weighting matrix with linear decay over number of periods leading up to expiry def getroll weightsstart expiry items rollperiods5 start first date to compute weighting DataFrame expiry Series of ticker expiration dates items sequence of contract names dates pd. daterangestart expiry1 freqB weights DataFramenp. zeroslendates lenitems indexdates columnsitems prevdate weights. index0 for item exdate in enumerateexpiry. iteritems if lenexpiry weights. ixprevdateexdate pd. offsets. BDay item rollrng pd. daterangeendexdate pd. offsets. BDay periodsroll periods freqB decay weights np. linspace0 roll periods weights. ixrollrng item decay weights weights. ixrollrng expiry. indexi decay weights else weights. ixprevdate item prevdate exdate More Example Applications 349 return weights The weights look like this around the ESU2 expiry In 135 weights getrollweights612012 expiry prices. columns In 136 weights.  ix2012091220120921 Out 136 ESU2 ESZ2 20120912 1. 0 0. 0 20120913 1. 0 0. 0 20120914 0. 8 0. 2 20120917 0. 6 0. 4 20120918 0. 4 0. 6 20120919 0. 2 0. 8 20120920 0. 0 1. 0 20120921 0. 0 1. 0 Finally the rolled future returns are just weighted sum of the contract returns In 137 rolledreturns prices. pctchange weights . sum1 Rolling Correlation and Linear Regression Dynamic models play an important role in financial modeling as they can be used to simulate trading decisions over historical period.  Moving window and exponentially weighted time series functions are an example of tools that are used for dynamic models.  Correlation is one way to look at the comovement between the changes in two asset time series.  pandass rolling corr function can be called with two return series to compute the moving window correlation.  First load some price series from Yahoo Finance and compute daily returns aapl web. getdatayahooAAPL 20000101Adj Close msft web. getdatayahooMSFT 20000101Adj Close aaplrets aapl. pctchange msftrets msft. pctchange Then compute and plot the oneyear moving correlation see Figure 114 In 140 pd. rolling corraaplrets msftrets 250. plot One issue with correlation between two assets is that it does not capture differences in volatility.  Leastsquares regression provides another means for modeling the dynamic relationship between variable and one or more other predictor variables.  In 142 model pd. olsyaaplrets xMSFT msftrets window250 In 143 model. beta Out 143 class pandas. core. frame. DataFrame DatetimeIndex 2913 entries 20001228 00 to 20120727 00 Data columns 350 Chapter 11 Financial and Economic Data Applications MSFT 2913 nonnull values intercept 2913 nonnull values dtypes float642 In 144 model. beta MSFT. plot og ov ge ge Wh gh og Date Figure 114.  Oneyear correlation of Apple with Microsoft 1. 0 0. 9 0. 8F 0. 7 0. 6 0. 5 0. 4 0. 3 as as Date oy 0.  ae or aw ao aw vo gr gg Figure 115.  Oneyear beta OLS regression coefficient of Apple to Microsoft pandass ols function implements static and dynamic expanding or rolling window least squares regressions.  For more sophisticated statistical and econometrics models see the statsmodels project httpstatsmodels. sourceforge. net.  More Example Applications 351 CHAPTER 12 Advanced NumPy ndarray Object Internals The NumPy ndarray provides means to interpret block of homogeneous data either contiguous or strided more on this later as multidimensional array object.  As youve seen the data type or dtype determines how the data is interpreted as being floating point integer boolean or any of the other types weve been looking at.  Part of what makes ndarray powerful is that every array object is strided view on block of data.  You might wonder for example how the array view arr2 does not copy any data.  Simply put the ndarray is more than just chunk of memory and dtype it also has striding information which enables the array to move through memory with varying step sizes.  More precisely the ndarray internally consists of the following pointer to data that is block of system memory The data type or dtype Atuple indicating the arrays shape For example 10 by array would have shape 10 In np. ones10 5. shape Out8 10 tuple of strides integers indicating the number of bytes to step in order to advance one element along dimension For example typical order more on this later array of float64 8byte values has strides 160 40 In np. ones3 dtypenp. float64. strides Out9 160 40 While it is rare that typical NumPy user would be interested in the array strides they are the critical ingredient in constructing copyless array views.  Strides can even be negative which enables an array to move backward through memory which would be the case in slice like obj1 or obj 1.  353 See Figure 121 for simple mockup the ndarray innards.  ndarray object datal TT TTT Figure 121.  The NumPy ndarray object NumPy dtype Hierarchy You may occasionally have code which needs to check whether an array contains in tegers floating point numbers strings or Python objects.  Because there are many types of floating point numbers float16 through float128 checking that the dtype is among list of types would be very verbose.  Fortunately the dtypes have superclasses such as np. integer and np. floating which can be used in conjunction with the np. issubd type function In 10 ints np. ones10 dtypenp. uint16 In 11 floats np. ones10 dtypenp. float32 12 np. issubdtypeints. dtype np. integer 12 True 13 np. issubdtypefloats. dtype np.  floating 13 True You can see all of the parent classes of specific dtype by calling the types mro method In 14 np. float64. mro Out14 numpy. float64 numpy.  floating numpy. inexact numpy. number numpy. generic float object Most NumPy users will never have to know about this but it occasionally comes in handy.  See Figure 122 for graph of the dtype hierarchy and parentsubclass relationships .  1.  Some of the dtypes have trailing underscores in their names.  These are there to avoid variable name conflicts between the NumPyspecific types and the Python builtin ones.  354 Chapter 12 Advanced NumPy ann Figure 122.  The NumPy dtype class hierarchy Advanced Array Manipulation There are many ways to work with arrays beyond fancy indexing slicing and boolean subsetting.  While much of the heavy lifting for data analysis applications is handled by higher level functions in pandas you may at some point need to write data algorithm that is not found in one of the existing libraries.  Reshaping Arrays Given what we know about NumPy arrays it should come as little surprise that you can convert an array from one shape to another without copying any data.  To do this pass tuple indicating the new shape to the reshape array instance method.  For exam ple suppose we had onedimensional array of values that we wished to rearrange into matrix In 15 arr np. arange8 In 16 arr Out16 array0 In 17 arr. reshape4 Out 17 array0 multidimensional array can also be reshaped In 18 arr. reshape4 2. reshape2 Out 18 Advanced Array Manipulation 355 array0 One of the passed shape dimensions can be in which case the value used for that dimension will be inferred from the data In 19 arr np. arange15 In 20 arr. reshape5 Out20 array 10 11 12 13 14 Since an arrays shape attribute is tuple it can be passed to reshape too In 21 otherarr np. ones3 In 22 otherarr. shape Out22 In 23 arr. reshapeotherarr. shape Out 23 array 10 11 12 13 14 The opposite operation of reshape from onedimensional to higher dimension is typ ically known as flattening or raveling In 24 arr np. arange15. reshape5 In 25 arr Out25 array 10 14 12 13 14 In 26 arr. ravel Out26 array 10 11 12 13 14 ravel does not produce copy of the underlying data if it does not have to more on this below.  The flatten method behaves like ravel except it always returns copy of the data In 27 arr. flatten Out27 array 10 11 12 13 14 The data can be reshaped or raveled in different orders.  This is slightly nuanced topic for new NumPy users and is therefore the next subtopic.  versus Fortran Order Contrary to some other scientific computing environments like and MATLAB NumPy gives you much more control and flexibility over the layout of your data in 356 Chapter 12 Advanced NumPy memory.  By default NumPy arrays are created in row major order.  Spatially this means that if you have twodimensional array of data the items in each row of the array are stored in adjacent memory locations.  The alternative to row major ordering is column major order which means that you guessed it values within each column of data are stored in adjacent memory locations.  For historical reasons row and column major order are also know as and Fortran order respectively.  In FORTRAN 77 the language of our forebears matrices were all column major.  Functions like reshape and ravel accept an order argument indicating the order to use the data in the array.  This can be or in most cases there are also less commonly used options and see the NumPy documentation.  These are illustrated in Figure 123.  In 28 arr np. arange12. reshape3 In 29 arr Out 29 array 10 11 ocr of Oo .  In 30 arr. ravel Out30 array 10 11 In 31 arr. ravelF Out31 array 10 11 Reshaping arrays with more than two dimensions can be bit mindbending.  The key difference between and Fortran order is the order in which the dimensions are walked Crow major order traverse higher dimensions first e. g.  axis before advancing on axis 0.  Fortran column major order traverse higher dimensions last e. g.  axis before advancing on axis 1.  Concatenating and Splitting Arrays numpy.  concatenate takes sequence tuple list etc.  of arrays and joins them together in order along the input axis.  In 32 arr1 nparray1 In 33 arr2 np. array7 10 11 12 In 34 np. concatenatearr1 arr2 axis0 Out 34 array Advanced Array Manipulation 357 10 11 12 In 35 np. concatenatearr1 arr2 axis1 Out 35 array 10 11 12 pols fetal ei siel ej arr. reshape4 order order row major Fortran order column major orderC orderF Figure 123.  Reshaping in row major or Fortran column major order There are some convenience functions like vstack and hstack for common kinds of concatenation.  The above operations could have been expressed as In 36 np. vstackarr1 arr2 In 37 np. hstackarr1 arr2 Out 36 Out 37 array array 10 11 12 10 11 12 split on the other hand slices apart an array into multiple arrays along an axis In 38 from numpy. random import randn In 39 arr randn5 In 40 arr Out 40 array 0. 1689 0. 3287 0. 4703 0. 8989 0. 1535 0. 0243 0. 2832 1. 1536 0. 2707 0. 8075 In 41 first second third np. splitarr In 42 first 358 Chapter 12 Advanced NumPy Out42 array 0. 1689 0. 3287 In 43 second In 44 third Out 43 Out 44 array 0. 4703 0. 8989 array0. 2832 1. 1536 0. 1535 0. 0243 0. 2707 0. 8075 See Table 121 for list of all relevant concatenation and splitting functions some of which are provided only as convenience of the very general purpose concatenate.  Table 121.  Array concatenation functions Function Description concatenate Most general function concatenates collection of arrays along one axis vstack rowstack Stack arrays rowwise along axis hstack Stack arrays columnwise along axis columnstack Like hstack but converts 1D arrays to 2D column vectors first dstack Stack arrays depthwise along axis split Split array at passed locations along particular axis hsplit vsplit dsplit Convenience functions for splitting on axis and respectively.  Stacking helpers and There are two special objects in the NumPy namespace and that make stacking arrays more concise In 45 arr np. arange6 In 46 arr1 arr. reshape3 In 47 arr2 randn3 In 48 np. rarr1 arr2 In 49 np. cnp. r arr1 arr2 arr Out 48 Out49 array 1.  array 1.  0.  3.  3B 4.  0. 7258 1. 5325 0. 7258 1. 5325 3.  0. 4696 0. 2127 0. 4696 0. 2127 4.  0. 1072 1. 2871 0. 1072 1. 2871 5.  These additionally can translate slices to arrays In 50 np. c16 105 Out50 array 10 35 See the docstring for more on what you can do with candr.  Advanced Array Manipulation 359 Repeating Elements Tile and Repeat Oo The need to replicate or repeat arrays is less common with NumPy than .  it is with other popular array programming languages like MATLAB.  448s The main reason for this is that broadcasting fulfills this need better which is the subject of the next section.  The two main tools for repeating or replicating arrays to produce larger arrays are the repeat and tile functions.  repeat replicates each element in an array some number of times producing larger array In 51 arr np. arange3 In 52 arr. repeat3 Out52 array0 By default if you pass an integer each element will be repeated that number of times.  If you pass an array of integers each element can be repeated different number of times In 53 arr. repeat2 Out53 array0 Multidimensional arrays can have their elements repeated along particular axis.  In 54 arr randn2 In 55 arr In 56 arr. repeat2 axis0 Out55 Out56 array 0. 7157 0. 6387 array 0. 7157 0. 6387 0. 3626 0. 849 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 Note that if no axis is passed the array will be flattened first which is likely not what you want.  Similarly you can pass an array of integers when repeating multidimen sional array to repeat given slice different number of times In 57 arr. repeat2 axis0 Out 57 array 0. 7157 0. 6387 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 0. 3626 0. 849 In 58 arr. repeat2 axis1 Out 58 array 0. 7157 0. 7157 0. 6387 0. 6387 0. 6387 0. 3626 0. 3626 0. 849 0. 849 0. 849 360 Chapter 12 Advanced NumPy tile on the other hand is shortcut for stacking copies of an array along an axis.  You can visually think about it as like laying down tiles In 59 arr Out 59 array 0. 7157 0. 6387 0. 3626 0. 849 In 60 np. tilearr Out 60 array 0. 7157 0. 6387 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 The second argument is the number of tiles with scalar the tiling is made rowby row rather than column by column The second argument to tile can be tuple in dicating the layout of the tiling In 61 arr Out 61 array 0. 7157 0. 6387 0. 3626 0. 849 In 62 np. tilearr In 63 np. tilearr Out 62 Out 63 array 0. 7157 0. 6387 array 0. 7157 0. 6387 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 0. 3626 0. 849 0. 7157 0. 6387 0. 7157 0. 6387 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 0. 3626 0. 849 0. 7157 0. 6387 0. 7157 0. 6387 0. 3626 0. 849 0. 3626 0. 849 Fancy Indexing Equivalents Take and Put As you may recall from Chapter one way to get and set subsets of arrays is by fancy indexing using integer arrays In 64 arr np. arange10 100 In 65 inds In 66 arrinds Out66 array700 100 200 600 There are alternate ndarray methods that are useful in the special case of only making selection on single axis In 67 arr. takeinds Out67 array700 100 200 600 In 68 arr. putinds 42 In 69 arr Out69 array 42 42 300 400 500 42 42 800 900 In 70 arr. putinds 40 41 42 43 Advanced Array Manipulation 361 In Out 71 arr 71 array 41 42 300 400 500 43 40 800 900 To use take along other axes you can pass the axis keyword In 72 inds In 73 arr randn2 In 74 arr Out74 array0. 8237 2. 6047 0. 4578 1.  2. 3198 1. 0792 0. 518 0. 2527 In 75 arr. takeinds axis1 Out75 array0. 4578 0. 8237 0. 4578 2. 6047 0. 518 2. 3198 0. 518 1. 0792 put does not accept an axis argument but rather indexes into the flattened onedi mensional order version of the array this could be changed in principle.  Thus when you need to set elements using an index array on other axes you will want to use fancy indexing.  As of this writing the take and put functions in general have better performance than their fancy indexing equivalents by significant mar ia gin.  regard this as bug and something to be fixed in NumPy but its something worth keeping in mind if youre selecting subsets of large arrays using integer arrays In 76 arr randn1000 50 Random sample of 500 rows In 77 inds np. random. permutation1000 500 In 78 timeit arrinds 1000 loops best of 356 us per loop In 79 timeit arr. takeinds axis0 10000 loops best of 34 us per loop Broadcasting Broadcasting describes how arithmetic works between arrays of different shapes.  It is very powerful feature but one that can be easily misunderstood even by experienced users.  The simplest example of broadcasting occurs when combining scalar value with an array In 80 arr np. arange5 In 81 arr In 82 arr Out81 array0 Out82 array 12 16 362 Chapter 12 Advanced NumPy Here we say that the scalar value has been broadcast to all of the other elements in the multiplication operation.  For example we can demean each column of an array by subtracting the column means.  In this case it is very simple In 83 arr randn4 In 84 arr. mean0 Out84 array 0. 1321 0. 552 0. 8571 In 85 demeaned arr arr. mean0 In 86 demeaned In 87 demeaned. mean0 Out 86 Out87 array 0.  0.  0.  array 0. 1718 0. 1972 1. 3669 0. 1292 1. 6529 0. 3429 0. 2891 0. 0435 1. 2322 0. 2465 1. 4122 0. 4776 See Figure 124 for an illustration of this operation.  Demeaning the rows as broadcast operation requires bit more care.  Fortunately broadcasting potentially lower dimen sional values across any dimension of an array like subtracting the row means from each column of twodimensional array is possible as long as you follow the rules.  This brings us to 43 appa Bhs atss Figure 124.  Broadcasting over axis with 1D array The Broadcasting Rule Two arrays are compatible for broadcasting if for each trailing dimension that is start ing from the end the axis lengths match or if either of the lengths is 1.  Broadcasting is then performed over the missing and or length dimensions.  Even as an experienced NumPy user often must stop to draw pictures and think about the broadcasting rule.  Consider the last example and suppose we wished instead to subtract the mean value from each row.  Since arr. mean0 has length it is compatible Broadcasting 363 for broadcasting across axis because the trailing dimension in arr is and therefore matches.  According to the rules to subtract over axis that is subtract the row mean from each row the smaller array must have shape In 88 arr Out 88 array 0. 3039 0. 3548 0. 5097 0. 0029 2. 2049 0. 5142 0. 1571 0. 5085 2. 0893 0. 3786 0. 8602 1. 3347 In 89 row means arr. mean1 In 90 rowmeans. reshape4 Out 90 array 0. 0496 0. 9073 0. 8136 0. 2844 In 91 demeaned arr row means. reshape4 In 92 demeaned. mean1 Out92 array 0.  0.  0.  0.  Has your head exploded yet See Figure 125 for an illustration of this operation.  43 41 Figure 125.  Broadcasting over axis of 2D array See Figure 126 for another illustration this time adding twodimensional array to threedimensional one across axis 0.  Broadcasting Over Other Axes Broadcasting with higher dimensional arrays can seem even more mindbending but it is really matter of following the rules.  If you dont youll get an error like this In 93 arr arr. mean1 ValueError Traceback most recent call last ipythoninput937b87b85a20b2 in module 364 Chapter 12 Advanced NumPy arr arr. mean1 ValueError operands could not be broadcast together with shapes 43 34 42 34 Figure 126.  Broadcasting over axis of 3D array Its quite common to want to perform an arithmetic operation with lower dimensional array across axes other than axis 0.  According to the broadcasting rule the broadcast dimensions must be in the smaller array.  In the example of row demeaning above this meant reshaping the row means to be shape instead of In 94 ary arr. mean1. reshape4 Out94 array 0. 2542 0. 3051 0. 5594 0. 9044 1. 2976 0. 3931 0. 9707 0. 3051 1. 2757 0. 0942 1. 1446 1. 0503 In the threedimensional case broadcasting over any of the three dimensions is only matter of reshaping the data to be shapecompatible.  See Figure 127 for nice visual ization of the shapes required to broadcast over each axis of threedimensional array.  very common problem therefore is needing to add new axis with length specif ically for broadcasting purposes especially in generic algorithms.  Using reshape is one option but inserting an axis requires constructing tuple indicating the new shape.  This can often be tedious exercise.  Thus NumPy arrays offer special syntax for inserting new axes by indexing.  We use the special np. newaxis attribute along with full slices to insert the new axis In 95 arr np. zeros4 In 96 arr3d arr np. newaxis In 97 arr3d. shape Out97 In 98 arr1d np. random. normalsize3 In 99 arrid np. newaxis In 100 arridnp. newaxis Out99 Out100 array0. 3899 0. 396 0. 1852 Broadcasting 365 array0. 3899 0. 396 0. 1852 Full array shape Axis Axis axis Figure 127.  Compatible 2D array shapes for broadcasting over 3D array Thus if we had threedimensional array and wanted to demean axis say we would only need to write In 101 arr randn3 In 102 depthmeans arr. mean2 In 103 depthmeans Out103 array 0. 1097 0. 3118 0. 5473 0. 2663 0. 1747 0. 1379 0. 1146 0. 4224 0. 0217 0. 3686 0. 0468 1. 3026 In 104 demeaned arr depthmeans np. newaxis In 105 demeaned. mean2 Out105 array 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  If youre completely confused by this dont worry.  With practice you will get the hang of it 366 Chapter 12 Advanced NumPy Some readers might wonder if theres way to generalize demeaning over an axis without sacrificing performance.  There is in fact but it requires some indexing gymnastics def demeanaxisarr axis0 means arr. meanaxis This generalized things like np. newaxis to dimensions indexer sliceNone arr. ndim indexeraxis np. newaxis return arr means indexer Setting Array Values by Broadcasting The same broadcasting rule governing arithmetic operations also applies to setting values via array indexing.  In the simplest case we can do things like In 106 arr np. zeros4 In 107 arr 108 aucthane array 5.  5.  5. 5 5. 5 5. 5 5. 5 55 5. 5 However if we had onedimensional array of values we wanted to set into the columns of the array we can do that as long as the shape is compatible In 109 col np. array1. 28 0. 42 0. 44 1. 6 In 110 arr col np. newaxis In 111 arr Out111 array 1. 28 1. 28 1. 28 0. 42 0. 42 0. 42 0. 44 0. 44 0. 44 1. 6 1. 6 1. 6 In 112 arr2 1. 37 0. 509 In 113 arr Out 113 array1. 37 1. 37 1. 37 0. 509 0. 509 0. 509 0. 44 0. 44 0. 44 1. 6 1. 6 1. 6 Advanced ufunc Usage While many NumPy users will only make use of the fast elementwise operations pro vided by the universal functions there are number of additional features that occa sionally can help you write more concise code without loops.  Advanced ufunc Usage 367 ufunc Instance Methods Each of NumPys binary ufuncs has special methods for performing certain kinds of special vectorized operations.  These are summarized in Table 122 but ll give few concrete examples to illustrate how they work.  reduce takes single array and aggregates its values optionally along an axis by per forming sequence of binary operations.  For example an alternate way to sum ele ments in an array is to use np. add.  reduce In 114 arr np. arange10 In 115 np. add. reducearr Out115 45 In 116 arr. sum Out116 45 The starting value for add depends on the ufunc.  If an axis is passed the reduction is performed along that axis.  This allows you to answer certain kinds of questions in concise way.  As less trivial example we can use np.  logicaland to check whether the values in each row of an array are sorted In 118 arr randn5 In 119 arr2. sort1 sort few rows In 120 arr arr Out120 array True True True True False True False False True True True True True False True True True True True True dtypebool In 121 np. logicaland. reducearr arr axis1 Out121 array True False True False True dtypebool Of course logicaland. reduce is equivalent to the all method.  accumulate is related to reduce like cumsum is related to sum.  It produces an array of the same size with the intermediate accumulated values In 122 arr np. arange15. reshape3 In 123 Out123 np. add. accumulatearr axis1 array 10 11 18 26 35 10 21 33 46 60 outer performs pairwise crossproduct between two arrays In 124 arr np. arange3. repeat1 368 Chapter 12 Advanced NumPy In 125 arr Out125 array0 In 126 np. multiply. outerarr np. arange5 Out 126 array0 The output of outer will have dimension that is the sum of the dimensions of the inputs In 127 result np. subtract. outerrandn3 randn5 In 128 result. shape Out128 The last method reduceat performs local reduce in essence an array groupby op eration in which slices of the array are aggregated together.  While its less flexible than the GroupBy capabilities in pandas it can be very fast and powerful in the right cir cumstances.  It accepts sequence of bin edges which indicate how to split and ag gregate the values In 129 arr np. arange10 In 130 np. add. reduceatarr Out130 array10 18 17 The results are the reductions here sums performed over arr05 arr58 and arr8.  Like the other methods you can pass an axis argument In 131 arr np. multiply. outernp. arange4 np. arange5 In 132 arr In 133 np. add. reduceatarr axis1 Out 132 Out 133 array ol array 10 12 15 12 Table 122.  ufunc methods Method Description reducex Aggregate values by successive applications of the operation accumulatex Aggregate values preserving all partial aggregates reduceatx bins Local reduce or group by.  Reduce contiguous slices of data to produce aggregated array.  outerx Apply operation to all pairs of elements in and y.  Result array has shape x.  shape y.  shape Advanced ufunc Usage 369 Custom ufuncs There are couple facilities for creating your own functions with ufunclike semantics.  numpy.  frompyfunc accepts Python function along with specification for the number of inputs and outputs.  For example simple function that adds elementwise would be specified as In 134 def addelementsx severe return In 135 add them np. frompyfuncaddelements In 136 addthemnp. arange8 np. arange8 Out136 array0 10 12 14 dtypeobject Functions created using frompyfunc always return arrays of Python objects which isnt very convenient.  Fortunately there is an alternate but slightly less featureful function numpy. vectorize that is bit more intelligent about type inference In 137 addthem np. vectorizeaddelements otypesnp. float64 In 138 addthemnp. arange8 np. arange8 Out138 array 0.  2.  4.  6.  8.  10.  12.  14.  These functions provide way to create ufunclike functions but they are very slow because they require Python function call to compute each element which is lot slower than NumPys Cbased ufunc loops In 139 arr randn10000 In 140 timeit addthemarr arr 100 loops best of 2. 12 ms per loop In 141 timeit np. addarr arr 100000 loops best of 11. 6 us per loop There are number of projects under way in the scientific Python community to make it easier to define new ufuncs whose performance is closer to that of the builtin ones.  Structured and Record Arrays You may have noticed up until now that ndarray is homogeneous data container that is it represents block of memory in which each element takes up the same number of bytes determined by the dtype.  On the surface this would appear to not allow you to represent heterogeneous or tabularlike data.  structured array is an ndarray in which each element can be thought of as representing struct in hence the struc tured name or row in SQL table with multiple named fields In 142 dtype np. float4 np. int32 In 143 sarr np. array1. 5 np. pi dtypedtype 370 Chapter 12 Advanced NumPy In 144 sarr Out 144 array1. 5 3. 141592653589793 dtypex f8 id There are several ways to specify structured dtype see the online NumPy documen tation.  One typical way is as list of tuples with fieldname fielddatatype.  Now the elements of the array are tuplelike objects whose elements can be accessed like dictionary In 145 sarro Out145 1. 5 In 146 sarroy Out146 The field names are stored in the dtype. names attribute.  On accessing field on the structured array strided view on the data is returned thus copying nothing In 147 sarrx Out147 array 1. 5 3. 1416 Nested dtypes and Multidimensional Fields When specifying structured dtype you can additionally pass shape as an int or tuple In 148 dtype np. int64 np. int32 In 149 arr np. zeros4 dtypedtype In 150 arr Out150 array0 dtypex i8 Cy i4 In this case the field now refers to an array of length three for each record In 151 arrox Out151 array0 Conveniently accessing arrx then returns twodimensional array instead of onedimensional array as in prior examples In 152 arrx Out152 array0 This enables you to express more complicated nested structures as single block of memory in an array.  Though since dtypes can be arbitrarily complex why not nested dtypes Here is simple example Structured and Record Arrays 371 153 dtype f8 f4 Cy np. int32 In 154 data np. array1 dtypedtype In 155 datax Out155 array1. 0 2. 0 3. 0 4. 0 dtypea f8 f4 In 156 datay Out156 array5 dtypeint32 In 157 dataxa Out157 array 1.  3.  As you can see variableshape fields and nested records is very rich feature that can be the right tool in certain circumstances.  DataFrame from pandas by contrast does not support this feature directly though it is similar to hierarchical indexing.  Why Use Structured Arrays Compared with say DataFrame from pandas NumPy structured arrays are com paratively lowlevel tool.  They provide means to interpreting block of memory as tabular structure with arbitrarily complex nested columns.  Since each element in the array is represented in memory as fixed number of bytes structured arrays provide very fast and efficient way of writing data to and from disk including memory maps more on this later transporting it over the network and other such use.  As another common use for structured arrays writing data files as fixed length record byte streams is common way to serialize data in and code which is commonly found in legacy systems in industry.  As long as the format of the file is known the size of each record and the order byte size and data type of each element the data can be read into memory using np.  fromfile.  Specialized uses like this are beyond the scope of this book but its worth knowing that such things are possible.  Structured Array Manipulations numpy. lib. recfunctions While there is not as much functionality available for structured arrays as for Data Frames the NumPy module numpy. 1lib. recfunctions has some helpful tools for adding and dropping fields or doing basic joinlike operations.  The thing to remember with these tools is that it is typically necessary to create new array to make any moditfica tions to the dtype like adding or dropping column.  These functions are left to the interested reader to explore as do not use them anywhere in this book.  372 Chapter 12 Advanced NumPy More About Sorting Like Pythons builtin list the ndarray sort instance method is an inplace sort meaning that the array contents are rearranged without producing new array In 158 arr randn6 In 159 arr. sort In 160 arr Out160 array1. 082 0. 3759 0. 8014 1. 1397 1. 2888 1. 8413 When sorting arrays inplace remember that if the array is view on different ndarray the original array will be modified In 161 arr randn3 In 162 arr Out 162 array0. 3318 1. 4711 0. 8705 0. 0847 1. 1329 1. 0111 0. 3436 2. 1714 0. 1234 0. 0189 0. 1773 0. 7424 0. 8548 1. 038 0. 329 In 163 arr 0. sort Sort first column values inplace In 164 arr Out164 array1. 0111 1. 4711 0. 8705 0. 0847 1. 1329 0. 3318 0. 3436 2. 1714 0. 1234 0. 0189 0. 1773 0. 7424 0. 8548 1. 038 0. 329 On the other hand numpy. sort creates new sorted copy of an array.  Otherwise it accepts the same arguments such as kind more on this below as ndarray. sort In 165 arr randn5 In 166 arr Out166 array1. 1181 0. 2415 2. 0051 0. 7379 1. 0614 In 167 np. sortarr Out167 array2. 0051 1. 1181 1. 0614 0. 2415 0. 7379 In 168 arr Out168 array1. 1181 0. 2415 2. 0051 0. 7379 1. 0614 All of these sort methods take an axis argument for sorting the sections of data along the passed axis independently In 169 arr randn3 In 170 arr Out 170 array 0. 5955 0. 2682 1. 3389 0. 1872 0. 9111 0. 3215 1. 0054 0. 5168 1. 1925 0. 1989 0. 3969 1. 7638 0. 6071 0. 2222 0. 2171 More About Sorting 373 In 171 arr. sortaxis1 In 172 arr Out172 array0. 2682 0. 1872 0. 5955 0. 9111 1. 3389 0. 5168 0. 3215 0. 1989 1. 0054 1. 1925 1. 7638 0. 2222 0. 2171 0. 3969 0. 6071 You may notice that none of the sort methods have an option to sort in descending order.  This is not actually big deal because array slicing produces views thus not producing copy or requiring any computational work.  Many Python users are familiar with the trick that for list values values1 returns list in reverse order.  The same is true for ndarrays In 173 arr Out 173 array 1. 3389 0. 9111 0. 5955 0. 1872 0. 2682 1. 1925 1. 0054 0. 1989 0. 3215 0. 5168 0. 6071 0. 3969 0. 2171 0. 2222 1. 7638 Indirect Sorts argsort and lexsort In data analysis its very common to need to reorder data sets by one or more keys.  For example table of data about some students might need to be sorted by last name then by first name.  This is an example of an indirect sort and if youve read the pandas related chapters you have already seen many higherlevel examples.  Given key or keys an array or values or multiple arrays of values you wish to obtain an array of integer indices refer to them colloquially as indexers that tells you how to reorder the data to be in sorted order.  The two main methods for this are argsort and numpy. lexsort.  As trivial example In 174 values np. array5 In 175 indexer values. argsort 176 indexer 176 array1 177 valuesindexer 177 array0 As less trivial example this code reorders 2D array by its first row In 178 arr randn3 In 179 arr0 values In 180 arr Out180 array 5.  0.  1.  3.  2.  0. 3636 0. 1378 2. 1777 0. 4728 0. 8356 0. 2089 0. 2316 0. 728 1. 3918 1. 9956 374 Chapter 12 Advanced NumPy In 181 arr arr0. argsort Out 181 array 0.  1.  2.  3.  5s 0. 1378 2. 1777 0. 8356 0. 4728 0. 3636 0. 2316 0. 728 1. 9956 1. 3918 0. 2089 lexsort is similar to argsort but it performs an indirect lexicographical sort on multiple key arrays.  Suppose we wanted to sort some data identified by first and last names In 182 firstname np. arrayBob Jane Steve Bill Barbara In 183 lastname np. arrayJones Arnold Arnold Jones Walters In 184 sorter np. lexsortfirstname lastname In 185 ziplastnamesorter firstnamesorter Out 185 Arnold Jane Arnold Steve Jones Bill Jones Bob Walters Barbara lexsort can be bit confusing the first time you use it because the order in which the keys are used to order the data starts with the last array passed.  As you can see lastname was used before firstname.  Va pandas methods like Seriess and DataFrames sortindex methods and the Series order method are implemented with variants of these func tions which also must take into account missing values Alternate Sort Algorithms stable sorting algorithm preserves the relative position of equal elements.  This can be especially important in indirect sorts where the relative ordering is meaningful In 186 values np. array2first 2second 1first 1second 1third In 187 key np. array2 In 188 indexer key. argsortkindmergesort In 189 indexer Out189 array2 In 190 values. takeindexer Out190 array1first 1second 1third 2first 2second dtypeS8 The only stable sort available is mergesort which has guaranteed On log performance for complexity buffs but its performance is on average worse than the default More About Sorting 375 quicksort method.  See Table 123 for summary of available methods and their relative performance and performance guarantees.  This is not something that most users will ever have to think about but useful to know that its there.  Table 123.  Array sorting methods Kind Speed Stable Workspace Worstcase quicksort NC On2 mergesort Yes n2 On log heapsort No On log At the time of this writing sort algorithms other than quicksort are not tay available on arrays of Python objects dtypeobject.  This means occa sionally that algorithms requiring stable sorting will require work arounds when dealing with Python objects.  numpy. searchsorted Finding elements in Sorted Array searchsorted is an array method that performs binary search on sorted array re turning the location in the array where the value would need to be inserted to maintain sortedness In 191 arr np. array0 12 15 In 192 arr. searchsorted9 Out192 As you might expect you can also pass an array of values to get an array of indices back In 193 arr. searchsorted0 11 16 Out193 array0 You might have noticed that searchsorted returned for the element.  This is because the default behavior is to return the index at the left side of group of equal values In 194 arr np. array0 In 195 arr. searchsorted0 Out195 array0 In 196 arr. searchsorted0 sideright Out196 array3 As another application of searchsorted suppose we had an array of values between and 10000 and separate array of bucket edges that we wanted to use to bin the data In 197 data np. floornp. random. uniform0 10000 size50 In 198 bins np. array0 100 1000 5000 10000 In 199 data 376 Chapter 12 Advanced NumPy Out199 array 8304.  4181.  9352.  4907.  3250.  8546.  2673.  6152.  2774.  5130.  9553.  4997.  1794.  9688.  426.  1612.  651.  8653.  1695.  4764.  1052.  4836.  8020.  3479.  1513.  5872.  8992.  7656.  4764.  5383.  2319.  4280.  4150.  8601.  3946.  9904.  7286.  9969.  6032.  4574.  8480.  4298.  2708.  7358.  6439.  7916.  3899.  9182.  871.  7973.  To then get labeling of which interval each data point belongs to where would mean the bucket 100 we can simply use searchsorted In 200 labels bins. searchsorteddata In 201 labels Out201 array4 This combined with pandass groupby can be used to easily bin data In 202 Seriesdata. groupbylabels . mean Out202 649 .  333333 3411. 521739 7935 . 041667 Note that NumPy actually has function digitize that computes this bin labeling In 203 np. digitizedata bins Out 203 array4 35 35 35 35 NumPy Matrix Class Compared with other languages for matrix operations and linear algebra like MAT LAB Julia and GAUSS NumPys linear algebra syntax can often be quite verbose.  One reason is that matrix multiplication requires using numpy. dot.  Also NumPys indexing semantics are different which makes porting code to Python less straightforward at times.  Selecting single row e. g.  X1 or column e. g.  from 2D array yields 1D array compared with 2D array as in say MATLAB.  In 204 np. array 8. 82768214 3. 82222409 1. 14276475 2. 04411587 weeee 3. 82222409 6. 75272284 0. 83909108 2. 08293758 soneed 1. 14276475 0. 83909108 5. 01690521 0. 79573241 wwesed 2. 04411587 2. 08293758 0. 79573241 6. 24095859 In 205 onedimensional Out205 array 8. 8277 3. 8222 1. 1428 2. 0441 In 206 twodimensional by slicing NumPy Matrix Class 377 In 207 Out 207 array 8. 8277 3. 8222 1. 1428 2. 0441 In 208 Out 208 array 8. 8277 3. 8222 1. 1428 2. 0441 3. 8222 6. 7527 0. 8391 2. 0829 1. 1428 2. 0441 0. 8391 2. 0829 5. 0169 0. 7957 0. 7957 6. 241 In this case the product would be expressed like so In 209 np. doty. T np. dotX Out209 array 1195. 468 To aid in writing code with lot of matrix operations NumPy has matrix class which has modified indexing behavior to make it more MATLABlike single rows and col umns come back twodimensional and multiplication with is matrix multiplication.  The above operation with numpy. matrix would look like In 210 Xm In 211 ym Xm In 212 Xm Out212 matrix 8. 8277 3. 8222 1. 1428 2. 0441 In 213 ym Out 213 matrix 8. 8277 3. 8222 1. 1428 3. 8222 6. 7527 0. 8391 2. 0829 2. 0441 In 214 ym. T Xm ym Out214 matrix 1195. 468 np. matrixX 1. 1428 2. 0441 0. 8391 2. 0829 5. 0169 0. 7957 0. 7957 6. 241 matrix also has special attribute which returns the matrix inverse In 215 Xm. I Out 215 matrix 1.  0.  Oss ds 0.  0.  0.  0.  eevee rROoOOO es moe ee VY BR ve ev 378 Chapter 12 Advanced NumPy do not recommend using numpy. matrix as replacement for regular ndarrays because they are generally more seldom used.  In individual functions with lots of linear algebra it may be helpful to convert the function argument to matrix type then cast back to regular arrays with np. asarray which does not copy any data before returning them.  Advanced Array Input and Output In Chapter Iintroduced you to np.  save and np.  load for storing arrays in binary format on disk.  There are number of additional options to consider for more sophisticated use.  In particular memory maps have the additional benefit of enabling you to work with data sets that do not fit into RAM.  Memorymapped Files memorymapped file is method for treating potentially very large binary data on disk as an inmemory array.  NumPy implements memmap object that is ndarraylike enabling small segments of large file to be read and written without reading the whole array into memory.  Additionally amemmap has the same methods as an inmemory array and thus can be substituted into many algorithms where an ndarray would be expected.  To create new memmap use the function np. memmap and pass file path dtype shape and file mode In 216 mmap np. memmapmymmap dtypefloat64 modew shape10000 10000 In 217 mmap Out 217 memmap 0.  0.  0.  . .  O.  0.  0O.  0.  0.  0.  . . .  0.  0O.  O.  0.  0.  0.  . . .  0O.  0O.  O.  wey 0.  0.  0.  . . .  0.  0O.  O.  0.  0.  0.  . . .  0.  0O.  O.  0.  0.  0.  . . .  0.  O.  0.  Slicing memmap returns views on the data on disk In 218 section mmap5 If you assign data to these it will be buffered in memory like Python file object but can be written to disk by calling flush In 219 section np. random. randn5 10000 In 220 mmap. flush In 221 mmap Out221 memmap0. 1614 0. 1768 0. 422 . . .  0. 2195 0. 1256 0. 4012 0. 4898 2. 2219 0. 7684 . . .  2. 3517 1. 0782 1. 3208 0. 6875 1. 6901 0. 7444 . . .  1. 4218 0. 0509 1. 2224 Advanced Array Input and Output 379 OF yay OF 85 OF 0.  OF . 0 OF . 645 In 222 del mmap Whenever memory map falls out of scope and is garbagecollected any changes will be flushed to disk also.  When opening an existing memory map you still have to specify the dtype and shape as the file is just block of binary data with no metadata on disk In 223 mmap np. memmapmymmap dtypefloat64 shape10000 10000 In 224 mmap Out 224 memmap0. 1614 0. 1768 0. 422 . . .  0. 2195 0. 1256 0. 4012 0. 4898 2. 2219 0. 7684 . . .  2. 3517 1. 0782 1. 3208 0. 6875 1. 6901 0. 7444 . . .  1. 4218 0. 0509 1. 2224 0.  0.  yp eeey OD O.  0.  0.  0.  0.  yp eeey OD O.  0.  OF yee OF Since memory map is just an ondisk ndarray there are no issues using structured dtype as described above.  HDF5 and Other Array Storage Options PyTables and h5py are two Python projects providing NumPyfriendly interfaces for storing array data in the efficient and compressible HDF5 format HDF stands for hierarchical data format.  You can safely store hundreds of gigabytes or even terabytes of data in HDF5 format.  The use of these libraries is unfortunately outside the scope of the book.  PyTables provides rich facility for working with structured arrays with advanced querying features and the ability to add column indexes to accelerate queries.  This is very similar to the table indexing capabilities provided by relational databases.  Performance Tips Getting good performance out of code utilizing NumPy is often straightforward as array operations typically replace otherwise comparatively extremely slow pure Python loops.  Here is brief list of some of the things to keep in mind Convert Python loops and conditional logic to array operations and boolean array operations Use broadcasting whenever possible Avoid copying data using array views slicing Utilize ufuncs and ufunc methods oo Chapter 12 Advanced NumPy If you cant get the performance you require after exhausting the capabilities provided by NumPy alone writing code in Fortran or especially Cython see bit more on this below may be in order.  personally use Cython httpcython. org heavily in my own work as an easy way to get Clike performance with minimal development.  The Importance of Contiguous Memory While the full extent of this topic is bit outside the scope of this book in some ap plications the memory layout of an array can significantly affect the speed of compu tations.  This is based partly on performance differences having to do with the cache hierarchy of the CPU operations accessing contiguous blocks of memory for example summing the rows of order array will generally be the fastest because the memory subsystem will buffer the appropriate blocks of memory into the ultrafast L1 or L2 CPU cache.  Also certain code paths inside NumPys codebase have been optimized for the contiguous case in which generic strided memory access can be avoided.  To say that an arrays memory layout is contiguous means that the elements are stored in memory in the order that they appear in the array with respect to Fortran column major or row major ordering.  By default NumPy arrays are created as Ccontigu ous or just simply contiguous.  column major array such as the transpose of contiguous array is thus said to be Fortrancontiguous.  These properties can be ex plicitly checked via the flags attribute on the ndarray In 227 arrc np. ones1000 1000 orderC In 228 arrf np. ones1000 1000 orderF In 229 arrc. flags In 230 arrf. flags Out229 Out 230 CCONTIGUOUS True CCONTIGUOUS False FCONTIGUOUS False FCONTIGUOUS True OWNDATA True OWNDATA True WRITEABLE True WRITEABLE True ALIGNED True ALIGNED True UPDATEIFCOPY False UPDATEIFCOPY False In 231 arrf. flags. f contiguous Out231 True In this example summing the rows of these arrays should in theory be faster for arrc than arrf since the rows are contiguous in memory.  Here check for sure using timeit in Python In 232 timeit arrc. sum1 1000 loops best of 1. 33 ms per loop In 233 timeit arrf. sum1 100 loops best of 8. 75 ms per loop Performance Tips 381 When looking to squeeze more performance out of NumPy this is often place to invest some effort.  If you have an array that does not have the desired memory order you can use copy and pass either or In 234 arrf. copyC. flags Out 234 CONTIGUOUS True FCONTIGUOUS False OWNDATA True WRITEABLE True ALIGNED True UPDATEIFCOPY False When constructing view on an array keep in mind that the result is not guaranteed to be contiguous In 235 arrc50. flags. contiguous In 236 arrc 50. flags Out235 True Out 236 CCONTIGUOUS False FCONTIGUOUS False OWNDATA False WRITEABLE True ALIGNED True UPDATEIFCOPY False Other Speed Options Cython f2py In recent years the Cython project httpcython. org has become the tool of choice for many scientific Python programmers for implementing fast code that may need to interact with or libraries but without having to write pure code.  You can think of Cython as Python with static types and the ability to interleave functions im plemented in into Pythonlike code.  For example simple Cython function to sum the elements of onedimensional array might look like from numpy cimport ndarray float4 def sumelementsndarrayfloat64 arr cdef Py ssize lenarr cdef float64t result for in rangen result arri return result Cython takes this code translates it to then compiles the generated code to create Python extension.  Cython is an attractive option for performance computing because the code is only slightly more timeconsuming to write than pure Python code and it integrates closely with NumPy.  common workflow is to get an algorithm working in Python then translate it to Cython by adding type declarations and handful of other tweaks.  For more see the project documentation.  382 Chapter 12 Advanced NumPy Some other options for writing high performance code with NumPy include f2py wrapper generator for Fortran 77 and 90 code and writing pure extensions.  Performance Tips 383 APPENDIX Python Language Essentials Knowledge is treasure but practice is the key to it.  Thomas Fuller People often ask me about good resources for learning Python for datacentric appli cations.  While there are many excellent Python language books am usually hesitant to recommend some of them as they are intended for general audience rather than tailored for someone who wants to load in some data sets do some computations and plot some of the results.  There are actually couple of books on scientific program ming in Python but they are geared toward numerical computing and engineering applications solving differential equations computing integrals doing Monte Carlo simulations and various topics that are more mathematicallyoriented rather than be ing about data analysis and statistics.  As this is book about becoming proficient at working with data in Python think it is valuable to spend some time highlighting the most important features of Pythons builtin data structures and libraries from the per spective of processing and manipulating structured and unstructured data.  As such will only present roughly enough information to enable you to follow along with the rest of the book.  This chapter is not intended to be an exhaustive introduction to the Python language but rather biased nofrills overview of features which are used repeatedly throughout this book.  For new Python programmers recommend that you supplement this chap ter with the official Python tutorial httpdocs. python. org and potentially one of the many excellent and much longer books on general purpose Python programming.  In my opinion it is not necessary to become proficient at building good software in Python to be able to productively do data analysis.  encourage you to use Python to experi ment with the code examples and to explore the documentation for the various types functions and methods.  Note that some of the code used in the examples may not necessarily be fullyintroduced at this point.  Much of this book focuses on high performance arraybased computing tools for work ing with large data sets.  In order to use those tools you must often first do some munging to corral messy data into more nicely structured form.  Fortunately Python is one of 385 the easiesttouse languages for rapidly whipping your data into shape.  The greater your facility with Python the language the easier it will be for you to prepare new data sets for analysis.  The Python Interpreter Python is an interpreted language.  The Python interpreter runs program by executing one statement at time.  The standard interactive Python interpreter can be invoked on the command line with the python command python Python 2. 7. 2 default Oct 2011 09 GCC 4. 6. 1 on linux2 Type help copyright credits or license for more information.  a5 print The you see is the prompt where youll type expressions.  To exit the Python inter preter and return to the command prompt you can either type exit or press Ctr1D.  Running Python programs is as simple as calling python with .  py file as its first argu ment.  Suppose we had created hello world. py with these contents print Hello world This can be run from the terminal simply as python hello world. py Hello world While many Python programmers execute all of their Python code in this way many scientific Python programmers make use of IPython an enhanced interactive Python interpreter.  Chapter is dedicated to the Python system.  By using the run command IPython executes the code in the specified file in the same process enabling you to explore the results interactively when its done.  ipython Python 2. 7. 2 EPD 7. 12 64bit default Jul 2011 51 Type copyright credits or license for more information.  IPython 0. 12 An enhanced Interactive Python.  Introduction and overview of IPythons features.  quickref Quick reference.  help Pythons own help system.  object Details about object use object for extra details.  In run hello world. py Hello world In 386 Appendix Python Language Essentials The default Python prompt adopts the numbered In style compared with the standard prompt.  The Basics Language Semantics The Python language design is distinguished by its emphasis on readability simplicity and explicitness.  Some people go so far as to liken it to executable pseudocode.  Indentation not braces Python uses whitespace tabs or spaces to structure code instead of using braces as in many other languages like Java and Perl.  Take the for loop in the above quicksort algorithm for in array if pivot less. appendx else greater . appendx colon denotes the start of an indented code block after which all of the code must be indented by the same amount until the end of the block.  In another language you might instead have something like for in array if pivot less.  appendx else greater . appendx One major reason that whitespace matters is that it results in most Python code looking cosmetically similar which means less cognitive dissonance when you read piece of code that you didnt write yourself or wrote in hurry year ago.  In language without significant whitespace you might stumble on some differently formatted code like for in array if pivot less.  appendx else greater . appendx The Basics 387 Love it or hate it significant whitespace is fact of life for Python programmers and in my experience it helps make Python code lot more readable than other languages Ive used.  While it may seem foreign at first suspect that it will grow on you after while.  strongly recommend that you use spaces to as your default indenta tion and that your editor replace tabs with spaces.  Many text editors via have setting that will replace tab stops with spaces automatically do this.  Some people use tabs or different number of spaces with spaces not being terribly uncommon.  spaces is by and large the stan dard adopted by the vast majority of Python programmers so recom mend doing that in the absence of compelling reason otherwise.  As you can see by now Python statements also do not need to be terminated by sem icolons.  Semicolons can be used however to separate multiple statements on single line a5 b6 c7 Putting multiple statements on one line is generally discouraged in Python as it often makes code less readable.  Everything is an object An important characteristic of the Python language is the consistency of its object model.  Every number string data structure function class module and so on exists in the Python interpreter in its own box which is referred to as Python object.  Each object has an associated type for example string or function and internal data.  In practice this makes the language very flexible as even functions can be treated just like any other object.  Comments Any text preceded by the hash mark pound sign is ignored by the Python interpreter.  This is often used to add comments to code.  At times you may also want to exclude certain blocks of code without deleting them.  An easy solution is to comment out the code results for line in file handle keep the empty lines for now if lenline continue results. appendline. replacefoo bar 388 Appendix Python Language Essentials Function and object method calls Functions are called using parentheses and passing zero or more arguments optionally assigning the returned value to variable result fx Almost every object in Python has attached functions known as methods that have access to the objects internal contents.  They can be called using the syntax obj. somemethodx Functions can take both positional and keyword arguments result fa d5 efoo More on this later.  Variables and passbyreference When assigning variable or name in Python you are creating reference to the object on the right hand side of the equals sign.  In practical terms consider list of integers In 241 Suppose we assign to new variable In 242 ba In some languages this assignment would cause the data to be copied.  In Python and actually now refer to the same object the original list see Figure A1 for mockup.  You can prove this to yourself by appending an element to and then examining In 243 a. append4 In 244 Out244 list eee Figure A1.  Two references for the same object Understanding the semantics of references in Python and when how and why data is copied is especially critical when working with larger data sets in Python.  The Basics 389 Assignment is also referred to as binding as we are binding name to an object.  Variables names that have been assigned may occasionally be 12 referred to as bound variables.  When you pass objects as arguments to function you are only passing references no copying occurs.  Thus Python is said to pass by reference whereas some other languages support both pass by value creating copies and pass by reference.  This means that function can mutate the internals of its arguments.  Suppose we had the following func tion def appendelementsomelist element somelist. appendelement Then given whats been said this should not come as surprise In data In append elementdata In data Out4 Dynamic references strong types In contrast with many compiled languages such as Java and object references in Python have no type associated with them.  There is no problem with the following In 245 a5 In 246 typea Out246 int In 247 foo In 248 typea Out248 str Variables are names for objects within particular namespace the type information is stored in the object itself.  Some observers might hastily conclude that Python is not typed language.  This is not true consider this example In 249 TypeError Traceback most recent call last ipythoninput249f9dbf5f0b234 in module woo 45 TypeError cannot concatenate str and int objects In some languages such as Visual Basic the string might get implicitly converted or casted to an integer thus yielding 10.  Yet in other languages such as JavaScript the integer might be casted to string yielding the concatenated string 55.  In this regard Python is considered stronglytyped language which means that every object has specific type or class and implicit conversions will occur only in certain obvious circumstances such as the following 390 Appendix Python Language Essentials In 250 4. 5 In 251 String formatting to be visited later In 252 print is is typea typeb is type float is type int In 253 Out 253 2. 25 Knowing the type of an object is important and its useful to be able to write functions that can handle many different kinds of input.  You can check that an object is an instance of particular type using the isinstance function In 254 a5 In 255 isinstancea int Out255 True isinstance can accept tuple of types if you want to check that an objects type is among those present in the tuple In 256 53 4. 5 In 257 isinstancea int float In 258 isinstanceb int float Out257 True Out258 True Attributes and methods Objects in Python typically have both attributes other Python objects stored inside the object and methods functions associated with an object which can have access to the objects internal data.  Both of them are accessed via the syntax obj.  attributename In foo In a. Tab a. capitalize a. format a. isupper a. rindex a. strip a. center a. index a. join a. rjust a.  swapcase a. count a. isalnum a. ljust a. rpartition a. title a. decode a. isalpha a.  lower a. rsplit a. translate a. encode a. isdigit a. lstrip a. rstrip a. upper a. endswith a. islower a. partition a. split a. zfill a. expandtabs a. isspace a. replace a. splitlines a.  find a. istitle a. rfind a. startswith Attributes and methods can also be accessed by name using the getattr function getattra split function split While we will not extensively use the functions getattr and related functions hasattr and setattr in this book they can be used very effectively to write generic reusable code.  The Basics 391 Duck typing Often you may not care about the type of an object but rather only whether it has certain methods or behavior.  For example you can verify that an object is iterable if it imple mented the iterator protocol.  For many objects this means it has iter magic method though an alternative and better way to checkis to try using the iter function def isiterableobj try iter obj return True except TypeError not iterable return False This function would return True for strings as well as most Python collection types In 260 isiterablea string In 261 isiterable1 Out260 True Out261 True In 262 isiterable5 Out 262 False place where use this functionality all the time is to write functions that can accept multiple kinds of input.  common case is writing function that can accept any kind of sequence list tuple ndarray or even an iterator.  You can first check if the object is list or NumPy array and if it is not convert it to be one if not isinstancex list and isiterablex listx Imports In Python module is simply py file containing function and variable definitions along with such things imported from other .  py files.  Suppose that we had the following module somemodule.  py PI 3. 14159 def fx return def ga return If we wanted to access the variables and functions defined in somemodule. py from another file in the same directory we could do import somemodule result somemodule. f5 pi somemodule. PI Or equivalently from somemodule import PI result g5 PI 392 Appendix Python Language Essentials By using the as keyword you can give imports different variable names import somemodule as sm from somemodule import PI as pi as gf x1 sm. fpi r2 gf6 pi Binary operators and comparisons Most of the binary math operations and comparisons are as you might expect In 263 57 In 264 12 21. 5 Out 263 Out 264 33. 5 In 265 Out265 False See Table A1 for all of the available binary operators.  To check if two references refer to the same object use the is keyword.  is not is also perfectly valid if you want to check that two objects are not the same In 266 In 267 ba Note the list function always creates new list In 268 lista 269 is In 270 is not 269 True Out270 True Out Note this is not the same thing is comparing with because in this case we have 271 Cc 271 True Out very common use of is and is not is to check if variable is None since there is only one instance of None In 272 None In 273 is None Out273 True Table A1.  Binary operators Operation Description atb Add andb ab Subtract froma ab Multiply by ab Divide by ab Floordivide by dropping any fractional remainder The Basics 393 Operation Description Raise to the power ab True if both and are True.  For integers take the bitwise AND.  True if either or is True.  For integers take the bitwise OR.  ab For booleans True if or is True but not both.  For integers take the bitwise EXCLUSIVEOR.  True if equals True if is not equal to Trueifais less than less than or equal to ab Trueifais greater than greater than or equal to ais True if and reference same Python object is not True if and reference different Python objects Strictness versus laziness When using any programming language its important to understand when expressions are evaluated.  Consider the simple expression abce5 dabc iW In Python once these statements are evaluated the calculation is immediately or strictly carried out setting the value of to 30.  In another programming paradigm such as in pure functional programming language like Haskell the value of might not be evaluated until it is actually used elsewhere.  The idea of deferring computations in this way is commonly known as lazy evaluation.  Python on the other hand is very strict or eager language.  Nearly all of the time computations and expressions are evaluated immediately.  Even in the above simple expression the result of is computed as separate step before adding it to a.  There are Python techniques especially using iterators and generators which can be used to achieve laziness.  When performing very expensive computations which are only necessary some of the time this can be an important technique in dataintensive ap plications.  Mutable and immutable objects Most objects in Python are mutable such as lists dicts NumPy arrays or most user defined types classes.  This means that the object or values that they contain can be modified.  In 274 alist foo In 275 alist2 In 276 alist Out276 foo 394 Appendix Python Language Essentials Others like strings and tuples are immutable In 277 atuple In 278 atuple1 four TypeError Traceback most recent call last ipythoninput278b7966a9ae0f1 in module atuple1 four TypeError tuple object does not support item assignment Remember that just because you can mutate an object does not mean that you always should.  Such actions are known in programming as side effects.  For example when writing function any side effects should be explicitly communicated to the user in the functions documentation or comments.  If possible recommend trying to avoid side effects and favor immutability even though there may be mutable objects involved.  Scalar Types Python has small set of builtin types for handling numerical data strings boolean True or False values and dates and time.  See Table A2 for list of the main scalar types.  Date and time handling will be discussed separately as these are provided by the datetime module in the standard library.  Table A2.  Standard Python Scalar Types Type Description None The Python null value only one instance of the None object exists str String type.  ASCllvalued only in Python 2. x and Unicode in Python unicode Unicode string type float Doubleprecision 64bit floating point number.  Note there is no separate doub1e type.  bool True or False value int Signed integer with maximum value determined by the platform.  long Arbitrary precision signed integer.  Large int values are automatically converted to long.  Numeric types The primary Python types for numbers are int and float.  The size of the integer which can be stored as an int is dependent on your platform whether 32 or 64bit but Python will transparently convert very large integer to long which can store arbitrarily large integers.  In 279 ival 17239871 In 280 ival Out280 26254519291092456596965462913230729701102721L The Basics 395 Floating point numbers are represented with the Python float type.  Under the hood each one is doubleprecision 64 bits value.  They can also be expressed using scien tific notation In 281 fval 7. 243 In 282 fval2 6. 78e5 In Python integer division not resulting in whole number will always yield floating point number In 284 Out284 1. 5 In Python 2. 7 and below which some readers will likely be using you can enable this behavior by default by putting the following crypticlooking statement at the top of your module from future import division Without this in place you can always explicitly convert the denominator into floating point number In 285 float2 Out 285 1. 5 To get Cstyle integer division which drops the fractional part if the result is not whole number use the floor division operator In 286 Out286 Complex numbers are written using for the imaginary part In 287 cval 2j In 288 cval Out288 507 Strings Many people use Python for its powerful and flexible builtin string processing capa bilities.  You can write string literal using either single quotes or double quotes one way of writing string another way For multiline strings with line breaks you can use triple quotes either or ez This is longer string that spans multiple lines Python strings are immutable you cannot modify string without creating new string 396 Appendix Python Language Essentials In 289 this is string In 290 a10 TypeError Traceback most recent call last ipythoninput2905ca625d1e504 in module a10 TypeError str object does not support item assignment In 291 a. replacestring longer string In 292 Out292 this is longer string Many Python objects can be converted to string using the str function In 293 5. 6 In 294 stra In 295 Out295 5. 6 Strings are sequence of characters and therefore can be treated like other sequences such as lists and tuples In 296 python In 297 lists Out297 ps hl In 298 s3 Out298 pyt The backslash character is an escape character meaning that it is used to specify special characters like newline or unicode characters.  To write string literal with backslashes you need to escape them In 299 1234 In 300 print 1234 If you have string with lot of backslashes and no special characters you might find this bit annoying.  Fortunately you can preface the leading quote of the string with which means that the characters should be interpreted as is In 301 rthishasnospecialcharacters In 302 Out302 thishasnospecialcharacters Adding two strings together concatenates them and produces new string In 303 this is the first half In 304 and this is the second half In 305 ab Out305 this is the first half and this is the second half The Basics 397 String templating or formatting is another important topic.  The number of ways to do so has expanded with the advent of Python here will briefly describe the mechanics of one of the main interfaces.  Strings with followed by one or more format characters is target for inserting value into that string this is quite similar to the printf function in C.  As an example consider this string In 306 template . 2f are worth In this string means to format an argument as string .  number with decimal places and an integer.  To substitute arguments for these format parameters use the binary operator with tuple of values In 307 template 4. 5560 Argentine Pesos Out307 4. 56 Argentine Pesos are worth String formatting is broad topic there are multiple methods and numerous options and tweaks available to control how values are formatted in the resulting string.  To learn more recommend you seek out more information on the web.  discuss general string processing as it relates to data analysis in more detail in Chap ter.  Booleans The two boolean values in Python are written as True and False.  Comparisons and other conditional expressions evaluate to either True or False.  Boolean values are com bined with the and and or keywords In 308 True and True Out308 True In 309 False or True Out309 True Almost all builtin Python tops and any class defining the nonzero magic method have True or False interpretation in an if statement In 310 weeeet ifa wenn ed print found something found something In 311 . . eee if not acuea of print Empty Most objects in Python have notion of true or falseness.  For example empty se quences lists dicts tuples etc.  are treated as False if used in control flow as above with the empty list b.  You can see exactly what boolean value an object coerces to by invoking bool on it 398 Appendix Python Language Essentials In 312 bool bool1 Out312 False True In 313 boolHello world bool Out313 True False In 314 bool0 bool1 Out314 False True Type casting The str bool int and float types are also functions which can be used to cast values to those types In 315 3. 14159 In 316 fval floats In 317 typefval Out317 float In 318 intfval In 319 boolfval In 320 bool0 Out 318 Out319 True Out320 False None None is the Python null value type.  If function does not explicitly return value it implicitly returns None.  In 321 None In 322 is None Out322 True In 323 b5 In 324 is not None Out324 True None is also common default value for optional function arguments def addandmaybemultiplya cNone result ab if is not None result result return result While technical point its worth bearing in mind that None is not reserved keyword but rather unique instance of NoneType.  Dates and times The builtin Python datetime module provides datetime date and time types.  The datetime type as you may imagine combines the information stored in date and time and is the most commonly used In 325 from datetime import datetime date time In 326 dt datetime2011 10 29 20 30 21 The Basics 399 In 327 dt. day In 328 dt. minute Out327 29 Out328 30 Given datetime instance you can extract the equivalent date and time objects by calling methods on the datetime of the same name In 329 dt. date In 330 dt. time Out329 datetime. date2011 10 29 Out330 datetime. time20 30 21 The strftime method formats datetime as string In 331 dt. strftimemdY HM Out331 10292011 Strings can be converted parsed into datetime objects using the strptime function In 332 datetime. strptime20091031 Ymd Out332 datetime. datetime2009 10 31 See Table 102 for full list of format specifications.  When aggregating or otherwise grouping time series data it will occasionally be useful to replace fields of series of datetimes for example replacing the minute and second fields with zero producing new object In 333 dt. replaceminute0 second0 Out 333 datetime. datetime2011 10 29 20 The difference of two datetime objects produces datetime.  timedelta type In 334 dt2 datetime2011 11 15 22 30 In 335 delta dt2 dt 336 delta In 337 typedelta 336 datetime. timedelta17 7179 Out337 datetime. timedelta Adding timedelta to datetime produces new shifted datetime 338 dt 338 datetime. datetime2011 10 29 20 30 21 339 dt delta 339 datetime. datetime2011 11 15 22 30 Control Flow if elif and else The if statement is one of the most wellknown control flow statement types.  It checks condition which if True evaluates the code in the block that follows if print Its negative 400 Appendix Python Language Essentials An if statement can be optionally followed by one or more elif blocks and catchall else block if all of the conditions are False if print Its negative elif print Equal to zero elif 0x print Positive but smaller than else print Positive and larger than or equal to If any of the conditions is True no further elif or else blocks will be reached.  With compound condition using and or or conditions are evaluated lefttoright and will short circuit In 340 b7 In 341 In 342 if bor cd werey print Made it In this example the comparisonc never gets evaluated because the first comparison was True.  for loops for loops are for iterating over collection like list or tuple or an iterater.  The standard syntax for for loop is for value in collection do something with value for loop can be advanced to the next iteration skipping the remainder of the block using the continue keyword.  Consider this code which sums up integers in list and skips None values sequence None None total for value in sequence if value is None continue total value for loop can be exited altogether using the break keyword.  This code sums elements of the list until is reached sequence totaluntil5 for value in sequence if value break totaluntil5 value The Basics 401 As we will see in more detail if the elements in the collection or iterator are sequences tuples or lists say they can be conveniently unpacked into variables in the for loop statement for in iterator do something while loops while loop specifies condition and block of code that is to be executed until the condition evaluates to False or the loop is explicitly ended with break xX 256 total while if total 500 break total xx2 pass pass is the noop statement in Python.  It can be used in blocks where no action is to be taken it is only required because Python uses whitespace to delimit blocks if print negative elif TODO put something smart here pass else print positive Its common to use pass as placeholder in code while working on new piece of functionality def fx TODO implement this function pass Exception handling Handling Python errors or exceptions gracefully is an important part of building robust programs.  In data analysis applications many functions only work on certain kinds of input.  As an example Pythons float function is capable of casting string to floating point number but fails with ValueError on improper inputs In 343 float1. 2345 Out 343 1. 2345 In 344 floatsomething ValueError Traceback most recent call last ipythoninput344439904410854 in module 402 Appendix Python Language Essentials floatsomething ValueError could not convert string to float something Suppose we wanted version of float that fails gracefully returning the input argu ment.  We can do this by writing function that encloses the call to float in try except block def attemptfloatx try return floatx except return The code in the except part of the block will only be executed if floatx raises an exception In 346 attemptfloat1. 2345 Out 346 1. 2345 In 347 attemptfloatsomething Out347 something You might notice that float can raise exceptions other than ValueError In 348 float1 TypeError Traceback most recent call last ipythoninput348842079ebb635 in module float1 TypeError float argument must be string or number You might want to only suppress ValueError since TypeError the input was not string or numeric value might indicate legitimate bug in your program.  To do that write the exception type after except def attemptfloatx try return floatx except ValueError return We have then In 350 attemptfloat1 TypeError Traceback most recent call last ipythoninput3509bdfd730cead in module attemptfloat1 ipythoninput3493e06b8379b6b in attemptfloatx def attemptfloatx try return floatx except ValueError return TypeError float argument must be string or number The Basics 403 You can catch multiple exception types by writing tuple of exception types instead the parentheses are required def attemptfloatx try return floatx except TypeError ValueError return In some cases you may not want to suppress an exception but you want some code to be executed regardless of whether the code in the try block succeeds or not.  To do this use finally openpath try write tofilef finally f. close Here the file handle will always get closed.  Similarly you can have code that executes only if the try block succeeds using else openpath try write tofilef except print Failed else print Succeeded finally f. close range and xrange The range function produces list of evenlyspaced integers In 352 range10 Out352 Both start end and step can be given In 353 range0 20 Out353 10 12 14 16 18 As you can see range produces integers up to but not including the endpoint.  com mon use of range is for iterating through sequences by index seq for in rangelenseq val seqi For very long ranges its recommended to use xrange which takes the same arguments as range but returns an iterator that generates integers one by one rather than generating 404 Appendix Python Language Essentials all of them upfront and storing them in potentially very large list.  This snippet sums all numbers from to 9999 that are multiples of or sum for in xrange10000 is the modulo operator if or x5 sum In Python range always returns an iterator and thus it is not necessary to use the xrange function Ternary Expressions ternary expression in Python allows you combine an ifelse block which produces value into single line or expression.  The syntax for this in Python is value trueexpr if condition else falseexpr Here trueexpr and falseexpr can be any Python expressions.  It has the identical effect as the more verbose if condition value trueexpr else value falseexpr This is more concrete example In 354 In 355 Nonnegative if else Negative Out355 Nonnegative As with ifelse blocks only one of the expressions will be evaluated.  While it may be tempting to always use ternary expressions to condense your code realize that you may sacrifice readability if the condition as well and the true and false expressions are very complex.  Data Structures and Sequences Pythons data structures are simple but powerful.  Mastering their use is critical part of becoming proficient Python programmer.  Data Structures and Sequences 405 Tuple tuple is onedimensional fixedlength immutable sequence of Python objects.  The easiest way to create one is with commaseparated sequence of values In 356 tup In 357 tup Out357 When defining tuples in more complicated expressions its often necessary to enclose the values in parentheses as in this example of creating tuple of tuples In 358 nested tup 359 nestedtup 359 75 Any sequence or iterator can be converted to tuple by invoking tuple In 360 tuple4 Out360 In 361 tup tuplestring 362 tup 362 th ry ny Elements can be accessed with square brackets as with most other sequence types.  Like Java and many other languages sequences are 0indexed in Python In 363 tupo Out 363 While the objects stored in tuple may be mutable themselves once created its not possible to modify which object is stored in each slot In 364 tup tuplefoo True In 365 tup2 False TypeError Traceback most recent call last ipythoninput365c7308343b841 in module tup2 False TypeError tuple object does not support item assignment however In 366 tup1. append3 In 367 tup Out367 foo True Tuples can be concatenated using the operator to produce longer tuples In 368 None foo bar Out368 None foo bar 406 Appendix Python Language Essentials Multiplying tuple by an integer as with lists has the effect of concatenating together that many copies of the tuple.  In 369 foo bar Out369 foo bar foo bar foo bar foo bar Note that the objects themselves are not copied only the references to them.  Unpacking tuples If you try to assign to tuplelike expression of variables Python will attempt to un pack the value on the righthand side of the equals sign In 370 tup 55 In 371 tup Even sequences with nested tuples can be unpacked In 373 tup In 374 tup Using this functionality its easy to swap variable names task which in many lan guages might look like tro ll tmp aab One of the most common uses of variable unpacking when iterating over sequences of tuples or lists seq for in seq pass Another common use is for returning multiple values from function.  More on this later.  Tuple methods Since the size and contents of tuple cannot be modified it is very light on instance methods.  One particularly useful one also available on lists is count which counts the number of occurrences of value In 376 Data Structures and Sequences 407 In 377 a. count2 Out377 List In contrast with tuples lists are variablelength and their contents can be modified.  They can be defined using square brackets or using the list type function In 378 alist None In 379 tup foo bar baz In 380 blist listtup In 381 blist Out381 foo bar baz In 382 blist1 peekaboo In 383 blist Out383 foo peekaboo baz Lists and tuples are semantically similar as onedimensional sequences of objects and thus can be used interchangeably in many functions.  Adding and removing elements Elements can be appended to the end of the list with the append method In 384 blist. append dwarf In 385 blist Out385 foo peekaboo baz dwarf Using insert you can insert an element at specific location in the list In 386 blist. insert1 red In 387 blist Out387 foo red peekaboo baz dwarf insert is computationally expensive compared with append as references ta to subsequent elements have to be shifted internally to make room for the new element.  The inverse operation to insert is pop which removes and returns an element at particular index In 388 blist. pop2 Out388 peekaboo In 389 blist Out389 foo red baz dwarf Elements can be removed by value using remove which locates the first such value and removes it from the last 408 Appendix Python Language Essentials In 390 blist. appendfoo In 391 blist. removefoo In 392 blist Out392 red baz dwarf foo If performance is not concern by using append and remove Python list can be used as perfectly suitable multiset data structure.  You can check if list contains value using the in keyword In 393 dwarf in list Out393 True Note that checking whether list contains value is lot slower than dicts and sets as Python makes linear scan across the values of the list whereas the others based on hash tables can make the check in constant time.  Concatenating and combining lists Similar to tuples adding two lists together with concatenates them In 394 None foo Out394 None foo If you have list already defined you can append multiple elements to it using the extend method In 395 None foo In 396 x. extend7 In 397 Out397 None foo Note that list concatenation is compartively expensive operation since new list must be created and the objects copied over.  Using extend to append elements to an existing list especially if you are building up large list is usually preferable.  Thus everything for chunk in listoflists everything.  extendchunk is faster than than the concatenative alternative everything for chunk in listoflists everything everything chunk Sorting list can be sorted inplace without creating new object by calling its sort function In 398 Data Structures and Sequences 409 In 399 a. sort In 400 Out400 sort has few options that will occasionally come in handy.  One is the ability to pass secondary sort key i. e.  function that produces value to use to sort the objects.  For example we could sort collection of strings by their lengths In 401 saw small He foxes six In 402 b. sortkeylen In 403 Out403 He saw six small foxes Binary search and maintaining sorted list The builtin bisect module implements binarysearch and insertion into sorted list.  bisect. bisect finds the location where an element should be inserted to keep it sorted while bisect. insort actually inserts the element into that location In 404 import bisect In 405 In 406 bisect. bisectc In 407 bisect. bisectc Out406 Out407 In 408 bisect. insortc In 409 Out409 The bisect module functions do not check whether the list is sorted as ta doing so would be computationally expensive.  Thus using them with an unsorted list will succeed without error but may lead to incorrect results.  Slicing You can select sections of listlike types arrays tuples NumPy arrays by using slice notation which in its basic form consists of start stop passed to the indexing operator In 410 seq In 411 seq15 Out411 Slices can also be assigned to with sequence In 412 seq34 410 Appendix Python Language Essentials In 413 seq Out413 While element at the start index is included the stop index is not included so that the number of elements in the result is stop start.  Either the start or stop can be omitted in which case they default to the start of the sequence and the end of the sequence respectively In 414 seq5 In 415 seq3 Out414 Out415 Negative indices slice the sequence relative to the end In 416 seq4 In 417 seq62 Out416 Out417 Slicing semantics takes bit of getting used to especially if youre coming from or MATLAB.  See Figure A2 for helpful illustrating of slicing with positive and negative integers.  step can also be used after second colon to say take every other element In 418 seq2 Out418 clever use of this is to pass which has the useful effect of reversing list or tuple In 419 seq1 Out419 pu fete fefofe string24 string52 Figure A2.  Illustration of Python slicing conventions Builtin Sequence Functions Python has handful of useful sequence functions that you should familiarize yourself with and use at any opportunity.  Data Structures and Sequences 411 enumerate Its common when iterating over sequence to want to keep track of the index of the current item.  doityourself approach would look like i0 for value in collection do something with value it1 Since this is so common Python has builtin function enumerate which returns sequence of value tuples for value in enumeratecollection do something with value When indexing data useful pattern that uses enumerate is computing dict mapping the values of sequence which are assumed to be unique to their locations in the sequence In 420 somelist foo bar baz In 421 mapping dictv for in enumeratesomelist In 422 mapping Out422 bar baz foo sorted The sorted function returns new sorted list from the elements of any sequence In 423 sorted7 Out423 In 424 sortedhorse race Out 424 Gy re ry common pattern for getting sorted list of the unique elements in sequence is to combine sorted with set In 425 sortedsetthis is just some string Out 425 mS ny Org Ss tty zip zip pairs up the elements of number of lists tuples or other sequences to create list of tuples In 426 seq1 foo bar baz In 427 seq2 one two three In 428 zipseq1 seq2 Out428 foo one bar two baz three 412 Appendix Python Language Essentials zip can take an arbitrary number of sequences and the number of elements it produces is determined by the shortest sequence In 429 seq3 False True In 430 zipseq1 seq2 seq3 Out430 foo one False bar two True very common use of zip is for simultaneously iterating over multiple sequences possibly also combined with enumerate In 431 for in enumeratezipseqi seq2 worewed printd baz three Given zipped sequence zip can be applied in clever way to unzip the sequence.  Another way to think about this is converting list of rows into list of columns.  The syntax which looks bit magical is In 432 pitchers Nolan Ryan Roger Clemens Saale Schilling Curt In 433 firstnames lastnames zippitchers In 434 firstnames Out434 Nolan Roger Schilling In 435 lastnames Out435 Ryan Clemens Curt Well look in more detail at the use of in function call.  It is equivalent to the fol lowing zipseq0 seq1 . . .  seqlenseq reversed reversed iterates over the elements of sequence in reverse order In 436 listreversedrange10 Out436 Dict dict is likely the most important builtin Python data structure.  Amore common name for it is hash map or associative array.  It is flexiblysized collection of keyvalue pairs where key and value are Python objects.  One way to create one is by using curly braces and using colons to separate keys and values In 437 empty dict In 438 d1 some value Data Structures and Sequences 413 In 439 d1 Out439 some value Elements can be accessed and inserted or set using the same syntax as accessing ele ments of list or tuple In 440 d17 an integer In 441 da Out441 an integer some value In 442 dab Out442 You can check if dict contains key using the same syntax as with checking whether list or tuple contains value In 443 in d1 Out443 True Values can be deleted either using the del keyword or the pop method which simulta neously returns the value and deletes the key In 444 d15 some value In 445 dadummy another value In 446 del d15 In 447 ret d1. popdummy In 448 ret Out448 another value The keys and values method give you lists of the keys and values respectively.  While the keyvalue pairs are not in any particular order these functions output the keys and values in the same order In 449 d1. keys In 450 d1. values Out449 Out450 some value an integer If youre using Python dict. keys and dict. values are iterators tay instead of lists.  One dict can be merged into another using the update method In 451 di. updateb foo 12 In 452 d1 Out452 an integer some value foo 12 414 Appendix Python Language Essentials Creating dicts from sequences Its common to occasionally end up with two sequences that you want to pair up ele mentwise in dict.  As first cut you might write code like this mapping for key value in zipkeylist valuelist mapping key value Since dict is essentially collection of 2tuples it should be no shock that the dict type function accepts list of 2tuples In 453 mapping dictziprange5 reversedrange5 In 454 mapping Out454 Ina later section well talk about dict comprehensions another elegant way to construct dicts.  Default values Its very common to have logic like if key in some dict value somedictkey else value defaultvalue Thus the dict methods get and pop can take default value to be returned so that the above ifelse block can be written simply as value somedict. getkey defaultvalue get by default will return None if the key is not present while pop will raise an exception.  With setting values common case is for the values in dict to be other collections like lists.  For example you could imagine categorizing list of words by their first letters as dict of lists In 455 words apple bat bar atom book In 456 byletter In 457 for word in words sees letter word0 wenn ed if letter not in by letter soneed byletterletter word ecomned else soneed byletterletter. appendword In 458 byletter Out458 apple atom bat bar book The setdefault dict method is for precisely this purpose.  The ifelse block above can be rewritten as Data Structures and Sequences 415 byletter. setdefaultletter . appendword The builtin collections module has useful class defaultdict which makes this even easier.  One is created by passing type or function for generating the default value for each slot in the dict from collections import defaultdict byletter defaultdictlist for word in words byletterword0. appendword The initializer to defaultdict only needs to be callable object e. g.  any function not necessarily type.  Thus if you wanted the default value to be you could pass function returning counts defaultdictlambda Valid dict key types While the values of dict can be any Python object the keys have to be immutable objects like scalar types int float string or tuples all the objects in the tuple need to be immutable too.  The technical term here is hashability.  You can check whether an object is hashable can be used as key in dict with the hash function In 459 hashstring Out459 9167918882415130555 In 460 hash1 Out460 1097636502276347782 In 461 hash1 fails because lists are mutable TypeError Traceback most recent call last ipythoninput461800cd14ba8be in module hash1 fails because lists are mutable TypeError unhashable type list To use list as key an easy fix is to convert it to tuple In 462 In 463 dtuple1 In 464 Out464 Set set is an unordered collection of unique elements.  You can think of them like dicts but keys only no values.  set can be created in two ways via the set function or using set literal with curly braces In 465 set2 Out465 set1 416 Appendix Python Language Essentials In 466 Out466 set1 Sets support mathematical set operations like union intersection difference and sym metric difference.  See Table A3 for list of commonly used set methods.  In In In Out In Out In Out In Out 467 468 469 469 470 470 471 471 472 472 union or set1 intersection and set3 ab difference set1 symmetric difference xor set1 You can also check if set is subset of is contained in or superset of contains all elements of another set In In Out In Out 473 474 474 475 475 aset 3. issubsetaset True aset. issuperset1 True As you might guess sets are equal if their contents are equal In 476 Out476 True Table A3.  Python Set Operations Function Alternate Syntax Description a. addx NA Add element to the set a. removex NA Remove element from the set a. unionb All of the unique elements in and b.  a. intersectionb ab All of the elements in both and b.  a. differenceb ab The elements in that are not in b.  a. symmetricdifferenceb ab All of the elements in or but not both.  a. issubsetb NA Txue if the elements of are all contained in b.  a. issupersetb NA Txue if the elements of are all contained in a.  a. isdisjointb NA True if and have no elements in common.  Data Structures and Sequences 417 List Set and Dict Comprehensions List comprehensions are one of the mostloved Python language features.  They allow you to concisely form new list by filtering the elements of collection and transforming the elements passing the filter in one conscise expression.  They take the basic form expr for val in collection if condition This is equivalent to the following for loop result for val in collection if condition result. appendexpr The filter condition can be omitted leaving only the expression.  For example given list of strings we could filter out strings with length or less and also convert them to uppercase like this In 477 strings as bat car dove python In 478 x. upper for in strings if lenx Out478 BAT CAR DOVE PYTHON Set and dict comprehensions are natural extension producing sets and dicts in idiomatically similar way instead of lists.  dict comprehension looks like this dictcomp keyexpr valueexpr for value in collection if condition set comprehension looks like the equivalent list comprehension except with curly braces instead of square brackets setcomp expr for value in collection if condition Like list comprehensions set and dict comprehensions are just syntactic sugar but they similarly can make code both easier to write and read.  Consider the list of strings above.  Suppose we wanted set containing just the lengths of the strings contained in the collection this could be easily computed using set comprehension In 479 uniquelengths lenx for in strings In 480 uniquelengths Out480 set1 As asimple dict comprehension example we could create lookup map of these strings to their locations in the list In 481 locmapping val index for index val in enumeratestrings In 482 locmapping Out482 as bat car dove python Note that this dict could be equivalently constructed by locmapping dictval idx for idx val in enumeratestrings 418 Appendix Python Language Essentials The dict comprehension version is shorter and cleaner in my opinion.  Va Dict and set comprehensions were added to Python fairly recently in 43 Python 2. 7 and Python 3. 1.  Le As Nested list comprehensions Suppose we have list of lists containing some boy and girl names In 483 alldata Tom Billy Jefferson Andrew Wesley Steven Joe aaa Susie Casey Jill Ana Eva Jennifer Stephanie You might have gotten these names from couple of files and decided to keep the boy and girl names separate.  Now suppose we wanted to get single list containing all names with two or more es in them.  We could certainly do this with simple for loop names of interest for names in all data enoughes name for name in names if name. counte namesofinterest. extendenough es You can actually wrap this whole operation up in single nested list comprehension which will look like In 484 result name for names in all data for name in names setae if name. counte In 485 result Out485 Jefferson Wesley Steven Jennifer Stephanie At first nested list comprehensions are bit hard to wrap your head around.  The for parts of the list comprehension are arranged according to the order of nesting and any filter condition is put at the end as before.  Here is another example where we flatten list of tuples of integers into simple list of integers In 486 sometuples In 487 flattened for tup in sometuples for in tup In 488 flattened Out488 Keep in mind that the order of the for expressions would be the same if you wrote nested for loop instead of list comprehension flattened for tup in sometuples for in tup flattened.  appendx Data Structures and Sequences 419 You can have arbitrarily many levels of nesting though if you have more than two or three levels of nesting you should probably start to question your data structure design.  Its important to distinguish the above syntax from list comprehension inside list comprehension which is also perfectly valid In 229 for in tup for tup in some tuples Functions Functions are the primary and most important method of code organization and reuse in Python.  There may not be such thing as having too many functions.  In fact would argue that most programmers doing data analysis dont write enough functions As you have likely inferred from prior examples functions are declared using the def keyword and returned from using the return keyword def myfunctionx z1. 5 if 41 return else return There is no issue with having multiple return statements.  If the end of function is reached without encountering return statement None is returned.  Each function can have some number of positional arguments and some number of keyword arguments.  Keyword arguments are most commonly used to specify default values or optional arguments.  In the above function and are positional arguments while is keyword argument.  This means that it can be called in either of these equivalent ways my function5 z0. 7 my function3. 14 3. 5 The main restriction on function arguments it that the keyword arguments must follow the positional arguments if any.  You can specify keyword arguments in any order this frees you from having to remember which order the function arguments were specified in and only what their names are.  Namespaces Scope and Local Functions Functions can access variables in two different scopes global and local.  An alternate and more descriptive name describing variable scope in Python is namespace.  Any variables that are assigned within function by default are assigned to the local name space.  The local namespace is created when the function is called and immediately populated by the functions arguments.  After the function is finished the local name space is destroyed with some exceptions see section on closures below.  Consider the following function 420 Appendix Python Language Essentials def func for in range5 a. appendi Upon calling func the empty list is created elements are appended then is destroyed when the function exits.  Suppose instead we had declared def func for in range5 a. appendi Assigning global variables within function is possible but those variables must be declared as global using the global keyword In 489 None In 490 def binda variable ecesene global In 491 print generally discourage people from using the global keyword frequently.  tay Typically global variables are used to store some kind of state in sys tem.  If you find yourself using lot of them its probably sign that some objectoriented programming using classes is in order.  Functions can be declared anywhere and there is no problem with having local func tions that are dynamically created when function is called def outerfunctionx def innerfunctiona pass pass In the above code the innerfunction will not exist until outerfunction is called.  As soon as outerfunction is done executing the innerfunction is destroyed.  Nested inner functions can access the local namespace of the enclosing function but they cannot bind new variables in it.  Pll talk bit more about this in the section on closures.  In strict sense all functions are local to some scope that scope may just be the module level scope.  Functions 421 Returning Multiple Values When first programmed in Python after having programmed in Java and one of my favorite features was the ability to return multiple values from function.  Heres simple example def a5 c7 return In data analysis and other scientific applications you will likely find yourself doing this very often as many functions may have multiple outputs whether those are data struc tures or other auxiliary data computed inside the function.  If you think about tuple packing and unpacking from earlier in this chapter you may realize that whats hap pening here is that the function is actually just returning one object namely tuple which is then being unpacked into the result variables.  In the above example we could have done instead returnvalue In this case returnvalue would be as you may guess 3tuple with the three returned variables.  potentially attractive alternative to returning multiple values like above might be to return dict instead def a5 c7 return Functions Are Objects Since Python functions are objects many constructs can be easily expressed that are difficult to do in other languages.  Suppose we were doing some data cleaning and needed to apply bunch of transformations to the following list of strings states Alabama Georgia Georgia georgia FlOrIda south carolina West virginia Anyone who has ever worked with usersubmitted survey data can expect messy results like these.  Lots of things need to happen to make this list of strings uniform and ready for analysis whitespace stripping removing punctuation symbols and proper capital ization.  As first pass we might write some code like import re Regular expression module def cleanstringsstrings result 422 Appendix Python Language Essentials for value in strings value value. strip value re. sub value remove punctuation value value. title result. appendvalue return result The result looks like this In 15 cleanstringsstates Out15 Alabama Georgia Georgia Georgia Florida South Carolina West Virginia An alternate approach that you may find useful is to make list of the operations you want to apply to particular set of strings def removepunctuationvalue return re. sub value cleanops str. strip remove punctuation str. title def cleanstringsstrings ops result for value in strings for function in ops value functionvalue result. appendvalue return result Then we have In 22 cleanstringsstates cleanops Out 22 Alabama Georgia Georgia Georgia Florida South Carolina West Virginia more functional pattern like this enables you to easily modify how the strings are transformed at very high level.  The cleanstrings function is also now more reusable You can naturally use functions as arguments to other functions like the builtin map function which applies function to collection of some kind In 23 mapremovepunctuation states Out 23 Alabama Georgia Functions 423 Georgia georgia FlOrIda south carolina West virginia Anonymous lambda Functions Python has support for socalled anonymous or lambda functions which are really just simple functions consisting of single statement the result of which is the return value.  They are defined using the lambda keyword which has no meaning other than we are declaring an anonymous function.  def shortfunctionx return equivanon lambda usually refer to these as lambda functions in the rest of the book.  They are especially convenient in data analysis because as youll see there are many cases where data transformation functions will take functions as arguments.  Its often less typing and clearer to pass lambda function as opposed to writing fullout function declaration or even assigning the lambda function to local variable.  For example consider this silly example def apply to listsomelist return fx for in somelist ints apply to listints lambda You could also have written for in ints but here we were able to succintly pass custom operator to the applyto list function.  As another example suppose you wanted to sort collection of strings by the number of distinct letters in each string In 492 strings foo card bar aaaa abab Here we could pass lambda function to the lists sort method In 493 strings. sortkeylambda lensetlistx In 494 strings Out494 aaaa foo abab bar card Vs sO One reason lambda functions are called anonymous functions is that the function object itself is never given name attribute.  424 Appendix Python Language Essentials Closures Functions that Return Functions Closures are nothing to fear.  They can actually be very useful and powerful tool in the right circumstance In nutshell closure is any dynamicallygenerated function returned by another function.  The key property is that the returned function has access to the variables in the local namespace where it was created.  Here is very simple example def makeclosurea def closure printI know the secret return closure closure makeclosure5 The difference between closure and regular Python function is that the closure continues to have access to the namespace the function where it was created even though that function is done executing.  So in the above case the returned closure will always print know the secret whenever you call it.  While its common to create closures whose internal state in this example only the value of is static you can just as easily have mutable object like dict set or list that can be modified.  For example heres function that returns function that keeps track of arguments it has been called with def makewatcher haveseen def hasbeenseenx if in haveseen return True else haveseenx True return False return hasbeenseen Using this on sequence of integers obtain In 496 watcher makewatcher In 497 vals In 498 watcherx for in vals Out498 False False False True True True False True However one technical limitation to keep in mind is that while you can mutate any internal state objects like adding keyvalue pairs to dict you cannot bind variables in the enclosing function scope.  One way to work around this is to modify dict or list rather than binding variables def makecounter count def counter Functions 425 increment and return the current count count0 return count0o return counter counter makecounter You might be wondering why this is useful.  In practice you can write very general functions with lots of options then fabricate simpler more specialized functions.  Heres an example of creating string formatting function def formatandpadtemplate space def formatter return template x. rjustspace return formatter You could then create floating point formatter that always returns length15 string like so In 500 fmt formatandpad. 4f 15 In 501 fmt1. 756 Out501 1. 7560 If you learn more about objectoriented programming in Python you might observe that these patterns also could be implemented albeit more verbosely using classes.  Extended Call Syntax with args kwargs The way that function arguments work under the hood in Python is actually very sim ple.  When you write funca dsome evalue the positional and keyword arguments are actually packed up into tuple and dict respectively.  So the internal function receives tuple args and dict kwargs and internally does the equivalent of args kwargs. getd ddefaultvalue kwargs. gete defaultvalue This all happens nicely behind the scenes.  Of course it also does some error checking and allows you to specify some of the positional arguments as keywords also even if they arent keyword in the function declaration.  def say hello thencall ff args kwargs print args is args print kwargs is kwargs printHello Now Im going to call return fargs kwargs def gx z1 return Then if we call with say hello then call we get 426 Appendix Python Language Essentials In sayhellothencall fg z5.  args is kwargs is 5. 0 Hello Now Im going to call function at ox2dd5cf8 Out8 0. 6 Currying Partial Argument Application Currying is fun computer science term which means deriving new functions from existing ones by partial argument application.  For example suppose we had trivial function that adds two numbers together def addnumbersx return Using this function we could derive new function of one variable addfive that adds to its argument addfive lambda addnumbers5 The second argument to addnumbers is said to be curried.  Theres nothing very fancy here as we really only have defined new function that calls an existing function.  The builtin functools module can simplify this process using the partial function from functools import partial addfive partialaddnumbers When discussing pandas and time series data well use this technique to create speci alized functions for transforming data series compute 60day moving average of time series ma60 lambda pandas. rolling meanx 60 Take the 60day moving average of all time series in data data. applyma60 Generators Having consistent way to iterate over sequences like objects in list or lines in file is an important Python feature.  This is accomplished by means of the iterator proto col generic way to make objects iterable.  For example iterating over dict yields the dict keys In 502 some dict In 503 for key in somedict acerece ed print key When you write for key in some dict the Python interpreter first attempts to create an iterator out of somedict In 504 dictiterator itersomedict Functions 427 In 505 dictiterator Out 505 dictionarykeyiterator at 0x10a0a1578 Any iterator is any object that will yield objects to the Python interpreter when used in acontext like for loop.  Most methods expecting list or listlike object will also accept any iterable object.  This includes builtin methods such as min max and sum and type constructors like list and tuple In 506 listdictiterator Out506 generator is simple way to construct new iterable object.  Whereas normal func tions execute and return single value generators return sequence of values lazily pausing after each one until the next one is requested.  To create generator use the yield keyword instead of return in function def squaresn10 for in xrange1 print Generating squares from to yield When you actually call the generator no code is immediately executed In gen squares In gen Out3 generator object squares at 0x34c8280 It is not until you request elements from the generator that it begins executing its code In for in gen print Generating squares from to 100 149 16 25 36 49 64 81 100 As less trivial example suppose we wished to find all unique ways to make change for 100 cents using an arbitrary set of coins.  You can probably think of various ways to implement this and how to store the unique combinations as you come up with them.  One way is to write generator that yields lists of coins represented as integers def makechangeamount coins1 10 25 handNone hand if hand is None else hand if amount yield hand for coin in coins ensures we dont give too much change and combinations are unique if coin amount or lenhand and hand1 coin continue for result in makechangeamount coin coinscoins handhand coin yield result The details of the algorithm are not that important can you think of shorter way.  Then we can write 428 Appendix Python Language Essentials In 508 for way in makechange100 coins10 25 50 women print way 10 10 10 10 10 10 10 10 10 10 25 25 10 10 10 10 10 25 25 25 25 50 10 10 10 10 10 50 25 25 50 50 In 509 lenlistmakechange100 Out509 242 Generator expresssions simple way to make generator is by using generator expression.  This is generator analogue to list dict and set comprehensions to create one enclose what would other wise be list comprehension with parenthesis instead of brackets In 510 gen for in xrange100 In 511 gen Out511 generator object genexpr at 0x10a0a31e0 This is completely equivalent to the following more verbose generator def makegen for in xrange100 yield gen makegen Generator expressions can be used inside any Python function that will accept gen erator In 512 sumx for in xrange100 Out512 328350 In 513 dicti for in xrange5 Out513 16 itertools module The standard library itertools module has collection of generators for many common data algorithms.  For example groupby takes any sequence and function this groups consecutive elements in the sequence by return value of the function.  Heres an exam ple In 514 import itertools In 515 firstletter lambda xo In 516 names Alan Adam Wes Will Albert Steven In 517 for letter names in itertools. groupbynames firstletter arma ef print letter listnames names is generator Alan Adam Functions 429 Wes Will Albert Steven See Table A4 for list of few other itertools functions Ive frequently found useful.  Table A4.  Some useful itertools functions Function Description imapfunc iterables Generator version of the builtin map applies Func to each zipped tuple of the passed sequences.  ifilterfunc iterable Generator version of the builtin Filter yields elements for which func is True.  combinationsiterable Generates sequence of all possible ktuples of elements in the iterable ignoring order.  permutationsiterable Generates sequence of all possible ktuples of elements in the iterable respecting order.  groupbyiterable keyfunc Generates key subiterator for each unique key Va In Python several builtin functions zip map filter producing lists have been replaced by their generator versions found in itertools in Python 2.  ae ww se Files and the operating system Most of this book uses highlevel tools like pandas.  readcsv to read data files from disk into Python data structures.  However its important to understand the basics of how to work with files in Python.  Fortunately its very simple which is part of why Python is so popular for text and file munging.  To open file for reading or writing use the builtin open function with either relative or absolute file path In 518 path ch13segismundo. txt In 519 openpath By default the file is opened in readonly mode r.  We can then treat the file handle like list and iterate over the lines like so for line in pass The lines come out of the file with the endofline EOL markers intact so youll often see code to get an EOLtfree list of lines in file like In 520 lines x. rstrip for in openpath In 521 lines 430 Appendix Python Language Essentials Out 521 Suexc3xb1a el rico en su riqueza que mxc3xa1s cuidados le ofrece suexc3xb1a el pobre que padece su miseria su pobreza suexc3xb1a el que medrar empieza suexc3xb1a el que afana pretende suexc3xbi1a el que agravia ofende wt en el mundo en conclusixc3xb3n todos suexc3xb1an lo que son aunque ninguno lo entiende.  If we had typed openpath new file at ch13segismundo. txt would have been created overwriting any one in its place.  See below for list of all valid file read write modes.  Table A5.  Python file modes Mode Description Readonly mode Writeonly mode.  Creates new file deleting any file with the same name Append to existing file create it if it does not exist Read and write Add to mode for binary files that is rb or wb Use universal newline mode.  Pass by itself or appended to one of the read modes like rU To write text to file you can use either the files write or writelines methods.  For example we could create version of profmod. py with no blank lines like so In 522 with opentmp. txt as handle worewed handle. writelinesx for in openpath if lenx In 523 opentmp. txt. readlines Out 523 Suexc3xb1a el rico en su riquezan que mxc3xa1s cuidados le ofrecen suexc3xb1a el pobre que padecen su miseria su pobrezan suexc3xb1a el que medrar empieza suexc3xb1a el que afana pretenden suexc3xb1a el que agravia ofenden en el mundo en conclusixc3xb3n todos suexc3xb1an lo que sonn aunque ninguno lo entiende. n See Table A6 for many of the most commonlyused file methods.  Files and the operating system 431 Table A6.  Important Python file methods or attributes Method readsize readlinessize readlinessize writestr writelinesstrings close flush seekpos tell closed Description Return data from file as string with optional size argument indicating the number of bytes to read Return list of lines in the file with optional size argument Return list of lines as strings in the file Write passed string to file.  Write passed sequence of strings to the file.  Close the handle Flush the internal 10 buffer to disk Move to indicated file position integer.  Return current file position as integer.  True if the file is closed.  432 Appendix Python Language Essentials Symbols character 60 61 64 operator 91 cmd command 60 twolanguage problem 23 hash mark 388 PATH variable 10 character 398 datetime format 293 datetime format 293 alias magic function 61 automagic magic function 55 datetime format 293 datetime format 293 bookmark magic function 60 62 datetime format 293 cd magic function 60 cpaste magic function 5152 55 datetime format 292 datetime format 293 format character 398 debug magic function 5455 62 dhist magic function 60 dirs magic function 60 env magic function 60 datetime format 293 gui magic function 57 datetime format 292 hist magic function 55 59 datetime format 292 logstart magic function 60 logstop magic function 60 lprun magic function 70 72 datetime format 292 Index datetime format 292 magic magic function 55 datetime format 293 page magic function 55 paste magic function 51 55 pdb magic function 54 63 popd magic function 60 prun magic function 55 70 pushd magic function 60 pwd magic function 60 quickref magic function 55 reset magic function 55 59 run magic function 4950 55 386 datetime format 292 format character 398 time magic function 55 67 timeit magic function 54 67 68 datetime format 293 datetime format 292 datetime format 293 who magic function 55 whos magic function 55 whols magic function 55 datetime format 293 datetime format 293 xdel magic function 55 59 xmode magic function 54 datetime format 292 datetime format 292 datetime format 293 operator 91 operator 105 operator 406 409 2012 Federal Election Commission database example 278287 Wed like to hear your suggestions for improving our indexes.  Send email to indexoreilly. com.  433 bucketing donation amounts 283285 donation statistics by occupation and employer 280283 donation statistics by state 285287 operator 393 prompt 386 question mark 49 brackets 406 408 backslash 397 underscore 48 58 two underscores 58 braces 413 operator 91 file mode 431 abs function 96 accumulate method 368 add method 95 130 417 addpatch method 229 addsubplot method 221 aggfunc option 277 aggregate method 260 262 aggregations 100 algorithms for sorting 375376 alignment of data 330331 all method 101 368 alpha argument 233 and keyword 398 401 annotating in matplotlib 228230 anonymous functions 424 any method 101 110 201 append method 122 408 apply method 39 132 142 266268 270 apt package management tool 10 arange function 82 arccos function 96 arccosh function 96 arcsin function 96 arcsinh function 96 arctan function 96 arctanh function 96 argmax method 101 argmin method 101 139 argsort method 135 374 arithmetic 128132 operations between DataFrame and Series 130132 with fill values 129130 arrays boolean arrays 101 boolean indexing for 8992 conditional logic as operation 98100 creating 8182 creating PeriodIndex from 312 data types for 8385 fancy indexing 9293 file input and output with 103105 saving and loading text files 104105 storing on disk in binary format 103 104 finding elements in sorted array 376377 in NumPy 355362 concatenating 357359 object 359 layout of in memory 356357 replicating 360361 reshaping 355356 object 359 saving to file 379380 splitting 357359 subsets for 361362 indexes for 8689 operations between 8586 setting values by broadcasting 367 slicing 8689 sorting 101102 statistical methods for 100 structured arrays 370372 benefits of 372 mainpulating 372 nested data types 371372 swapping axes in 9394 transposing 9394 unique function 102103 where function 98100 arrow function 229 as keyword 393 asarray function 82 379 asfreq method 308 318 asof method 334336 astype method 84 85 attributes in Python 391 starting with underscore 48 average method 136 ax argument 233 axes 434 Index broadcasting over 364367 concatenating along 185188 labels for 226227 renaming indexes for 197198 swapping in arrays 9394 AxesSubplot object 221 axis argument 188 axis method 138 file mode 431 backslash 397 bar plots 235238 Basemap object 246 . bashrc file 10 bashprofile file bboxinches option 231 benefits of Python 23 glue for code solving twolanguage problem with of structured arrays 372 beta function 107 defined 342 betweentime method 335 bfill method 123 bin edges 314 binary data formats 171173 HDF5 171172 Microsoft Excel files 172173 storing arrays in 103104 binary moving window functions 324325 binary search of lists 410 binary universal functions 96 binding defined 390 variables 425 binomial function 107 bisect module 410 bookmarking directories in IPython 62 Boolean arrays 101 data type 84 398 indexing for arrays 8992 bottleneck library 324 braces 413 brackets 406 408 break keyword 401 broadcasting 362367 defined 86 360 362 over other axes 364367 setting array values by 367 bucketing 283285 calendar module 290 casting 84 cat method 156 212 Categorical object 199 ceil function 96 center method 212 Chaco 248 chisquare function 107 chunksize argument 160 161 clearing screen shortcut 53 clipboard executing code from 5052 clock function 67 close method 220 432 closures 425426 cmd. exe collections module 416 colons 387 cols option 277 columns grouping on 256257 columnstack function 359 combinations function 430 combinefirst method 177 189 combining data sources 336338 data sources with overlap 188189 lists 409 commands 65 see also magic commands debugger 65 history in IPython 5860 input and output variables 5859 logging of 5960 reusing command history 58 searching for 53 comment argument 160 comments in Python 388 compile method 208 complex128 data type 84 complex256 data type 84 complex64 data type 84 concat function 34 177 184 185 186 267 357 359 Index 435 concatenating along axis 185188 arrays 357359 conditional logic as array operation 98100 conferences 12 configuring matplotlib 231232 conforming 122 contains method 212 contiguous memory 381382 continue keyword 401 continuous return 348 convention argument 314 converting between string and datetime 291293 timestamps to periods 311 coordinated universal time UTC 303 copy argument 181 copy method 118 copysign function 96 corr method 140 correlation 139141 corrwith method 140 cos function 96 cosh function 96 count method 139 206 212 261 407 Counter class 21 cov method 140 covariance 139141 CPython crosssection 329 crosstab function 277278 crowdsourcing 241 CSV files 163165 242 CtrlA keyboard shortcut 53 CtrlB keyboard shortcut 53 CtrlC keyboard shortcut 53 CtrlE keyboard shortcut 53 CtrlF keyboard shortcut 53 CtrlK keyboard shortcut 53 CtrlL keyboard shortcut 53 CtrlN keyboard shortcut 53 CtrlP keyboard shortcut 53 CtrlR keyboard shortcut 53 CtrlShiftV keyboard shortcut 53 CtrlU keyboard shortcut 53 cummax method 139 cummin method 139 cumprod method 100 139 cumsum method 100 139 cumulative returns 338340 currying 427 cursor moving with keyboard 53 custom universal functions 370 cut function 199 200 201 268 283 Cython project 382383 object 359 data aggregation 259264 returning data in unindexed form 264 using multiple functions 262264 data alignment 128132 arithmetic methods with fill values 129 130 operations between DataFrame and Series 130132 data munging 329340 asof method 334336 combining data 336338 for data alignment 330331 for specialized frequencies 332334 data structures for pandas 112121 DataFrame 115120 Index objects 120121 Panel 152154 Series 112115 data types for arrays 8385 for ndarray 8385 for NumPy 353354 hierarchy of 354 for Python 395400 boolean data type 398 dates and times 399400 None data type 399 numeric data types 395396 str data type 396398 type casting in 399 for time series data 290293 converting between string and datetime 291293 nested 371372 data wrangling manipulating strings 205211 methods for 206207 vectorized string methods 210211 with regular expressions 207210 merging data 177189 436 Index combining data with overlap 188189 concatenating along axis 185188 DataFrame merges 178181 on index 182184 pivoting 192193 reshaping 190191 transforming data 194205 discretization 199201 dummy variables 203205 filtering outliers 201202 mapping 195196 permutation 202 removing duplicates 194195 renaming axis indexes 197198 replacing values 196197 USDA food database example 212217 databases reading and writing to 174176 DataFrame data structure 22 27 112 115 120 arithmetic operations between Series and 130132 hierarchical indexing using 150151 merging data with 178181 dates and times 291 see also time series data data types for 291 399400 date ranges 298 datetime type 291293 395 399 DatetimeIndex Index object 121 dateutil package 291 dateparser argument 160 daterange function 298 dayfirst argument 160 debug function 66 debugger Python in IPython 6266 def keyword 420 defaults profiles 77 values for dicts 415416 del keyword 59 118 414 delete method 122 delimited formats 163165 density plots 238239 describe method 138 243 267 design tips 7476 flat is better than nested 75 keeping relevant objects and data alive 75 overcoming fear of longer files 7576 det function 106 development tools in IPython 6272 debugger 6266 profiling code 6870 profiling function linebyline 7072 timing code 6768 diag function 106 dicts 413416 creating 415 default values for 415416 dict comprehensions 418420 grouping on 257258 keys for 416 returning system environment variables as 60 diff method 122 139 difference method 417 digitize function 377 directories bookmarking in IPython 62 changing commands for 60 discretization 199201 div method 130 divide function 96 . dmg file donation statistics by occupation and employer 280283 by state 285287 dot function 105 106 377 doublequote option 165 downsampling 312 dpi dotsperinch option 231 dreload function 74 drop method 122 125 dropna method 143 dropduplicates method 194 dsplit function 359 dstack function 359 dtype object see data types duck typing in Python 392 dummy variables 203205 dumps function 165 duplicated method 194 duplicates indices 296297 removing from data 194195 dynamicallygenerated functions 425 Index 437 edgecolo option 231 editcompilerun workflow 45 eig function 106 elif blocks see if statements else block see if statements empty function 82 83 empty namespace 50 encoding argument 160 endswith method 207 212 enumerate function 412 environment variables 60 EPD Enthought Python Distribution 79 equal function 96 escapechar option 165 ewma function 323 ewmcorr function 323 ewmcov function 323 ewmstd function 323 ewmvar function 323 ExcelFile class 172 except block 403 exceptions automatically entering debugger after 55 defined 402 handling in Python 402404 exec keyword 59 executeexplore workflow 45 execution time of code 55 of single statement 55 exit command 386 exp function 96 expanding window mean 322 exponentiallyweighted functions 324 extend method 409 extensible markup language XML files 169 171 eye function 83 fabs function 96 facecolor option 231 factor analysis 342343 Factor object 269 factors 342 fancy indexing defined 361 for arrays 9293 ffill method 123 figsize argument 234 Figure object 220 223 file inputoutput binary data formats for 171173 HDF5 171172 Microsoft Excel files 172173 for arrays 103105 HDF5 380 memorymapped files 379380 saving and loading text files 104105 storing on disk in binary format 103 104 in Python 430431 saving plot to file 231 text files 155171 delimited formats 163165 HTML files 166171 JSON data 165166 Ixml library 166171 reading in pieces 160162 writing to 162163 XML files 169171 with databases 174176 with Web APIs 173174 filling in missing data 145146 270271 fillna method 22 143 145 146 196 270 317 fillmethod argument 313 fillvalue option 277 filtering in pandas 125128 missing data 143144 outliers 201202 financial applications cumulative returns 338340 data munging 329340 asof method 334336 combining data 336338 for data alignment 330331 for specialized frequencies 332334 future contract rolling 347350 grouping for 340345 factor analysis with 342343 quartile analysis 343345 linear regression 350351 return indexes 338340 rolling correlation 350351 438 Index signal frontier analysis 345347 find method 206 207 findall method 167 208 210 212 finditer method 210 first crossing time 109 first method 136 261 flat is better than nested 75 flattening 356 float data type 83 354 395 396 399 float function 402 float128 data type 84 floatl6 data type 84 float32 data type 84 float64 data type 84 floor function 96 floordivide function 96 flow control 400405 exception handling 402404 for loops 401402 if statements 400401 pass statements 402 range function 404405 ternary expressions 405 while loops 402 xrange function 404405 flush method 432 fmax function 96 fmin function 96 fname option 231 for loops 85 100 401402 418 419 format option 231 frequencies 299301 converting 308 specialized frequencies 332334 week of month dates 301 frompyfunc function 370 fromcsv method 163 functions 389 420430 anonymous functions 424 are objects 422423 closures 425426 currying of 427 extended call syntax for 426 lambda functions 424 namespaces for 420421 parsing in pandas 155 returning multiple values from 422 scope of 420421 functools module 427 future contract rolling 347350 futures 347 gamma function 107 gcc command 11 generators 427430 defined 428 generator expressions 429 itertools module for 429430 get method 167 173 212 415 getattr function 391 getchunk method 162 getdummies function 203 205 getvalue method 128 getxlim method 226 GIL global interpreter lock global scope 420 421 glue for code Python as gov domain 18 Granger Brian 72 graphics Chaco 248 mayavi 249 greater function 96 greaterequal function 96 grid argument 234 group keys 268 groupby method 39 252259 297 316 343 377 429 iterating over groups 255256 on column 256257 on dict 257258 on levels 259 resampling with 316 using functions with 258259 with Series 257258 grouping 2012 Federal Election Commission database example 278287 bucketing donation amounts 283285 donation statistics by occupation and employer 280283 donation statistics by state 285287 apply method 266268 data aggregation 259264 returning data in unindexed form 264 using multiple functions 262264 Index 439 filling missing values with groupspecific values 270271 for financial applications 340345 factor analysis with 342343 quartile analysis 343345 group weighted average 273274 groupby method 252259 iterating over groups 255256 on column 256257 on dict 257258 on levels 259 using functions with 258259 with Series 257258 linear regression for 274275 pivot tables 275278 crosstabulation 277278 quantile analysis with 268269 random sampling with 271272 Haiti earthquake crisis data example 241246 halfopen 314 hasattr function 391 hash mark 388 hashability 416 HDFS5 hierarchical data format 171172 380 HDFStore class 171 header argument 160 heapsort sorting method 376 hierarchical data format HDF5 171172 380 hierarchical indexing in pandas 147151 sorting levels 149150 summary statistics by level 150 with DataFrame columns 150151 reshaping data with 190191 hist method 238 histograms 238239 history of commands searching 53 homogeneous data container 370 how argument 181 313 316 hsplit function 359 hstack function 358 HTML files 166171 HTML Notebook in IPython 72 Hunter John D.  219 hyperbolic trigonometric functions 96 icol method 128 152 IDEs Integrated Development Environments 11 52 idxmax method 138 idxmin method 138 if statements 400401 415 ifilter function 430 igetvalue method 152 ignoreindex argument 188 imap function 430 import directive in Python 392393 usage of in this book 13 imshow function 98 in keyword 409 inplace sort 373 inld method 103 indentation in Python 387388 IndentationError event 51 index method 206 207 Index objects data structure 120121 indexes defined 112 for arrays 8689 for axis 197198 for TimeSeries class 294296 hierarchical indexing 147151 reshaping data with 190191 sorting levels 149150 summary statistics by level 150 with DataFrame columns 150151 in pandas 136 integer indexing 151152 merging data on 182184 indexcol argument 160 indirect sorts 374375 374 input variables 5859 insert method 122 408 insort method 410 int data type 83 395 399 int16 data type 84 int32 data type 84 int64 data type 84 Int64Index Index object 121 int8 data type 84 integer arrays indexing using see fancy indexing 440 Index integer indexing 151152 Integrated Development Environments IDEs 1152 interpreted languages defined 386 Python interpreter 386 interrupting code 50 53 intersectld method 103 intersection method 122 417 intervals of time 289 inv function 106 inverse trigonometric functions 96 ipynb files 72 IPython bookmarking directories 62 command history in 5860 input and output variables 5859 logging of 5960 reusing command history 58 design tips 7476 flat is better than nested 75 keeping relevant objects and data alive 75 overcoming fear of longer files 7576 development tools 6272 debugger 6266 profiling code 6870 profiling function linebyline 7072 timing code 6768 executing code from clipboard 5052 HTML Notebook in 72 integration with IDEs and editors 52 integration with mathplotlib 5657 keyboard shortcuts for 52 magic commands in 5455 making classes output correctly 76 object introspection in 4849 profiles for 7778 Qt console for 55 Quick Reference Card for 55 reloading module dependencies 74 run command in 4950 shell commands in 6061 tab completion in 4748 tracebacks in 5354 ipythonconfig. py file 77 irow method 128 152 is keyword 393 isdisjoint method 417 isfinite function 96 isin method 141142 isinf function 96 isinstance function 391 isnull method 96 114 143 issubdtype function 354 issubset method 417 issuperset method 417 ismonotonic method 122 isunique method 122 iter function 392 iterating over groups 255256 iterator argument 160 iterator protocol 392 427 itertools module 429430 429 ix function 93 join method 184 206 212 JSON JavaScript Object Notation 18 165 166 213 KDE kernel density estimate plots 239 keepdatecol argument 160 kernels 239 keyvalue pairs 413 keyboard shortcuts 53 for deleting text 53 for IPython 52 KeyboardInterrupt event 50 keys argument 188 for dicts 416 method 414 keyword arguments 389 420 kind argument 234 314 kurt method 139 label argument 233 313 315 lambda functions 211 262 424 last method 261 layout of arrays in memory 356357 left argument 181 leftindex argument 181 lefton argument 181 legends in matplotlib 228 Index 441 len function 212 258 less function 96 lessequal function 96 level keyword 259 levels defined 147 grouping on 259 sorting 149150 summary statistics by 150 lexicographical sort defined 375 lexsort method 374 libraries 36 IPython matplotlib NumPy pandas 45 SciPy limit argument 313 linalg function 105 line plots 232235 linear algebra 105106 linear regression 274275 350351 lineterminator option 164 lineprofiler extension 70 Linux setting up on 1011 list comprehensions 418420 nested list comprehensions 419420 list function 408 lists 408411 adding elements to 408409 binary search of 410 combining 409 insertion into sorted 410 list comprehensions 418420 removing elements from 408409 slicing 410411 sorting 409410 just method 207 load function 103 379 load method 171 loads function 18 local scope 420 localizing time series data 304305 loffset argument 313 316 log function 96 log1p function 96 log2 function 96 logging command history in IPython 5960 logicaland function 96 logicalnot function 96 logicalor function 96 logicalxor function 96 logy argument 234 long format 192 long type 395 longer files overcoming fear of 7576 lower method 207 212 Istrip method 207 212 Istsq function 106 Ixml library 166171 mad method 139 magic methods 48 5455 main function 75 mainpulating structured arrays 372 manytomany merge 179 manytoone merge 178 map method 133 195196 211 280 423 margins 275 markers 224 match method 208212 matplotlib 219232 annotating in 228230 axis labels in 226227 configuring 231232 integrating with IPython 5657 legends in 228 saving to file 231 styling for 224225 subplots in 220224 ticks in 226227 title in 226227 matplotlibre file 232 matrix operations in NumPy 377379 max method 101 136 139 261 428 maximum function 95 96 mayavi 249 mean method 100 139 253 259 261 265 median method 139 261 memmap object 379 memory layout of arrays in 356357 memorymapped files defined 379 saving arrays to file 379380 mergesort sorting method 375 376 merging data 177189 442 Index combining data with overlap 188189 concatenating along axis 185188 DataFrame merges 178181 on index 182184 meshgrid function 97 methods defined 389 for tuples 407 in Python 389 starting with underscore 48 Microsoft Excel files 172173 mil domain 18 min method 101 136 139 261 428 minimum function 96 missing data 142146 filling in 145146 filtering out 143144 mod function 96 modf function 95 modules 392 momentum 343 MongoDB 176 MovieLens 1M data set example 2631 moving window functions 320326 binary moving window functions 324325 exponentiallyweighted functions 324 userdefined 326 mpkg file mro method 354 mul method 130 MultiIndex Index object 121 147 149 multiple profiles 77 multiply function 96 munging 13 mutable objects 394395 NA data type 143 names argument 160 188 namespaces defined 420 in Python 420421 naming trends in US baby names 18802010 example 36 43 boy names that became girl names 42 43 measuring increase in diversity 3740 revolution of last letter 4041 NaN not number 101 114 143 navalues argument 160 ncols option 223 ndarray 80 Boolean indexing 8992 creating arrays 8182 data types for 8385 fancy indexing 9293 indexes for 8689 operations between arrays 8586 slicing arrays 8689 swapping axes in 9394 transposing 9394 nested code 75 nested data types 371372 nested list comprehensions 419420 New York MTA Metropolitan Transportation Authority 169 None data type 395 399 normal function 107 110 normalized timestamps 298 NoSQL databases 176 not number NaN 101 114 143 NotebookCloud 72 notnull method 114 143 notequal function 96 . npy files 103 . npz files 104 nrows argument 160 223 nuisance column 254 numeric data types 395396 NumPy arrays in 355362 concatenating 357359 object 359 layout of in memory 356357 replicating 360361 reshaping 355356 object 359 saving to file 379380 splitting 357359 subsets for 361362 broadcasting 362367 over other axes 364367 setting array values by 367 data processing using where function 98100 data processing using arrays 97103 Index 443 conditional logic as array operation 98 100 methods for boolean arrays 101 sorting arrays 101102 statistical methods 100 unique function 102103 data types for 353354 file input and output with arrays 103105 saving and loading text files 104105 storing on disk in binary format 103 104 linear algebra 105106 matrix operations in 377379 ndarray arrays 80 Boolean indexing 8992 creating 8182 data types for 8385 fancy indexing 9293 indexes for 8689 operations between arrays 8586 slicing arrays 8689 swapping axes in 9394 transposing 9394 numpydiscussion mailing list 12 performance of 380383 contiguous memory 381382 Cython project 382383 random number generation 106107 random walks example 108110 sorting 373377 algorithms for 375376 finding elements in sorted array 376 377 indirect sorts 374375 structured arrays in 370372 benefits of 372 mainpulating 372 nested data types 371372 universal functions for 9596 367370 custom 370 in pandas 132133 instance methods for 368369 object introspection 4849 object model 388 object type 84 objectify function 166 169 objs argument 188 offsets for time series data 302303 OHLC OpenHighLowClose resampling 316 ols function 351 Olson database 303 on argument 181 ones function 82 open function 430 OpenHighLowClose OHLC resampling 316 operators in Python 393 or keyword 401 order method 375 OS setting up Python on 910 outer method 368 369 outliers filtering 201202 output variables 5859 pad method 212 pairs plot 241 pandas 45 arithmetic and data alignment 128132 arithmetic methods with fill values 129 130 operations between DataFrame and Series 130132 data structures for 112121 DataFrame 115120 Index objects 120121 Panel 152154 Series 112115 drop function 125 filtering in 125128 handling missing data 142146 filling in 145146 filtering out 143144 hierarchical indexing in 147151 sorting levels 149150 summary statistics by level 150 with DataFrame columns 150151 indexes in 136 indexing options 125128 integer indexing 151152 NumPy universal functions with 132133 plotting with 232 bar plots 235238 density plots 238239 histograms 238239 444 Index line plots 232235 scatter plots 239241 ranking data in 133135 reductions in 137142 reindex function 122124 selecting in objects 125128 sorting in 133135 summiaty Statistics in correlation and covariance 139141 isin function 141142 unique function 141142 valuecounts function 141142 usa. gov data from bit. ly example with 21 26 Panel data structure 152154 panels 329 parse method 291 parsedates argument 160 partial function 427 partial indexing 147 pass statements 402 passing by reference 390 pasting keyboard shortcut for 53 magic command for 55 patches 229 path argument 160 Path variable pcetchange method 139 pdb debugger 62 . pdf files 231 percentileofscore function 326 Prez Fernando 45 219 performance and time series data 327328 of NumPy 380383 contiguous memory 381382 Cython project 382383 Period class 307 PeriodIndex Index object 121 311 312 periods 307312 converting timestamps to 311 creating PeriodIndex from arrays 312 defined 289 307 frequency conversion for 308 instead of timestamps 333334 quarterly periods 309310 resampling with 318319 periodrange function 307 310 permutation 202 pickle serialization 170 pinv function 106 pivoting data crosstabulation 277278 defined 189 pivot method 192193 pivottable method 29 275278 pivottable aggregation type 275 plot method 23 36 41 220 224 232 239 246 319 plotting Haiti earthquake crisis data example 241 246 time series data 319320 with matplotlib 219232 annotating in 228230 axis labels in 226227 configuring 231232 legends in 228 saving to file 231 styling for 224225 subplots in 220224 ticks in 226227 title in 226227 with pandas 232 bar plots 235238 density plots 238239 histograms 238239 line plots 232235 scatter plots 239241 . png files 231 pop method 408 414 positional arguments 389 power function 96 pprint module 76 pretty printing and displaying through pager 55 defined 47 private attributes 48 private methods 48 prod method 261 profiles defined 77 for IPython 7778 profiledefault directory 77 profiling code in IPython 6870 pseudocode 14 Index 445 put function 362 put method 362 py files 50 386 392 pydata Google group 12 pylab mode 219 pymongo driver 175 pyplot module 220 pystatsmodels mailing list 12 Python benefits of using 23 glue for code solving twolanguage problem with data types for 395400 boolean data type 398 dates and times 399400 None data type 399 numeric data types 395396 str data type 396398 type casting in 399 dict comprehensions in 418420 dicts in 413416 creating 415 default values for 415416 keys for 416 file inputoutput in 430431 flow control in 400405 exception handling 402404 for loops 401402 if statements 400401 pass statements 402 range function 404405 ternary expressions 405 while loops 402 xrange function 404405 functions in 420430 anonymous functions 424 are objects 422423 closures 425426 currying of 427 extended call syntax for 426 lambda functions 424 namespaces for 420421 returning multiple values from 422 scope of 420421 generators in 427430 generator expressions 429 itertools module for 429430 IDEs for 11 interpreter for 386 list comprehensions in 418420 lists in 408411 adding elements to 408409 binary search of 410 combining 409 insertion into sorted 410 removing elements from 408409 slicing 410411 sorting 409410 Python vs.  Python 11 required libraries 36 IPython matplotlib NumPy pandas 45 SciPy semantics of 387395 attributes in 391 comments in 388 functions in 389 import directive 392393 indentation 387388 methods in 389 mutable objects in 394395 object model 388 operators for 393 references in 389390 strict evaluation 394 stronglytyped language 390391 variables in 389390 duck typing 392 sequence functions in 411413 enumerate function 412 reversed function 413 sorted function 412 zip function 412413 set comprehensions in 418420 sets in 416417 setting up 611 on Linux 1011 on OS 910 on Windows 79 tuples in 406407 methods for 407 unpacking 407 pytz library 303 446 Index qcut method 200 201 268 269 343 qr function 106 Qt console for IPython 55 quantile analysis 268269 quarterly periods 309310 quartile analysis 343345 question mark 49 quicksort sorting method 376 quotechar option 164 quoting option 164 file mode 431 file mode 431 Ramachandran Prabhu 249 rand function 107 randint function 107 202 randn function 89 107 random number generation 106107 random sampling with grouping 271272 random walks example 108110 range function 82 404405 ranking data defined 135 in pandas 133135 ravel method 356 357 rc method 231 232 re module 207 read method 432 readonly mode 431 reading from databases 174176 from text files in pieces 160162 readline functionality 58 readlines method 432 readshapefile method 246 readclipboard function 155 readcsv function 104 155 161 163 261 430 readframe function 175 readfwf function 155 readtable function 104 155 158 163 recfunctions module 372 reduce method 368 369 reduceat method 369 reductions 137 see also aggregations defined 137 in pandas 137142 references defined 389 390 in Python 389390 regress function 274 regular expressions regex defined 207 manipulating strings with 207210 reindex method 122124 317 332 reload function 74 remove method 408 417 rename method 198 renaming axis indexes 197198 repeat method 212 360 replace method 196 206 212 replicating arrays 360361 resampling 312319 332 defined 312 OHLC OpenHighLowClose resampling 316 upsampling 316317 with groupby method 316 with periods 318319 resetindex function 151 reshape method 190191 355 365 reshaping arrays 355356 defined 189 with hierarchical indexing 190191 resources 12 return statements 420 returns cumulative returns 338340 defined 338 return indexes 338340 reversed function 413 rfind method 207 right argument 181 rightindex argument 181 righton argument 181 rint function 96 rjust method 207 rollback method 302 rollforward method 302 rolling 348 rolling correlation 350351 rollingapply function 323 326 rollingcorr function 323 350 Index 447 rollingcount function 323 rollingcov function 323 rollingkurt function 323 rollingmean function 321 323 rollingmedian function 323 rollingmin function 323 rollingmint function 323 rollingquantile function 323 326 rollingskew function 323 rollingstd function 323 rollingsum function 323 rollingvar function 323 rot argument 234 rows option 277 rowstack function 359 rstrip method 207 212 object 359 save function 103 379 save method 171 176 savefig method 231 savez function 104 saving text files 104105 scatter method 239 scatter plots 239241 scattermatrix function 241 Scientific Python base SciPy library scipyuser mailing list 12 scope 420421 screen clearing 53 scripting languages scripts search method 208 210 searchsorted method 376 seed function 107 seek method 432 semantics 387395 attributes in 391 comments in 388 duck typing 392 functions in 389 import directive 392393 indentation 387388 methods in 389 mutable objects in 394395 object model 388 operators for 393 references in 389390 strict evaluation 394 stronglytyped language 390391 variables in 389390 semicolons 388 sentinels 143 159 sep argument 160 sequence functions 411413 enumerate function 412 reversed function 413 sorted function 412 zip function 412413 Series data structure 112115 arithmetic operations between DataFrame and 130132 grouping with 257258 set comprehensions 418420 set function 416 setattr function 391 setdefault method 415 setdiffld method 103 setsset comprehensions 416417 setxorld method 103 setindex function 151 setindex method 193 settitle method 226 settrace function 65 setvalue method 128 setxlabel method 226 setxlim method 226 setxticklabels method 226 setxticks method 226 shapefiles 246 shapes 80 353 sharex option 223 234 sharey option 223 234 shell commands in IPython 6061 shifting in time series data 301303 shortcuts keyboard 53 for deleting text 53 for IPython 52 shuffle function 107 sign function 96 202 signal frontier analysis 345347 sin function 96 sinh function 96 size method 255 skew method 139 skipinitialspace option 165 448 Index skipna method 138 skipna option 137 skiprows argument 160 skipfooter argument 160 slice method 212 slicing arrays 8689 lists 410411 Social Security Administration SSA 32 solve function 106 sort argument 181 sort method 101 373 409 424 sorted function 412 sorting arrays 101102 finding elements in sorted array 376377 in NumPy 373377 algorithms for 375376 finding elements in sorted array 376 377 indirect sorts 374375 in pandas 133135 levels 149150 lists 409410 sortlevel function 149 sortcolumns argument 235 sortindex method 133 150 375 spaces structuring code with 387388 spacing around subplots 223224 span 324 specialized frequencies data munging for 332334 split method 165 206 210 212 358 splitapplycombine 252 splitting arrays 357359 SQL databases 175 sql module 175 SQLite databases 174 sqrt function 95 96 square function 96 squeeze argument 160 SSA Social Security Administration 32 stable sorting 375 stacked format 192 start index 411 startswith method 207 212 statistical methods 100 std method 101 139 261 stdout 162 step index 411 stop index 411 strftime method 291 400 strict evaluationlanguage 394 stridesstrided view 353 strings converting to datetime 291293 data types for 84 396398 manipulating 205211 methods for 206207 vectorized string methods 210211 with regular expressions 207210 strip method 207 212 stronglytyped languages 390391 390 strptime method 291 400 structs 370 structured arrays 370372 benefits of 372 defined 370 mainpulating 372 nested data types 371372 style argument 233 styling for matplotlib 224225 sub method 130 209 subn method 210 subperiod 319 subplots 220224 subplots method 222 subplotsadjust method 223 subplotkw option 223 subsets for arrays 361362 subtract function 96 sudo command 11 suffixes argument 181 sum method 100 132 137 139 259 261 330 428 summary statistics 137 by level 150 correlation and covariance 139141 isin function 141142 unique function 141142 valuecounts function 141142 superperiod 319 svd function 106 swapaxes method 94 swaplevel function 149 swapping axes in arrays 9394 symmetricdifference method 417 syntactic sugar 14 Index 449 system commands defining alias for 60 tab completion in IPython 4748 tabs structuring code with 387388 take method 202 362 tan function 96 tanh function 96 tell method 432 terminology 1314 ternary expressions 405 text editors integrating with Python 52 text files 155171 delimited formats 163165 HTML files 166171 JSON data 165166 Ixml library 166171 reading in pieces 160162 saving and loading 104105 writing to 162163 XML files 169171 TextParser class 160 162 168 textcontent method 167 thousands argument 160 thresh argument 144 ticks 226227 tile function 360 361 time series data and performance 327328 data types for 290293 converting between string and datetime 291293 date ranges 298 frequencies 299301 week of month dates 301 moving window functions 320326 binary moving window functions 324 325 exponentiallyweighted functions 324 userdefined 326 periods 307312 converting timestamps to 311 creating PeriodIndex from arrays 312 frequency conversion for 308 quarterly periods 309310 plotting 319320 resampling 312319 OHLC OpenHighLowClose resampling 316 upsampling 316317 with groupby method 316 with periods 318319 shifting in 301303 with offsets 302303 time zones in 303306 localizing objects 304305 methods for time zoneaware objects 305306 TimeSeries class 293297 duplicate indices with 296297 indexes for 294296 selecting data in 294296 timestamps converting to periods 311 defined 289 using periods instead of 333334 timing code 6768 title in matplotlib 226227 top method 267 282 tocsv method 162 163 todatetime method 292 topanel method 154 toperiod method 311 trace function 106 tracebacks 5354 transform method 264266 transforming data 194205 discretization 199201 dummy variables 203205 filtering outliers 201202 mapping 195196 permutation 202 removing duplicates 194195 renaming axis indexes 197198 replacing values 196197 transpose method 93 94 transposing arrays 9394 trellis package 248 trigonometric functions 96 truncate method 296 tryexcept block 403 404 tuples 406407 methods for 407 unpacking 407 type casting 399 type command 156 TypeError event 84 403 types 388 450 Index tzconvert method 305 tzlocalize method 304 305 file mode 431 uint16 data type 84 uint32 data type 84 uint64 data type 84 uint8 data type 84 unary functions 95 underscore 48 58 unicode type 19 84 395 uniform function 107 union method 103 122 204 417 unique method 102103 122 141142 279 universal functions 9596 367370 custom 370 in pandas 132133 instance methods for 368369 universal newline mode 431 unpacking tuples 407 unstack function 148 update method 337 upper method 207 212 upsampling 312 316317 US baby names 18802010 example 3243 boy names that became girl names 4243 measuring increase in diversity 3740 revolution of last letter 4041 usa. gov data from bit. ly example 1826 USDA US Department of Agriculture food database example 212217 useindex argument 234 UTC coordinated universal time 303 ValueError event 402 403 values method 414 valuecounts method 141142 var method 101 139 261 variables 55 see also environment variables deleting 55 displaying 55 in Python 389390 Varoquaux Gal 249 vectorization 85 defined 97 vectorize function 370 vectorized string methods 210211 verbose argument 160 verifyintegrity argument 188 views 86 118 visualization tools Chaco 248 mayavi 249 vsplit function 359 vstack function 358 file mode 431 Wattenberg Laura 40 Web APIs file inputoutput with 173174 week of month dates 301 when expressions 394 where function 98100 188 while loops 402 whitespace structuring code with 387388 Wickham Hadley 252 Williams Ashley 212 Windows setting up Python on 79 working directory changing to passed directory 60 of current system returning 60 wrangling see data wrangling write method 431 writeonly mode 431 writelines method 431 writer method 165 writing to databases 174176 to text files 162163 Xcode xlim method 225 226 XML extensible markup language files 169 171 xrange function 404405 xs method 128 xticklabels method 225 yield keyword 428 ylim argument 234 yticks argument 234 Index 451 zeros function 82 zip function 412413 452 Index About the Author Wes McKinney is New Yorkbased data hacker and entrepreneur.  After finishing his undergraduate degree in mathematics at MIT in 2007 he went on to do quantitative finance work at AQR Capital Management in Greenwich CT.  Frustrated by cumber some data analysis tools he learned Python and in 2008 started building what would later become the pandas project.  Hes now an active member of the scientific Python community and is an advocate for the use of Python in data analysis finance and statistical computing applications.  Colophon The animal on the cover of Python for Data Analysis is goldentailed or pentailed tree shrew Ptilocercus lowii.  The goldentailed tree shrew is the only one of its species in the genus Ptilocercus and family Ptilocercidae all the other tree shrews are of the family Tupaiidae.  Tree shrews are identified by their long tails and soft redbrown fur.  As nicknamed the goldentailed tree shrew has tail that resembles the feather on quill pen.  Tree shrews are omnivores feeding primarily on insects fruit seeds and small vertebrates.  Found predominantly in Indonesia Malaysia and Thailand these wild mammals are known for their chronic consumption of alcohol.  Malaysian tree shrews were found to spend several hours consuming the naturally fermented nectar of the bertam palm equalling about 10 to 12 glasses of wine with 3. 8 alcohol content.  Despite this no goldentailed tree shrew has ever been intoxicated thanks largely to their impressive ethanol breakdown which includes metabolizing the alcohol in way not used by humans.  Also more impressive than any of their mammal counterparts including hu mans Brain to body mass ratio.  Despite these mammals name the goldentailed shrew is not true shrew instead more closely related to primates.  Because of their close relation tree shrews have be come an alternative to primates in medical experimentation for myopia psychosocial stress and hepatitis.  The cover image is from Cassels Natural History.  The cover font is Adobe ITC Gara mond.  The text font is Linotype Birka the heading font is Adobe Myriad Condensed and the code font is LucasFonts TheSansMonoCondensed.  Yeah we Yup.  000 Okay again.  Welcome everybody.  Its 32 now and its still Wednesday April the twelfth.  And this is pretty much one of the last classes that we are doing.  So.  002 Let me pull up 019 me share the screen.  021 Brandon Vuong bye.  023 and let me pull this up.  026 So we are right here.  030 We we talk about machine learning with Python and we will 034 spend some time on the the final.  How is going to be structured What are going to be the topics and few other things and will present some of the 040 oh the previous fine Also just to give you an idea of how things should be done.  057 There will be no assignment for next week.  Thats good news.  So 105 but really want you to focus on on the final.  So stop thinking about the final.  So Dont ask me about the extensions when you started the days before the due date so the due date is going to be 113 on the 20 first.  133 We need to have some time to review your finals and to 136 ere 145 that means that we will need the some time to review them and to decide who is going to present and if we will present them 153 in terms of presentation just to start with the finals.  206 Some of you lets say of you will be asked the to present day.  Find out.  212 Find out so our individual.  220 if you will be asked to present.  You are supposed to present so there will be points of if you dont 223 if you can.  mean the 232 number of days we have is not big.  That means 239 that we will let you know days in advance.  If you are going to present or not so presume that you May 247 selected for representing and its Random.  257 Excuse me.  305 final Sara individual as all the other assignments that we did so far.  309 and then we will go into the details on how to structure them up there.  Some examples so and what they find out so are going to be in terms of topics.  317 So before we 332 continue.  336 let me spend little bit of time on the the assignment.  So the assignment was about the extracting 338 headlines so pretty much from website and then do some analysis.  351 So we use the this presented this very basic Excuse me.  358 Script just to have base for you to use to build on top of it for screening content in this case from the New York Times 408 and for the assignment You have been asked to do something little bit more complex than that 250 424 meaning calculating or creating the the word cloud.  433 calculating the sentiment.  And thats why it was assignment and not just 441 im in that snipet to to be incorporated somewhere else.  450 anyway.  So 456 imported 459 the libraries that they are required.  502 as in many other cases.  511 Im using function for cleaning the text.  So this is again said min of clients so its something that strongly encourage you to do.  517 You may want to create your own.  If you plan to use natural language processing in the future.  529 you may want to create your own text cleaning function.  So in this case this function is is taking up the string of words so sometimes its at least sometimes its string.  It really depends on how you create it.  541 It takes the minimum length of of of the world that will be acceptable.  This is based on the assumption that if word 559 is smaller than certain number of characters then as no semantic meaning is this true It is wrong for 612 Hmm.  English language.  Yes probably for others.  Not so much.  But 621 were using a.  626 And then you have the list of of software 628 So its doing its transforming the string into list is looping into the list.  Its transforming into lower case checking.  If theres alphabetical or not if is bigger than the minimum line.  632 if its not in the socalled list or not.  If well pass all those.  Ifs then well add the the word to the list of clean words 150 651 and we retire not the least of clean boards then.  703 and connecting 709 my script to the web page.  So thats the URL.  711 Get in the body.  718 then passing it through beautiful super 720 initialize the string that will hold the words in the headline.  726 printing it.  732 Now you dont have to do that but because of that was getting quite lot of lines so ending with the mean red like min or read the min.  Read the 734 min Read the or things like that.  decided to keep them.  750 Youll not need to do it and mean for another.  756 the website.  This would not 802 make much sense so 806 mean if you dont have that will just mean pass for each one of them.  But in this case.  If its not ending with the mean read.  809 then we will print the the text mean the the line.  Now that im reading its keeping one line and then adding to the 822 the the the single worse then creating.  834 So once have the string.  Im.  Extending 839 the software list at this point this may not make sense but thats fine 848 Setting the minimum length.  856 leaving the text sir.  857 And then im tracking diagrams.  So extra team diagrams.  901 So again thats very basic way to to extract diagrams and taking the most common could be any number.  907 Then im 919 im checking for the most.  Call Mona.  929 Oh my Thats kind of lived on that.  But thats okay.  934 appending to the list.  937 generating the work.  Cloud.  944 Then go into the sentiment analysis using father calculating positive negative new role and and then printing it.  949 So when run it you have the the word cloud here.  and you have the headlines.  You have the seventeenth.  Its kind of common.  Again we said million times the the new drilla is way much more than the other 2.  Most of what we say doesnt really have any positive or negative connotation Hmm.  It could be interesting to see over the days over the months the years.  What is the the fluctuation of positiveness and negativeness all the headlines so and see if we can determine some sort of correlation with the leading events or things that can be somehow correlated erez agmoni.  The work cloud in this case is not telling us much.  Most likely you may want to eliminate some other words like what the said 101 because its not really doing much.  Again we have still quite lot of trump related that.  So this Donald the most likely its Donald Trump.  But investigation could be about the Donald Trump investigation.  But thats what we have just to let you know.  also play with another script that they call web mining but its not redoing the web mining.  But just.  want to go through that to share with you form of development thats not necessary is better.  but its its its more clear.  So this script is not doing anything because mean its all definition of functions just printing.  Im in that.  Thanks so.  But what is interesting is is the fact that each logical step of your possible script is function.  Some people are more familiar more comfortable working this way.  It will give you logical decomposition of your script in that logical steps.  So loading the files instead of having in the main program is function.  So you pass the name of the file and well open it and we what you would do just with the opening.  obviously things like that that may have more sense.  If you have mean there are reasons one if its something that you do million times so and its long enough.  Then you want to create your function once for all and then you will reuse it or if you have mouth.  people like in this case finds to open up.  and then instead of writing the same lines youre right.  Just one line th that thats an option for removing punctuation.  mean that may be more justified because its bigger or it can be just part of larger text cleaning.  Thats another option.  Remove the alpha numerical lot same thing remove so forth so remove what it less than given number of characters remove irrelevant words.  So you will create list of the 11 what You you and even have file with the relevant words and then read the file the load the the words into list and then do the cleaning sentiment pretty much same thing by Graham sir.  Work cloud.  So again it it it collection of all the snipets of code around the natural language processing.  So you may want to have this approach.  You may not but just wanted to share with you an option.  All right so let me stop sharing for second.  Let me check if you have any question.  All right.  So let me go to the main content.  All right.  So we will.  We will talk about machine learning data mining and we will do in in class so exercise on that.  So in the next how we also will talk about machine learning.  will give you some examples in in in Python.  and then we will do an in class that would really like.  Hmm you to spend little bit more time.  Then we will.  We will discuss the solution of the assignment up.  and we will talk about the the final and that could be the end of the class.  Again there would be no assignment for next week.  All right so let me shut the screen again and let me go here.  Okay.  So we would talk about machine learning in general and we would talk about python in particular.  What is machine learning So generally speaking machine do not learn now.  We said several times so but they have different behaviors based on the different data.  So thats pretty much the main characteristic of all those systems.  So generally speaking they are models.  So have components Teda.  more complex machine learning systems like Chat Gpt more than model.  They have pipeline that is including the algorithm but its not just data an algorithm but its data.  And now got it as part of it.  Process.  There is no machine learning without data.  Pretty much Hmm.  Erez agmoni mostly if not all what we today call machine learning is based on neural networks on of different sizes different shapes different uses 101.  But the core is linear algebra.  Apply to the meta for of neural networks.  So thats basically what they are now.  Activual.  Neural networks became somehow used the in the second half of the eighties.  but because of it its very computational intensive.  Algorithm They didnt become widely used till the second half of the Ninetys.  Actually.  mean that started working in artificial intelligence many years ago at that time machine learning that wouldnt be possible at all for reasons.  One we didnt have enough data because everything was analog and no digit.  and the sake on the the computers we had the they didnt have the power to process mean meaningful neural networks so that could generate results that would have been acceptable.  So now with the evolution our the we can run that ill gr its little more complex.  We have more data and at the very end we are reaching so neural networks.  So they have an input layer an output layer and in between you have layers that are called the hidden layers so that can be many.  So when you have something like Chat Gpt then really they dont even know how many layers are there.  Yeah but what is kind of measure for the complexity is what they called parameters for the parameter in neural network you have input at each layer you have the inputs and you have weights.  So the weights are the parameters and TV got it.  There is one parameter each input per each layer.  So in the current mit ctl and even Gpt.  2.  That is the base for chat gpt as several billion of those parameters one.  So thats an indication of the complexity.  When we talk about the explainable AI.  There is quite lot of confusion on what the explain ball can be.  It can be how the AI is present in the results in intelligible or human like erez agmoni where your presentation like child gpt that is interacting in natural language or can be explain how they work.  If we say 150 on that the explaining how they work we we we will probably never know how they work.  The main reason is because if you want to know what the lay your number dont know 1333 is doing.  We need to have sort of probe that is getting the data and there is nothing like that because of the calculation is ongoing.  There is no memory stage meaning that we cannot really know what is happening at each layer.  We know what is happening as input we know what is happening as output what is happening in between is unknown.  hey The only thing we can do is basically to have system so checking one the other.  But its not much more than that.  anyway.  So thats machine learning.  Machine learning is using pretty much all the algorithms originally developed for data mining and eventually expand like neural networks.  the at the very beginning they had not many.  He then lay.  If so now again.  we dont even know how many layers we have but is several 100000 that when we talk about how we handle the how we learn.  there are main categories of of learning supervised the unsupervised.  If want to do predictions need to have the equivalent of the experience so cannot predict.  The dont know results or or estimator will be in that case the the result of any event if dont have experience in those types of event whatever event is can be remaining and raining could be one team winning or another.  So need to have some experience.  So in terms of computing experience is data meaning.  need to have data about the similar cases happening in the past.  and thats the supervised learning.  Then we use the past experience to do predictions.  Now few shorter can never be predicted.  So there are famous cases there.  There is book that is called the the Blacks One highly recommended written by the mathematician.  The think hes.  From then he became.  was to it.  Broker made lot of money wrote this interesting book and another one again.  So all gods that are based on the fact that everything is consistent with the past still is not the name of the black One now is from an example that he used the that everybody was thinking that all this once were white.  Then they went to New Zealand and they realized that over there they were swans that they are black.  So the rule we have swan is white was through till the moment that this call and that that was not true anymore.  So other TV gala example is with the the targets.  So before Thanksgiving they think that you months are great taking big care of you.  They feed you they treat you well.  And then Thanksgiving happened that and that think so.  change quite dramatically for them.  So everything is through till there is the moment that is not true.  So thats the limitation of the predictions that that we we can do.  Then we can create system that can learn now somehow from the experience.  But again.  even if we learn from experience so there could be something different that that we will make the predictions wrong.  But thats the way we do so every time you see any system predicting the future is predicting the future or future events even at very small scale based on the past experience.  If it will change.  The system is not going to work unsupervised that is when you do not have the supervision.  When you do not have this experience.  Think about.  You have information about your clients and you want to create an off or addressing that needs you.  Dont know what the needs can be but you can the cluster your clients in category so that they are as much homogeneous as possible.  So thats an an an example of all the unsupervised learning.  So what you are learning is basically the singularity they have one with the other.  There is third way that is called reinforcement learning.  That is basically when you have reward you generate cases and then you measure the score that each case is getting by collecting all the different cases you are generating your supervision.  So reinforcement.  Learning is actually selfgenerated the supervised learning.  So those plus one are the ways for to to in supervised learning.  There are steps.  So you have your data set with the all the cases.  You split the the data set into portions one that you use to create model.  Again model is combination of data plus.  Algorithm So you take this subset.  That is typically the largest of of the splits.  You apply out the the proper algorithms and you get the model.  Once you have the model you want to test the model to test the model you use the the remaining portion of the supervised the data that you have to evaluate the accuracy of your predictions or classifications.  So the accuracy is measured by dividing the number of classifications at the right by the total number of cases.  So it its pretty intuitive.  When you do this type of supervised learning you are assuming that the training and the testing our representations of the same thing.  So if you have data about the apparel.  then you take for training the data in Samara and for testing the data in winter.  You may not have good accuracy in terms of the the current classification that the system can generate because the the the training and the testing are different.  Same thing.  If you want to create to create system that will predict the the selling of our in the summer and we use all the data from winter both the training and testing your model even if well have in cure that that could be high in the model creation.  But when you bring the the model into real life the the the model we not perform well.  So staying in the in the homogeneity or more genetic whatever is the term between or the similarity between training and testing when you split the the original data set between training and testing.  You want to do split that is as much random as possible to keep the diversity all the all the classification.  So the same in training and testing the think about the raining.  No raining you want.  And there are dont know.  of days of rain.  You want to have those or similar in the training subset and in testing subset 150.  If you use in training subset with or raining and you are using testing with 10 or raining.  Then the accuracy will be low.  and also not going to be much represented.  So the distribution of values of has to be the same between training and testing and model reality.  We mentioned about reinforcement Learning again its pretty much similar to supervised learning with the main difference that you have the supervision the experience about the the past the data about the past that our selfgenerated will skip all of those.  and will go.  Genetic calories are kind of similar to enforcement learning.  So the the system is generating groups cases that are similar to generation.  So you create generation of input and you get the results then based on the results.  You adjust the input that you provide but to something else.  and you move on functional.  Its called the fitness function that will tell you how good you are for each generation all the data that you are creating deep learning.  We mentioned briefly.  and machine learning.  Its all about neural networks.  And right now.  Its all about neural networks with lot of those he delay.  Yes.  So in this case this is what its called the neural network.  You have one input layer one output layer and you have one hidden layer.  When you have multiple in the layers and then this mountain is big number.  Then its normally called deep learning.  mean its all about playing on the names it that depth of of the learning.  Its basically the number of there is nothing more than that.  So deep learning.  Its an artificial neural network with high number of he.  Then lay it.  Let me skip.  Yeah.  that one.  So one of the things that we already realized the in the assignments that we did so far.  the data collaboration its really essential.  Whatever you do in data science.  In broad sense.  if the quality of the data is low the quality of the results will be no machine learning models.  They have a.  As was saying before any model mean data based models.  data and algorithm the algorithm can be as good as you want.  But if the data is not really representing the reality that you want to model.  the result would be poor anyway.  Representing means things one on the quote You decide that you need to have enough cases to create the knowledge of of the domain.  and they say on the the quality.  So they really need to be representative of the actual condition or the reality that you are modeling.  So the data is essential.  So keeping in mind that that when you collect data from real world.  There is always quite lot of preparation to do because data can be incomplete no easy inconsistent.  So all of those are things that you really need to address the preprocessing.  Its basically basically Nina.  So you want to remove things.  So that seems to be not proper for the context you are considering that can be improper content in straight sense.  So you are doing chat Gpt.  And a.  This is going to be something that that people will use.  You want to remove from the mountain the ocean what text you have all the text with inappropriate content.  and mean because hes from the open web.  You have everything possible.  So you need to remove that to avoid the that people will be negatively affected by the results that the system would present.  Thats an example of cleaning but cleaning can be.  You have one rule one column in your data set with more than 50 or missing values.  There is no need to keep it because its not telling you much.  You have the the you are creating system to predict the the the whether it is raining or not.  All the the data points with the no value for rain no rain as no meaning because you cannot use the data because you dont know what is going to happen under those circumstances.  So those are examples of data cleaning.  And another example is the correlation.  So you want to eliminate the variable so that correlated if you have one variable with value and another variable that is times the the first one.  There is no need to to keep them both.  You keep one and you have the behavior of that variable anyway.  So thats the Greening integration is the more sources you have the more you know about the the domain.  Think about what market thats know about us.  They know lot because they are getting data from multiple sources.  So they have data from Google equivalent about the that we visited the sites we clicked on.  So not just visiting.  But what are the elements that are more relevant to us Erez Agmoni but also they have the information about the credit Cats companies.  They have information from social media.  Think about Facebook.  Facebook is also you on list for Gram and Whatsapp meaning that they can provide the market that with the information up to the phone number with the phone number.  They can go to your name now.  In some cases there are privacy laws preventing them from doing that.  But you can recreate using machine learning algorithm so or basic data mining algorithm the identity so thats the sanitizing.  Its always business.  But but anyway you have multiple sources.  You want to integrate the sources when you integrate the sources.  So you have million issues.  technical issues.  One source is in one for another another for matter.  But thats an easy issue to fix.  But then there are things that are more complex and the same variable named in different ways across the different sources.  E.  C.  So when you do integration that you need to do all of that.  and then you may want to do transformation.  You want to put together variables.  You want to eliminate variables that are not relevant for your particular case.  So those steps.  Cleaning integration and transformation are the steps that are more relevant in that the in data preparation we mentioned unsupervised learning.  And so advice learning is TV gala through clustering clustering is is process we you generally use.  means for that.  You create K.  Is number.  So K.  Cluster and then you place your objects in those classes and in those buckets and then you move objects from one back to to another to have buckets with elements that they are as close as possible one to the other.  And then you also want to have the buckets that are as much different as possible one from the other.  Its in data.  They process.  So you keep moving objects since there is no better place to move them than that the one that they already are and thats the end of the process.  So the algorithm its pretty basic.  It can be done manually but we fortunately have libraries for doing that.  This can be used for clustering and for meaning for unsupervised and supervised learning.  Typically theyd use the for supervised learning because they are very easy to explain and they are kind of similar to the way we do months in some condition under some conditions.  Thats an example.  You want to go restaurant.  You check if there are people there if none you presume that the restaurant is not particularly good and you work away.  If some meaning that there are some tables available.  then you say its full.  You ask what is the waiting time Who Yeah for getting table And then you have your own threshold.  So if its very long you say you know what im not going to wait.  If its something in the middle.  Do you say okay is there anything else in the nearby things like that So when you put together all of this you basically have the the the choices that you have at each single step like when you play chess.  The goal of this process is to go from condition with maximum uncertainty meaning.  If you are doing system predicting rain or rain.  you have data set with all the days with some case of rain some days of of no rain.  Then applying filters like what is the level of humidity If the level of humidity is above certain number its more likely that there will be rain.  So applying rules like that that again like humidity above given number you reduce the the uncertainty the impurity in your data set creating subsets somehow and then you keep refining the results.  Still you reach level of impurity that is acceptable.  So sometimes can be the maximum meaning that you have all the days with rain on in one back at the and all the days without rain on another bucket.  Some other times you can define that the how you are your data could be to measure that.  We use entropy or gene in the excel.  There are methods just to measure this.  In period we mentioned neural networks.  So our TV show and neural networks are.  Are we making the human new run So they those activities are new runs.  So they have inputs weights.  You have summation of those inputs and weights.  And then you have another function giving the output.  So thats basically what it is.  In this processing element or new run.  You have function that is doing the summation and function that is doing the the transfer to the next layer that its and each layer its matrix.  and that what its doing is multiplying matter so TV show neural networks is an application.  Whatever is the model.  You may want to have way to measure the results.  So one of the most common way for doing it is the so called er error madrics or confusion matrix where you compare the true positive faults positive or negative false negative.  So in this case the system was trying to predict.  If buying computer yes or no you have You have 10000 cases.  Your model is saying Yes by computer for about 7000 cases and mean saying yes it saying yes for 7300 and then change and all those less than 7000 are actual.  Yes from the testing subset.  and that the meaning that they are positive and 412 are false positive.  So the system is saying that yes its positive and reality is no its negative.  So similarly for the No is saying no and hes no for 2020 2600 the cases.  So this is case where the system is is predicting well like both the yes and no meaning.  The accuracy overall is really good.  Sometimes you are not so lucky that when you have case with the data set that this queue the in way or in the other.  You may not have good prediction for the one where you have less cases.  If you think for second on the its pretty much like you months.  So if you do not have cases so that means you will not have experience.  If you have been asked the things where you dont have experience.  Okay you are capability to interpret.  Results will be low.  A.  And thats exactly what what is happening.  So give you an example.  You want to predict the the cases on the general of population of all of cancer.  So the number of cases of people with cancer in the general population is low.  meaning in data set collecting all the data.  You are going to have.  very few yes cancer and way much more no cancer.  meaning that your system is not going to predict the no cancer the the yes cancer as well as the no cancer.  So and and there is no way to that.  So thats the data you have.  Then there are ways to balance in the but you are changing the data.  So the model is data driven.  If you change the data the the model will not be.  mean that it will not work well.  So is using any reality that is not real.  So anyway.  you have the error madrics or confusion.  That is what we normally use to evaluate the accuracy.  Another way is the receiver operating the characteristics curve.  That is measuring the area under the car.  The meaning.  the main that you are gonna look is meaning can be yes can be.  No.  If you go above.  your system is predicting better than flipping the going.  if its too high there there is something wrong because no prediction can be 100 right unless you are predicting something using variables that already have the solution.  So you are predicting the the weather and you have the millimeters of rain.  Obviously if you needed so rain is more than 0.  Then there is rain.  So obviously those variables are highly correlated and if you keep the millimeters of rain in the model.  the model will predict the 100 right.  But basically what are you getting You are getting that if there is you bring in on the split its.  You already knew that.  So you want to eliminate the variable so that to correlate.  It is part of the data.  and when you mind text things are quite different.  So we had another class on that 120.  You need to find metaphor somehow to let your system your model dealing with text because text cannot be interpreted as it is by any system.  because languages for humans is not for computers.  So you need to have again made up for representing the the language mit ctl.  And one of the possibilities is to transform text into numbers.  Once you transform text into numbers then computers are pretty good in dealing with numbers 150.  But then the way you transform the text into numbers will impact heavily the quality of the results that you have.  So in in this slide.  Im mentioning what to back.  That is method to transform words into vectors.  but we will not spend too much time on that.  But thats an example.  So we generally use back towards the that 200 or 300 the elements or dimension so meaning they are points in in dimensional space meaning if you imagine to the dimension then you have points and the distance between those points we tell you how close works can be.  Let me skip that.  So now how we do data science we do data science using tools.  So in particular if we do machine learning.  We cannot do machine learning manually so it wouldnt work.  That is too much complexity too many data.  and there is no way that you can do it manually.  So in the past the people use the more erez agmoni of statistical tools like Sas informatic spss.  So those are our tools from different Vandals then had the the majority of the market one now more and more.  We have people using languages like Python and our Arra was very popular up to 10 years ago but definitely now tied on is more popular than that.  Obviously if you want to analyze the data you have no idea how to code.  You are business administrator all the due respect but they may not know how to code the majority of that or the traditional ones meaning.  You use tools.  So you use tools like S.  All the others that they was mentioned.  But when you go with people that are more technical in any sense.  The number of people using those tools is going definitely down and definitely not close up to but not too far from that.  Then when you develop your system you can do million different ways.  Many years ago we didnt have python.  We didnt have those tools that are quite high level with lot of libraries and we started from scratch.  So we built our our models creating ill go.  Its literally from scratch.  So each time you need it either you had the code in your text study or somewhere or there is no place where you can go and get it.  So thats the level 0.  dont know as several 1000 libraries all those libraries really helping lot in developing systems is probably the most popular in data oriented libraries.  But then there are libraries that are more on the machine learning side.  would say that the vast majority of the machine learning running today are using either tensorflow or pie torch wine.  Tensorflow was developed by Google.  Python was developed by Menda Slash Facebook.  They have advantages and disadvantages.  was using tens of flow but unfortunately is not running on the new Max with the the apple microprocess of the apple civicon.  and at this point mean kind of converting my scripts from using tensorflow to using pi touch.  Nevertheless there are other libraries very popular even if they may not be intrinsically machine learning and us.  So you may want to have data structures and is what is doing quite efficiently.  was hesitating while was saying because now there are other libraries that are able to be more efficient with the larger data set keeping the data set in memory.  So they have embedded some compressing compression algorithm that we make in the in memory working with larger data set.  But pandas is what it use the most of the time noon pie.  Those are the other libraries that are very popular and those are embedded in in the as he learn.  That is definitely one of the most popular for common tasks.  did the this search this morning just to compare tensorflow with.  So thats basically what was saying for long time so this is from 2018.  For for long time tens of flow was the most popular.  Now Pi Torch is becoming more popular.  Yeah know the big fun of Facebook but have to say that its more more than its more easy to use.  Its more flexible.  mean.  The first release of Python was really complicated to use.  Then they they moved the to an integration with another component that its called Kras and then the combination of the made the the tens of flow easier.  But still mean obviously if you come for so you are.  mean breaking the ground.  Python came sag on the and they leverage the on one tens of full was doing and they built on top of it.  They are both open source meaning.  They are not getting direct value out of that.  And we thank somehow.  Google and met.  Okay so thats basically what had to say in terms of the theor.  Let me go now into some practical applications.  and let me go into some examples.  So the first one is an example of how to generate decision 3.  Thats super basic example.  So you have a.  So the goal is to predict the if the subject is male or female that based on height.  length and voice beach.  And you have your training data.  When where you have some heights.  some hey Lansa And you have men of woman.  So basically.  thats the X.  So you and then one the decision is being generated you will do the prediction.  So if run it.  so if you want to predict if someone with the height 133 headline to 37.  So presuming is and then that you know.  and voice pitch is woman.  So again you have those values Hi Voice speech.  and then the mean that other variable.  So this is this is this is man and so on.  Thats basic application with no visualization No nothing.  So lets do the same with the visual representation.  so let me run it.  So in this case is generating.  What is the name of is generating dot png that should be somewhere.  There we go.  Let me open it.  So does the decision 3.  So you have voice speech.  So thats the root.  You have fivex and also.  and then if Hera is less of well 28 then you have ginny indexes measuring the the Entropy Gin index was created to measure the wealth.  distribution.  and how the world is distributed meaning pretty much the same concept as entropy as as the impurity that we mentioned before.  So you have genie index when you have all the samples that are on one type.  the and so on.  So thats the visualization for the same.  Lets do something similar with the Kmeans.  So imported the the values im using.  Yep sure.  Okay lets go here.  So in this example the input didnt change much.  You have the same and the names of the features.  the prediction.  So the main difference is the generation of the of the graph im using this library that is called the then its called pi dot plus that mean for that particular.  It is not the only choice.  You have think in another case Im using something different.  Im using.  Yeah im using the plane.  Im not plotting but in another example.  There mean that creating the data.  Keep in mind that that this library in order to run needs to have graph wes installed.  So you may want to use probably the other example.  Well.  you have the classification.  Not that you created the Let me go back here.  so you have from skill or not you are importing 3.  So subtype of is decision.  classifier.  So in the client you have the classifier.  and then you use and and as the input for the classifier.  So at the end in the classifier you will have You are model to classify.  It is the model.  So in this case its called classified.  And then this is the prediction.  So the values that you want to classify and you pass those values to the prediction component of your classified of your model.  and you will get the result based on that.  Why that is the class that you are considering.  and then you have the prediction.  So.  and its basically way to represent it.  So mean wouldnt spend too much time on that it its for more of visualization.  Let me go here and let me go through the same example or senior one with different method.  So in this case im doing both okay means and and decision 3.  So and im using data set that downloaded the from library.  That is so in skill or not that our data sets that you can use for training purposes.  So in particular this is so is one of the most.  We use the data set in the history of data science probably and its typically used for classification purposes for clustering purposes but can be used for classification as well.  and its about predicting.  The type of irr is based on the length and the with the of the and thats for the Kmeans defining the size defining the color map.  This is scatter plot.  and you will have discounted plot.  will run it in moment.  Decision.  you have copied the all the the parameters so that you can pass.  and you can go through that.  The mean is from the official library.  So in this case there is no need that we import this.  did it just to have independent paths training the 3.  The confusion matrix graph is again is library.  That will let us do the visualization loading the the data set they already have loading the classifier.  applying the data.  mean that you have target and data from the source.  Then im working now on creating the graph.  Those are the parameters that that you are passing you.  and then you do that.  The evaluation you split the training and testing.  and you calculate the confusion matrix and then you visualize it 500.  So does the visualization on the decision that is obviously similar Erez.  and thats the the confusion magic.  So.  and thats the distribution of the values for the class setting here.  So in the classroom use the plus that sir.  and that thats how they distribute it.  anyway.  So thats basically it.  Let me stop sharing for moment and let me make sure that you have all the material available.  Okay.  you should have everything.  Let me go now with the inclass exercise.  So again that Dont leave the class please because after the the exercise so would talk about the the final and you may be you may want to say in the class to get what Im going to say on the final.  All right so let me share the screen again.  And let me go here.  Thats the in class so exercise.  So using the file diabetes data dot csv create model using decisionthree algorithm to predict the class that is representing the Poly DVD to the diabetes.  You can reuse the machine learning sample dot pie that is posted on canvas to the data set is derived from this data set here with the following replacement.  male one female yes one no positive one negative 0.  So you will go into the data set.  You will do little bit of preparation and then you will apply the algorithms.  So let me create the breakout rooms.  So we have breakout rooms.  opening the room so will pose the the recording.  will give you good 20 min so to work on that because can be little bit complex and they really want you to spend time on it.  Okay.  So the rooms think created.  Im opening them.  See you in about 2025 min.  will.  mean will send you reminder my broadcast.  And the reminders resume in the recording.  Okay anyone want to say something about the assignment.  Vilan Kvyat guess can shine in if you okay Absolutely sure.  So Vilan Kvyat ran out of time little bit but think got something to run with the results.  But it was all was only able to get maybe Vilan Kvyat of the lines going before kind of started to figure it out.  Go ahead.  Vilan Kvyat Oh you want me to share.  Yeah.  Vilan Kvyat all right.  Why not Vilan Kvyat Okay Here it is.  So Vilan Kvyat basically these are my results here.  Vilan Kvyat think was kind of getting on to something here but did.  decided to do it differently than the file that you sent.  So imported the same libraries.  Vilan Kvyat But this but thought it would be easier for me personally just to define what the Csv.  Was and use it that way rather than the data frame because think was starting to struggle with that and it wasnt really working.  Vilan Kvyat So you know.  And just you know define data data set length shape etc.  you know created the target variables.  think maybe this is probably the reason why it was one to 5.  had to kind of check the the number of rows had.  Vilan Kvyat but kind of again ran out of time.  but moving on.  So Vilan Kvyat So split the data set to train and test.  Set up the Genie Index here as you did in Yoda file did the entropy.  think there was an issue.  Im not sure if this is an issue here with the xtest noticed that before but and get chance to test it out.  Vilan Kvyat So once the set up the entropy created function to make.  The predicted values Vilan Kvyat created another another function to well few more functions to calculate the accuracy with the confusion matrix accuracy score classification report.  Vilan Kvyat Then this is the code the driver code and the you know with Y.  The train and test.  Vilan Kvyat And Vilan Kvyat here is just prediction using genie and just the results using the entropy.  And called the main function just Vilan Kvyat main.  Just gave it name and this is Vilan Kvyat what came out with Vilan Kvyat so far.  But kind of towards the end started to get something going there.  Okay.  So there are good elements and not totally clear why youre using both the end to be in the Genie Index.  So generally speaking we use one or the other because both are kind of measuring the confusion or the impurity that is in the data set.  Okay its its good.  Okay so let me go through.  Let me share the screen and let me go through another option.  That is this one.  So again.  if you use skill or not.  The default for measuring an impurity is the genie.  Not necessarily.  You need to use that.  You can change it but thats what use.  So you have importing all the libraries that you need setting the names of the reading the the the the so of data into Pandas structure.  naming the features the variables defining the target variable.  So you have class.  Then it Yep.  Yeah the confusion.  Politics is good.  You want to do that.  So you have exa is the values.  Why is the names So its the categories.  So you want to split the 70 30.  Thats what you normally do.  and then you create the decision 3.  You can define what is the depth of the depth of decision.  is number of layers that that you have.  When you create decision you can define what is the level best level of or the lowest level of impud that you want to reach and the depth of the decision whatever will be reached the first the algorithm we will stop.  But in this case set the the maximum depth to training at the decision.  with the portion.  Again.  why is the class and of the features or the independent variables Generally speaking another way to call them.  You have dependent variable that is the target and in the event and variables that are all the other.  So then that predict the response export in the for visualization.  visualizing.  aval waiting.  using confusion metrics graph running it.  So its level because thats what said.  as you can see not everybody.  The Genie Index reach the meaning of If change the the theft increasing probably may have something better than this.  but thats what it is.  So thats the the decision.  does the error Mavericks in visual terms so that is not telling much.  so its definitely better when you have numbers.  So you have mean in this case you have the true positive and true negative.  So 54 against one and 97 against for so the model is relatively good.  anyway.  So just let me stop sharing for second on that and and let me.  Okay im publishing the script that you just saw.  and let me go now into the final so couple of things on the final.  So first of all.  want to review with you the template that you will eventually that you may use or your final close this let me share the screen again.  So we already discuss that.  But want to be sure that that is clear and you are going to use it.  So you do not need to create Powerpoint but you may want to use table of content or your document that will be kind of similar to this one.  So you want to have the goals and conditions.  You want to have Erez agmoni methodology or method for the analysis.  So you want to cover those steps.  You can call them whatever you like 101.  But the very end that you need to have one step by defining what is your goal Once that by defining the data that you are using to get the goal then you want to do the preparation meaning all the faces that we discussed before.  So the phases you want to clean the data you want to merge the data if required the N.  And you want to.  and the the Google is probably better with the visualization.  So let me cool.  What is it Okay cannot find it.  So Here we go sorry about that.  So you want to do the cleaning the integration and the transformation.  So thats what you are going to do in the the data.  Then once the data is prepared then you will do your representation that it can be.  Tables can be visualization.  So it can be.  Whatever is the method that you are going to use eventually.  If you are doing Nlp.  It will be all up the different things that we did with text and including.  dont know diagrams sentiment work cloud all those things.  If its numbers you can do decision class setting and then write an explanation on the the results.  So whatever is the format that you are going to use you will cover those for faces and you want to have something like table of content resembling that somehow what you have in your screen now.  So for each one of the faces you will describe but what the face means and what in your particular case is the business understanding.  So why you are doing the the type of analysis that you are doing same thing with the data.  What is the data you have You want to do the exploratory data analysis We went through couple of options for that.  We use the one script.  the for the correlation analysis and one for analyzing the old data keeping in mind that when you do correlation on this is correlation analysis is going to work only on numerical data.  So and then you do data preparation.  You do the representation and then you will.  E.  C.  Now in terms of what is going to be.  There are tracks.  So again in the past we had the opportunity to give students in this course 100 freedom to do whatever analysis they want to be.  After being approved by us.  This became complicated to get the data set.  Some of the students may change the data that might not send the data set the meaning that we need to change students to get the actual data to run the code.  And then Kaggle happened and at that point we couldnt really be sure that you didnt use problem that was in cargo and eventually the solution that was in Cardiff.  So at the very end the old thing was not manageable and and decided to give students specific tasks they can choose from.  So there are tasks you can pick anyone you want out of those 4.  So one is and is individual.  Analyze people migration data and mean migration is always an issue when you have conflicts.  So we have the the war in Ukraine and you have quite lot of migration from Ukraine to other countries.  You have the migration from people from the South in Central America to United States You have the migration from North and Africa to Europe.  So all of those are continues continue mean in continuous streams of people going from one place to another place.  Fortunately there is also something that that is more driven by choice and not by necessity.  So migrated from Italy to United States and not because didnt have fortunately anything mean tweet or didnt have job.  But just because they wanted think about the the situation the economical conditions.  So people had in China 30 years ago or 40 years ago.  Compare that to what is the current economic condition in China Some people is is going back to China.  So thats migration back somehow.  So.  But whatever is the reason there is continuous migration since the very beginning of humankind.  So the question that you may have.  What are the major flows of migration where people from more developed regions are migrating to where people from less developed regions are migrating to what are the dynamics by income and geographic region And then you can agree down on on what region and and get more insights.  And you have data set for that.  The second is analyzing research projects.  So the naval postcard with school is graduate university and they have material that is available in terms of research and you can drill down.  What are the key areas Slash topics over time What that The network so researchers that are more active.  What are the institutions that are more active What is the collaboration between institutions So you have mean that that can be more complex because you.  You need to download the the data meaning you need to write code that will be crawler getting the data from the website.  You can get any subset because there are lot of.  But you just download the subset the way you want.  The crawler manually is up to you and then you will create document and you will set the documents and you will analyze it.  Coronavirus.  So its analyzing Coronavirus.  So there are files.  One is list of cases of and and thats by county and data.  You have the the annual estimates of housing units per county.  You have the Gdp for counties.  You have the the mean all the data from.  and all They estimate the combination.  And is it least of county level from census So so the study its focus on allies in the files and getting inside.  So thats basically what you have Thats new one for this year and is analyzing people.  Perception of AI AI is becoming more and more the common topical compensation both in the scientific and non scientific complexes.  In particular after chat Gpt was announced in November.  Everybody is talking about it.  So the perception about AI changed the all over time from considering the possible future of this topic Society ruled by an AI being sort of big brother big sister to the youd faith in the AI that will become sort of fix it all erez agmoni.  So what people is thinking today What are the trends in their opinion You may want to extrapolate the trend and see what could be possible scenarios in the future 150.  This task this project would be Mlp so you want to collect data and thats an additional complication that you have for this task.  You want to use the sources that you think are more appropriate.  It could be news reports plugs social media papers pro corona.  You probably remember that as one on the topics on what people is thinking about.  AI.  Then you can get.  mean those are will be all text based on top of that you may want to.  W.  You may have access to number related number based data set that can provide additional viewpoints is time analysis.  Its not as nap short of what is happening today.  So again is time analysis.  You need to analyze things in time.  Not just today.  Again all the requirements for all the the possible projects for the final.  Well stay the same in this case.  So you want to have data set that is big enough to create that right complexity.  You want to write script that will have more or less the same size or at least the same size as as the last scripts that you wrote for the the assignments.  You want to have report that is not shorter than lets say 18 page.  So something like that.  In this case you have an additional level of complexity.  That is the collection of the data text that you need to do this telephone analysis.  Like all the other the source data needs to be submitted along with the report and the script.  Just one thing that want to share with you.  Thats one of the best.  and im not going to publish it because its about one of the tasks.  So but just want to share with you the and then Joshua created the last year.  and he was on global migration dynamics.  Its its big rep of that.  Its 30 page.  So just going very fast.  So you have table of content.  You have table of figures and tables.  abstract introduction with the sort of taxonomy with the terms and definitions.  factors driving migration.  research questions.  data description.  preparation.  representation.  So thats good view representing the migrant migratory close.  for migration flows table representing source and destination.  meaning from lets say central and and Southern Asia.  this the source destination.  Many people going to this region.  other representations.  dynamics thats using the Sun key diagram that is really giving you an idea.  All the who is going where this one was for the mean for the development status.  This is for the less developed the to more developed countries.  This is based on the income friends conclusions.  So you want to have something like that.  So the the fact that that people in less developed the lower income region are migrating to more developed countries.  That is something that we already knew.  But something was not so obvious.  People in more developed regions do not always migrate to more developed region.  they may actually migrate back.  So thats what was mentioning before.  So mean that thats an example.  Im not saying that you need to do something exactly like that.  But keep in mind that that thats goal somehow.  Its its target somehow.  Very briefly.  im publishing.  Let me share again and thats the last thing want to share with you today.  So im going to publish all.  All of this you are going to have Erez agmoni quite lot of information.  You are going to have the description that was presenting to you the template.  There is this document 150.  That is how to write paper.  If you want to write not in terms of in the powerpoint of playing Pdf.  You can write an academic paper so the form the structure will be abstract introduction background where background that you will have the lead ratio review results critic discussion conclusion.  references.  So thats an example of how to write your paper.  Then you have some examples that you can use the data files.  and thats basically it.  Okay so its almost 90clock.  So sorry again for keeping you so late.  Thats basically it feel free to send mit Ctl.  And me and see you questions you may have.  Im going to publish what you so before in moment 250 and so next week will be soft of presenting some applications.  So and then will introduce the last assignment to.  and that would be pretty much the final class before your presentation of finance.  Okay.  So have good night and yeah sure.  Good.  Tanmayi Soma Shekar Hi Professor.  So Tanmayi Soma Shekar this final the report.  It is due on the 20 first.  Yeah will update the due date.  Let me check for second.  Yeah.  will probably stretch it to the 20 third meaning the end of the weekend.  because then at 26 that will be the presentation and we really need to have at least couple of days to decide who is going to present what Tanmayi Soma Shekar Okay No.  was just wondering because doing the assignments by themselves takes me the entire week to do and this seems like an awfully lot of work to finish in like weeks time especially since have other final.  You know all the subjects finals to do as well.  Tanmayi Soma Shekar and was.  was wondering why were finishing off this zone because our semester goes all the way up to May 16.  Tanmayi Soma Shekar So was wondering why we cant have little more time to do it.  Well mean we.  We published the the schedule since the very beginning so the schedule as 13 weeks.  considering.  Yes we do have some more time.  We can skip one week giving you an additional week.  so thats something that we can definitely do.  mean we have room for doing that.  We can do that.  Tanmayi Soma Shekar Okay.  Tanmayi Soma Shekar Yeah.  So Tanmayi Soma Shekar im sorry im confused.  So does that mean we will try to finish the final by 24 or say 23.  But youre saying that you could extend it if you okay so let me check.  What is the the the final period of the that Stevens is giving to us dont want to take any options out of mean if we have more time will give you more more time.  The only thing that we need to consider is that we need to submit to post the the final grades within 72 from the final meaning.  We need to go back and we need to be sure that we will be on time.  So let let me review what is the final period of the that Stevens is giving to us and if its later than the end of the Webinar as its probably is will extend to whatever is going to be the latest moment possible.  So check canvas and will change the due date for the final not based on that Tanmayi Soma Shekar right Okay thats why asked.  Because did check.  Tanmayi Soma Shekar All right.  SYSTEMS ENGINEERING RESEARCH CENTER Extracting decisionmaking metrics from text Using the Room Theory by Dr.  clipizzistevens. edu This material is based upon work supported in whole or in part by the U. S.  Department of Defense through the Systems Engineering Research Center SERC under Contract H9823008D0171.  The SERC is federally funded University Affiliated Research Center UARC managed by Stevens Institute of Technology consisting of collaborative network of over 20 universities.  More information is available at www. SERCuarc. org March 2020 SYSTEMS Natural Language Processing today ENGINEERING RESEARCH CENTER Communications today are becoming shorter less structured more chopped even more context dependent Some of the media have intrinsic limitations in terms of length but even those with no such limitations tend to be used for short fragmented multi threads or even single message communications.  This implies less syntactic structure less rhetorical elements Traditional methods to extract knowledge from text are based on the existence of predefined structure that can be in the syntax in writing patterns in preset taxonomiesontologies The lack of structure makes the traditional media either less or not effective anymore March 2020 were Limits of Supervised Learning ENGINEERING RESEARCH CENTER Language is evolving continuously.  Rate of change is increasing Different group of population have different jargon.  Rate of change of those jargons is even faster that overall language Language has unavoidable bias from the writerauthor and from the readerrecipient.  Supervised learning add third bias that is in the interpretation algorithms.  This bias may be out of our control and can determine the final interpretation In order to control the algorithm related bias we need to be able to determine and model it exante in dynamic way to accommodate the language evolution and the jargons presence March 2020 SYSTEMS Text Metrics ENGINEERING RESEARCH CENTER To reduce the risk of wrongsubjective interpretations when taking decision based on text we need to extract metrics out of it How to get numbers from text Statistical methods do not work lacking semantic evaluation and requiring large corpora If we use semantics how can we deal with subjectivitycontextuality of the interpretation in text that can or cannot be in given semantic structures such as ontologies Plain use of generalized reference corpus does not provide any subjectivity Valuing the relativity of the interpretation is essential.  For example if we classify emotions in text ecstasy may have different meanings for narcotics officer Vatican scholar or psychologist March 2020 rE Text Metrics the room theory ENGINEERING RESEARCH CENTER The room theory is addressing the relativity of the point of view providing computational representation of the context we want to use to evaluate the text.  The non computational theory was first released as schema theory by Sir Frederic Bartlett 18861969 and revised for Al applications as framework theory by Marvin Minsky mid 70 When we enter physical room we instantly know if its bedroom bathroom living room Roomsschemataframeworks . . .  Are mental framework that an individual possesses mental framework is what humans use to organize remembered information Represent an individuals view of reality and are representative of prior knowledge and experiences We create computational rooms by processing large corpora from the specific domaincommunity generating embeddings tables.  We consider table as knowledge base for the contextpoint of view.  In mathematical terms rooms are Euclidian spaces The room method makes the whole approach easy to be moved to different domain March 2020 From words cooccurrence to ENGINEERING embeddings RESEARCH CENTER Word cooccurrence measure how often word occurs with another within given number of words of separation Using cooccurrence we can create wordword cooccurrence matrix where rows and columns are the unique words in the source text Each word is represented this way by vector that is sparse and with most of the values being zero Leveraging on word cooccurrence Mikolov Chen Corrado Dean created in 2013 word2vec that is group of models that are used to produce word embeddings We are exploring different options besides Word2Vec to create embeddings 2Vi NN Embeddings March 2020 SYSTEMS Word2Vec to generate embeddings RESEARCH CENTER Published by Google in 2013 Python implementation in 2014 gensim library Generates distributed vector representations of words word to vec using neural net In those distributed vector representations of words each word is encoded as vector of floats WOCg ren 0. 2 O. 3 Oy ose od VCyoman 0. 1 0. 2 . 6 0. 1 . . .  . 2 length of the vectors dimension of the word representation key concept of word2vec words with similar vectors have similar meaning context March 2020 Why this approach is relevant how ENGINEERING is structured RESEARCH CENTER Zellig Harris 1954 oculist and eyedoctor . . .  occur in almost the same environments If and have almost identical environments we say that they are synonyms.  Firth 1957 You shall know word by the company it keeps Intuition for algorithm Two words are similar if they have similar word contexts The meaning of word is vector of numbers Vector models are also called embeddings March 2020 SYSTEMS ENGINEERING RESEARCH CENTER compared with Room Domainspecific Knowledge base using Documents to analyze Benchmarks Keywords defining what we are looking for Proximity of the documents to each keyword March 2020 How the room theory works Room theory enable the use of contextsubjectivity in the analysis of the incoming documents.  To work it needs 1.  Acriteria for the analysis the benchmark.  This is represented by list of wordschunks with possible attributesweights 2.  point of view for the comparison the room.  This is represented by an embeddings table extracted from the specific domain Adding elements to the room theory RESEARCH CENTER Optimizing the process Single words may not represent concepts school of business weapon of mass destruction chunking Creating standard room generation processscript running on GPUs Creating standard 3way weighted comparison engine Using the theory for prediction Future cannot really be predicted but evolutions can be estimated Estimate future vectors from past positions in multidimensional space then from vectors estimate the closest words reverse engineering the process Using the theory to estimate people reactionsmoods Sentiment analysis is not working providing limited view of the reactions Using emotion classification from psychology literature Plutchik as benchmark document on proper rooms March 2020 11 Room theory at work Processing Information The larger bucket can be indefinitely filled up or regularly purged Larger bucket for generating rooms oes to weeks Room theory at work ENGINEERING Using Information Numeric value of interest metric March 2020 SYSTEMS ENGINEERING RESEARCH CENTER STEVENS INSTITUTE of TECHNOLOGY THE INNOVATION UNIVERSITY Thank you Dr.  clipizzistevens. edu Okay.  001 All right.  So lets slowly start 003 slowly to lose some time to the other students to join.  009 So 015 its much 20 its 32 and we will do.  mean the the the for use of the class today is going to be visualization.  But we will also talk about 017 the midterm and we will do an in class except size and we will introduce the next assignment.  036 All right.  So let me start the sharing the screen 049 and let me start as usual from here up.  055 So we are right here.  So once they march 20 we we talk about the 101 visualization.  Well talk little bit about what to do with data but well be kind of the everybody what the visualization in this case and then will introduce exercise Number 6.  110 So 126 let me start with the at the mid term.  131 So we all know what the midterm was about.  136 So let me start with the 140 the code the to be checked.  So the initial code that was doing something like this.  So let me run it.  145 So thats what 159 Yeah will talk about the final project that we do have little bit of time for that.  But will start introducing the the what are what are going to be the rules of the game.  207 So 224 the output for the way it was initially 227 was something like that.  Thats not what was supposed to do.  236 So the way we changed it its basically we converted the the original string into list calculated the length.  241 and then for each one of the characters that at that point will be an element of the list.  We multiplied it by 254 and then we joined the the 307 string the at least creating string.  and then we printed it.  313 So if run 321 this 324 so the same one 332 at this point is doing the right way.  335 So that was the first one the second one.  cannot run it right away because if run section and there is file its not recognized in the file.  341 But mean there were several issues here.  What did was basically initialize an empty list.  351 Then looping into the words in the file.  402 eliminating the blanks and the special characters that are right and and checking if its not in the list if its not in the list im appending the the result.  mean this is kind of red or not but thats fine.  408 Then im getting and sorting by length and taking the last in the list and then im printing them.  could print right away this way.  Its kind of nicer because you have one after there.  427 The third one is very straightforward.  So they were again.  Several issues including some else misplaced the and things like that 448 so imported the 501 library string as it was not originally.  But thats right.  506 and then enter the string 511 the check.  515 then the list of our wells and then.  516 and then checking.  If the world in lowercase is in the list of our well if not 523 531 mean that if yes so then 533 mean im asking if is in the list if yes meaning is about.  Well its not consonant otherwise is consonant.  539 So if run it.  550 lets say our 559 is console.  So there.  There was no request to do.  And mean in this case it was yeah mean when you run this way you dont have much of loop.  602 but thats fine.  616 So thats basically for the first part part of the assignment.  The second part of the assignment was analyzing.  617 analyzing 634 file with the words and counting and doing some other statistical analysis on the words in the file 638 erez agmoni.  So open the the files the the file and the the file with the so forth.  So initialize the list of of unique words 101 654 string that will contain eventually the longest world and counter for the total length.  and then also initialize with an empty list the the collection awards and it called the bag awards and the list of so forth.  711 starting the looph populating the list of software similar thing for the the list of words.  And in the process eliminated the the words that 730 are in the software.  748 Then over here.  Im im im im im im im im im im im im im im im looping into the list of words and then 751 for each one calculating the length If the length of the current word is 810 the bigger is is more than the length of the longest word and that initially will be not.  will replace it in that the 818 variable that will contain the longest world the the current world.  Then im asking if is unique word.  If not will mean if its in the list of unique words it now they will append.  832 and will increase the the 850 length ofwards.  So then im calculating after the loop the number of unique words 854 using the line commander.  905 And then at this point already have some of the information to be printed.  So there are this number of unique words and this is the list you were not required to to print the list but mean have it and printed.  908 Then calculating the frequency.  So frequency is the counter or the beg awards.  924 then initialize to or the occurrence.  and then 933 and looping into frequency that is this counter here 940 and Im.  946 Adding it is 948 additionally im.  Adding the frequency of the current board.  Then im printing the most frequent 952 and calculating the relevance of the most frequent words you dont need to do the rounding with the certain number of of this amount so but it would look nicer.  and then those that we are not required.  But mean just to have some more statistics printing the average what length and the average accordance.  And thats basically So let me run it.  So you have Those are again.  You are not required to bring the list of unique words meaning that you could stop.  There are 386 unix works.  Period.  The most frameworks are the following this is the relevance average length of required.  So thats Basically it.  Again there are few things that we are not required like the rounding did with the days emails in one case days emails in the other.  Doesnt really matter.  The last were not required and thats basically it.  So let me.  So for second on that.  And before we proceed want to be sure that there is no question from you.  All right.  So she you posted the most of the grading.  So for the midterm.  If you dont have your grade yet chances are it it could be potential case of really dont know why you are doing that.  So most likely no one the 25 of you did it.  But in the class some students cheated.  So im spending really lot of time to explain how we evaluate the the assignments how we compare the assignments last class presented Powerpoint describing the entire process.  So so it is pretty clear that that the chances to be quote are very high.  So each time we have achieving we will apply penalties.  When we apply penalties along the road.  You will may not have enough points to pass the the course at that point because we have the rings all everything that happen during the the the semester.  We will not give you second chance.  meaning if you lost points from cheating and you will not have points enough to to pass the course you will fail period.  So again really dont know why some of the students in the class are doing so.  really really strong encourage you not to do so.  Im also analyzing class that so to see if is an occasional cheating or if is systematic cheating.  So for the occasional achieving that we can be little bit more flexible because there could be special circumstances.  But in most of the cases there are classes.  So we dont really have any flexibility in those cases.  So and oh yeah okay dont have it right away.  But while you would do the in class assignment will pull exercise and will review it with you.  So Anyway thats the story on the the We will discuss with you tomorrow the the courts of action for those of you with no grading on on the mid term few words about the final mean will talk about the final more next week.  But just as an anticipation.  so the final is going to be project.  would be something that you will develop individually like all the other assignments that you did so far and it will be on given problem with given data set.  The class.  Its relatively big and cannot give any one the opportunity to pick a.  They own Us data set and problem.  because when we have quite lot of data sets there are way much more issues.  So you may not use the data set that you said you should have used the the link to the data set may not work or we need to go back to you.  Then you did modification to the data set.  So we dont have the the bandwidth that to deal with the 15 change different data sets and problems.  So we will give you options and you will pick one of them again.  It could be project.  So you will have yeah data set and problem.  And you will do the data exploration on on the the data set.  And you will come up with report that will be something the around.  all included we are all included will be with the graphs with the tables and on the rest.  and you would submit the the report and the python script that you will use to create the visualization of the tables.  The metrics then will be needed for the for the final.  How big the script could be.  Well mean that thats fine Allah.  Keep in mind the that mean that the scripts that we are right now are roughly around the 100 lines.  So for the final you want something more or less that length so not shorter than lets say 60 70.  The number of lines is is not full indication of the complexity but its kind of difficult to to have complex analysis of all of data set with the 20 lines of code.  So lines so obviously are not all created igual meaning.  You may have lines that are comments lines so that are repetition of the other lines.  You can have blank lines so realign.  So it should be around 100 the complexity of the analysis.  Again if you have and visualizations that are pretty much the same with different data that doesnt mean that there is more complexity.  So you are just repeating the same lines of code.  So again 100 roughly or more lines of code around the 10 page.  think shared with you the a.  template for presentation.  You dont need to do powerpoint it Its either dog Pdf or Powerpoint or all good.  It really depends on you.  When it was the consultant was used to think in Powerpoint terms meaning to me was more natural to write Powerpoint document instead of word document.  Now working in Academy writing more papers and kind of more familiar at this point in that type of for much but but its up to you.  keeping in mind the the writing.  Powerpoint has some limitations meaning that you cannot really explain match in Powerpoint unless you do Powerpoint that it is so dense.  There shouldnt be powerpoint that should be word document.  So mean presentations should have more visual so than what so And you may not have enough to.  mean visual.  So it just to do as far what point the meaningful power for you dont need the to do the presentation so most of the presentations will be done by us so primarily myself.  will present some on the finance.  but will ask some of you and the day before the last class will let people know the day and been selected for presenting in class.  If you are selected for the presentation you need to do the presentation.  meaning the day on the presentation.  So you will do it.  Why if you cannot do for any reason you are travelling you are seek.  You have problem of any kind that doesnt mean that you are excused.  So it only means that that we need to work with you on in another moment.  So thats basically it.  Anyone has other questions on the final.  Again we will talk again about the final.  We do have time.  So let me share the screen again.  So you will start the the final by mid of April.  So right here.  keeping in mind that that you will have time.  But you will not have lot of time and we will not have lot of time for grading it.  So.  by Stevens regulation we need to post the final grades within days after the final meaning.  We dont have lot of time.  So be sure that that once we are approaching the final all the questions issues that you may have on past assignments has been settled because once post the the final grades on the register on our website changing it.  The is process can be done but its process and can be done only for exceptions.  So it is.  Its not normal.  So you have spreadsheet where you can trace all the the grades that you had.  So far you can do an extrapolation.  You have the statistical skills for doing it.  You can do an extrabolation and see what would be the final grade.  So if you see that there is something wrong meaning that you are failing do something now because you still have time to correct the situation.  So again know that will have people the day before the last reaching out to me saying im failing the courts so can do something So the answer 99 of the time is No because mean im telling you now and we are for weeks from the end of the course so you have time to plan in the proper way.  But exceptions can happen and we can definitely handle but not everybody who is raising an issue that is legitimate one or an issue that couldnt be added.  can.  We could be addressed before right like right now.  all right.  So that was longer almost half an hour before the current topics.  So let me go now to the current topics that are related to visualization.  Let me share the screen and let me go here.  All right.  So visualization is an essential portion of of the data exploration.  And when we explore data the certain point we need to present the results.  So presenting the results meaning calculating the proper metrics and express present the the metrics in way that can be helpful for the the ringer.  Obviously the visualization is something that is very strictly quarterly and with the capabilities on the hardware where the the programs are running on begging time the seventies the eighties.  So the was not particularly power.  Tool.  We didnt have display.  mean most of the computers.  We are character based meaning apart from very specific applications.  So like all the applications where based on characters that is not much in terms of visualizations that you can do with the character based interface.  So going fast forward with the evolution of our computers with the introduction of graphic Oriented the operating systems.  And you know Gpus graphic processing units things changed lot.  And right now we can really do lot in in terms of using the visualizations for presenting the results or analyzing the results.  But one of the thoughts that is kind of growing pushed by Van Nuts is the term visual analytics.  So reality is the visualizations are the the the tip of the iceberg.  If you dont have enough data enough metrics in particular you are not going to get much out of the visualization.  So no matter what vendors can say the real goal of the visualizations is to represent the right metrics.  If you dont have those metrics there is no visualization that can really help you match.  So there is no intrinsic visual analytics.  but you need to do quite lot of homework or preparation before going into the visualization.  So the visualization is super useful.  It needs to be addressed in the proper way.  keeping in mind that that anyway is something that is subject to the quality of the method of of the data of course but on top of the data of the metrics use the to.  mean stress one particular aspect of the analysis that you are doing erez agmoni.  When we do visualizations we can do visualizations for medium different reasons for analyzing relationships between whole and part for discovery and relationships 250 for doing sort of exploratory and confirmatory analysis on multiple screens.  We can have different data types combined somehow in visualizations just to get sense and we have some tools where the different visualization.  So it can be.  mean connected meaning.  You change something on one visualization and you have the changes affecting the adults.  You can use visualizations for temper or you for analyzing time series you can use for supporting your reasoning.  So mean there are quite lot of applications in visualization.  So.  and dont know its really helping lot in all of that.  We do have in visualization that is em 622.  mean.  This is just to say that visualization is more than just one class because its its its complex topic with the implications in terms of economics psychological impact and things like that am 622 was originally developed.  Using ara.  We are slowly but kind of surely moving towards pies.  On us Initially python was not particularly good in visualization with the Mt.  Properly but being at that time probably the only the library available.  But now between See Bonnet Bouquet plotly.  There are definitely better options than was primarily Gg.  Plot there.  There is Gg.  Plot for python but not particularly great.  so no no one is its pretty much using Gg plot on python.  So we use booky and we use plugin Seborn.  Its library on top of my plot lib and he is also integrated with the Pandas and Pandas are integrated with with noon pie.  The old combination is making this library quite powerful so you can do quite lot of things using few lines of code with the bouquet.  Its another interesting library created by continuum analytics.  One of the main advantages is the that now is on nothing blockly as well is the possibility to create HTML directly from the library.  Thats big advantage because with that you can use your visualization in webpage.  You can send the HTML to your client.  There is little bit of of processing that that you can do on that.  So And then there are quite lot of options with the book in so you can.  Really.  those are some of the examples so you can link different plots as was mentioning before.  and you have sort of tool box for doing few things and again that in the past that you had to provide the HTML to have your graph in HTML code with the bouquet.  This is from the random.  You dont need to do it.  Plotley is combination of open source and commercial software and its very powerful and we use it for creating complex dashboards.  Dashboards are integrated the visualization.  So where you have more visualizations on the same screen linked or not together but the all combination is giving you much more insights than individual individual visualization.  So let me go now into the some code.  So let me close what we had before and let me go into.  and the visualizations.  So thats an example of very basic visualization with okay.  So you import the library and the components that you will need in you name the file that you are going to generate an HTML.  Then you define the conditions for the that you are creating and are the data you define the type of plot you want and then you show it.  So if run it up so thats what you have it.  Its real.  You can move it.  You can.  mean have it zoom in.  You can to set it if you want and so on so is an HTML for all instant.  And so and its this one is separate file.  So few more examples.  So in this case its mean little bit more complex visualization of same principle.  So you have the dots in each one of the intersection of the yeah intersection and on the curb on the line.  In this case.  and some other examples.  mean you are going to have all those examples in canvas.  So this is little bit more complex.  Let me close the other more room.  So in this case im defining function up and in representing the the Lorentz function in particular using bouquet.  and if run it.  thats what they have.  all right.  So this is pretty much it for bookie again.  all of those would be on on canvas just couple of examples.  So in this case.  as usual im importing the the libraries again.  See Bona is using pandas and importing the pandas and is on top of M.  Plotterly by importing Macloply as well reading file and then setting parameters and show it.  mean when you do things that are relatively sample.  Simple life is easy.  But when you want to do visualization of the more complex then things will become ere mean explorer even partner.  Another example.  See But now again.  So those are in this case its generating different visualizations.  So you have analyzing by genre is music.  and this is platform.  So did it not hes not using his game so sorry about that.  So lets go to Plotley.  Thats basic example of plotting.  mean thats working with properly can be complex because it is more powerful.  Again you can create the dashboard.  So when you create dashboards things are more structure more complicated.  meaning that there are more parameters to play with.  So in this case let me run it and then we would go back to the code.  So in this case im analyzing different universities by set of parameters.  So those are the universities.  and those are the parameters the the values.  In this case the parameter is the number of students and you have the different mean the distribution for the different schools.  So in this case you have You are analyzing citations and teaching for the mean different schools.  and in this case you have another view with what rank and citation and teaching.  So thats plly.  So those are the visualizations that we created.  That is one that want to show you.  That is quite interesting.  That is the Sun key diagram the same key diagram that was created to analyze the hydraulic flows.  You will see why once run it.  But so you basically have the starting and the ending of the flow.  So you have this flow that basically was divided in in sub flows.  Then there is merger and you can eventually have intermediate stage.  So for the fluid the analysis is its quite obvious but can be done for processes.  It can be done for analyzing.  mean one of the applications that it pretty common during the elections is to see how the the boats change the from one political party to another political party.  So you have the previous elections.  And what is the dynamic of those flow.  so in general is representing flows.  Obviously hydraulic flows is the original purpose.  But processes or evolution in time of events all good examples.  We use that for analyzing the relation between the different topics in conversation.  So how the conversation involved in time.  So you have the initial topics and how they change in time.  Its pretty cool approach.  So again mean in this case its its pretty basic.  So you have the original stage as the final stage.  Just so you have so star.  Get the and values.  And thats basically what you do.  all right.  So there are couple of additional things that want to share with you on visualization.  So one is related to book that is of knowledge that is quite the atlas of knowledge.  Im sorry that is quite an interesting book.  It is not recent one.  Its probably years old.  That was originally mean.  The original scope of the order was to analyze the the geographical of research.  So how the different topics are moving around the globe.  But then the scope of kind of broken up.  and became sort of point of reference for visualization.  This slide its.  hey Kind of useful because when you have problem you need to define what is the the visualization and it is going to work better for you.  So what are the the the the the metrics that you are going to use to decide which will work better for you and which without so Theodora defines the the type of analysis that you are doing and the level of analysis that that you are doing.  And then in the intersection you have an optimal form of visualization.  So the types statistical analysis.  When were what with whom the level negro and based on where you are you can have graph of one type or or another type.  So it it.  Its kind of systematic approach and then the other goes into the details of each one on the different level.  cannot share the book on canvas.  bought it on Amazon in kinder format it.  It.  Its good book with great visualization.  So have Pdf.  From one of the presentations that you order gave all over the years and in that one of the page it page 16 and this Pdf.  Is available on on.  So you will have the different visualizations and you have the same slide that they was using there.  So with the the types and the level.  also share the on campus.  This che it on what is the best visualization for what So is flow chart.  So you basically have the options you navigate the in the chart and you will pick whatever is the visualization that seems to be more appropriate.  You have versions.  This version is one page with page in it that and then there is the one that is us more dates.  So that is basically this one thats split into.  So thats pretty much it on the visualization of that.  just want to go back for moment on on pi charm to share with you more the scripts.  the Dara on the Mmm.  Analyzing the data.  So when you analyze the data you really want to be sure that you do set of steps analyzing missing values analyzing your outliers.  But the single most important part on the analysis is analyzing the correlation.  So correlation is important because if you have one or more variables that are highly correlated there there is no real need to keep them in the analysis.  because they are telling the same story.  So if you have one variable saying length of all of an object and then on another variable.  dont know millimeter of length of the object.  They are clearly the the same thing.  mean.  This is very obvious but and they would be highly correlated.  Or if you are measuring brain or no rain you are the variable saying Ring no rain and you have another variable saying the so rain obviously if is not is raining meaning that there is an eye correlation between the millimeter or rain and rain or rain.  so there is no need for you to keep both of them up that you want to remove one of them.  So correlation analysis is important for cleaning but its also important to get insights because it will give you an idea.  What are the variables that are more depending one from the other.  and this will give you good insights of whats going on.  So there are mean.  There are many ways to do the correlation analysis.  We are talking about linear correlation.  One is growing the other is growing.  One is decreasing the other is increasing.  Obviously the not all the correlation are.  Linear it can be any function and there are other methods.  But for the time being we are focusing on the linear correlation.  So this case mean we are using different methods.  So this met on the is pretty straightforward what is using seaborn.  and the data set is the Nfl.  Census in Csv file.  and im calculating the correlation again.  Keep in mind that the C.  Born as embedded pandas and my plot lab.  So im reading the the file into pandas data structure.  And then im applying the correlation between the data and as one of the functions that is available in the Pandas and then representing it as an heat map.  That is pretty much equivalent to correlation matrix and then show it and eventually save it as Png.  So if run it it will take little bit of time because its big data set.  so thats what you have.  So mean the subject again is Nfl.  Census and you have for example the salary.  So in this representation you have the the darker values that are positively correlated the the lighter values that are on the negative correlation side.  But then you have also the number.  So is each cell is giving you the same information twice.  So you have the visual with the call order and the number that is its pretty much the the same story.  So along the demand that you are going.  All everything is one because each variable its 100 positively correlated to itself.  So if you go to the salary this salary is more correlated with.  If they are pro bowler or not the experience the age is less correlated to the number of teams.  So thats an example.  So you are getting some insights just looking at the the and thats one way to to do it the other way it using this.  Why data profiling that its working on pandas.  So same thing.  You read the the same file in Pandas data structure and then with one line pretty much you create the report.  So the right part is going to be nhtml.  So if you run it so its doing set of steps analyzing the the file.  You would see the results of in second.  So its finished.  Thats the output.  Let me open in browser.  So thats what you have.  So is full HTML record with the menu on the top that will drive you in the different parts of the so you have the overview.  Where do you have the number of variables so number of observations missing sales and all the rest.  So all of those are really valuable information.  What are the variables that are categorical.  What are numerical keeping in mind that you can do correlation analysis only for numerical variables.  So we said that that correlation means one is growing the other is growing or vice versa.  if its not numerical how can you say if it is growing or not So If you have file with only categorical variables.  Or if you want to represent categorical variables as as you if you want to analyze if categorical variables are are correlated that you need to transform at the category of variables into the medical level and then do the correlation analysis.  So this is giving you list of variables with all the analysis for some of them you will have the distribution.  Thats obviously only for the so the way you have the distribution is selling something because because you can say what is the most common in this case.  So a.  And when you have to your Gaussian distribution.  It is is what is called the normal distribution.  When you have something like in this case where it is not normal distribution you see that there are seeks somehow and you can say why there are those peaks.  Why there is peak little bit more than 200 and peak little bit more than 300.  So chances are its because there are different play.  Yes and the role.  Its kind of associated to the then the age is is queued as you can see is queue the to the the the 2423 and that makes sense and thats another indication.  So from wrap up to like this one you can really get lot in terms of interpretation.  You need to write the narrative.  You need to do this explanation but you have the number so for doing it.  Then again you dont have the distribution for the then you have correlation that is pretty much the same as the one thats been generated before.  The obviously again is only for the numerical variables.  The representation is little bit different but the meaning that is exactly the same.  So you have go into the blue being positively correlated going to the red being negatively correlated.  So in this case there is pretty much no one that is negatively correlated with this is something that is pale red that is number of team and high but mean to we just so you can read the into that because you can see again.  We mentioned the salary but there are mean position probably and wait.  You can see that there is correlation as we imagine.  mean that position way in height are correlated more way than height and then missing values.  You have all the analysis and assembles.  So again with the basically lines of code you have with the several page that you can use and you can attach to your presentation if needed.  Okay so let me stop sharing for moment.  Its the and would introduce.  Now its in class exercise.  If there is no question.  Obviously if you have questions feel free to ask.  All right so let me share again and let me go here up so we will talk about the Us.  Baby names.  So the reason why im using this its because of the certain point quite lot of students.  We are doing their final project on us.  really dont know why but thats whats log of students did the at the point in that they decided to move it to an in class exercise.  taking dead option out of all the options.  For you know the final because as you already did it in the in in class ex at sites.  So you want to read the this Us.  Baby names file into Pandas data structure.  You want to pre instead of basic information.  You want to delete the call on that unnamed the 0.  And Id you want to determine if there are more female or male.  The the the top in tens of number of bring the number of names and the data set between the standard deviation of the name of core answer.  meaning this mean the the average just under deviation on the name of and then print basic descriptive analytics on the data set.  Okay so let me make sure that that all of those are are published and give me s.  Okay you have all the slides the in class exercise.  And okay.  okay.  well be talking about this data exploration after that.  All right.  So let me create the breakout rooms and and let you work on them.  and then so we are creating breakout rooms with the participants probably better if we do breakout rooms so we participants per room.  So the rooms are open.  Please join them.  will post the recordings and we will be talking in the 20 min around the 80clock to discuss the results.  Resuming the the recording.  So rooms would be closed in s.  Theyre almost there.  Okay.  They are over closed.  all right.  So how was it anyone want to share what you did All right so let me share if possible solution.  They share the screen go here all right.  So importing the the library that they need the the library.  reading the the file into the it into data structure.  printing playing info on the on the the data structure.  mean its going it.  Its going to be not particularly nice looking but this is what both in the requirements.  deleting the the columns that we wanted to delete printing the first names in the structure.  then im counting those by gender.  and then grouping the mean im creating new data structure with group by name and removing where dont have either the blank the that there is no automatic values.  Then printing the observations mean did in Here we have the you have the first.  Whatever is the number in the parentheses.  sorting from the biggest to the smallest.  with names printing the had the then number of unique names.  So with the A.  What is interesting is that when you do the group by it will keep only the unique names meaning do not need to.  mean do loop so its feeling variable mean its super straightforward but its compass to so and then names with the highest so calculating the the mean just as lying the sound that the and then little bit of descriptive statistics.  If keerthi thats what get.  So thats the initial that information.  Whats names in the structure distribution of my female names in the all the unique names.  not mean that sorted the top names.  total unique names names with the highest accordance standard deviation and the descriptive statistics.  So it was just an exit size on Pandas.  Pretty much so on exercise 5.  Im sorry if your except size.  is not being graded yet.  send an email to see you.  It will be graded between tomorrow and day after.  So import in the libraries.  Open the file again.  In this case im not using pandas.  Im creating this.  Get index that will get the data set.  and we will not generate an index from to based on the value on the age.  have another version with but thats fine.  Then initialize counter with multiple values.  Each one will count the the the number over for each one of the different age category.  So initializing dictionary initializing the the number of max the maximum number of that.  So the name of the doing loop into the file again.  could have been done not using pandas.  didnt use pandas in this case but thats fine.  Im looping into it for each.  Im getting the the index.  So if the index is 10000 so going here so meaning has not been changed meaning that there is something wrong in the value so it is not to 24 or whatever it is but it is either blank or wrong value.  So if this is the case.  they next will be 1000 and then that point will pass.  So we continue the the iteration.  So otherwise im getting from that particular line.  Im getting the the number of that.  and will add the the number of thats to the of that particular counter because in in at that point in the index have the position within this multiple counters counter that initialized.  and then you will iterate.  and at the very end you will have the the counting of all the debts for each one of the category.  then on the condition identifying the condition and then im checking.  If the condition is already in the the dictionary.  If is not initializing key and value.  and if it is am adding the number of that to that particular condition and then will iterate then printing the the results and counter by age printing the condition with name of the specific culmability and the number.  This is the plotting.  So im mean will be the xaxis and im.  Calculating this subplot this is the bar chart calculating all the components.  im adding labels to and the title the Rotation just to have better reading on the chart by chart seeming think.  then that mean sorry this is misspelling here.  So im using siding where im taking this.  and then showing it so.  If run it.  you have the counter by age the condition with more Covid that says respiratory diseases with the that that much thats for the identified age.  and then on the charts you have the bar chart that you have the pie shot.  So thats basically it.  This solution has been posted already.  You will have it.  Let me take another few minutes on something that you would use on the final presentation of final project.  So briefly.  when you do data exploration you want to be sure that you use methodology to cover all the needs that you have.  When you do the exploration.  we we use modified version of methodology that was originally developed for data mining.  The the middle of allergy was called the Priest Vm.  Crossing the the process for data mining.  So its its vm.  That modified the increase.  The where the is is data exploration.  So there are faces one you initially defined before the phases.  What are the goals.  Then you define the what is in the faces.  So the first phase is business understanding.  You define what you are going to do because if you dont say what you are going to do.  There is no way that the exploration can be successful.  So you define the reason the goal the research question or questions so that you have then data understanding.  You define.  You explore the data you have and you evaluate it.  If the data you have.  Its good enough to address the questions that you have in the business understanding.  Once you are good with the data you have.  But it was the the questions you have.  Then you set the data preparation where you do all the exploratory analysis that is pretty much in the mean the correlation analysis and the the script generating the HTML had that piece of before.  Once you have all the preparation meaning exploratory but eventually even changing things.  So you are doing correlation analysis.  You realize that there are variable so that correlated that you eliminate one of them to have more lean representation of your problem.  Once you have the data in the best shape possible.  At that point you do the data representation that can be visualization stables or calculating so.  And then in the Powerpoint.  You have all the details on the different phases.  so you do not need to do for the final the Powerpoint like this one but you may want to have table of content that will resemble this one.  You want to be sure that you are covering the faces.  So then you can call whatever you like.  But you need to be sure that those points are fully addressed.  So defining the research questions analyzing in critical way the data you have to be sure that the data can actually address the questions you have doing.  Then the preparation on the data meaning analyzing the data and eventually reducing the variable.  So combining variables.  eventually combining data set.  If this is the case.  once you have the final data set or data sets in the right shape.  Then you start working on extracting metrics doing the visualizations and do whatever you may need to have the proper representation that can be visualization or whatever else.  When you finish that that you draw your conclusions you are tidying together all the pieces and then eventually you will have attachments meaning all the tables so there are not mean so relevant to be in the main document but they can be useful.  You dont want to use the attachments as sort of trash bin.  so you will post in the attachments only those elements that are all some sort of of use for the the better understanding of of the insights that you are providing.  So thats basically.  It.  And you had that.  So let me go now into the next assignment.  Im not sure if have it here.  Yeah.  So the assignment.  Yeah.  One of the dont know if its its critic or it just the consideration that some of the students did the in some of the previous editions.  So was why Dont we have more exit sizes and they are more on the management side.  So is engineering management.  Why dont we do something on management So one of the things that that did the in the last couple of years and now for its and its going to do by himself.  Who the vast majority of it is managing courses managing the scheduling managing the the load for the faculty.  So put together in this excel spreadsheet simple mean.  it its not real data but its reasonable data.  So you have faculty from one to 27.  You have the program.  We are those faculties to the most.  And then you have for certain number of years components the load.  the target and the balance.  So the load is basically the number of courses that that instructor actually thought the target is what they were supposed to teach because at the beginning of each academy here each faculty as load.  There is mean there is certain number of courses so that we need to teach by contract.  But then we can have reduction based on research project that we have or activities services that we provide the to and or to the school of systems and enterprises so based on that you have reduction in terms of youre ready load and thats your target.  So you have the load.  The number of courses that you to in that particular year what was the target and the balance So that is the difference between that load and and target.  Sometimes you can be like in this case you are overloaded some other times like in this case your target was but you told only courses.  You are under loaded.  So you have from from 2019 to 2023.  So thats the data set that that you have Again some of the elements may be me singer.  maybe missing because for example the faculty number was high in the in 2021 meaning before 2021.  You have an a.  So before working on the number so you may want to do some preprocessing eliminating the in and replacing them with the or something that that would make more sense to you.  So thats the data set that you have on this data set.  You want to do some statistical analysis and some visualization.  So you want to calculate the number of courses by each program at each academy.  Here the average number of courses per faculty per academic year and this will be from the load.  The the number of the underloaded faculty pretty much academic here.  This load that is less than the target number or overloaded faculty for each academy here meaning load the that is more than the target.  Then using bouquet you want to create plots.  One that is courses per program per academy here and this will be line plot and you will add the legend for the programs.  The average number of courses per faculty over the years and this is from the load.  Each faculty will have one value.  That is.  The average of of course is total.  In that year number of overloaded faculty over the year.  Each year well have one value that is the number under loaded mean the courses by under loaded faculty.  and and then pie chart with courses by program in 2022 2023 using the names so em Ssw.  And as well as as labels for the wedges.  Once you have all of those meaning those numbers so their metrics and those visualizations.  You will write that page record incorporating the visualizations and highlighting the the key facts that those visualization will show and you will submit the the python script and the the the slash.  Pdf report.  So thats basically it comments all right.  So if there is no comment.  Thats the end of the class.  will make sure that everything will be on canvas.  and and that we will complete the green by the end of the week.  So Im stopping the recording.  All right.  So this is January 18th 631.  001 And as the first class of the semester four 624 Im happy you joined this class.  008 So this class is one of the most popular we have at the School of Systems and Enterprises.  019 And that most of the time one of the classes with the highest number of the students registered at Stephens the class is going to run on Wednesday.  026 So if you have issues with Wednesday send me an email.  044 We can work around that.  If large number of you cannot make it on Wednesday we will try to find the other options.  051 But again classes will be recorded meaning if you miss class.  105 So thats another major problem.  110 Eventually mean that again classes are recorded the lights will be available and we can have office hours either in person or online.  112 Let me start sharing the screen.  And let me go first to the campus for the cause.  131 So thats basically your Campbells minimizes thats your Campbells so so far.  143 But you will find the time.  Thats my office Barb.  150 Bill five or seven email showing from Shoe Line.  155 So the information on myself will go back to that.  202 We do have part time V. A.  She you she you is one of my students.  209 So.  We will.  220 mean that we will talk about the syllabus.  227 Will we talk about the distribution of content within the semester 233 The distribution of grades 240 Again theres the link for the zoom and Im in that the class today could be shorter because its pretty much an introduction.  242 We will go through the main elements of the class.  257 Recently the class was.  Was a.  reader nominated.  302 So initially was informatics for engineering management.  308 That doesnt make much sense anymore.  313 So now is data exploration and informatics for engineering management.  317 The data exploration is definitely more in line with the goals that we will try to achieve.  323 So will open doors with lots of content during the following weeks.  331 So for this week you will have orientation and exercise zero that will introduce later on today.  346 So you will have your grace discussion.  355 And lets start with discussion and quizzes.  359 So if you click on quizzes you will go here to.  405 And am prepared to quizzes 410 So quizzes are to determine what is the level of knowledge you have in coding and you to please the mute yourself.  415 Thank you.  So for this class there is no prerequisite.  429 Meaning we will start from very zero and you will end up writing 100 203 on the line.  436 So code by the end of the semester seems to be for some of you mission impossible.  450 But the reality is not so.  Again the code is one of the most popular we have and they had over the years.  458 So the course was originally developed by another professor who revived it completely.  509 am teaching it since dont know 40 years five years 517 and most of the time the students didnt have any experience in coding and any experience in coding in either.  522 So there would be two questions.  Question one Do you have previous coding experience any language 534 Zero is no knowledge.  Ten is professional level so you will write down the number between at zero and then.  542 Question to see me to.  Question one buddy on Python.  554 Do you have previous experience in coding using Python 559 No experience.  professional grade.  So and you will write down what is up.  603 You are level.  strongly encourage you to do those quizzes.  608 There is no grading but its very useful for me to address the class in the proper way.  615 Just to give you an idea of the average in the past several semesters for question one that was around three for the average for question two was one.  624 Two where the mode the meaning the most popular answer for question two was zero.  640 So if you have no knowledge of Python dont worry.  648 If you have no knowledge or coding thats absolutely fine.  654 Again had people from different backgrounds say that the majority and nothing to do with coding.  658 Coding is essential.  So on the other side let me stop sharing for second.  710 So coding is becoming more and more essential and little bit of background about about myself.  717 So my academic background originally had master equivalent degree in mathematics from the University of Rome 727 Italy and Sapienza million years ago at that time we coded in Fortran.  743 So thats my thesis was on eigenvalues and eigenvectors calculated on large matrices using Fortran.  751 At the time we didnt have any user interface so we used the the the punching cards.  804 So it was nightmare but it was Fortran and it was a.  818 Me.  Daddys around ladies.  Then went to industry.  825 So initially as uh Im developer so was coding in Kabbalah.  832 That was another language that was pretty popular at the time.  843 So Fortran was formula translator.  COBOL is common business oriented language.  846 mean those languages are still around somehow because there are legacy systems.  856 So Fortran that is actually part is embedded in but as language is defined for all intents and purposes.  904 So then developed my career in information technology telecommunication and management consulting the age of 50.  916 decided to go back to Academy because the type of consulting that was doing was kind of difficult to do because it was on strategies 927 new products new business models and its really difficult to demonstrate that you are better than adults.  943 And at the very end that was all about the people you know within the organization and more than what you are able to do.  953 So decided to go back to academy at that point the age of 50 again.  It was around between ten and 15 years ago.  Im 65 now and at that time social media we are kind of starting becoming relevant for society somehow.  And my idea was to go back to the math departments and do research on applying mathematical models and my business experience to get the insights on the social media.  applied the for Ph. D.  programs to different universities but then realized that mean that obviously as mathematician would have loved to go to Princeton.  So the head of the Department of Math at Princeton replied to me saying We would be happy to work with you on this topic.  But obviously Princeton is highly competitive.  So Stevenson has had that and has great reputation.  live in Hoboken now so it was the natural choice to be at and Stevens.  had great conversation with.  What was the head of the math department.  The.  At the time that he passed away he was kind of mentor to me in my academic life.  Charlie Hustle.  was admitted and started working at the very end that got.  mean my original idea was to do it to do mean math sociology and little bit of computer science but not much.  So that was the original idea to redirect.  Somehow my consulting activity is more in line with the quantitative approach that was definitely emerging.  During the period of my GFC continued working as consultant for about year.  was CTO coCEO of technology company and did other consulting.  So it was part time.  It took me about five years.  During the last period started developing courses in data science for the School of Systems and Enterprises.  They offered me job.  stayed in the loop and so Im in the last five years and change am in and Stephen says full time non tenure track professor during the development.  So am telling you the whole story just to give you little bit of background.  During my research activities didnt want to code so thought Im too old for going back to coding.  definitely want to be more on using the results.  But then realized that if you want to deal with data the only way to deal with data is to work.  Hands on on.  There is no middle ground.  You cannot just ask someone to do the job because it doesnt work this way.  So you really need to get your hands dirty and work with data.  So at the very end started studying Python and then teaching Python developing courses in Python.  Right now its kind of form of relaxation and meditation to me.  So have my ideas.  So my research focus is on machine learning and natural language processing and natural language processing in particular.  So have ideas of models so that want to develop and coding those models to me is it it is relaxing so dont pretend that you will be and that point lately that on that you may continue to dislike eventually according but is skill that you definitely want to have because you can apply that to whatever you are going to do if you will be managing team doing the coding.  You definitely want to have real experience in coding.  So firsthand experience because otherwise you will never see the problems they will have.  So 624 is core course for engineering management and is becoming core course for systems analytics as well because the course is basically teaching how to use Python for doing things.  So is not on teaching Python but is using Python and as byproduct teaching Python for doing things primarily data exploration.  So thats long thought.  Let me go back in sharing the screen and giving you some more background information.  So let me start with the content of the course.  So the course is over 13 weeks.  So there would be some weeks that we will keep because on the academic calendar we will do the orientation today introduction next week.  And then we will continue each week.  Pretty much you have one assignment.  The initial assignments are easy so but each assignment is built on top of the previous one.  If you fall behind the catching up its really complicated.  So in this course in the past we had quite some or several cases of cheating.  Cheating primarily is either having someone else doing the assignment for you or sharing the assignment with other fellow students.  All the assignments are individual so all the assignments meaning the regular from to the midterm and the final.  So.  They are individual meaning if two of you will do the same.  So with would submit the same exercise.  Lets say any of you are doing exactly the same and these same is well done.  So it worth hundred.  The grade for each one of the end will be hundred divided by an.  And there is no ifs or buts to that.  The only exception is if one of the will come up saying was the original owner and then the remaining minus one will tell yes we copied them and they point the the one will get less than hundred the because you are supposed to protect your assignment.  We get around the 80 between 80 and 90 and all the adults will get ten 15 20 just because they kind of are being honest in not acknowledging the fact that they cheated.  If you look at the numbers.  If you start losing chunks there are chances that at the end you will not make it so.  And then at that point there is not much that they can do or want to do for you because you lost points by cheating.  And mean.  The rules are clear.  So if you dont follow the rules you will be penalized.  So the way you will be penalized can be up to the point that you will not reach that.  And let me go to here.  You will not reach that minimum grade pass.  The courts.  So theres distribution of that and you do have both the previous spreadsheet and this one.  So you have all the exercises.  So the participation is based on the metrics that they get from what they what they is.  Tracing the page that you visited the time that you spend on the online on canvas on the course.  And what they do is basically calculate the average and then define mean how much from the average is to be considered to give the full 30 order portion of it Its sort of standard deviation from the average.  So those are the points that you can use this spreadsheet as dashboard to have an idea of what is going to be your final grade.  So the formula is the formula that you have here.  mean there is no secret in that theres formula that am going to use.  And if you dont get to at least 73 you will fail.  So.  If hes more Im sorry if hes more than 64 you will get C.  So between 73 between 64 and 73 there is below.  That is an F.  So you can eventually do some sort of extrapolation meaning you have grades from exercise zero to exercise lets say five.  You can calculate an average and you can extrapolate the points and you will get for the following and you will get an idea of if you continue the same way what is going to be your final grade If you come to me by the end of the course saying Im not getting Im not going to pass at that point its going to be too late.  So use this spreadsheet as sort of tableau the board dashboard for understanding what is going to be based on what you have so far your final grade.  Use it.  Use it lot.  So thats something that you have.  Assuming that you have thought in the backseat in the participation.  All right syllabus.  So the syllabus is the main then on the syllabus.  So again my name and my email address.  My office.  Wednesday 630 is generally till 830 900 sometimes maybe longer or sometimes like today may be shorter.  In the first editions of this course had textbook.  So then realized that students do not really read much.  The textbooks so is required.  But you do have version.  So if you go all the way down you have those as PDFs.  Later on will post some more readings.  So use the MOOCs as sort of reference.  So the slides should be enough to let you do the assignments.  The assignments are learning opportunity so you are forced to study some elements because you want to do that.  You want to pass or get good grade in the assignment.  When you called the when we called that at any level sometimes we do not remember how to do things or we do not know how to do one specific task.  Google is the source so google the information.  Go to StackOverflow.  That is kind of a.  The place to go to get supported in your coding and you will get answers.  So answers that are obviously not for your specific case but are in the class of what you are doing somehow and then you use it for whatever is the goal again.  Sometimes in the assignments you will be asked to do things that are not that were not in the slides.  Thats intentional because thats something that when you write code is happening all the time meaning that you are kind of push the beyond your comfort zone and you need to go online and get some help from the community.  Again.  We use Python.  So is one of the most popular.  At this point is the most popular computer language and there are up in the medium versions.  So we use 3. 6 3. 7 that is OC 3. 8.  The 3. 9 is little bit of stretch and there is 3. 10.  But the main problem is one of the main advantages of Python is the fact that there are quite lot several thousand libraries that you can use to add the functionalities to the basic python.  If you use versions of Python that are very recent 3. 10 those libraries may not be compatible with those releases.  So if you are anywhere between 3. 6 and 3. 9 you would be okay to be on the safe side the 3. 6 at 3. 8.  So if you go above that the libraries may not work.  We use the.  Adds These integrated development environment you can use any idea you want that we recommend to use by China.  That is probably the most common idea in Python developers or in Python development community that we do not use what is called notebooks.  So notebooks are great for proof of concept or things like that but they are not good for developing products and programs that will be part of product that you are developing.  We will go back on these concepts but if some of you are already familiar with the concept of notebook please dont use it use any etc.  or any idea but not notebooks like that.  There are few of them.  mean at this certain point will spend portion of my class on how to use those tools but not now.  In sense am revising those tools and in particular those that are online collab.  In particular have mac.  My Mac is latest generation with Apple silicon.  The Apple silicon the Apple microprocessor is not compatible with some of the machine learning libraries.  So because of that Im using an online environment that is called collab in itself but it is not the only one until there are few of them.  Im using this collab that is by Google and is probably one or the most common.  So Campbell we went briefly into canvas that it is your responsibility to check the assignments to check the new material up.  Im not going to send you reminders.  So you know that by the end of each class will force the new material to new material on an average includes both the slides.  Eventually some reading material.  And in most of the cases all the cases but one where cases are class is the assignment for the following week.  We dont use much the discussion board either but you can open one if you like.  Submissions.  So.  To me is more important that you do an assignment.  Well more than you do.  Exactly.  Within by the minute by the deadline will apply some late submission.  Just to be fair.  So when we teach one of the things that we really care lot is to be fair across the class.  So if someone is doing their best to be on time it wouldnt be fair with those people.  If accept the submission that is one day late then obviously there are two days maybe.  There are exceptions.  So you are working and you are traveling.  You have an emergency.  So mean emergencies are emergencies.  Exceptions can always happen.  But the rule is that you will submit your assignment before the beginning of the following class.  So the reason for that is because most of the time will present the solution at the beginning of the following class.  So at that point cannot be sure that you need to use my solution for your submission.  So the deadline is the beginning of the following class.  think is fair way to approach it.  As mentioned how relevant is the ethical component of being in these courts We come from different cultures so we may consider cheating more or less impactful on that ethical code.  But the reality is in this case the rules are clear and the rules are what you see in on your screen in the syllabus.  So again all the assignments are individual.  So if you share code you will share the grade.  So again you have ten students doing in 100 grade assignment.  Each one will get ten.  So if you are losing 90 of your grades or even 30 of your grades by the end of the course you will not reach the minimum to pass the courts.  There is no problem using online resources.  So mention that StackOverflow that is the most popular site for getting support in some critical steps in your development.  So if you do so you need to cite the source that you use that if you dont say if you if you dont cite the source then cannot tell if you shared the code with someone else or you just shared the source.  So you need to cite the source.  If there is no citation of the source have to assume that you are sharing the code with fellow student.  In theory when that is case of cheating should report it to the Ethical Committee.  Once you are in the ethical committee then things can go pretty bad meaning you can be expelled by the students at that point.  Finding another university would be really challenging.  You dont want to go that way so please dont cheat.  Im doing this course again since quite while with our.  We are using tool to help detecting the level or similarity between assignments.  But cheating without being caught is is difficult.  So if you cheat the you need to cheat while cheating.  Well its most likely as much complicated as doing the job yourself.  So mean those are the outcomes.  And again you have here the content.  Generally speaking the up to the meter is pretty much basic based on an introduction.  So if you are already very familiar with Biden the first half is not going to be very challenging for you.  So but you will review some of the concepts after the midterm.  So the midterm in on campus classes.  So the midterm is on campus.  In this case obviously would be online.  still not sure if we will do in real time.  Meaning you will have two in an hour.  Fireworks like in the regular.  On campus or if you will have one day or two days to develop it.  After that you have more of the application so you have better visualization the text processing web mining and things like that.  All right.  So let me stop sharing for second the questions around the.  Are you all good All right.  So.  Let me keep sharing a.  And let me go through the first the OPs.  Set those lights up.  So again we are going to do an introduction.  So we did the introduction to the formal aspects of the courts.  Now we would do an introduction to the materials.  So users versus builders.  Though we are.  In what we do each day sometimes use ups sometimes builders.  So in our job what they want is the job.  We may be builders so we may actually build things.  You are an engineer.  You are building bridges or whatever.  You are software developer.  You are writing software.  But we are also user.  So we use the television but we dont build television.  We use computers.  We dont build Mozilla so we dont build computers.  So we are in this range all the time.  When you are on the coding side we are both users.  So code the we all use software everyone using PowerPoint and Zoom right now.  But we are also builders meaning we write code.  So when you are on the coding side the developer is programmer.  So the demarcation line can be kind of thin because if youre using spreadsheet you can have quite lot of developments in the spreadsheet as building can tell.  Meaning you can have formulas.  You can have the.  mean even some coding embedded in the chip.  But generally speaking when you are on the program side you use computer language whatever the language is going to be.  Languages is code software so is sequence of instructions that you write one after the other.  Most of the time the sequence you write the code is the sequence.  The program will be executed.  Generally speaking computer is something providing an input output.  So is the portion that is the entry point the element for the user to use the computer.  Then you have the computer itself that is processing unit and memory and software up to user.  Both the central processing unit and the memory.  And then eventually you have an external memory like hard drive or thumb drive or cloud drive.  So thats the general schema of traditional computer.  We are all bombarded by the concept of the AI machine learning deep learning things like that.  What is machine learning So machines do not be loaded.  So in strict terms what is learning Learning is getting skills.  Machines do not really get new skills.  They get more data.  So based on data they apply the same skills to the new data.  So is this learning mean if you look at the system as black box is kind of acting as it was learning but is not really learning.  Same thing when we call up artificial intelligence.  Are computers intelligent We cannot really define the concept of natural intelligence so we cannot measure intelligence.  So the IQ is America but has lot of criticism and it is very biased from the cultural standpoint.  It more is working better if you are in line with the current.  The common culture meaning is not really measuring the root.  The intelligence that we have if you cannot measure not can be in that you cannot know meaning.  If we cannot know what intelligence and national intelligence is we cannot really define artificial intelligence.  So we define artificial intelligence.  Or are we we consider system as an when the behavior is intelligent or we consider it as comparable to what human would have would do.  That is another definition to.  So there are lot riding on the application of AI and machine learning that will share with you down the road by the very end.  There is no real learning in machines and there is no real artificial intelligence.  So there are more sophisticated ways to get answers.  You probably heard about the chat GPT.  So we will we will talk about this board that is based on algorithms is based on machine learning.  So machine learning as to make mean systems based on machine learning they have two main components.  One the data.  One the algorithms.  If you have good algorithms crappy data the system will have crappy behavior.  If you have lot of data an okay algorithm it will be smarter than you expect.  So bottom line what is really driving machine learning is the data inside the system and the how fast the data are processed.  At the very end the way they are processed.  Its statistical approach.  Even the most advanced systems they are actually rooted in statistics is basically statistics on steroids.  By the very end the.  What they are doing is recognizing partners in the data and matching those partners with your request.  So its part of recognition that is correlation on steroids.  And thats what machine learning is.  So it seems to be little bit on the destructive side but thats the way it is.  So we dont have real models to represent the knowledge yet that we can use within better use of data.  So there is no real hybrid machine between the knowledge based systems and the machine learning systems.  We will go back to that down the road.  So but we use this kind of machine learning because sometimes it can provide the answers to solutions.  So if we have a.  topic domain that is highly documented and we have quite lot of cases.  Then we can create system that can detect the patterns and match the patterns with the requests.  Machine learning.  At the very end more machine learning.  would say A. I.  has quite lot of competencies so some of the competencies are typically in the computer science so information theory and databases.  So those are typically computer science but you have statistics and you have data mining.  There is debugger machine learning algorithm so you should have cognitive science psychological models and neuroscience all of those.  Its kind of like creating the magical mix for having systems with an intelligent behavior.  Just to have little bit of taxonomy.  So.  A. I.  is general part of automation.  So not all the automation is has intelligent behavior.  But if you have something that has an intelligent behavior is trying to automate something that can be process can be just one particular task.  Excuse me.  So robots can have a.  An intelligent behavior can not.  So if you dont see that dont know the robotic for tightening bolts thats not much intelligence about the automatic process.  Its automation.  Its robot.  Autonomy can be part of artificial intelligence is part of it.  The artificial intelligence may be robotic or not artificial intelligence.  Its broader term.  Machine learning is part of it.  So machine learning generally speaking we have two different approaches to artificial intelligence one that is based on data and is machine learning.  One that is based on the equivalent of urine sticks.  So you have behaviors that are represented by rules taxonomies.  So those are forms of representation of those risks.  Data science is combination of tools techniques that can sort of artificial intelligence and machine learning probably serving more machine learning than artificial intelligence because that or that non machine learning artificial intelligence because the machine learning being based more on data needs more work on data.  So data science is definitely more synergetic with machine learning.  So we brought you some python python and break now.  Biden is the most popular language.  One of the reasons why is so popular is because its relatively easy to get.  So the learning curve is not too steep and there are several thousand libraries that can have the functionalities to Pythons.  mentioned StackOverflow.  StackOverflow is providing support for all the like most of the languages.  So but if you look at how much is growing by doing so the number of the items items can be answered questions interaction in built sense over the years on StackOverflow on python is driving python to the leading position.  Job posting up again.  And within that the jobs where you have some coding that there is quite lot of python.  So and thats why we are teaching Python as core course and thats called on systems and enterprises.  So again why its so popular at its high level is the interpreted.  So there are two ways to do computer languages.  One is compiler one is interpreted compiler means you write your code then you have tool called the compiler that is translating your code into machine to machine language.  Machine language is sequence of zero one.  Obviously for computer working on that zero one is faster than interpreting the statements one at the time.  So the interpreted languages like Python that are executed top to bottom left.  So write the one statement at the time.  Compiler languages kabbalah with one another up so they are up faster.  Plus classes compiled can be compiled.  So those are faster because at the very end they are like one block that would be executed that in the fastest way possible.  But they are more complex to debug because if you have an error you need to go back to the source code compile it again run it again and see whats going on.  Because mean in the past that was more of an issue because processing was really slow.  Right now our computers are very fast so its kind of difficult to see the differences between interpreting and compile them unless you do very complex tasks.  So we mentioned the difference between Compiegne and by them.  So the name by.  So the language was created in 1989 by Guido Rosen and.  The name is not from Disney but is from Monty Python.  There is group of individuals who did several movies that were kind of defining the period and the good.  Guido was most likely big fan of them and named the language after them.  Installing Python.  So thats an example for installing.  There is 3. 7.  11 but obviously you can have different the last numbers for different releases.  So.  You may want to develop.  Do use an I. D.  an integrated development environment.  Again we use a.  Yeah.  Its kind of funny the fact that it is named after the movie.  So thats an example up.  But its probably easier if we stop here and we go directly to.  Bigshot.  So thats by Sharma.  You have on the left side you have your files and they are organized by projects.  So you may want to create the.  full draft and you will address by owned by Sharma to that folder like in this case that have within this directory this folder EMC 24 and have all the files here.  So thats pretty much like finder in your Mac or equivalent in in Windows.  Then over here you have the editor.  So in the editor you can write whatever you want you will write your code.  Basically mean is an editor like dont know what.  So you can write whatever you want.  Then you can save it in the proper way.  Here you have multi functional area with all those features.  So in this case is the output of this program.  You have eventually python console.  And let me move this up.  So the version of Python that Im using is 3. 9 and you can interact the here doing things like two plus four at the end and you have the answer.  You can create variables.  So variables are like containers.  So can say equals three.  Be equal to six and then can do plus B.  And they can get the result.  Keeping in mind that implied or not more letters and capital letters are different.  Meaning if they do capital plus.  Capital B.  will get an error.  So mean that it would it be for both for and but is basically stopping the first road.  So.  can do multiplication can do three multiplied by five.  can do Division three or 33 divided by seven.  So the outcome in this case in this case was an integer 15.  In this case is floating in the latest version of Python.  There is not much of difference.  You do not need to define invariable as one or the other in three point in to point something.  They were different variables.  So all of those are some of the examples of ways to do things.  In theory can write everything in this interactive window but obviously it is not particularly mean friendly.  And thats why we write programs like this one.  And we will go back to this one in moment.  So let me go back here.  Thats pretty much the example that we had.  Uh let me go back again here.  mean in this case you not really need that.  So you can do class B.  And you will get the result.  Or you can do print.  A.  Class B.  And you will get the same result.  little bit nicer.  So you dont have out of that actually the number.  So in Python three point whatever you need to write the parentheses.  So when you want to print something up if like in this case are just variable to you just write inside of it whatever it is.  Variables can also contain.  Things like you and say.  Name.  Equal.  You can have single or double quotation.  And then if do print.  Name.  will have the value of that assigned here.  So all of those are super basic.  But any statements that youve can write in the interactive Python console as its called the great.  So let me go back here to.  Again those are some of the examples that we use the.  We name lists.  Dont worry about that.  So we will stay with the integer strings for while.  But there are other types of variables.  You can do all the operations up as mentioned.  There are some that are kind of obvious plus or minus multiplied divided some.  Probably less power is the double sara modulo that is the remainder.  Meaning if you divide the nine more by two you will get remainder of two.  By seven you will get the remainder or two.  So the result will be one with the remainder or two.  So modulo giving you the remainder.  You can assign again names to variables.  The names can change.  Meaning if now do name.  Equal.  Do.  Oops.  And then do print.  Name.  So it was Carlo.  Now his job meaning those variables can be the content of the variables can be changed that these characteristics this characteristic is called being mutable.  And so the variable by that the content on their variable can change is mutable.  Not all the variables in Python are mutable.  We will go back to that down the road.  Okay.  So names you can assign any name to the variables.  So keeping in mind that names are Rickys sensitive.  So we saw the example with small small capital cabinet would be that python that didnt recognize the capital because we didnt define it yet.  You want to use names for the variables that are meaningful for the use of the variable you have.  So if you want to calculate the BMI or someones BMI the body mass index is weight in meter in kilograms so divided by high in meter to the power of two.  So you can call the variable ABC.  But then if down the road you want to do something you may not remember one the variables.  What was the value or the meaning of the variables So you want to use names the variables that are mnemonic so you can remember.  So when you have code that is few lines life is easy but when you have code that is hundreds of lines and probably you are not even the order or the code or someone else is looking at your code.  Then you definitely want to have your code with the mnemonic names for the variables.  You can.  Use the interactive.  Console under the Python console or you can write programs in the editing window and then you can save it and run it all together.  When you run the program all together Python is reading as said from top to bottom from left to right.  There are some rules so the syntax is not super heavy in Python but is something.  So you want to be sure that you will follow the rules and we will discover the rules.  Why We will use it.  We move on to programs.  We mentioned what this could be.  Those are the links and thats the end.  So let me go back to here and let me introduce the oh let me stop for second and check if there is any question.  All right.  So there is no question.  So let me continue sharing.  And let me go.  Here and Id be glad to accept side zero.  So except say zero.  As you may deduct from the number of points is very basic is only 20 points.  So on an average mean that most of the assignments are 50 points after the midterm because they are more complex.  So they will be 100 points.  The midterm is 200.  And the project that is also the final there is no final.  So the final the project is the final is 300 points.  So what you are asked to do is to set up pie chart and python.  So you go to jet plane brains dot com website to download and install pie chart either at the free or the academy version.  You want to set up folder with your current and future files from this course and you want to have it.  Right here.  So like in this case you have em.  624 And if you go to the actual organization is probably easier to do like this.  So you have the highest level.  You have directory with all the projects.  One of them is this 624.  That is what you have here.  So again you place it whatever you want.  So in this case had all of them together.  But then you need to go into file open.  And then you want to go to.  The folder where you have your folder or directly the folder.  And then you take for example this one you open and you have all the files that are in it.  This is project.  Then Im developing for the Department of Defense.  Okay.  So.  One more thing on page Obama.  If you go into settings you are going to have quite lot of information.  So then in particular you will have information about the project the meaning this 624 in this case.  Recommendation in the previous one.  And you have the structure meaning exactly what you have here and your interpreter.  One of the good things all about by Sharma is that you can have more than one python on environment two different projects.  So you can have one project that you do with Python 3. 6 and one project than you do with 3. 9.  And you associate what its called virtual environment for each one on the.  And then within the projector you can have fiber.  And so those are all the libraries that are associated to these 624 project.  You can eventually change the interpreter.  Okay.  So those are mean have 3. 7.  3. 9.  And again in this case Im using 3. 9.  And for while was using 3. 7 and 3. 8.  Recently migrated to 3. 9.  still having little bit of compatibility issues.  So my recommendation would be to use 3. 8 and eventually 3. 9.  So again you can change the appearance.  You can have different user interfaces different color schema.  You can have plug in.  So there are quite lot of mean and on and options that you can set in settings.  All right so thats by Sharma.  And let me go back here.  So you want to run some of the comments in the by them we know like we did we did here so those comments here and you want to save it with screenshot so you take screenshot of things like this one and and you save it and you will submit them.  So then you will download the access site zero.  That will be this one.  And.  You will have that.  Right here.  So thats the one that you can see here.  Now you dont need to know exactly what is the meaning of each one of the lines that are here.  So just take it the way it is and do what you are asked.  So in this case.  You open up.  And before the statement that withdrew you want to add those lines So those lines up will add your name.  So this character here is one of the special characters in Python.  When you have backslash and thats an indication that the characters are following it that is special character.  The stands for new line of meaning before printing ground by your name by Cardinal Eaton you are asking the interpreter to keep line.  The same result could be achieved using printer with nothing inside.  You can do either one.  generally use this notation because it is more compact.  So again you open the access site zero from Camus.  mean you download from Camus in the.  The folder that you created up.  You need to save it.  Into the folder and then you change it this way.  Then you save it and run it.  What is run it run it.  You should have this here.  name of the program and this arrow meaning run the exercise or you can right click go to run and then hit run.  So now the program is running and is basically doing what is called the loop meaning is staying here until there is break.  So in this case is asking me the first integer lets say 22.  Enter saying an integer 44 or whatever 24 and Id say.  And you have a.  So.  The first one.  Its right here.  Im assigning to the variable of first name the value from the input.  Then.  If the value is done we break meaning we go out of the loop.  Elsa Meaning if hes not done.  Hes asking for second number going to the variable signal number.  Then is doing the calculation while is printing.  So printer is keeping one line the sum of both.  Now that is the first number.  In this case was it 22 plus And this is mean not variable but the actual value.  Second number and it is the 44.  Is equal to is equal to.  And then you had the operation.  So with those statements you dont get the enigmatic value.  You have no numerical value.  So you need to transform the non numerical value into numerical.  And thats what you do with this statement float.  So its transforming in floating for tsunami meaning from being non numerical will become numerical.  And at that point that can do the operation.  And then mean in this case Im using combination but doesnt really matter much.  So the first one is transformed into floating of the second then integer.  But whatever could have used to transform the string into number both the floating or the integers.  And then when you eat that mean when you type down you go break meaning you go out of the loop and you will execute this one this print.  So if over here do.  Done.  And there.  At this point its leaving the loop and is going to print.  So again dont worry if you got just fraction up or the description of the code other than giving you at this point is not essential.  We will go into each one of those in the following classes.  One thing that worth mentioning is the fact that Biden is using lot the indentations.  So when you have loop like this one everything that is invented will be part of the.  Or when you have conditional statement like in this case the if true as to be indented.  So all of this block from here to here will be executed that as part of the.  This one will be executed only when you have that done for first name.  If not you will go into Elsa and then all of this will be executed in case of ends.  Again you dont need to really understand that whats going on.  Another element when you use the numbers sign up everything following the number of sign is that comment.  There are other ways to comment.  So when you have like in this case that is not the best way to do it but is clear.  So you can have a.  The characters at the beginning and the end and in between you can add all the comments you want and they will be not executed by Python.  So thats basically it.  Again let me go back to here on.  So.  You want to set up by Sharma including downloading Python.  And by the way you have video here.  Get getting started with Pi Sharma.  You have the link to pay Sharma.  This is the dock that we are viewing.  This is the the script to this script here.  And the due date is next week.  So you go back here again you will install Pi Sharma and PI.  Then you will create folder where you will place this person map and the following assignments.  Then you want to run you by.  Dont call monster like we did that.  Look right here and you want to take screenshot of the results and submit that in a.  Right here.  When you will do the submission then you download the access side zero.  You save it in the folder that you created here.  Then you add that before the while through those lines.  Then you save the program.  mean shama is saving automatically the program but you can.  Also do pile up.  Im in save up.  So eventually Im in this case.  And because there is no change and Biden didnt pay Shaman didnt allow me to do the same because there is no change.  Then.  You execute the program Not again to execute it right click run exercise.  You can also do Run Run.  You can also go here and run but make sure that the name of the program is here.  The first time you open it the the name is not there.  Meaning at this point the only way is either through that.  The menu or to the right click.  You want to execute the loop couple of times entering two numbers and then enter in.  Done take the screenshot and.  Rename eventually the screenshot the file and submit it.  Again its individual.  If you use external sources youll need to cited.  Most likely you dont need any external source.  So because its kind of straightforward.  Questions.  All right.  So.  Thats basically it.  So the majority of our classes will be longer than this one.  already mentioned that this class is sort of an introduction so let me be sure that published all the material.  So you have.  All the lights.  And the assignment.  Everything has been published and you will be you should be in good shape.  ft STEVENS lw INSTITUTE of TECHNOLOGY Working in Teams Le kd aA ll clipizzistevens. edu SSE software Development Organization Software Develooment can be complex task and needs multiskills multiple person effort meaning that an organization must put in place Organization seeks to construct software development support and service organization based on the project plan Activities include Acquiring various skilled individuals needed for the project Obtaining the tools to support the process and methodologies Creating set of welldefined metrics to track and gauge the project STEVENS INSTITUTE of TECHNOLOGY General Software Project Organization STEVENS INSTITUTE of TECHNOLOGY ae.  th ep Mairix vs.  Hierarchical Orientation The software develooment structure Is flexible based on the size of the project The organization structure may be represented either as hierarchy or as matrix Hierarchy org.  all the people associated with project are grouped into functional departments that report directly within the vertical line of command of the organization Matrix org.  people are grouped based on the functions they perform Functions may be performed by nonmembers of official project organization Less function duplication better focus on specialized skill.  What about team loyalty and confusion STEVENS INSTITUTE of TECHNOLOGY Functional Orientation The general organizational structure may be further refined to show more precise structure It is important that the organization be defined down to level where each individual can see herhis name STEVENS INSTITUTE of TECHNOLOGY Sh 3slUUi Highly Specialized Organization STEVENS INSTITUTE of TECHNOLOGY Software development specialization Pee af Software Support Structures je Support managers must set Up an extensive Customer interface group such as call service dept.  that handles the following duties Answer calls Analyze each problem Respond to the customer if possible solution exist Generate problem report when an immediate solution does not exist Track problem resolution activities Report and deliver solutions to the customer Close problems STEVENS INSTITUTE of TECHNOLOGY STEVENS INSTITUTE of TECHNOLOGY Recruiting and Hiring Software Personnel Once the organizational positions are outlined the software project management needs to fill open positions The actual hiring of the employees starts with having clear definition of the open position in terms of the skills training and character of the candidates required for each position Recruiting It is Usually not sufficient fo provide general description of the position title to the HR department STEVENS INSTITUTE of TECHNOLOGY Project Team Life Cycle Very few projects can be completed by individuals.  Group becomes team through proactive efforts by members and project manager.  Typical project team life cycle goes through three stages Team formation Team develooment Team maintenance STEVENS INSTITUTE of TECHNOLOGY 10 Project Team Life Cycle Teams need forming developing and maintaining Amount of management activity differs at different stages of the team life cycle Team Stages ZL STEVENS INSTITUTE of TECHNOLOGY 11 Project Team Life Cycle Team building activities center on education and training on areas like Building trust Negotiation skills Listening skill Responding to pressure Project manager must ensure that there is enough time in the project schedule for such training STEVENS INSTITUTE of TECHNOLOGY 12 Team Formation lw Having the best people does not guarantee success unless experts work effectively as team Project might be delayed or fail due to personnel conflicts Tasks may be independent but interrelated STEVENS INSTITUTE of TECHNOLOGY 13 Team Formation Project manager will review tasks and decide on the Skills required to complete them Team members should possess other behavioral Characteristics or soft skills No perfect person exists managers should not look for mythical candidates STEVENS INSTITUTE of TECHNOLOGY 14 Soft skills and personal traits Traditionally managers tend to focus on technical Skills and experience Managers should look for other characteristics many of which are soft skills Soft skills Anontechnical skill that can be utilized on multiple occasions and Is not restricted to any specific domain STEVENS INSTITUTE of TECHNOLOGY 15 Soft skills and personal traits These personal traits might include Personal ambition Interoersonal communication skill Sense of urgency Strongly held likes and dislikes Attention to detail Some team member may have negative personal traits E. g.  Personal ambition over team goals STEVENS INSTITUTE of TECHNOLOGY 16 Team Development lw Team members behavior need to be continuously monitored Project managers should perform conscientious socializing Informal data gathering to pick up any signs of team disorder e. g.  Nonreturn of emails With remote and virtual teams Communication is major source of team related problems Members may need counseling on basic working etiquette STEVENS INSTITUTE of TECHNOLOGY 17 Team Development Team or personal Issues One or more people are upset about something and Its negatively impacting the team E. g.  personal Il cant stand working with Fred E. g.  systemic Il hate how we do code reviews Start by talking onetoone To people involved Ask what Is going on and what can be done Seek Out Causes not just symptoms STEVENS INSTITUTE of TECHNOLOGY 18 All right.  So let me start with some general considerations.  So extended that by days the deadline for the previous assignment sent everybody an email.  002 The main reason is because several of you requested extension.  So for all good reasons.  So but because the number was significant decided that that it probably is more fair to extend that for everybody 021 for days.  044 So we have todays extension so that doesnt mean that that is kind of the moving down the the due date for the next assignment.  046 So it will be the same meaning that there would be an overlap and just giving you more days for this one.  056 Pay yourself for the next assignment that will introduce at the end of this class.  103 Cheating is is still problem.  So we had the 111 some students cheating in more than an assignment.  120 Again really try 125 not to go in the formal way.  go into the the the the the editor committee whatever it is and the whole or board.  131 because when you go to the Honor Board you will know what is going to happen 141 so it could end up with the expelling the student.  So thats very extreme conclusion.  147 and want to avoid that.  We want 158 avoid that for you.  201 But when see students cheating in more than assignments so then mean at that point is too much so would refer to the on the board.  204 So be aware that when we go that way things can go all over the places.  So going there with the case or for cheating.  220 Youre not going to see benevolent people on the other side.  so the chances are to be expelled 234 about high.  245 so please make sure that you do everything by yourself and if you use it there not sources site the sources.  246 All right.  So let me share the screen now.  301 and let me start working on this.  So thats where we are.  We are over here March 29 305 and we will talk about text.  So next week we we talk about the web mining.  will introduce excess size Number 7.  That will have different 316 types of complications.  Lets say compare to excess.  Size 6.  329 Its mean it will be on the dealing with texts or courts.  will not.  336 srivatsav Could you please 346 Okay so will not present the solution for accept Size because gave you more days and want to be sure that that no one will use or would be inspired by the by the solution that im going to present.  So more days.  355 no presentation in class of the solution.  414 All right.  So changed the the something that mentioned in my email changed the 419 little bit.  mean added the some details to the the specs the the the the requirements for the the exercise 6.  430 didnt specify on this point number of courses per each program for each academic here where you take the quote the number because didnt specify.  It was okay whatever you use it.  But the actual course is what is in the load the meaning the courts that actually ran for that particular program.  446 Same thing for this one for the last one not the courses will be calculated using the load.  But again if you did in different way thats fine because in the original specs it was not specified.  512 and 532 im not sure that that was necessary.  So when asked the average number of courses per faculty is per faculty not per program.  So just 536 clarify that there is no program involved in this calculation or in the following to 548 so its for faculty not per program.  So those are the the changes that made.  557 Sai Mohit Bekkem Mani Prasad Please mute yourself 609 Sai Mohit Bekkem Mani Prasad what mean.  612 Could you please mute yourself 614 Okay.  So 618 let me 623 go here again.  624 Yes each.  Id is faculty.  So just to go back here.  629 So thats what you have instead of having the now the the name.  So the faculty you have an Id 639 So it its just progressive number but its unique identifier for the 5.  Okay.  So 646 faculty number one to those courses and so on.  655 All right.  So we we talk about the 702 texts we we talk about text the in different ways this evening.  708 So one would be using the basic python functionalities.  One will be doing an actual lets say text processing.  715 and the third would be from seminar that they gave 730 this morning for the Phd series.  737 want to stress few points out of the presentation and we will spend about 10 or 15 min of that.  746 All right.  Okay.  So what is the text The part singer Its kind of common task when you deal with the string.  So when you deal with with text 758 erez agmoni meaning taking pieces of string and doing something that can be useful for the type of analysis that you are doing 150.  811 There are different ways to do it.  The 822 one is using the basic string functions so that are embedded into 825 the basic python without the additional libraries and the second is using regular expression.  So that is 833 formal coding that is common to different languages so there is regular expression in our regular expression invite on any other languages.  843 The regular expressions are very powerful but they are with quite low readability meaning the the the the syntax is not intuitive.  We will not spend too much time on that.  Probably just couple of slides.  854 Theyre not.  mean the main part of the program.  But eventually you can spend more time if needed the 914 going online or just checking the rest of the slides.  926 So lets start the with the managers rings.  So we already so few things about managing.  So lets recap and do little bit more 930 So if you have string like in this case 944 the the word banana.  You know that each character each letter can be addressed using pointer.  So the point the pointers start with and and at the end of the string.  948 So in this case if the name of this variable is fruit then if you want to get the the second value the first the character that is the letter a.  Then you do fruit the square square bracket.  one.  So one is this element here.  Then.  if you want to do operations in that you you can do that you can assign variable think about loop scanning the the entire thing.  So if you have the it variable in the pointer like in this case you assign the value to the variable and and then if you do minus one you have minus one.  That is 2.  Meaning is the third element that is N.  And you can do all kind of operations inside those square brackets.  If you pull into too far you will get an error.  So meaning the index is out of range.  You can calculate the line mean the length of of the string and we already use that you can do loops.  As was mentioning keeping in mind that when you loop inside the of string you will get the the individual up that let us that are part of the string you can obviously count.  You can do whatever you want.  Inside the loop you can slice strings.  So you have this string Monty Python with the blank separating the words.  So if you do in square brackets that that means that you are starting from the first character labeled til for that is the mean before and the the the number 4.  That is T.  So you have the sub stream the O.  And you can slice from beginning to the end and all from the very beginning meaning that is starting from Number up to excluded.  The meaning is one letter and its letter.  Yeah.  Same thing.  If you do to 20 mean this could get an error.  Thats not what you want to do but you can do to 11 and you will get it.  You can do concatenation so meaning you can attach strings together.  So with the plus over Dora you are mean speaking one to the other.  So if you do the first that is hello and then you say is Well the previous ring plus there you will have the strings with no separation between the because we didnt say that it is any.  So if you have the space so then you will have the space so you can concatenate any number of string.  So creating new string you can do.  You can explore if one letter or if substring is inside the given string.  so you can ask and in that fruit and you will get through.  This can be just like that or can be part of the conditional statement like in this case.  If is in fruit then print found it right.  And in this case because the value of the variable fruit is banana.  will find the first and that will get found it.  You can do comparison so you can compare strings.  mean.  Sometimes you may want to do that.  You are in loop and you are set of that you want to compare with the given string and do something.  So thats the way it would be.  You can have quite lot of subfunction or functions that are part of a.  So those are some examples lower.  You will lower the value of the mean.  If its capital will become more.  Let us If its more let us say the same.  You can transformer again one string in all lower.  There are bunch of other functionalities that you can use capitalized center and with th this is something that in loop or can be useful.  You are analyzing bunch of things so and you want to do something if the string is ending with given value.  and then all the rest and if you go online you would see all the lease of libraries or functionalities that you can add.  You can search for given element of the string.  Im.  Saying Elementa because its threeing.  It can contain letters but also non alphabetical characters.  So you can do find the Na.  And will give you the position of the beginning of the this substring.  That would be the position of number 2.  If you try to find something that is not there.  You will get negative value.  You can do search and replace so you can.  so we.  So what the so sure can be replaced you can replace one substring with something else using replace.  You can eliminate the wide spaces and special characters at the beginning or at the end of the string using the strip command.  So if you do me so that you are going to eliminate the widespread spaces and special characters on the left are means on the right if nothing is specified that is both the left and side left and right so and thats an example of application.  This is particularly useful when you are reading Csv files so that we eliminate the and the line that you have at each line an example.  You have this long string.  and mean an example of application or some all the things that we did so far.  So you have This is the data.  This is the string that you want to analyze.  You want to find the at symbol using the at pulse and the did mean calling at this position at possible using find and if you print the the value will be 21.  That is the position where that is.  Then you want to find the space starting from the 21 meaning that you will get the this space here the the first one.  and then you can extract the data from this initial position and the position of the at symbol plus one till this 31 excluded meaning that you are slicing this piece.  mean.  Yeah there is piece missing here this piece here regular expressions or guess you can go on Wikipedia because again its not something that is available only in pied on that but is available in many different languages.  Its kind of cryptic the way it is shaped.  So those are the call months that are making the regular expressions.  So as you can see it it is really crypt gala so it is not particularly easy to use it.  and thats why we have not.  Im.  Im.  Im.  Not asking you to use it but sometimes so the basic functions so that are in Python or may not be enough and you may need the some more power to slice your text and then you use the regular expressions.  Spurthi Raj Nagaraj So would keep all of them but you will have the slides.  Now we talked about the passing.  Lets talk now about we are mining so mining text.  Its either natural language processing text mining whatever you want to call it.  Why we want to do text mining what we want to mine text because there is lot of it and text.  It is an expression of language and you must use language to communicate meaning if we are able to get some form of insight from the text.  we would get knowledge about the domain the text is related to.  So if you want to know what people is doing in given field.  You collect the data on that particular field and you do some processing of the text we mentioned Med on time so that there is sort of an explo.  All the data but most of the data that is exploding is not structured is is data that can be.  Text can be.  Videos can be featured.  The size in terms of so obviously is no comparison.  Not so text.  Its more files.  Nothing compared to any much or or video.  But the number of those small files think about text message or tweet.  So those are small fights carrying quite lot of information eventually.  So mean.  you read about the the Silicon Valley Bank that probably will and the crack they had.  That was probably originated by tweet by leading investor.  So one tweet with the power of igniting sort of disaster in the financial industry.  So thats an extreme case.  But again mine in text the can really give us an advantage in the analyzing given domain.  Examples of obligations of text mining analyzing court of thats analyzing research articles quarterly reports customer con comments.  All of those are our basic examples.  You can analyze emails to eliminate spam to create sort of prioritization or categorization of the inmates generating automatic response.  So this is just to focus on the emails.  So there are really lot of of applications.  But dealing with text the is not exactly easy because Texas language has been created by few months for you months and we have much more knowledge of the domain that what is in the specific text.  So if we say apple is apple the company or apple the fruit.  we know by the context we know by portion of what is the common sense.  So when you when you talk about the vehicle so it can be addressed as as specific brand or automobile.  But its the same thing when you read the one company merge the with another.  But you know that one of the is bigger and in in best financial shape you know that is not merger but is an acquisition.  So those things are not they are.  If you have something on table you have stapler.  You have notpad and things like that.  Then you say okay what is on the table is related to office.  But there is nothing saying office in the objects in the things that they are on the table.  You know it because you know it.  So thats the common sense ere its an unsolved problem as today.  So some of the terminology that we use in the national language Processing will not go through each one of those but will jump from one to the other ere tibi gala examples.  So our articles pronounce.  So.  They have grammatical role syntactical role but not semantic role.  And most of the time you want to eliminate them.  The part of speech.  Tagging is a.  When you have phrase you have role that each word or set of words are playing in the phrase.  So if you have phrase like Im going somewhere the is.  The subject going is the verb but somewhere is Im going to the movie theater is noun.  So subject the adjectives birds are part of speech.  So when you analyze phrase when the phrase is fractured or like that.  Then you may want to tag each one of those words or group of words.  for up the grammatical role that they play in the phrase and this process is called the part of speech stacking.  So there are quite lot of other terms that we use up.  We will go through some of them.  So when you deal with the text there are several things that you didnt do so lets focus on one of those we we talked about other later on during this class the information extraction.  So its generic term.  And what does it mean Extracting information It depends on the information that you want to extract can be just some statistical values.  The number of people with master degree within group of people the the people liking chocolate in group of consumers things that that so you think that is 100 but its not.  dont like chocolate.  Just name one.  So it really depends on the type of information that you want to extract.  But before doing the extraction of information you may want to do some preparation.  So preparing text.  So its more complex than preparing regular data.  because it could be misspelling.  It could be synonyms.  So things like that.  So when you say Stevens you can call the University Stevens Steven Since you top technology S.  I.  T.  E.  C.  So if the goal is to count you have bunch of people.  How many of them went to Siemens So you want to be sure that you count as one.  Either is the way that the Institute was mean input it.  So lets go again.  Lets say with the text preparation.  And again there is some basic cleaning.  That is pretty much what we said the sometimes most of the time you want to do so called removal.  Again if you want to get the semantic sense you really want to eliminate those elements so that they are not adding semantic value.  But the things are kind of 3.  G.  So one of the things that you normally do is to create what are called the engrams.  So from mean an iga 2.  That is diagram system engineering project management.  So those are words with one unique semantic meaning.  So project as some meaning management as some meaning project management as specific meaning.  So this process is called the and Gramminga.  that can be from to more weapon of massive fraction.  So its basically one logical entity with multiple words.  if you remove the so forth.  So then lets say school of business.  So its its gram.  If you remove all the you dont have the gram school of business anymore.  So you may want to remove the the so forth so later on in the process.  But at the certain point you may want to remove them.  Stemming limitization.  Thats another step.  But that sometimes is is essential.  So when you use words for the same meaning you want to count them as one.  So we mentioned.  If you want to measure the number of vehicles that are mentioned in text then you want to count as one Kara because things like that there are ways to do that one is more statistical so that is called the sending.  So you take.  And and this is what the automatic correct or in our phones are doing.  So you start typing and then you see Bo something telling you what it could be the entire what that you are typing.  So its basically taking the character so that you typed.  And then get all the the words starting with the those characters and then hes adding and this would be already staming.  But in this case hes adding another algorithm that is suggesting over those words so that you use more frequently in some other cases.  When you have things that are previous mart they are suggesting that those that are semantically connected to the phrase that you are writing.  But there are very few of those automatic correct or that are in place.  So thats an example of all that standing limitization.  But mean the the resulting war.  The may not be word.  It its really common denominator.  All the all the words that you have.  So if you have words with 10 characters World W.  What with characters chances are the resulting will be award with characters that may or may not have semantic meaning.  Limitedization is more on the semantic value.  So again if you have car automobile vehicle you have vehicle so.  But at that point when you have semantic approach semantic problem and semantic solution you need to have semantic approach we will go there in moment.  so will keep all of that and will go.  will go here to talk about the natural language toolkit.  That is one of the first libraries for natural language processing not big fan or an Mtk.  The main reason is because it was created that many years ago.  A.  And it does all the basic tasks.  But those tasks are done the way we did the 10 years ago.  meaning.  All the portions that are more related to the semantic side are based on the on some training information that our not active anymore.  So language is changing in time.  Language is domainspecific when you use met on the.  That was working fine when we wrote the letter so not let uss characters but the last.  and then we are riding very short text messages or other eventually using emoji or using not in traditional languages.  then the metal thats used before or that its based on detecting patterns.  So in terms of the structure of this all of the phase.  part of speech talking is playing big role then that that that is not good anymore.  So the traditional and Ltk is not really effective anymore.  The reason why im still teaching is because it has all the elements that will help you understanding what are the challenges that you have in in national language processing.  Its library so you can import the just like you do for any libraries.  In this case Im importing mean.  The name is from the inventor of all of the printing machine.  and probably the right pronunciation.  Be good America and it is project for collecting all the books that theyve not covered the by copyright anymore.  So it.  It.  Its collection of text and we use it for our practicing.  So last text that you can download and and you can eventually play with it.  You have stop words so generally dont use the store ports so from an itk.  But have my own file for so the reason for that is because want to have control of the list awards.  And then considering stop what So Because eventually can replace some of the words can add the some of the words depending on the context where am.  So let me skip all of that and let me go directly.  That is probably easier.  Not if do it any way.  Okay let me go here.  So as part of an Mtk.  There is library that is called whatnet.  That is it intelligent dictionary.  So you have all the words structured by the so.  In this case as an example you have the animal kingdom and you have birds fish and many other and then bird the can be bunch of options for example Kennedy eagle fish bunch of options for example trout shark and you can go all the way down.  So if you want to analyze the similarity between elements what you do is basically measure the distance the degrees of separation between those elements.  So for example trout and shark or more similar.  then dont know trout and bald eagle.  So proud.  Shark they are One degree of separation.  Route and moldy go are degrees of separation.  so they are less similar.  So measuring the distance in this kind of is use the using an algorithm that is part of an Mpk that is the lean Alli and similarity.  It is actually measuring just the distance industry.  So this is taxonom is an organized the dictionary.  and can be useful if its related if its exactly related to your domain.  meaning that you cannot use the the taxonomy for the animal kingdom to analyze plans because the names of the plans are not there.  So all for any other thing.  So there are.  Taxonomy is for categories of me.  So there is taxonomy for the news within natural language to get.  There is taxonomy for other things.  but those taxonomy is at the near so and language again changed lot.  creating new taxonomy.  Its really complicated and its something that that needs to be done with the human intervention.  So meaning its lengthy process is expensive.  meaning that you cannot replace taxonomy each time you use it or each week.  But unfortunately language is changing fast and domains can be very specific domain in general.  But then we have jargon that we use in different conditions.  Circumstances so.  But anyway.  thats one of the ways.  Knowledge is represented.  So this for motor presentation is called the symbolic representation.  meaning in this case.  You are representing form of knowledge of the animal kingdom that will tell you how the animals are out related the one to the other.  So you are representing this kind of knowledge.  There are other ways so to rather than the knowledge in that this kind of formal symbolic way.  One way is again at taxonomy.  So another way is using rules.  If this then that the concept of taxonomy is it can be expanded to ontologies.  One topic can be part of multiple taxonomy.  So taxonomy is like and ontology is like forest.  So Egola can have role in the animal kingdom can have role in rock music and so on.  So each time depending on what you are analyzing you may want to use one element mean the element in one context or another context.  but its kind of easy to understand how complex is to navigate into all all of that.  So let me jump to here for second.  so one that package that use the in one of my courts is that is no forwarding so its called what the Joe or Dj.  That is and Java script that is analyzing texts and is creating networks out of the text.  Networks are created based on the the concept of call quorants who core answer means words according to together or one to the other in the text.  then the way you do it it.  It really depends on on those parameters.  So you want to consider only work so that the appeting more often than that certain number of times you want to consider pairs couple of words that are ping up more than certain number of times.  and you want to consider related words so that that are appearing within window of awards meaning the degrees of separation.  If they are one next to the other they are diagrams.  If the window is too large then you will have very large number of words so that they are putting together and the the network that you will create will be less readable and usable cool.  We want to have network of words because the network awards.  So its kind of first example of knowledge graph you can create class thats out of that.  And those class thats will be topics within that the text that you are analyzing.  So if you analyze in time.  text like you are collecting information from social media or whatever is the source and you want to see how the opinion of people is changing.  You can have those knowledge crafts.  You can have date class setting and see how those classes are changing.  So class.  Thats not labeled meaning that you cannot say this this topic is ready to.  dont know specific basketball team.  There.  There is no label on that but you may see that there are the play.  Yes of that team.  So meaning okay.  this cluster is about.  dont know the nets or so on.  So again using the the graph metaphor to understand language.  Its really important because it is way to recreate the somehow the structure then the text may not have so.  but not all the graphs are created in well because in this case we are using the the metaphor of the call quorance that may or may not work.  So the some Shauna is wars that are appearing together are related.  but maybe not so.  Thats something that we may want to consider.  anyway.  So thats what the J.  Just word the on sentiment analysis.  sentiment analysis is its one of those analysis that became very commonly used but they really dont have much of of theoretical ground.  So what is sentiment its really difficult to define.  So it might emotional analysis.  really use sentiment.  rather use the emotion so based on on on classification of emotions.  So measure the distance between the words in my document and the entire document to those seeks a.  The motion so depending on the classification you have.  then how you measure the But sentiment analysis is its pretty common.  There are different ways to do it.  So most of the time is supervised meaning.  You apply techniques from machine learning and in particular the most commonly uses support vector machine.  and then you classify given text or better you create model on some training data and then based on the the behavior on in the training data you do the classification for the rest of the of your document.  You can use Lexig on approach meaning You can have huge madrics with all the words and the sentiment associated to those words and then you can do look up and get in the sentiment for each word.  Add all the values for positive negative and neutral and you will have that after normalization you will have the sentiment for the entire document.  It is sort of supervised even if someone is calling that unsupervised.  So thats pretty much on text mining we pied on.  Let me go now on using python for some examples.  So let me go all the way here and let me do little bit of recap over this natural language toolkit.  So keep in mind that that natural an ntk is not part of all the standard libraries so meaning you need to install it.  So just to be sure that to remember how to do it when you go to you go to settings.  you go to python interpreter and you have all the libraries that are part of the of the that you are doing.  Yes maam.  so if you dont have the package that that you want.  Are you just to plus this case and L.  T.  K.  Actually you already have it but eventually you select it.  You still package and you are good to go with Python.  If you use library that is not there will be underlying in the dotted red and then if you who were on it.  you will have the option to install it.  So without going all the way on settings you can do.  Just write the import.  If its not part of the existing libraries then you will have the option to install it.  But anyway once you have installed the the library in your python project.  Then you can do the importer.  This is text that copied and paste from the New York times few years ago.  and then see how that some of the the Ntk.  Comments so it can be used.  So this this one is is is token is tokenizing text that means splitting the text into words.  mean you can do without the token eyes or just splitting transforming the string into list and the result would be the same.  But anyway with an Mtk.  You have word to organizer.  You pass the text to the function and you will get the results.  This is yeah measuring the most frequent works or tokens.  There are other ways to do it without an Mtk but thats fine.  So im taking the most common.  This is for printing the part of speech for the text have.  This is to calculate the bygrounds keeping in mind that the the way an Ltk is doing it is based on an existing list of diagrams.  So its matching the words the one that next to the other.  with the list of diagrams so that are embedded in the in an ntk.  That means if youre doing something that is no sound that you have your own jargon or its domain specific diagram.  dont know cardiovascular or you have something different.  That there is very specific one domain that that diagram cannot be in the list of diagrams so that an Mtk.  Has and you will not get it.  not using the diagramming from an Fdk of my own This is extracting the stop words and printing it in particular in printing the words from the text that they are not so.  and this is the least all the elements.  So from the If run it so thats what have have the list of token.  So again that was the text in the list of token.  So there is no distinction between regular war mean semantically relevant words and so forth.  So you have all the words.  then the most frequent with the frequency.  the part of pitch tagging.  So if see dont know.  Sarcastic in is an adjective.  and so on.  Those are the diagrams again.  Its its very basic approach.  Its taking in this case mean even the so forth.  Those are the nonsoft word words in the text.  and this is an initial list of of the So thats an example of how to use an Lt.  We mentioned sentiment.  So sentiment im using library that is called Vader.  That is the best you can get its more mean with the an ntk.  You can do sentiment analysis but the way to get it is more convoluted.  You need to do part of speech tagging first because it has different tables for different end of the meaning that you have sentiment mean.  Most of the sentiment is on adjectives but but there is some sentiment in some words so there are different tables for sentiment for denounce and and for the vote with.  Bother.  You dont have the distinction that you just pass the text and you will get the the sentiment.  In this case use the function to clean the text.  generally stronger encourage you if you plan to work with text to create the some all those functions that you will use continuously.  So you have the text cleaning.  That is one of those cleaning means eliminating the so forth.  So it means eliminating so that they are too short.  presuming that if word that is too short it will.  There are no semantic meaning.  and thats basically it.  And then if is numerical you want to eliminate them.  So mean that this cleaning is very basic but its just an example.  So you have file of the that you are reading you have the soapore file you.  You will pass through the cleaning function at the minimum length for the the to be considered acceptable.  and then you start grieving the files and populating the this.  Then you lean the text passing all the elements to the function.  So the file the content on the file the minimum length the for the word and the list of so forth.  So so and the end in clean text.  You will have clean text.  then you call the the analyzer for the sentiment.  Analysis is reading strings.  Not least my text is on list so want to transform at the least into string us the string to the analyzer and getting the positive and negative and then printing it.  So thats an example of how to use for sentimental.  So you have positive negative new roller.  keeping in mind that most of the time the high Yes value is on the new draft because mean not many words really bare positive or negative value.  The same word can have little bit of both.  So if you think about the exception im not.  Its all positive its 100 positive.  But if you say cool its some positive and some negative depends on the contest but this is too sophisticated for those are great so so its its little bit of both and this is the same for the entire text.  So this is working on on all the texts meaning doing for each word and then for the entire text.  the normalize the summation.  What cloud is is another think that is commonly used as way to to have sort of presentation of text.  So the word cloud is made in way that works so that our more frequent will appear bigger less frequent.  As As its graphic representation of the frequency all the words.  So this library there is again another library that you need to import in your python.  So you import the the work cloud and eventually the so forth.  The library needs plot lead to work.  So im reading.  text again is from the New York Times but doesnt really matter.  and reading the text Im replacing the the end of line with the space.  Then im changing and removing all the characters.  So the special characters and the space and im creating list award.  then that this is mean it.  Could could have done with the cleaning function but did the on the fly.  So in this case im.  Making sure that the the word is in in alpha medical.  and im lowering the the characters.  And then what cloud Just like sentiment Analysis is not taking list but its taking strings meaning and transforming the the list into string.  adding some elements to the so forth.  So those elements are elements so that they know are very popular and that they would be very big in the work.  Cloud and dont want that because it it would hide the words that could be more insightful.  Then passing and creating the work cloud with some of the parameters so.  and generating the work cloud.  Im.  Storing the work cloud in graphical file and Png format whatever.  And then Im.  Showing the cloud on the screen.  So if run it.  thats what you have.  mean that considering the name of the file could have eliminated the trump and because was the debate the Presidential debate.  It bad name.  Hillary Clinton should go when you remove those words so thats so big.  The other words will become bigger so and then at that point that to me would be more insightful.  All right.  So thats pretty much it let me go with the with the last piece mentioned that gave this presentation this morning for the Phd Seminar.  So that is shorter version or what gave last week at the C.  Sara.  That was h.  So in this case was 25 me 2020 25 min.  im also working on entire courts so on natural language processing that wed be off at the hopefully nextms that are most likely in the following one.  So will go relatively fast because just want to call her little bit more.  elements that we didnt discuss in the view slides so.  and right now there is sort of an hype on natural language processing.  Since the lounge of chat gpt in the middle of November.  Everybody is talking about national language processing and its becoming one of those topics that you read about pretty much on any newspaper any blog any journal the TV you name it So its creating some sort of an IP.  So those are from a.  then user 77 increase spending over 1218 months in the natural language processing.  Thats the the distribution of growth.  So 39 between one and 10 more than 11 to 38.  So 77 total is this number here.  This is basically how both manage those.  mean.  this increase can be quantified in terms of money.  So we are talking about right now.  Its 12 billionI mean consider that just the the money that Microsoft invested in open AI was 10 billionSo mean dont know if this has been accounted.  mean its 2021.  So it was not accounted but just to give you an idea.  Only that one investment is double on that match for what this Nlp.  In terms of business.  This is what we had before chat gpt.  So data production and governance knowledge management and classification chat boats including our CD lakes and things like that.  What is what are the technologies or the technological domains that we cover The mosques name entity recognition.  This is like saying award is related to people.  Its related to countries.  Its its ready to industry.  Things like that chat bots again creating chat about so natural language generation.  This is something that is growing and see quite lot of potential for that.  So you can generate language as for all presentation.  So one of the next features that the blue may have in the future it could be.  Instead of giving you chart will give you plain English representation description of the results.  Thats pretty cool and this can be done generating language based on it.  mean that not the conversational description of it.  What is natural language processing So we mentioned that is subset of artificial intelligence and is using linguistics and machine learning models to let computers process.  Human language is combination of all the computer science.  A.  human language and its kind of rolling in in different areas from generic natural language processing to natural language understanding.  dialogue management and natural language generation.  Why we do not a.  Nlp.  Now we have quite lot of digital text.  Now in the past we never had that much.  So when started working in this area.  It was mid eighties so we didnt have much of digital information.  There was no Internet and things we are not.  There was quite lot of the hardware we have is way much more powerful than what we had before.  for some of the processing hardware is really essential.  So we will go into the numbers for chat gpt.  That will give an idea of what lot of processing could mean.  Then the languages so in the past.  We didnt have python.  So we had the languages with no libraries meaning.  When you want to create an algorithm you need to write it from scratch and then you can create your own library.  But its going to be your own library and you mean the the the the language didnt have the concept of library.  meaning that all you have to do is to save those lines of code the copy and paste into your code.  So the type the the languages that we use for things like natural language processing.  We are primarily list.  We use the language that was created by by the now the fact the digital equipment that was rule base that was called the O.  Ps.  5.  That was pretty cool.  But again could do only rules.  At that time was developing what we call the knowledge based system so our expert system.  and that the assumption was the experts.  It could be represented by rules.  So we created the rules that were representing the knowledge of the expert.  and that the O.  Ps.  was relatively easy way to do this.  Roots writing up again it for all manual.  We mentioned the challenges so how we can use an endp we can use in direct way because we can extract the valuable information from text and and use it as results that that can be used.  mean selling the the analysis can be used to do better services to understand what customer are thinking about our products analyzing new products.  So all all of those are our direct values of an Lp.  And then there is also an in direct value of Nlp.  So you can use an Lp.  To do something that there can be sort of way to interact with the system.  If the system is not enough.  the type of instruction so that you are providing are creating sort of customization of the service so that the system will give you.  So thats an indirect value of of an Mp.  What is language.  Language again is for human being so as being created by human beings for human beings and is an expression of knowledge.  So we acquired knowledge using our senses.  and then we express the the knowledge through language.  But language is form of expression is not the knowledge but is is way to express the knowledge in our brain.  The the areas so dedicated to language are relatively small compared to the areas that are representing the knowledge.  The knowledge is toward the in the areas handling the different functions.  So again census we have areas for each one of those senses.  and the language is basically topping into this knowledge collecting pieces and presenting it when you have like large language model so they are whole language.  So the knowledge is embedded in the system.  But this is not the way human beings are using their knowledge.  If we go back into how knowledge has been representing the over the years.  You have schools of total one the rationalists.  They believe that the knowledge is coming from reason.  The reason is somehow embedded in our brain and we leave the reality based on those programs that we have in our brain.  Up to some extent this can be understandable.  Other people think that was not so.  They told the that actually we were born as black slate and we get the knowledge through the experience.  So by the circumstances that we are leaving we get the knowledge.  So now moving forward to current time.  So the rationalists are becoming the traditional AI supporters.  So the symbolic reason mentioned the the taxonomy is the rules.  All of those are representation of symbolic reason.  The in are now the machine learning people so they are using the data to get the the knowledge.  So again there is street one to one correlation between the philosophical approach and the current approach to AI machine learning.  If you want to implement natural language processing or or understanding you can follow either one or the approaches or eventually combination Of the 2.  There are pros and cons of each one so the first one that we mentioned that each domain as different taxonomy.  Logical taxonomy is changing constantly meaning that you cannot really create that taxonomy and use it for the rest of your life.  But you need to update the the taxonomy.  You need to change eventually taxonomy.  If you change domain that there are space in terms of domain there are space.  If you see these in terms of jargon meaning in theory it could work.  If you have an army of people constantly updating the symbolic approach.  There are companies that that are leaders in natural language.  Processing using taxonom is only and they are publicly traded and they are big.  Some some of them know personally them in several years and they are doing great.  But again there is quite significant limitation in the way they are doing on the other side the machine learning.  So its based on data sometimes.  So there are several limitations in this approach.  So the first one is the data you have really represent in the reality that you want to express opinion upon.  and thats the first.  And you can now really be sure that you have all the the text representing that reality.  the sag on the is the algorithm that you are using To get then to express the knowledge appropriate for what you are doing and thats another big.  If so each one of the approaches some.  Yeah.  As pros and cons the large language models that we are using chat.  Gpt is definitely the most known of them is in this category.  We we talk in moment about that.  So when you build a.  An you need to.  You can extract the information or you can create conversational system.  or you can just do some text manipulation like translation summarization.  If you do information abstraction you actually build pipeline for what you are doing.  That is from ingest in the document to do whatever is the information that you mean the the goal of your information instruction.  Sometimes you can stop at the certain point.  Im.  Okay with the statistical analysis some other time.  So you want to have visualization and so on.  So its pipeline and you need to follow the different sets in just the document that tokenizing cleaning removing the so forth and or doing the programming and so on.  When you do statistical analysis you need to keep in mind that that you are dealing with text.  You are dealing with language meaning.  You need to see the metrics that you are extracting from this standpoint heading semantic meaning.  So the most frequent words for for example are the most relevant words in the text.  So being relevant and being frequent is not the same thing.  So thats the semantic interpretation of statistical value.  The entropy is measure of the diversity and unpredictability of the language.  Obviously these more elements when you compare values because you you have number and then number lets say is not telling you much.  When you compare to documents you can see the differences.  the number of unique words can be interpreted as measurement or the richness diversity or specificity of the document.  So again.  the common denominator of those points when you do.  Statistical analysis is is not like statistical analysis.  So to get number but to get meaning out of the number.  When you detect topics.  Things are becoming complex because again topics may not be in the list of objects that you are considering in your text meaning.  If you use plain unsupervised machine.  Learning approach.  You may be disappointed because the topic is is more collection of different words or N.  Grams with no one being the leader.  When you move to the semantic space ending topic detection.  You are kind of both the line.  You can do topic the detection just for using on those conglomerate or you can go on the semantics.  But when you want the semantic side that you need to understand what is in the text that you are analyzing when you go in.  The understanding is about knowledge.  So the TV gala way for representing the knowledge is supervised or unsupervised.  supervised the means that you have knowledge about the past.  We briefly thought about that when we told briefly about machine learning.  So you know about the past and you use the path to classify the future unsupervised that you know nothing about the past and you extract the whatever meaning you can extract for what what you have.  The third way is reinforcement learning where the system is generating outcomes and then that based on the success or unsuccess of the outcome meaning.  You need to have score scoring system based on the success you use the configuration that you use to to generate that result as information that you will use in supervised learning.  So reinforcement learning is basically selfgenerated supervised learning.  hey E.  C.  Either pipeline with humans in the loop you months.  So in Chat Gpt does more than one thing.  We will have chat on that.  One of the largest se segments in AI is ginger topics.  So you have of people spending all the days reading text and labeling the text with the tags.  Its huge market borderline slavery.  They are underpaid most of the time even underdeveloped the countries.  but the entire industry somehow rely on them.  Even chat.  Gpt is using you chunk of them.  Were talking moment so.  and when you do information extraction with the semantic approach you need to decide that what is the way you want to go so and it really depends on the type of text you have.  When you have social media you can use the social network to kind of replace the lack of conversational structure.  When you dont have that then you need to recreate the structure in different way and the way people is doing now is transforming the text into back to us.  So this process that is text vectorization.  As long as we will spend one slide on that.  or you can create graphs.  But mean how you create the graph.  So its different story.  libraries that are more most commonly used for for information instruction and Ntk we spoke about that more recent spacey.  That is more reach.  It does pretty much the same functionalities as as an ntk.  plus all the portion that is more on the machine learning.  So you have the vectorization and you have bunch of things on top of the characterization.  So again an SDK is kind of outdated but its still doing some job.  But if you are analyzing the tapes so it is well structured that you are analyzing book.  Chances are that an Fdg.  Can do the job again.  In real world communication today is different from what it was years ago.  The conversations are more chopped or more are shorter less structured.  So creating graph is way to recreate the structure.  You my Phd.  developed the An algorithm to extract knowledge from social media that was based on that in this case was the tweets tweets.  They have several parts.  consider the sender timestamp and wars.  and created the the network of work so and people so ascend or is related to award if its using the word in its in in that tweet.  So its like in this chart.  Thats all the black people or the red that they are using.  So thats called the bypass that network bipartite because the sets are large degree.  This Jo You have people and you have words.  Then from that you can create network.  That is whats only so words are related.  If you use the by the same person.  then because you are using unique words.  This will become network more articulated like this one.  So.  but its network with only words is semantic networks somehow and then you can create class thats use the drove in the community the detection method that is similar to clustering.  Algorithm and then you have those clouds that are topics because of the elements all that those clouds are.  And had the student validating that with the mean quite good returns.  When you dont have social structure that can help you.  Then you need to create network in different way.  So we mentioned the what.  What did you want to with the call Qu.  On the next step Was that 2013 That what to that That is based on conditional pro probability of award being related to another because so it is the condition of probability of one word the appearing in the text because of another.  So this will generate sort of matrix.  You reduce the matrix using different methods.  and then you have one word or one and grammar that could become sequence of number.  So that is vector So that was 2013.  What to back what is called the shallow neural network.  There is network with one hidden layer so input layer.  hidden layer of output layers.  What to back as one hidden layer.  2017.  Attention is what you all you need is based on the attention algorithm.  And its basically considering not only the proximity but also the relevance of the word within the text the neural net worker became deeper neural network with lot of he delay it.  So that means that for creating the model with what to back on our computer was matter of hours in that.  But it is matter of day.  So Gpt.  Chapter Gpt.  In particular Gpt to.  That is the base for chat gpt or Gpt for that is the latest are all based on the the transport mass approach.  So the complexity is growing.  So if you can see that that that it was mentioned before.  Yeah the 340 medium parameters.  mentioned that it is all about the neural networks.  so neural network.  So they have an input and output in the input they have weights.  So the parameters are actually the weights in the neural network.  So.  having 17. 2 billionThat means that those are the weights all the network that means that those are the notes of the neural network.  Just imagine how big that can be.  Thats an example of how chat gpt was trained so.  And just to be clear what those large language models do is basically they they have mountain of data.  They analyze the data tagging the data for their content meaning.  They are defining patterns in the the that they have.  Then you have your request.  Your request has some patterns.  and what they do is to match the the patterns in your request with the partners that they already have.  and then they put the together and then they will present it as conversational approach.  Its basically like Google with the conversational layer and compiling the the answers thats all they do.  So I.  They are not intelligent in strict term.  They are just pattern matching pretty much what Google is doing in conversational way to train this system thats meaning to to determine the the pattern so meaning that open AI that is the company.  will develop the chat.  Gpt.  Spend that 4. 6 million in that energy usage.  Its the same amount of energy that would be used by more than 30000 American households for day.  So thats how expensive is to train those systems.  keeping in mind that the the human mind is using fraction of fraction of fraction of that amount of energy for the entire lives.  So meaning chat gpt is brute for it is not an efficient system.  So if we want chat gpt to do more we need to rethink the entire way.  Its handling knowledge.  So the way it was training them was in part automatic and in passing all.  So you have this amount of massive amount of data.  That is that is pretty much what is in this slide.  So its 45 TB of of text in the 90 languages but primarily English.  So 93 is English.  Thats an indication of how by as the is the system.  But nevertheless so you have this 45 TB of text.  So they took subset of it and then they had the you months going into the text and doing the the dirty job or removing in appropriate content.  Then the second round was to tag part of this text for topics.  Then they use the this this part of text.  We then now go it to expand that somehow to large amount of text.  and then having an approach based on recurrent neural network to get mean the answer.  mean to match the answer from the You months so expanding the size of the training data set that.  And then once you have data set that is large enough for training.  using that for the entire data set.  So its not unsupervised that you have humans in the loop in states actually in States.  So the first stage that is the cleaning up and thats okay for inappropriate content and there is no automatic solution for that.  The second is for tagging and the to the is for creating this core or evaluating the the answers from the recurrent neural network.  So it is an an expensive process and its basically working only in bad way.  So you dont have chat Gpt.  Real time.  So for months using A.  Of the that was created in 2016 using data set to evaluate the the semantic results.  Its working.  Okay.  So you see shock model shot meaning no pretraining that shot not performing.  Well so you need to have you once in the loop limitations again is brute force is not really knowledge.  Its limited to 2021.  If you ask questions that are beyond that is not going to be there.  We use the combination of supervised and unsupervised with more than that created that named erez agmoni room theory.  mean we would talk about that sometimes in the future.  dont want to spend too much time on it.  250.  But we will talk about that and we use it in several cases.  So the most recent one is for Siemens financial services in project for financing sustainability.  That was going into the Internet and getting project so that could be financed by seen as financial services and then present to them with some visualization and mean expanding their portfolio.  Obviously there are million things that needs to be revised.  One of the things is on last documents.  When you have large document the same content that the same piece of information can be scattered in different parts of the document so it can be page one page 22 footnot somewhere but its the same concept.  meaning.  If you want to do an analysis of the document that is large.  You cannot just say its good or bad that because there could be some good some bad.  But you will never know which is which.  And where is what you want to focus on.  Thats why created method to disassemble the the text and reassemble in in visual paragraphs that are semantically related.  and then analyze the semantic related paragraphs and then present the results so based on the those feature paragraphs or highlighting the results within the original document leveraging on large language models.  So we will go back to that.  Because so im talking since so what im not even sure if you are still there or you are sleeping somewhere.  and its probably lot of information.  So again im creating one semester long on.  So having it in h.  It is definitely not covering all the basis.  But anyway we are combining those large language models with domain specific systems like the one that developed that we want to incorporate that A.  And we are also building domain specific large language models.  From next week we will try to hire few students as research assistance deal at the end of the Academy here to the end of in June actually bit longer than that for creating school of systems and enterprises large language model.  So wed be initially for use that on this court.  So because it is the one have more information on and we will create sort of automatic online tube or for em 24 so im not sure that we would succeed.  But we will try to do that.  So again leveraging on those large language models.  we are going through sort of dec atomic view of the job market.  On one side the there is sort of new job that is coming out.  That is what is called the prompt the engineering.  When you have those large language models.  As was saying before they are working on pattern recognition.  They match the patterns they have with the patents.  In your query.  If your query has not many patterns it not going to be much better than doing equity in in Google apart from the compensation of my portion.  But if you provide more context if you give details on your query.  then there would be more elements for the system to match.  meaning that creating the right query is becoming critical.  Its like stupid user lets say you need to know how the system is working.  You need to be an expert in in the domain and creating sort of conversation that will give the system more elements to match to that point.  If you are good enough you will get the answer to the same query that someone else will not have.  So thats the new job of prompt engineering.  So thats one level new type of jobs.  So.  But then on the opposite side.  we allies and and we discuss some of the elements that that those large language models are have quite lot of limitations so they are ruthful so they are not representing the knowledge.  They are just adding factor recognition they using pattern recognition adding conversational layer.  We need to work more on the on the the commission part of it.  So combination of design systems around the better idea or representing knowledge but using mathematical models cognitive science software engineering.  and then talking about software engineering not just computer science because its really designing pipeline.  So its more complex than just writing code.  So writing code the in sense is the easy part but the more complex part is to design the pipeline.  creating the mathematical representation of it.  So thats the the call to me that was mentioning that you have sort of simplification compared to coding that we do now and you have novel complication on the other side with the cognitive engineer and you whatever you want to call it.  couldnt find better term for it low hanging fruits so we mean thats what we are doing.  You can do all of those we pied on quite easily.  So you can do what frequency number of unique words so entropy.  You can do the end gramming.  You can do sentiment analysis.  You can create graphs in different ways.  Once you have the graph you can calculate the the centrality that can be degree centrality between centrality.  Those will tell you what are the words or the classes so that they are more relevant more essential for the conversation.  You have page rank so page rank.  Its metric created by pager.  That is one of the creators of Google measuring the relevancy of the page mean page with the small P.  But can be used to measure the relevancy of word or cluster awards within larger documents.  So another element is the average path line that is measuring how distant to concepts it can be based on the distance in the graph.  Hmm.  That is measured by the degrees of separation.  They have.  So all of those are metrics that are that Ive been created for different purposes but can be reinterpreted and use the in IP.  Analysis in broad set.  Okay so that basically all have to say.  And im sorry if it was lot again.  Its almost of talking.  and apologize for that.  So we dont have time for the in class exercise.  But will not publish the in class so exercise anyway and will give you few days to practice on it and then after that will post possible solution.  So the in class exercise is on analyze articles.  So from newspaper.  So next class we will do web mining for this class.  You dont do Webinar scrapping or web mining.  But you just copy and paste.  So you go to web page.  Whatever it is.  you highlight.  You select text you copy it you paste into tech side.  You go creating Txc file and then you start analyzing the Dx.  Define that you will open the file.  You will use the software file.  You will read that both this file that you created and the soapore file.  You do some cleaning removing the so forth and eliminating the the non alphabetical words things like that and you will calculate and pre into the 10 top words and using the the cloud the the py script that they attached in this section of of canvas generating meaning printing and saving the the what cloud from the text.  So thats the in class exercise that they strongly encourage you to do it for practicing for up next week we will work on analyzing texts.  So what you will do will be to go to use this pro corona website.  That is kind of interesting website where they consider controversial topics socially controversial topics.  Those are some of the topics.  So if you can see that dont know artificial intelligence.  so you have brief description of the context.  Then you have list of pros and list of So you have people saying its good that people saying its bad.  and there are few of them.  So what you want to do is to put together the pros on one side the the on on the other side.  Analyze them.  So let me give you little bit more details.  so you will for use on the following controversial issues.  So dont want you just to pick whatever you want because it could be more difficult for us to control.  You wont to focus on one of those that are topics that are over here.  So it is in the new topics like this one is one of those you have pros and cons cool.  What you do.  You copy the pros and the separate the Dxy files.  The goal is basically to analyze the and write report on the differences.  So you clean the text just like we did in the in class.  explain how to do in the in in class using Father you will calculate the sentiment you will extract diagrams.  you will create the word cloud.  and then you will right or the that will be based on the results.  That would be page so or bigger must be human readable meaning.  You do not want to describe the process.  We dont care about the process we want to see at this point the results.  So what are the insights.  What did you get out of the comparison that you do again Its not an explanation of the code needs to be in plain English if it is not in plain English.  You will get lowgrade.  You will work individually mean.  Again please dont let me report to the on or board it.  Its pain in the neck for everybody and it may have terrible consequences for you.  So dont go that route because its not good for you.  So if you have problems we we have ta.  You have some of my time so use that you are paying 6000 for this education.  So for this assignment that we will evaluate the similarity based on the most similar of the between the script and records.  So even if in the model that they share with you.  weeks ago had the and then there was combination.  because we still have quite lot of cases the similarity will be based on the most similar or the 2.  So its the script.  Its more similar of the rep or the that will count and we will consider the similarity on the script only and vice versa if it is on the right.  So you will submit the report and the Python script in separate files.  Final script.  So thats basically it.  Im stopping the sharing and will publish all the content again.  My apologies for the long talking.  Natural language Processing is the core of my research and can become passionate and can carry on probably too much my apologies.  But think it is useful.  and mean chat gpt.  We are all talking about it so.  anyway so really thank you for being around for about h.  Questions.  Okay If not Im stopping the record.  All right so again.  Its April the fifth and its 31 and 001 this is the 24 Ws.  So as Well yes 24 Ws.  And let me start sharing the screen 009 and let me go here first.  024 So we are over here Class Number 10 and we we talk about web mining we introduce except size 8.  That is another heavy one.  029 We didnt discuss expert size and for sure like exercise 7.  We will discuss both of them 150.  044 will spend little bit of time on that.  055 recapping little bit what to do for the final just brief introduction.  The formal introduction would be next week.  100 But just want to give you some directions.  115 would talk about Chat Gpt because this is the right moment to to do that.  120 All right so let me start with the 129 so wed accept say so excess was on 138 some procon text processing.  146 So let me go here.  152 No except size.  Okay lets go with that.  Thats first except say was probably little bit complex.  So so basically 156 the data set that was 209 ere 213 issues somehow.  So again data set is Ssc faculty.  Csv.  And we want to deal with it using 229 So 242 because Pandas is using numpy we want to have noon pipe that we also give us little bit of more options so in terms of working with numbers.  244 So im reading the file up.  257 replacing the nonavailable with the we want to live in place through meaning.  We are not 300 replacing lines or adding lines.  312 Then Im.  Calculating and printing the number of courses for each program up per each academic here meaning did the group by program.  315 and 327 calculated the summation somehow for the and thats was basically new data frame called the Df One and im printing it.  331 mean it is always some amazing 346 and how powerful the that could be 352 Erez agmoni.  So with one line you basically do something that if you should have done with the loops it would take 250 359 decent number of the lines.  So this is the calculation for the same thing.  409 Then number of courses per faculty overloaded.  So im basically creating new data frame 423 with index.  Id 434 then 437 im 440 getting those mean the the balance is for the the for for the different areas dropping them on available 442 calculating and printing 456 number of courses per faculty under loaded pretty much the same 459 again.  Obviously.  509 this case is greater than in this case its less than so im focusing on the balance.  511 could have done function so 522 passing this string 525 that could have been possibility.  531 then create the the list of values for the programs.  537 created the list because im going to pass the list to bookie for the graph.  So so 544 em Ss.  W.  As well.  Yes.  554 calculating the loads.  558 Then that starting the graphs.  604 So Xaxis 609 would be the year.  So 612 call on sir.  whatever you decide.  615 Then that creating the line graphs so Epsilon Epsilon one at 2.  619 Why Why why Whatever is that 627 How you want to call it so Again Those are the values that they define here.  That was no needed to create additional variables.  But thats fine.  This is more clear somehow.  633 Then creating initializing the plot.  646 naming the the file.  creating the site in the parameters plotting happy legends 651 bar graph for for average load the restractor.  Similar things so obviously different 703 floating type 712 under loaded.  715 If you are plotting time 718 courses by program 722 bar graph.  725 calculating the the summation for all the values thats where no pie is coming to play.  the percentage 728 overloads.  741 So when you do the pie chat.  You need to calculate the angles and thats why im doing 746 all those calculations here.  Legend using the pie shot.  and thats here.  run it.  753 So let me go here for the second.  You have the the values 807 that are printed for the different loads for the different programs.  Number of courses per faculty.  813 will be overloaded 824 for the different years.  829 got the underloaded 834 what is different Yet again.  837 thats the end.  In terms of printing.  You have 841 programs over here 848 thats 851 call it 853 average loads for distractors over the years 857 under loads over the years 904 courses per program.  910 the pie shot and thats it.  913 So 918 that was exercise Number and the one on the Ssc.  Faculty.  It was complex.  So 920 why gave you this There are couple of reasons.  So one and mentioned that when presented that when introduced the the the assignment 931 in some of the past semester so some students we are kind of complaining that we didnt do enough in terms of 946 application to managing the situation.  So in course that is part of engineering management.  So wanted to give you the opportunity to do something on the management side obviously or from no one is managing the Ssc.  Courses.  but its way to work on that.  using data to get elements to take decisions.  So if you look at just the at the charts so you basically have engineering management.  That is the largest program is more than 50.  What is the message here Well mean.  if like in my case you are the the the the program director for engineering management.  Then you can say as promotional item you are in the program.  That is the largest in our school.  or probably you may want to have sort of over the years.  That means you can create different story.  think one of the shards was on that area.  So this chart is basically telling you what is the the mean.  It is the courses and not the students.  So but what you see.  So one of the things is that software engineering is growing lot.  It its.  mean that then what is growing lot.  So went from very little to bigger than system engineering.  So again im the organ director for engineering management.  Im happy.  Probably this angle its little bit smaller than this angle.  Probably not.  So.  The angle is telling you what is the increase meaning how fast is growing.  So im seeing that its growing lot of pretty much the same rate as the other program that is growing fast.  If was the program director of system.  Engineering this going down is something that you dont want to see meaning need to do something to revert the the trend that that is down it.  If was the the program director for software engineering because hes growing so much need more instructor.  And we are hiding actually modest factors in software engineering because we have more courses and we need more people.  So those are the values for those visualizations.  the values for the numbers.  So if you mean this is not adding match to the visualization.  So number of courses for faculty over here.  What you can say is that the there are some instructors so that they are teaching way much more than others.  So why So mean that one of the reasons is because we have tenure track and non tenure.  The tenure track tend to teach less so we we can eventually discriminate the the the faculty by being tenure taraka or non tenure crack and then do another round of analysis.  But this is just an indication.  So we dont have an even distribution of all the courses faculty overloaded.  So you see that there are some faculty that are really overloaded.  think one of those meaning in this case Number 14 is teaching courses in her overload and underload that.  This is something you dont want to see.  So why Number 13 and Number 18 are so under loaded.  So you want to dig into it that there could be good reasons.  So there is one with 5.  If im not wrong.  In this case it was kind of easy.  It was it was personal leave and thats the reason.  But those are elements for you to take actions.  So its really something that is on the management side.  So who put that they gave you an idea why we did the this exercise.  And obviously the second reason is to be sure that you are using Pandas the best way possible.  This library is really powerful and can really replace in many cases loops that could create million issues.  So said that to me on time the python is not great.  Its not very efficient in managing loops if you can avoid loops and in particular if you can avoid the loops in loops meaning that nested the loops.  those are highly inefficient.  That would be great erez agmoni.  So you want to have as much as possible operations done in Madrid sees and this is what Pandas are doing 150 So it is.  Its not part of this program to just give you the details on linear algebra between.  mean on on the differences between doing loops and doing multiplication multiplication between Madrid sees.  But just keep in mind that using Pandas and using all the attributes that you can have with the Pandas.  So all the operations that we can do with Pandas so.  and that are why they load all the sub libraries or components of that can be of great help.  So use them as much as you can.  So those reasons one on the management side one on the technique outside.  So if you want to use python for management reasons.  Most likely you will deal with tables.  In broad sense.  That means that most likely Pandas is what you will use to crunch the numbers so and get the the insights that you may need for your management.  So that was exercise again.  It was challenging.  If you look at the number of lines.  So we are talking about the 150 lines.  So that is quite something.  Exercise was definitely lighter than that.  So it was on comparing pros and cons on given topic ere the pro corona legalization or recreation or marijuana.  But it could be anyone so.  The process was just the same that you did going to the website coping the pros on one side the cones on the other side and doing and and paste the value into txes files and then working on it so imported the all the variables so they needed them.  Then use the function for cleaning text.  We already said that meaning on time.  So if you will work if you plan to work somehow on text in the future create your own functions for specific tasks.  and in particular for most common tasks and probably the most common tasks in text processing text mining natural language processing is cleaning text.  So in this case im using function that is very basic.  If you do so you want to have the right amount of comments because its something that you we reuse in the future meaning.  You may not remember what what is inside the something like that where you specify what are the parameters that the the the function is taking and what the what is what are the out the outputs generating generated by by the function and the type of parameter in and out.  So in this case im using mean again very basic functions.  You can do better than that the the the parameters so that mean that the input values they then taking in the text cleaning is that this the word that they want to clean the minimal length of assuming that whats that That smaller than certain number of characters are not semantically relevant.  And then the list of software.  So with toast with those elements do all the cleaning and then will return at least list of team words opening the files.  One is pro one is con and one is the soapore file initializing the the list that need erez agmoni.  So use the at least for the the soapboard and then for each one pro cones one with the lines and one with the words You would see how they are used.  101 initializing the parameter that will use for the cleaning with the the minimum for words to be accepted.  reading the the soap or file adding.  whats that They know that they are very call Mona and do not want them to be too relevant in my analysis because it wouldnt add any knowledge to the analysis that im doing.  because its pro call marijuana for sure the name.  Its of the words marijuana cannabis drug legal legalization will be very common and want to eliminate that to give more room to the other.  Then could have done that.  function for the reading files.  did.  mean for the rest of the script.  The the pro call now are separated.  Thats not.  Again.  Could it be done with functions.  and we would be more read Ebola and more efficient.  So im reading the file so im taking only those with the certain length.  so that should be more than dozen characters.  If so im appending to the list of lines.  Same thing for the corner.  Then im cleaning up.  Im taking the top 10 or whatever the number printing it.  Same thing calculating the diagrams.  So the way in calculating the backgrounds its what is called the brute force so there is No.  we are not met on that.  Just taking the the words the one next to the other and then im taking the the most common.  using the the first 1515 or whatever is the number we you want to have.  And obviously you need to be aware that if you take one and the next if you are at the last one and you are looking for the next you will get an error.  meaning You really need to have try except because at the certain point the last element of of the what.  So you will get an aurora.  And at this point you will not skate it.  Same thing for the corner.  and Im.  Taking the the most common printing them.  calculating the sentiment analysis and doing the sentiment analysis.  sentiment analysis and work cloud they take shrinks.  Not least.  Thats why im creating string.  Ill go the list.  and then passing the string to the library getting positive negative new roll up same thing for the corner and then printing it so again could have done half not half of W.  73 but probably could have saved the got the dirty lines some roughly probably when 40 lines creating functions for dealing with both.  So over here and generating the work cloud again.  This is already been down.  could have used the the the same but thats fine setting the parameters for the work Cloud generating the work cloud eventually saving it to file.  just commented it because dont need the to have another file in my directory.  and then show in the cloud and then end up processing if run it.  Thats the the work cloud.  and thats the the not the mean that that text.  the metrics.  So you have the top 10 pro words.  Probably you may want to eliminate state but dont know mean what is the interpretation here State It could be.  The States needs to take control of the process or they being charged for doing the laws for the liberalization having Washington.  If you see States 12 Washington then its kind of controversial.  Someone is more pretty much the same number of people.  mean that logically it is for decentralization of the decision process and the another portion significant portion is for centralization meaning he said.  Oh he being at the State level more at the Federal level.  united probably part of United States.  So probably mean that we should do the cleaning in better way when we see things like that.  probably eliminating users using.  anyway.  So the most common diagram so United States economic activity.  all things that we expect to be there.  Sentiment Analysis as usual.  is the majority.  and most of what we say as large component of nonnegative known positive.  And thats where the new.  And so if you look at the pro.  and would say in the board the cases you have the negative being bigger bigger than positive.  You need to read into it because and probably the the the the the work cloud could help.  What you see here is that people like even pro are leveraging more on the negative aspects.  mean erez agmoni.  Lets say improve marijuana because if we dont legalize it then there will be more crime.  There will be more illegal drugs 250 and thats mean using negative argument to support positive opinion on the negative side.  If you have more negative you you can say there will be more.  mean there will be more criminality.  That could be pretty much the same arguments.  But mean that you should read the into that.  All right.  So that was pretty much it for those 2.  Let me stop sharing for second and check.  If anyone has any question.  and if not we will move on to the next topic.  That would be the topic of the day.  That is web mining.  So let me share the screen again.  Let me go here and lets start talking about the web mining.  So what is web mining web Mining means going into website and getting the content.  Oh thats in nutshell that what web binding is getting the content could be It could be it could be videos.  So whatever is the content that we we want to explore the possibility of getting it now Some of the questions that they had over the years.  So one why we do that we already had Google or something like that second question.  Is it even legal.  Well on the first one.  Yes we do have Google.  But if you do Google search you basically have the link to the page.  You dont have the content.  You may want to have the content that to do something.  So you want to do an analysis like we did the with the pro call.  So instead of coping and pasting if we have multiple sources you may want to have an automatic way to go into the website getting the pros and the calls and then use it.  So Google cannot do that.  Google will eventually just give you the URL or the pro phone and then well be up to you.  Things can be done in more complex way.  You can get metrics you can get numbers and then you can process the numbers.  So thats the why we are doing it on being legal.  Well if Google built an empire on going into the websites and getting data.  That means that it has to be legal.  So if Google can do it and planet that a.  Sc.  That we can do and in our Miniscule domain.  Then there are kind of grey area so generally use an example that at this point is kind of outdated but its still real.  few years ago small company was mining linkedin to get indication of employees looking for jobs.  and then adding some processing and reselling to companies like another.  You have those people that are conducting sort of abnormal for jobs.  That means that they are thinking about leaving you.  So it was kind of valuable service.  Then at the certain point this company received the letter from the Linkedin low years saying that you cannot do that but if you continue doing it that we will sue you.  So that was kind of shock for them the the motivation for link in that.  Apart from the obvious economic reason they said that that yes what is on the Internet is public.  But this is breach of the intent of use of the information that we publish.  So it star New Year decided to to side the this small company and the litigation went on for while quite while means appropriate.  So in the meantime several of the employees of this small company left some of the customers left because they so kind of at least what they we are doing.  Bottom line day one.  But the company closed the because they couldnt survive anymore.  So thats an example of the grey area on web mining.  Another major issue of with mining is related on you are mining website.  am the owner of the website.  can change my website the way want because its my domain.  So if you write the code the picking specific elements in my website.  If change the the architecture on the website your script will not work anymore.  So thats how unstable is web mining.  Nevertheless several times it makes sense because we may need some type of information that we cannot really get in in different way.  So Obviously there is quite difference between that web mining and data mining.  So when you do mean they have mining in common but thats it.  So when you have data mining you have numbers.  So you have structured set of of information with the web mining is its definitely.  mean.  it is structured but each website has their own structure and structures within the same website as was saying before can change at any time.  So it is really different.  Web mining is more challenging to begin with.  And then what are you going to get Youre going to get text and then there is the text mining component.  So web mining is portions the web scrapping.  So you are getting the the text that you want.  But then you need to process it So its.  Its definitely more complex than the data mind.  What is the web So webminding web But what is the web It it.  Its 63 on page so we know no one really knows how many page are in the web.  lot.  some duplications meaning duplicated page.  Some are not indexed when they index it.  That means Googleized or Google Index it.  Yup.  No not all the page are available.  When you do Google search.  If write my page in way that is not going to be indexed by the by the search engines it will not be possible to find it so.  those page at the page so creating what is called the dark web so the dark web but doesnt necessarily mean that the that is in the gala but just that is not indexed.  So then could be mean legit business.  But just for any reason dont want my page to be public.  What we do with the web mining.  Again we can do exploration.  We can create models we can create services we can do predictions.  mean there are quite lot of things that that we can do.  We can use web mining for advertising getting advertising information.  Indeed the is one of the largest job such platforms.  So they started with no jobs that we are their own Erez agmoni.  So what they did there was basically they went into the web going to the different sites posting jobs and 101 scrapping the data and aggregating them adding layer of analysis like the one that that you see on the left side the salary company location job type and other things.  So they told what they were up.  and then that that was the first version of indeed.  Then they grew.  The business was successful.  Some companies that gave the jobs so directly to indeed that became either sponsored jobs or exclusive jobs on indeed.  But they started with the web mining.  so they build an entire business out of that they we are integrate or somehow all the information.  So hmm.  Sometimes they didnt use just the scraping they use the Api.  We will go there in moment.  So lets go little bit more into the web mining business.  So Web search is for all the web mining.  So you have the the webpage and you have an agent that is web crawler going into the page and getting the Hmm.  The keywords that are defining the page so it could be the location.  It could be the most common wars.  So those are the the elements that they use to time Good.  The page creating sort of an index for the page.  So the webcroller is basically creating crossreference table with the the URL on the page and the tags that that are related to to the page does the indexer.  So the crawler as components one scroll in the data and they say on the indexing.  When user is asking for something then the search engine is matching the keywords from the user with the the tax that are that that have been indexed by the roller.  and theres the match when there is match and then eventually it could be an algorithm to sort based on the quarter of the match.  Eventually if if people is paying for being higher in the presentation of the results than the other element that is consider is how much 150 the companies or people is paying for each key word.  So its kind of bit process and then the highest will go on top and the other will follow up.  If the model contains also placing ads then you have another component that is managing the advertisement portion where you have the name of the advertiser.  and eventually the message that can be the URL.  What other messages and the tags.  And basically at that point the the search engine on top of all the presenting the results is is also matching the tags in the query with the tags in the the the database and presenting the results.  So this is basically how search engine it is working need spider an indexer and query process.  So if you look in any page.  So you have mean this is an old one but the the concept is is still the same as you.  You have list of words that are links or hyperlinks to page when you mine into site that you basically jump from one page to another using those hyperlinks.  Each page is file in format that is called HTML Iber text markup language that its the the standard for browser so to transform the content in the eventually beautiful layouts that we see from web page.  So again.  hypotheses mark up language.  Thats an example is sort of like structure where you have in angle brackets the the the tags for what is following.  So you have HTML beginning and and and then you have header in this case.  mean because we call it the the the developer of the page.  Call it head but could have called it in any other way.  Then you have tied all you have body and so on.  When you send request the request mean when you through your browser send the request.  Your browser is sending bunch of other information.  So for sure the text all your query but also some additional information that wed be used by the server primarily to know more about you.  The no more can be finalized to advertising or just optimizing the traffic.  So you have what is the host What is in the the the the browser that you use And what is the language Eventually in some cases you also have the the IP address the response.  Yes we get the page.  We get the HTML and we see the page.  But actually your browser is getting little bit more.  So its getting know of similar information.  Then information that we send with the additional Meta information that are used by by the the browser to present in in the best way possible the information that they are received.  the correct that set is one of them having Php.  No Php or other elements.  So what is the the version of the Http So all those things are are useful for the browser or essential for the browser to present the the results in the most appropriate way.  Our browser may or may not use those elements.  So if is using those mean apart from functioning.  But what other purposes unless you have what is called the cookie That is piece of software installed in your browser spying on your activities some of the activities.  It could be unreached somehow by the the characteristics on the sides that you.  Basically So again thats another example.  Spiders plain pieces of software.  We will do some examples.  So very low level examples.  You will work on something slightly more complex.  Not much as an assignment for next week.  Obviously its vertex.  meaning you can go.  You can search in different ways so you can go completing an horizontal level or go in vertical in the end and then go back.  Each one of the strategies has pros and codes.  so as you can imagine if you do something vertical and is site that is lets say the New York Times site or whatever is news outlet.  So you go in depth in one.  Then you emerge you go up and then you go down to another one.  But chances are in the meantime the first line that you explored.  mean the results that you collected the are outdated because there is something new.  So when you move this way there are chances that you will keep cheating the last one without getting that much much new.  When you send your request you use your browser is using protocol.  So Http.  You know that we know that is HTML but they also mean its dialogue between your browser as the client and the server we are the information reside.  So get is the common to get something.  But its not the only one.  So in theory you can do with the same probable way much more if the server will allow it.  So lets go for moment that step out of that and lets go to some examples.  So in Python there are several libraries that we can use so request its pretty straightforward.  Its basically going to URL that you specify and its retarding the the HTML HTML that can be little bit convoluted.  But there is library called the Beautiful Soup name is from Alice in the wonderland that is transforming is parsing the HTML structure in tree like structure.  So in this case im importing Bs for that is beautiful Super im porting request.  So that is the library that will get the HTML.  Then im getting using requests the HTML for that page.  Then applying beautiful soup to transform the structure.  then im printing the the title from Super.  and then im printing the the paragraphs.  But if run it.  thats what you have.  So your time.  So mean if we go here.  So this is the page of New York Times.  and its basically what you get here.  So this is to some Democrats and Republic and the charge again.  Dont something that thats what we have in the page.  Unfortunately even this portion min thread.  The min thread are tag the as title and thats why we are getting them.  mean they can tongue with whatever they want.  Most likely they do it intentionally to make our lives as as scrap.  Its more difficult.  mean that thats pretty much.  think we can.  remember.  Oh we can.  this one.  Yeah.  So there is way to see.  never remember in safari how it is.  Yeah.  so does the HTML again.  The HTML is not exactly very readable.  so let me show you how the soup could be.  and let me comment this one just want to.  So this will.  So thats the way it looks.  Its big fine but you have tags that can help you.  and the tax is what we use to extract the those elements.  So anyway.  So this is way to do scraping content.  Thats very basic.  There are several libraries that it can do that.  keeping in mind that that sometimes things can be complicated.  So if you go into into page that are distributed on multiple page.  Then you need to have something that will be able to you for so so request is not going to do it right away.  You need to write the code in in different way or use different library.  There are libraries that are for meeting.  User They tend to be more efficient.  But again they not work on all the sources.  So we mention what is either request or or you are lib.  Thats for getting the data.  You can save eventually.  The HTML beautiful super is what is doing.  Let me keep that and can do here.  So we mentioned that things can change in page.  So sometimes you may want to establish direct relationship with the the the server so or with the administration of the server to do that some so versa.  They have what is called the application program interface.  That is sort of protocol establishing the rules of the game for downloading data.  So instead of just scraping the content from the page you basically go to the server using the Apis.  the vast majority or Apis they have first step but that is an authentication step we are.  You show your credentials and then the server will let you in for the privileges that you have.  Think about the news service.  So you pay for getting the news and you get the news connecting your your application to the server.  When you do that you basically send that an authentication saying Hi im Carolly pizza.  And I.  want the news from this date to this date.  Then the the server will check if my credentials are good for what im asking and then we will.  It will send me back the news.  So thats what the Apis do.  So when you use an Api you are kind of more sure.  The the results are appropriate when you do scraping.  Its kind of last results you have because things can change.  Content can be on multiple page.  Content can be in boxes.  mean that everybody is trying to have you paying for the content instead of giving it for free.  So some Apis are free not all are free.  would say some of the valuable Apis up not free.  was mentioning the use at the certain point.  We did the project extracting news of pad and some papers Erez agmoni.  So with patents we were okay because the Talent Office is allowing users to download the the pardons 150.  What news Initially we thought.  You know what we will and create our own Webcra and we will download the all the news didnt work well because we had with Google news that you have limitation in number on our elements that you are downloading with the New York Times.  So same thing you cannot play with those things but when you use in professional way you really need to establish contract with them and the Apis are are the way they contract its on order somehow and get the information in more structured way.  So sometimes there are limitations meaning for the news.  When we did the the the program and we ended up.  It was large project for the Dod.  We had money and we paid for the news.  and we had certain number of of news that we could download the the timing interval and we did that we there as free Api.  But you have limitation in terms of number of tweets that you can download the or number of queies that you can do for time interval.  Again this example to either.  When you download tweets tweets Are we much more complex than we think in terms of structure Yes you have the same that you have the timestamp.  You have the text but you have quite lot of additional information information about the user the geolocation and things like that.  We may not be interested in that or the majority of the searches on the projects or the researchers that they did on that we that use the only the sender the timestamp and the text.  But sometimes you may want to get more than that.  When you write your script mean that you can use or you cannot use library that will make your life easier.  You will pass anyway those elements so that are part of the authentication.  So you have consumer key and cigarette a.  You th token and cigarettes.  So those are our characteristics or credentials that you get when you create your when you establish the relationship with.  So you need to register your application.  When you register your application you will get those numbers.  So thats basically it.  That is not much more that can tell you about web mining.  So its even some that we offer courses on web mining.  Im reading up all that issue or that you really need courts on web mining.  But mean that it may have some merits so for engineering management that really dont see why we should do that.  But anyway.  you can explore.  You can do additional exercises.  You will have one for next week.  That will be on the easy side.  All right.  So let me go now on that something else.  the the portion strictly on web mining it is basically over.  So there is not much more than need to tell you on that that should be.  But we are not going that way.  What want to to talk now is about the larger language models like Chat Gpt.  So its kind of the elephant in the room.  When they announced the chat Gpt was made on November.  It was huge we all know million user in the one week something crazy like that.  It was planet that the phenomena it was planetary success in sense.  So why we didnt talk about it since the very beginning.  Well there are quite lot of reasons wrote about the user our chat.  We gpt in education.  Ive been interviewed by Do not magazine so on that how to leverage and how not to leverage what we are my positions.  To what the use of and those bolts mean that its very controversial issue.  want to share with you my opinion and would be happy to open conversation if you like.  So the first point is we need to know little bit more or we need to be aware How about how those things work.  So those things that are generally are called the large language models or llam such.  Sometimes call them just bots either ways.  So the proper category name is Ln.  M.  So much language model that so those large language models dont like calling them generative systems because they are not really generating anything.  They are just.  mean that compiling things.  So the the way those are its basically They started with the in notion of data we will go into how much in moment but just to stay in high level.  So you have quite lot of data quite lot of text that collected from different sources.  This content We are very high level as being tagged for recreating patterns.  meaning what are the topics for each one of the elements on this optional data What is the relationship with between those tags basically similar to what we saw with the scroller with the search engine.  So they had the an advanced version of the webcroller going into the page so not just taking the the URL and the tag but the entire text and thanks.  So its is indexing somehow.  Then you have your query.  So the query as elements that will be matched just like the so changing that will be matched with the content.  So at this point is matching not the Urls meaning not like Google that is giving us only the address of the URL meaning on the page but the actual content or the actual portion of the content that is being tagged in the same way as youre creating.  So its matching patterns so the that they have from the and the pattern from your query.  And then once the match is done.  They have another component.  That is natural language generation.  Its the only thing that is generating adding conversational layer to this match of patterns.  and thats all they do is basically like adding layer to Google in terms of providing content instead of URL and adding conversational layer.  So thats all they do.  What does it mean means that the more details you provide in the the query.  the more rich will be the match that the Anlm will do for you if you send straight question.  One sentence words.  then the match is going to be kind of dry so you will have an answer.  But the answer is not going to be much reach.  and Im.  Heading student an undergraduate suit.  Im sorry in high school the students because working on comparing the assignments she is submitting in history records with the the submission from chat.  G.  GPS and the teacher is analyzing both and is giving an equivalent of grade for both of them.  So the results are okay the main difference so that the teacher noticed the in a.  And who we are going to write paper on that that.  think that the teacher noticed.  That was just that the facts we are there.  But there is no real connection between those elements and there are no additional elements to explain the context where those facts happen while the submission from the student that was more reach somehow.  probably providing the more details would make life.  mean.  mean answers more structure the more complex.  How we can do that.  So let me share this screen now and let me share with you the way im using chat gpt.  So im using the plus version because as philosophy of your life.  and like to pay for what im using if can.  because fortunately in this case can.  Im paying for the plus version.  There are not many advantages in getting the plus version.  Apart from this he that you have the session or sessions that are always open.  You dont have services not available message.  but thats basically it.  So in terms of capabilities its pretty much the same.  A.  And they cost the for mean an online service.  Its relatively high.  Its 20 each month.  but mean for while plan to use it.  We are planning to build something by what service will never be as good as you would see in the reasons why.  But thats what we have.  Im writing book.  probably already mentioned that that that is so societal applications or so size and implications for the user yeah machine learning.  There are several things that are so.  Just to give you an idea thats the Table of content.  So some of the things it its working progress.  Some of the things requires sort of digging into sources.  So we are talking about the AI revolution.  But is this via revolution How you measure revolution What is the revolution So basically went into chat gpt and asked about the information about of the largest one technologydriven revolutions.  the industrial revolution and the so.  and then try to get as much information as possible.  Nothing at the day couldnt have done using Google.  but the difference is that have compiled version.  The difference is positive negative because dont have the sources meaning can not just take what chat Gpt is generating and using in my book because the chances are there will be an infringement of the rights of someone who wrote the the the the phrase keeping in mind that that Chat Gpt is not generating content but its taking pieces and patch them together.  So those phrases are from somewhere at certain point that someone can tell me this is so.  Once have an idea from chat G.  Gpt.  Then need to process it and if want to use some of the content.  Then go to Google and get the actual source and then side the source.  So thats what you need to do.  and thats one of the reasons why we are talking about the chat gpt now instead of Chat gpt at the beginning of the course.  So but let that.  Let me stay for moment with this creating context.  so you can create chats.  Each chat that you create.  You provide information.  So the system is not learning from what you are typing.  because the learning is batch process in chat.  G.  Gpt.  Meaning that there is training path that last about week.  That is very expensive.  will give you some details on that and its done and then is the user of the model.  What you are giving is basically the context as was mentioning.  So and where my new query.  well be playing meaning that dont need to reexplain things that are already in my chart.  so the more reach is the chat and the more reach will be the answer us that the boss will provide.  So if you want to have good answers you need to provide lot of information.  Now sometimes this can be doable in in an academic environment that sometimes not so much keeping in mind that once you create the the context through the chat the the answer that you will get that will be different from the answer that someone else can get to the same query.  because the result will be based on the on the context that the chat that you created.  All of this is creating new job that is called the Prompt Engineering.  The way you prompt your query is affecting big times the quality of the answer that you are getting So thats the part on noncoding.  Now chat gpt and again created the several chats and each time want to ask something in particular domain.  can get the answer based on the history of the conversation.  so could the its different.  Sorry.  So you probably read the that Microsoft invested the 10 billiondollar in the open.  AI that is the company who developed the chat Gpt.  They also provided quite lot of assets.  One of the assets that Microsoft has is github.  So Gitab has lot of code and this code thats being used to train the now tested it.  When have problem with some level of complexity can give you little bit of help keeping in mind that that sometimes is doing things right sometimes not so much meaning that you need to know how to code the to discriminate the the good answers and the bad answers.  Now.  if you will get job in the next years and coding will be part of your job.  You cannot get away with the using chat gpt at your work.  So you need to know how to code.  If dont teach you how to code and thats what we did from class one until today.  If dont teach you how to code the one that you will never know when that child gpt or equivalent is doing right and is doing wrong.  Second the you will not be on the to use chat Gpt.  You will be hired to write your own code.  so you can use chat Gpt as base.  And also mean we are engineering management that we are not in computer science.  We.  So we want to have we want to be integrators.  So we take all the inputs so that we can get from all the possible sources including the pieces of code that we can take from chat G.  And incorporating in our own code.  Again.  keeping in mind that if you do not cite the the source and someone else is using the same tool.  We will consider that as pleasure is Ma and you will take.  We will take points off.  So you would get some point reduction because of that.  So feel free to use whatever tools you want but keep using citing the the sources.  So let me share few more slides and then we will work on that Any class assigned that.  So we mentioned those large language models.  So open AI started.  mean that generating those large language models in 2018 with the first Gpt gpt generative pretrained the transfer.  They are based on An algorithm that is called the transformer that was created few years before.  Open AI Okay.  based on paper called the name.  The attention is all you need that is based on using the attention mechanism to victorize text.  So if you remember from the class on tax mining.  you can transform text into sequences of numbers.  This process is called vectorization and you can create matrix in different ways.  So one way hes analyzing the call for us awards.  You can say okay will consider connected the words that are appearing together more than certain amount number of times.  and then you have number of the number of times so they call core somehow.  Then you kind of normalize the madrics and you will get each word that will have sequence of numbers.  So thats basic form of vectorization.  Its not the most basic but its basic form of vectorization.  The next stage is using what is called the war to back.  We mentioned that that is again the next step.  So instead of having the number of core coordinates you have the the conditional probabilities or one word the upating because of another.  Then again you normalize the matrix and you will get the each word with certain number of numbers defining it.  That would be pretty much like having points in in space.  Thats what we what to back.  This calculation of the conditional probability is using neural network with one hidden layer.  Its called the shallow neural network.  So you have an input layer with your parameters.  You have an output layer and in the middle you have one or more hidden layers.  What to back her head.  One he the layer.  transform that so because they are not only looking at the conditional pro probability and not only forward but they are by directional and they are also taking into account the position of the word in the sentence.  But because you have more parameters the neural network is more complex and there are much more hidden layers.  So to do the training all the system to calculate these madrics using what to back in that when you have an auto text that it could take allow whats on one of our computer so it could take several days using their last nights.  So because you have more complex fraction based on the same principle open AI created the Gpt initially.  now we are 4.  So the complexity is measured the by the number of parameters.  We are talking about neural network neural network that are inputs in the neural network and there are weights to the different inputs for the parameters.  So is the number of weights in the the network.  So.  Bertha that was the one of the first model based on science formats.  They have 340 millionparameters.  Gpt.  the first commercially available 1. 5 billion So we are Gpt for that.  That is 400 billion of that.  So thats where we are.  Its the really complex structure.  So the training of all of this is kind of interesting so the estimated cost to train chat.  Gpt is 4. 6 million.  There are you months in the loop because they help the in the tagging process and in refining.  The results generated by one of the components of this and the energy that was used.  Keep in mind that the all of this is running on gpus.  And so Nvidia is doing lot of money out of that.  The estimated the energy used for training chat.  duration was about week is pretty much the same amount of power that can run more than 30000 households for day.  So thats the impact in terms of ecological impact.  Keeping in mind that our brain is using fraction of fraction of fraction or fraction of that much for the entire 5.  So that means that Chat Gpt is not an efficient way to represent knowledge.  but we already know that but its cool and its doing quite lot of things eternal sources.  45 TB of text.  So thats how much text is there.  Keep in mind.  The text is not using lot of memory.  and 45 TB it.  Its really lot.  So those are some of the sources.  So pretty much all the lets say open source sources that we have.  This is the distributional language.  Almost 93 is English.  and thats another indication that we should consider so.  The message here is chat.  Gpt is biased.  Its bias in terms of sources for sure but its biased in terms of language.  Yes the web.  Its more English than any other language.  But 93 is lot.  So If there are contents not in English chances are they are under represented.  So thats one of the things that we need to consider.  Another Things that we need to consider is that chat gpt is based on data up to 2021 meaning that if you are asking chat gpt things asked of that it doesnt have any information.  So why Google lots is it somehow updated the pretty much in the of time.  considering how much the training costs.  Chat Gpt and Gpt.  Whatever from to is definitely not real time.  So thats another limitation that we need to consider how they perform so difficult to say in 2016 and other.  Introduce the data set to benchmark the ability of language model to perform task or oriented toward the language understanding.  So if you look at the chart we are getting better probably with this particular metric in another couple of generations of Gpt.  It it will each somehow.  mean for that particular test thats human like performances.  You see shot at shot means machine learning models performing task without specific training on that particular task.  Those are not performing great and mean definitely those with the so confused short are doing better job limitations.  We already mentioned that another thing that we need to consider is that we have different areas in our brain for new ledger.  So we have senses.  each sense as an area in our brain getting the input but also storing the information and collected by the those senses.  And then we have another area.  That is the language.  But the language is the expression of knowledge.  With the hmm only the language component.  So there is no representation of the knowledge.  But the language is the knowledge somehow.  So again we have time limitation.  There is no real time.  There is limitation in terms of knowledge.  There is an in in inefficiency.  There is the fact that again.  what all is doing its matching patterns that is greater considering how much patterns it has to match but its still not the only way we as human being function.  Let me keep all of that and let me go all the way down to this consideration here.  So was mentioning while talking about how to use chat gpt the fact that that is that is new job that is emerging.  That is is prompt engineering.  That is sort of super user and its combination all but knowing how those can work and not even more than that.  knowledge of the domain.  So you create the context to have that you are giving your mean more to match in terms of parts of.  So on one side this new job that is more less on the technical side the more on the super user on the other side.  You have people working on the next generation of at an end.  So we so the limitations and they have those limitations so need to be addressed thinking out of the box.  So we need the new types of engineering with skills that will go from that map 150 mit c.  In high demand in the near future.  Its not going to be easy because no one as model or cognitive science.  So how the knowledge is representing.  But thats really something that that we love.  We grow quite lot.  So hope you enjoyed the this going into chat Gpt.  And large language models.  So again at this point of the course really think that that is something that should be this cast.  Okay so let me go now into the in class exercise and let me introduce this assignment.  So the program will extract the data from web page and perform some analysis.  so there is no input provided.  But the website is going to be New York or whatever side you want.  You want to print the headlines and you want to generate what cloud with the words in the headline.  So let me stop sharing.  will open breakout rooms and will post.  The example that used.  strongly encourage you not to leave the class because of the assignment that you will do for next week will be will benefit lot from what you are going to do tonight.  So lets create 8.  Lets say breakout rooms.  breakout rooms.  and im opening them.  Its 9.  Lets say you have 20 min to work on it till that pretty much 30 and then will close the rooms and will not proceed with the introducing the the next assignment and spending few words about the final that will be detailed the next class.  The rooms are open.  Join the room sir.  and posing the recording.  not the 10 s.  So all right so all the rooms are close the you are all back.  Anyone want to share the the what you did.  Come on.  Okay.  all right.  So let me share the screen and let me go here.  So in this case use the different library.  So mentioned to you that there are many libraries for doing web mining.  One is newspaper.  So if you plan to import the newspaper keep in mind that that is imported as newspaper K.  So if go here.  so you will see the the name of the library is not newspaper but newspaper K.  So if you try to install newspaper you will get nothing because there is no newspaper.  So the name of the library is newspaper K.  But when you call it from your script you will import it as newspaper so hope this is clear if you want to use it just mean install it as newspaper K.  Anyway.  So imported this library.  imported the word cloud.  imported my plot lab because its functional to work cloud.  define the the URL that want to mine.  Then we this library.  There are different parameters that you need to set.  So not going into too many details about it just want to be aware that there are other options.  So then im reading printing the number of articles.  So so in this case is an attribute to whatever has been downloaded.  Then im setting the the maximum number of optical.  So just because dont want 100 of them for this part.  creating at least headlines then generating.  mean that was list generating the the what cloud.  But before that in the into string and if run it hopefully it will come out.  You have the number of articles you have and then obviously Trump is big thing.  We knew that all right so that was for the in class.  So exercise.  So let me go.  Oh here and let me talk up briefly about the final.  We we talk again about the final next week.  just want to be sure that it is clear the way we are going to do it so today.  Considering its 47.  We do not want to to go too late but just want to give you some indications on how the final is going to be structured.  So next week will give you more details about mean the the the the outline.  Well give you some examples.  We will be talking about that.  But generally speaking the final up is going to be like one of them.  so that you wrote so far.  But obviously the reports for regular exercise our short term because you had week.  In this case you have weeks for doing it.  So it its supposed to be and its fine all and there are quite lot of more points the for the final than regular exercise so it will be around 10 page all all.  it could be at the level or complexity that would be similar to the level of complexity that you have in the last the exercises minimum the level of complexity of the last exercises.  So how we measure the level of complexity mean there is no way to be on measuring the level of complexity but but the length of the Python script is kind of an indication of the complexity.  So line of Code is never to indication or complexity but is kind of proxy.  So between 100 200 lets say 150 and 200 that that would be the range that would be acceptable.  Find out that individual in the past.  gave students at the opportunity to do their own topic data set but when have classes so big as this one really cannot do that because there are issues with getting the right sources approving the the the the topic being sure that you are not just copying and pasting something from.  So it it.  Its not going to work.  so will give you options and you will pick one of those lets say options and you will pick one of those any one of those will be individual.  You will have your problem and you are data set and you well work on those so complexity.  We already said that we said that the structure.  We we talk next week about the structure samples.  Next week will give you samples.  presentations.  So you dont need to do your presentation unless you would be selected.  So there will be of you that will present during the the final class your final.  because we will not have lot of time to review what you are sending to us.  You will have one day before the presentation to the notified that you will be presenter.  Once you will be selected as presenter you have to present.  So unless there is serious issue but issues that needs to be documented.  dont feel well doesnt work.  So you really need to have certification if its help Already the issue or any other issue that you may have.  So again some of you few of you lets say about 10 of you little bit between 10 and 50 of you will do the presentation then either myself or she you most likely myself.  But well present some other.  Find out sir.  that may be of interest all the class because they are particularly good but particularly not so good the particularly unique.  For any reason.  We think that those are relevant and we want to share them with the class.  You dont need to submit Powerpoint.  So if you will be selected for the presentation you can go through your Pdf.  Or what file and use that as base for your presentation.  Then if you want to do Powerpoint feel free to do it.  But you dont have to.  all right.  So next week will give you more details for the time being up.  Thats it for the final.  Let me share the screen and let me talk about next exercise.  So next exercise would be really similar to what you did today.  So the programmer that you will write will extract data from web page and well perform some analysis.  You will bring the headlines so generate what cloud calculate the sentiment and write an interpretation of the results.  So you will import the libraries.  They find the URL that can be in your time.  So whatever you want to use it you will load the the results into your super.  You will create list of words with the headlines.  You will clean that the file.  Then you will extract the diagrams just like you know how to do it.  You will merge the most common diagrams with the the list of words.  create the work cloud with the results and then write the interpretation.  So or more paid.  The code must be welcomed commented.  So keep in mind that that mean we are not in computer science meaning the style.  The quality of your coding is not essential up to certain point.  meaning that if you send code that with comments so we will take points off.  mean that it could be 30 so it could be less.  But definitely.  We will take points off if we have no comments.  Then the interpretation document has to be original.  Nonoriginal documents will be considered.  Now.  documents.  We count the 50 of the entire grade.  So obviously it its its little.  But again at this point in in time for this courts really want to be sure that you are using the code for doing something.  So thats basically it.  hey Some Hmm.  Students in the class had cases of plagiarism for more than once.  So if you are in debt category and you are close over 3.  Be aware the the next one will let Trigger.  the reporting to the Ethical committee of your case.  because you have history of cheating.  Im not sure that you will pass the the committee meaning that you could be expelled.  So thats seduce matter.  So Dont put yourself in that condition because will not do anything at that point because told you million times and Im still selling you.  So the next one we trigger the notification to the on our board.  Okay so thats all had to say.  Most likely no one of you is in that situation.  hope the whomever is in that situation that we listen to to the recording and we will act in the proper way.  atts STEVENS lw INSTITUTE of TECHNOLOGY lll TTT Data Exploration Template clipizzistevens. edu SSE Contents LJ Project Goals and Conditions LJ CRISP Business Understanding LJ Data Understanding Data Preparation Data Representation Practical Results Conclusions LJ Attachments STEVENS INSTITUTE of TECHNOLOGY Project Goals and Conditions je What are the project goals What is the key question you are required to answer Are there any conditions limiting or somehow defining the project like limited access to data data too old time constrains brief description of the expected results may be added STEVENS INSTITUTE of TECHNOLOGY Contents CRISPDE Background Info Definition An adjusted version of the CRISP DM CRISPDE with DE being Data Exploration Focused on extracting information from data No modeling only descriptive statistics and visualization Consists of phases intended as cyclical process All phases are necessary in every analysis STEVENS INSTITUTE of TECHNOLOGY Business Understanding ui Definition Define business requirements and objectives Translate objectives info data mining problem definition Prepare initial strategy to meet objectives You want to be sure to clearly describe the business needs and the steps to address them from D.  Larose Discovering Knowledge in Data STEVENS INSTITUTE of TECHNOLOGY Data Understanding iw Definition Collect data Assess data quality Perform exploratory data analysis EDA Overall data description sources organization key characteristics sensorhuman generated reliableunreliable source . . .  Here you run all the descriptive statistical tests that make sense for the specific case describing the different steps and their specific meanings from D.  Larose Discovering Knowledge in Data ee STEVENS INSTITUTE of TECHNOLOGY Data Preparation ie Definition Cleanse prepare and transform data set Prepares for modeling in subsequent phases Select cases and variables appropriate for analysis First define the steps you are going to perform e. g.  if you normalize why Here you perform all the data transformation applicable to the case missingmiscalculatedmisplaced values outliers normalization Describe the final dataset format new records number new variables . . .  from D.  Larose Discovering Knowledge in Data ee STEVENS INSTITUTE of TECHNOLOGY Data Representation lw Definition Select and apply one or more descriptive statistics to the dataset Select and apply one or more visualization to the dataset If may be an iterative process adjustments may be required necessary additional data preparation may be required Explain why you selected representation to an other Describe final results Read the results with business sense and provide your comments STEVENS INSTITUTE of TECHNOLOGY Contents LJ Project Goals and Conditions CRISP Business Understanding Data Understanding Data Preparation LJ Data Representation LJ Practical Results Conclusions LJ Attachments Eee STEVENS INSTITUTE of TECHNOLOGY 19 Conclusions iw This is the final recap you briefly describe the whole orocess from the business need to the data collected to the representations you choose to the results you obtained Describe possible limitations of your analysis and future possible developments STEVENS INSTITUTE of TECHNOLOGY 11 Contents LJ Project Goals and Conditions CRISP Business Understanding LJ Data Understanding Data Preparation Data Representation Practical Results Conclusions LJ Attachments MU STEVENS INSTITUTE of TECHNOLOGY 15 Attachments ie All the additionalnon essential tables and graphs will go here Add only the outputs that can support the case you described in previous slides Outputs have to be either readable no 1M row table in page STEVENS INSTITUTE of TECHNOLOGY 73 Hello.  230 Hi There Evening Professor.  234 How are you 237 doing Well Happy to be out of work.  Were doing our our release planning week this week.  So its 239 hard.  Course.  246 What What What is the company you are working in 249 work for Lockheed Martin Im software right now.  253 Okay okay.  257 we have quite lot of business with Lo located Martin.  We had more in the past but we still have quite some students from.  259 We just happened to split my project into dev and then set offs team which 313 kind of contrary to the like.  feel like thats set off.  But you know.  Oh well well see how it works out.  happen to be on the the set ups too so im excited to get 321 it more into infrastructure and out of depth.  333 Good Good good is this call so helping you in your activities as some also did contribution.  336 its helping.  So happen to have applied to program within the company that and even if dont get it im going to try to move into more role that python plays more of rolling 346 currently.  Im.  only use really like bash scripting yaml 359 like pipeline sustainment.  406 use this necessarily in my day to day but from my capstone and undergrad.  actually did AI project that let.  And so this is kind of bring me back to that.  But havent used Python.  Really since then.  408 mean that if you want to take the opportunity of the to do something that is more in line with what you are doing at work feel free to do so.  424 mean that will be happy to help you as much as can.  435 Yeah think only halfway through the degree.  Also there are classes that as far as electives go.  441 kind of inner working the 450 you know trajectory of the with.  Even some like systems work would be like really you know.  452 Help My.  500 Yeah.  Yeah.  Yeah.  Yeah.  501 Okay.  Good.  So anyone else want to share how the courts its helping or not helping what you do at work.  505 will say one other thing think.  519 At least its helped me gain some more 522 planning credibility like within my team since im one of the youngest contributors so like thats kind of been nice knowledge.  Slash confidence to have the you know the classes in my back pocket.  525 Its good.  Good.  540 All right.  Okay.  So 542 lets move with the content for this class.  545 So we we basically have more classes and then they they will be the presentations of your final.  So again if you have any question on the finals thats the moment for you to ask if 551 any.  the again.  The the final is going to be project.  611 You can develop the project in team as some of you already communicated to me.  620 You can pick one on the 629 suggestions that they provided the on canvas.  You dont need to do one of those but its just for your convenience somehow.  632 ere 644 or possibly data that even question that you have and you want to take the opportunity or the final to do it feel free to do so.  657 Final will be pretty much similar to what you did in the last assignments.  706 the 716 keeping in mind that that is final meaning.  If for the assignments you do an interpretation of the results That is few page for the final it should be more.  substantial is not.  717 and 800 project is is not TV so its not dissertation meaning it is not something of 20 page or or 50 page.  734 but it should be something around 1015 page all included.  748 share with you the 755 structure that the final shouldnt have.  So again there are phases defining the business defining the what the the data set and analyzing the data set.  759 to be sure to bet it somehow to be sure that the the data set is able to address the the questions so that you play the in the first step.  814 then the the data preparation that is always critical face.  828 And then you have the data exploration in broad sense.  So we are.  You do all the 834 the visualization.  So you calculate the metrics and things like that.  844 and its where you actually will write the the narrative that will put together all those pieces in way that people can read it can understand and even if they may not be experts.  853 all about how to do things.  They may be expert or the domain but they may not be expert in writing code or or extracting magics 150 912 so 924 complexity.  926 The last assignments are up little bit longer so they are around the 100 lines.  So as was mentioning last time the number of lines is not necessarily 100 through indication of the complexity of the problem.  930 But its kind of difficult to have problem 951 and analyze the with the proper level of complexity with the 20 lines of code.  957 Yes on not all the lines are created in well but 20 lines so it would be not on enough probably not even 50 probably not not even 80.  So be sure that that you have script that you would use to extract the the the metrics creating the scripts the visualization.  So that is more or less or at least not shorter than the last assignments.  So something around mean from 100 50 and move.  So again the length of of the script is not through complete indication of the complexity.  But again it is difficult to to do complex analysis with just few lines of code.  Thats E.  C.  Generally speaking when you send emails to me at the she you because this way you double the possibilities to get an answer soon we will give you an answer.  But sometimes we are droning in emails and in particular when we are approaching at the end of the semester and your email may get lost.  So just to be sure add always she you in the email that you sent to me.  Okay.  So this class and the following one well be more on how to apply things.  So there is nothing more that really we need to explore either in the informatics part or in the pied on paths.  The main reason is because obviously we could go into more details with Python.  We didnt erez agmoni work with the quite lot of potentially useful libraries.  We didnt spend too much time in applying some techniques.  101.  One of the things is what we we want to reduce loops using operations with Madrid sees but that would be more on spending time in linear algebra and this is not the goal of this course.  At this point really think that you have all the elements in terms of pied on that and in terms of how to develop projects to use coding to create story and to extract the meanings from data set in the direction or questions that that you may have.  will spend little bit of time on using chat.  Gpt.  A.  Recently mean Chat Gpt is representative of the family of large language models ere so Chat gpt is one is not the only one its for sure.  The one who created the the the most of the hype that we have since the announcement or the availability of this tool.  That it was you know November but its not the only one.  There are some others that are coming.  Ive been working on those.  the relatively lot.  Ive been interviewed on how to use those bots for education and there is no answer because no no one knows.  But will share with you my opinion and will also share with you little bit of insights on how to get the most out of them.  So it is matter of fact that is there chat gpt like that so that will come.  Its definitely good to know what our the the potential uses on one side and the limitations that they have and also how to better use the the tool to get something done.  So we we will talk about that.  Its not something that that was scheduled because mean that we started the E.  M.  24 way before the so but mean this area is evolving continuously and dont want to give you the impression that we are not following relevant changes that are happening in the sector in the area having potential high impact in what you do.  So lets go down to what is more directly related to this courts and lets go first on the proposed solution for the current assignment.  So the assignment was basically on downloading elements from web page and do some processing.  and some mean some cleaning some processing and some visualization.  So again like always thats one of the medium possibilities for addressing this problem create.  imported all the libraries one of the libraries didnt use it.  dont know why didnt delete it but thats the way it is.  So.  As was mentioning last time it it its good way to proceed to create your own cleaning function for text.  So in this case again may not be the most effective.  But look at it as source of placeholder so you can change it you can make it yours.  You can customize but you want to have your own text cleaning function.  So in this case this function is taking string to process to clean the minimum length of all the words that we want to consider.  Assuming that that works that they are shorter than given number of characters so are not semantically relevant and then list of so forth.  So basically the function is transforming the string awards into list and then its looping into the list 250.  Its transforming in lower case.  Its checking if its Alpha medical or not 250 and then its checking.  If the length of the the word the its bigger than the threshold that we set and then checking if its in the so what not If all good will append that the word to the list of clean words.  and then we loop up to the end of the list and well return that or of the initial string and well return the the release of cleaning up in clean words.  So again you have an explanation here on what is in and what is out.  Then its about webpage.  So defined what did the what is the URL for the the web page Do they want to get Im getting the the content Im moving the content into like structure using beautiful soup.  Then initialize string that we hold the the words in the headline.  im.  Looping into the paragraphs Again If New York Times will change the label for paragraphs from to something else.  My code will not work anymore and those are the limitations or this one and simulates are the limitations for scraping content from website.  and appending the then that initializing the listed will contain the so forth reading the soap or file extending the so so far the the the so setting the minimum length.  filtering the words using the function that we saw before extracting the diagrams and getting the most the most common.  could be any number then creating at least of the most common filtering mean extending the the list of words so that had the after the cleaning with the those common diagrams transforming up the the list of awards into string because work cloud is taking string solely.  and then pretty much printing it and saving eventually as Png file.  Then analyze in the sentiment using butter.  positive negative and neutral printing it and the process running it.  So you have here your work Cloud.  You have the headlines.  mean.  Some more cleaning should be done.  and obviously is lot about.  Trump is real time and today its pretty much trump day.  like it or not.  and thats thats it.  Sentiment so again like in most of the cases new drama is the vast majority.  Its more on the negative side now so it it would be interesting to do it end of the day each day and see if and that is trend somehow.  Its negative.  anyway.  So that was the assignment that mean if you look at the length.  Yes there are quite lot of spaces.  There are lot of comments the length its 132 probably the real number would be more 100 even little bit less than that.  So just to have an idea thats kind of basic simple relatively simple but that that there is process in it that mean the the script the as pipeline.  So the cleaning the downloading the cleaning and then you have the different analysis.  All right.  So let me go here and let me go into the content.  so that that was the the assignment that we just so the possible solution they close this we do not need any more so the content will change little bit.  So we spoke about the machine learning little bit in the past.  want to fault you more on how to extract metrics from text and then well be talking about the the Ls.  So let me start with the and will definitely give quite some time for the the in class the assignment.  So let me start with the couple of how we extract numbers from text.  So one of the issues let me stop for second sharing this.  So one of the issues that we always have when we deal with text is that text is.  mean its text and there is no number.  mean not semantically relevant in the text or may not be how we get insights from the text in numerical way in way that we can just take decisions based on that.  So decisions it could be of any kind.  So we will solve this on examples that they did the in the past few years.  So one is on social media.  So when started my Phd.  The social media was kind of beginning to be relevant.  But there were not many metrics to measure the semantic the meaning in the messenger that was in the social media.  So my idea was we need to find way that is beyond the the the the the statistical analysis the number of weeds the number of bits per time interval or the number of tweets from someone at the number of retweets.  So those are loosely toppled with the semantic meaning.  Okay obviously you have more tweets from an individual that that individual is more relevant that someone like myself with not many of those.  but it it its really not great indication mean.  It is not in in the content itself but its more from like like looking from outside.  At that time they were not many solutions to go into the content and extracting meanings from the content.  and that was one.  After few years did a.  was asked to be the principal investigator that is the project manager the one doing the the the the designing the solution for the problem in large project for the the Department of Defense.  It was the million dollar and change project over and half years.  with the 20 between 20 and 25 people in the in in my team.  and the question was the how we can do better the planning the the the cycle of production or Webinars so that customer was the the Piccadilly at all.  So they plan new weapon.  So what in advance and typically the way to do it is using the capabilities meaning more powerful weapons and improving the effective mess all those weapons so the usability and the effectiveness.  But that was basically it.  There was nothing working more on now.  How they said now that events may have an impact on the cycle the life cycle and eventually the the planning of new weapons.  From now to mean the duration of the life cycle.  So we we we started thinking okay we need to work on a.  We need to analyze what our the technologies that are making an impact on the competitive scenario of the development.  And the so we fall used on papers pardons and use giving different stage somehow or the maturity all the technology.  and we for use the on.  mean obviously for the Department of Defense.  The for use was on countries.  and so the competitive scenario was with the competitors being countries in universities and in particular in graduate program.  So the vast majority meaning probably 85 or something around that are international students.  Those topics are are sensitive topics and they need the at least people lot.  mean national.  We have National is either city zen or green card holder.  We didnt have many of them so.  And then when you move to the real content the the real text that you want to analyze that you need the the security guidance.  So got my my security guidance.  But was the only one in the team with the because of that we switch the from the Via scenario to and sort of an ultimate reality.  So the alternate reality was about the security industry and we for use on the operators in the security industry publicly traded the companies working in the security industry.  So at that point you have all the information you want because they are publicly rated.  All the information are public because again they are publicly traded companies.  So and you have but because if they are publicly traded.  chances are they are relatively big.  You have quite an other news and there could be some pad and some papers that could affect the somehow.  Theyve strategies in terms of technologies that they were using Erez agmoni.  But the problem was still there.  So how you guessed competitive scenario meaning doing risk analysis.  Risk analysis is based on numbers 250.  So you need to have numbers to work on risk panel and work on what if analysis with the different scenarios that you can have in this type of competitive environment decisions that could be what is going to happen in the competitive scenario If invest more in one technology and less in another one.  What if totally dismiss one technology What if go all the way with another technology.  So all of those are elements that really need to have to evaluate.  So there there was missing link social media how you get so the metrics relevant mean the semantic metrics relevant to to understand whats going on in the social media and on the other end how you get the metrics that will allow you to work on management risk management or risk analysis in that the second case.  So let me go into the projects to explain little bit how we did it.  In both the cases was force to create my own.  Ill got it because in both the cases there was nothing that could help me at that point.  So social media.  Again will go relatively fast because really want to give you time for the in class exercise.  So so most of the analysis at that time but even now are based on either statistical analysis or sentiment analysis.  That is what it is.  So that idea was to extract meaning somehow from text.  Why this is social media at that time in particular.  Now dont know what its going to be with tweet or but we tweeted social media was what we call the back channel for real life event meaning wise people.  We are doing something in real life.  They share the comments via the social media.  still through not sure that the Tweed or is is still the number one social media for those things.  But still when you are experiencing something that can be an event or can be watching TV show or whatever or commenting political event.  Again you share your toes on that this channel.  So this channel is what is normally called back channel.  So the front channel is real life that things that are happening.  The back channel is is basically the social media giving you insights on what is happening.  We consider types of events events that are not evolving in time meaning.  You have one single event the presentation of new product or or movie or something like that.  and you want to get some meaningful keeper months indicators that that can give you sense on what was going on and then events evolving in time.  And you want to monitor how how things are going and eventually change what you are doing based on the feedback that you got.  So again we use you know Twitter with most of the social media.  You dont have real conversation probably the only social media.  mean that that there are very few that can really be.  consider conversational where conversation is You say something.  the other person is replying in certain way and there is back and forth.  So thats compensation.  There is no real conversation in most of the social media.  But when you have common ground so the event that that you are tweeting about the then there is sort of convergency around this common events so this having something in common its what is called the the common ground theory and its well documented in the the literature.  So the methodology that they use the was detecting the the event collecting the data.  use the combination of the search Api from twitter to python python for all the cleaning Mongodb for getting the data.  mean when you download the the tweets you get a.  Json file.  Json files are really easy to be handled by mongodb Mongod.  It be its non SQL or database.  and the structure of the mean since to be kind of all the but the the the the engine of Mongodb is based on Jason structure meaning.  If you have Jason you dump the Json into Mongodb thats optimizing the tool You have.  What some other things extract from one Would it be some particular characteristics And then those will go to Mysql database all the preprocessing when you have events that are happening in given period of time.  created it back.  Its all tweets just to compare the semantics for each period of time.  Then combined the metrics in sub events along this major again so that im monitoring and then create eventually classification model and then visualize evaluate the the capabilities of the model.  So the methodology was in in multiple stage.  So the first stage is obviously collecting as in the previous chart the data and then creating types of networks one that is the social network.  That is the easy one.  Notes are of the messages.  and notes are connected.  If one is citing another.  so doesnt need to be retweets.  But if you have the name of another user meaning another screen name then you have an edge from the notes.  and theres social and then created what is called the bipartite network.  That is so bypassed networks we are the the elements that are connected the are are these joint So the TV gala example is when you have dont know people activities.  So you have someone doing given activity.  The same activity can be done by multiple things.  So the same person can do multiple activities.  So looking from the outside.  That is network like all the other.  Inside the the sets are semantically this joint so you need to lay bowl up without the notes in one set and what that the notes on the other set.  But once you do that then when you connect them.  the network that you have is what is is called the bypass.  From the bipartite you can extract the its called one mode where there is no sets but it is just one.  You can have network all the people only network of words only whats or backgrounds.  who works are connected if used by the same person.  because we then go with the unique words the same word that can be used by multiple people like creating networks that that can be somehow complex like the example that you have on the top right and and is the other example.  Once you have this network this network as words or engrams only is W.  What is called semantic network.  Someone in some cases they call it knowledge graph it because you have all whats works in broad sense.  Again it could be single words or multiple words like diagram and gram in general.  Once you have that you can apply class setting.  Ill go it so and there are Ill go.  Its for clustering in graphs so the most popularly use the is the lobby and community the detection method and basically you have classes awards.  Those classes awards are potentially topics because those are worth so that are highly interconnected.  had the student validating the topics created in in this way and for using on the last topics the accuracy mean that he did it manually on that 5000 tweets and then compared the results with my script and the accuracy was close to 90.  So you have topics at that point.  If you analyze in time those topics you can see how the conversation is evolving in time.  So we applied the to quite lot of different events.  I.  share the scripts with people in many places around the world getting mean and validation of the results.  So this case mean consider that we are talking about.  few years ago collect it.  So this was 2015 but the concept is pretty much the same was the announcement of what at the time was the new apple watch.  collected the 700000 tweets.  There was quite wide less coverage for everything that was presented in each particular moment of the event.  So did the what presented before so created the the relational network then the semantic network.  then They do the preparation.  And then created the visualizations.  So instead of timeline with the time use the the single events meaning the introduction on the apple TV the iphone the new functions for Macbook and then finally the apple Watch.  So.  and then try to find way to connect those.  But this is not the the one that want to spend more time.  want to spend time right here.  So was mentioning that there are networks the relational network and the semantic network.  One of the metrics did they extract it from the graphs is the clustering coefficient.  The clustering coefficient is way to measure the homophily of the network in given time meaning how connected the are the notes So if you look at this spy.  Here you have high value for the clustering coefficient for both the relational and and the semantic networks.  That was the moment when they introduced the the new Macbook.  So W.  What is the interpretation The interpretation is a.  At that point.  People where talking about the the the same things.  So the new keyboard that that was total of failure but was the new keyboard the new the new monitor so few topics gathering collecting the attention of the the Macbook enthusias.  So it it was people gathering together and talking about few things.  This is when the the apple watch was introduced.  So you have relatively high clustering coefficient for the relational network meaning the people gathering together talking about something.  But the something it was all about the places because they didnt know the product.  So it was a.  Its good.  like it.  Its cool.  Not only knows how much its going to cost.  So things like that its more on the as more to.  We use the same approach to calculate or to evaluate the radicalization of groups of people.  So we measure the in time the clustering coefficient and the semantic mean the costing coefficient for both the semantic network and the relational network and we created the composite index that is kind of the summation.  They normalize the summation of the 2.  If you analyze in time when you see that there is growth on this composite index.  There is tendency to the radicalization because you have more people gathering together and talking about few things.  So thats radicalization.  We use that to analyze violence related to political elections in Kenya was few years ago.  Okay so this is an example.  dont want to spend too much time on that but just wanted to give you very briefly.  This was a.  On predicting so collected data about million tweets 22 movies over period of few months a.  And then wanted to predict the either one on those 3.  So the box office revenues 3D score audience score.  So we ended up not having much on both of the critics courts and the audience for little bit on on the audience core but definitely nothing with the critics score.  So we collected the let me go very fast.  This.  So we collected the all the data on the then we created some prediction modeling.  So in this case is decision 3.  But we also tried different models.  Then we put together all the models in one chat.  So we created that for categories of metrics metrics on the sentiment medics on the traffic that was not the number of tweets but number of tweets per time unit social meaning the clustering coefficient for the social and then some semantic medics.  So and we played with the combination of all of those.  So the very end.  One thing that is interesting that that sentiment is is not good predictor.  meaning using sentiment that you cannot really mean in this case was predicting the the box office revenues after week.  You cannot really predict the the box office revenues based on sentiment.  What people say is not what people do so but traffic social and semantic.  combination of those is definitely what it its more over an indicate or what people is going to do.  and then we applied to other cases.  dont want to spend too much time on that.  Thats another application we try to predict.  to calculate for the the emotion generated by artists.  mean the target was music.  So artists albums and songs using the Bluchnik emotional wheels.  So there are those major emotions.  shades and we try to analyze the proximity of all the the the the mean.  We can see that the comments that people left.  We had huge data set of comments the correlation somehow between comments and emotions because in this way you could eventually create sort of emotional DNA.  All the the artists songs and albums and then eventually see if there are correlation between the number of all booms number of songs sold and the emotional partners.  So there was another application.  We use the so we for use on fan of those 3.  Thats why we selected them.  and those are the numbers of the number of artists lyrics rooms and members on this on this website that is no more active.  So again.  in this case we use the natural language toolkit.  That was not great way to do things so natural language toolkit.  We mentioned that has whatnet where you have this taxonomy and you measure the distance between whats and we measure the distance between the emotions.  So the what to represent in the motions and the words in the comments like tools that you see here.  But the problem is word net is relatively old.  and comments are younger and the match was not good.  Do we revise it in that in different way and we didnt use natural language toolkit.  And think were definitely better.  Okay.  So let me jump up to the other project that was mentioning.  That is this 1010.  Not that was the internal lacking code for this project and again the project was about getting metrics out of text.  So let me skip all of it and let me go here.  So the main issue as was mentioning before was on the how to calculate the semantic matrix out of the text.  So thats why we created the this room theory.  So let me skip some of those and let me go here.  So room theory.  Its based on the framework theory that was created by Marvin Minsky in mid or seventies.  The example that that means he use the was a.  When you enter into room you know right away.  If is bedroom bathroom kitchen not because there is label saying path from kitchen or bedroom but because there are things in the room that its kind of resonate with classification that that meaning framework that you have in mind.  There was no computational component on it at that time.  A.  But like the idea of this framework approach.  added the a.  computational layer to it and named it the room theory using the example that Marvin Minsky was using.  So those rooms are representation of the knowledge of the individual or the specific knowledge of the individual entering the room or doing something on given domain.  use the at the time what to back is form of victorization.  It is one of the for not the first but one of the first of the new generation of victorization of text.  So you basically have an application of the Meta for of the so to what so are related.  If they up here somehow together.  What to back is calculating the conditional probability of one word the appealing because of the other is using shallow neural network for doing that we are.  Charlotte means one hidden layer.  So you have input.  Layer output layer and he delay it in this case is one in the layer.  So you have this conditional probability meaning that you start with the matrix.  That is and were in the unique words in the text that you are using by N.  And you have numbers.  Then you apply reduction in the dimension.  like principal component analysis.  then you have.  that is in by whatever it is the number of typically we use 200 or 300 meaning that each word or anram will become vector with the 200 or 300 components.  meaning the words in the text that will become points in dimensional space.  Now if you go down from dimensions to dimensions.  You have Cartesian space and you have points on the Cartesian space representing the words the more the words are closer.  the more they are logically related.  So thats basically what is behind the the vectorization then mean with the attention its all you need the they use the potential mechanism to do better that just the conditional probability awards.  And but the concept mean the result.  Its creating matrix representing the text in that no matter of terms.  So you have text transform into numbers.  And thats basically how the room theory would work.  So you have your room.  That is numerical representation of your knowledge base meaning.  You collect as many documents as as possible.  You victorize the documents and this is basically Madrid representing the knowledge on the specific domain.  Then you have words or engram so defining your your You are elements all the attention because mean you as an individual can do different things.  So with the same knowledge you can do multiple things if your fog is the dont know in the financial aspects your fog is will will be on.  think so.  The that are on the financial side.  If you are in project management you are more on those words.  So the the the benchmarks are our collections of of keywords and eventually wait the all the different keywords.  Then you have document that you want to analyze.  You scan at the document what by word And you calculate the proximity all the words with the the the words in the benchmark doing look up getting the vectors from the the madrics.  That is the room and then the the result will be the the distance between the document and each one of the benchmarks.  So in symbolic terms you basically have your corpus that many documents representing the knowledge that that will be victorized.  Then you have elements that you have the keywords in the benchmark and you have the the document that you want to analyze.  So what you do is basically what By what That you take one word from the text to evaluate one word from the benchmark and you calculate the distance that most simple example of calculating the distance is the cosine similarity.  So you calculate the proximity that is number and this will tell you how much each word is far from each one of the benchmarks.  and then you add all of them.  You normalize the the results and you have the similarity between the document and the and and the in each benchmark and the cumulative value for all the benchmarks.  meaning that at this point can tell that one document is more on given technology or another technology.  So meaning at this point im really getting the values.  So that was the way we use the for all of this.  Then we created the a.  A.  process pipeline.  So you have gathering the data meaning You have news patents papers doing little bit of preparation going into Mongodb.  creating the rooms or or just analyzing it.  And then the results meaning the the actual metrics will go in in relational database we use.  but it could be Mysql or or any other and those will go with the use the by the systems this panel and then another system for monitoring technologies.  We will go back to the applications.  But the goal for today is just on how to extract metrics from text.  So would stop here and will go back to examples.  So next week.  But just want to jump now into chat Gpt.  Im.  Using slides that presented.  Here we go.  that presented the to workshop that they gave weeks ago so large language models.  So we mentioned chat gpt that is Gpt based on transform thats so the transform that again are sort of the next generation to what To back ere this is an essential step.  You cannot really do much if you do not do the transformation.  But anyway so erez agmoni mentioned also the fact that what to back was shallow neural network meaning you have one hidden layer one when you work with neural network.  So and you already know that you have parameters meaning weights that you give to each one of the inputs.  So those weights are are normally called parameters.  So when you see those numbers.  Gp as 175 billiona parameter so those are the weights in the the network.  That is an indication of how complex is the model.  So we are going into several billionparameters.  So Bertha that was one on the first using transform.  That was 340 millionNow we have more than the same number in billions.  So when you train those models like Chat Gpt the training Its really an intensive process and an intense mean very time consuming resource consuming process.  There are few months in the loop for cleaning the data meaning eliminating all the in appropriate content but also to start the tagging.  So we will go back eventually on that.  How J.  Gt.  Was trained if you look at the number.  So at the bottom on the page 4. 6 million.  It was the cost to train the the board.  the energy that was used because mean its lot of computing time.  They use the quite lot of N.  Media Gpu Graphical processing units a.  A.  And they use lot of energy.  So the amount of energy is enough to power more than 30000 American households for day.  So thats how mean that energy intensive is the training keeping in mind.  The human mind is using fraction of fraction of that much energy for the entire life.  meaning that those systems are highly inefficient.  So we are applying brute force to an algorithm that most likely its not really representing the way we reason.  So those are the sources.  So there are an estimated 45 data bytes of text Thats the distribution.  So if you look at the distribution you have quite lot of English and thats an intrinsic buyer so that you have in Chat G.  Gpt.  Meaning that other languages are are under represented.  then that Yes the web is pretty much in English but that doesnt mean that that you dont have good representation of the other languages.  How we evaluate the how they its very difficult to say so in the 2016.  This lambda the data set.  That was use the as benchmark for task oriented the language understanding so based on that.  mean they are pretty good compared to humans.  It its just one of the ways to measure it.  When you see short few short the shot models with no training data for that particular task.  few short meaning.  You have some examples.  So short and not very effective limitations.  We we really need to understand how they work.  So they work as matching patterns.  So you have the training generating with the some human intervention and then you have your quidy.  and what the is doing is matching the the pattern in your query with the pattern so that he does.  and then once it does the match is adding presentation conversational layer.  To present the results.  The more data you provide in terms of you are quitting.  the more reach would be the answer because there will be more elements to match.  So thats key point.  So first of all.  those so far are pretty much the same as Google with the difference that you have compilation or or the answers and presentation of the results in plane English or plane whatever is the language that you are using.  and thats valuable.  But you are losing the reference to the sorts.  meaning that if you are using chat gpt or another Llm.  Or something that that we go public.  There are chances that someone can sue you for a.  because you dont know what the source is going to be.  so will show you in moment the the way im using it.  So again.  It is not intelligence but is nicer way to do what Google was doing since more than decade.  But its great.  mean you have plain English interface.  im starting project on having projects.  But before go that let me go in another element that is relevant in in terms of limitation or or and they are not domain specific meaning considering how they had been.  Train the and those are the sources you you cannot have specific knowledge in one particular area.  If you are in the defense industry.  mean that.  apart from the fact that some of the material is restricted and for sure it is not public domain but even in the in the public domain that are several elements that are that could be potentially relevant if you want to do something in the defense industry.  But in this case those elements there will be drop in the ocean.  meaning the answer so that you will get that will be highly deluded and you will not get the the knowledge from one specific domain.  So we we are working on projects one to create an for the school of systems and enterprises and will start using 24 as an example.  the and well be sort of Tudor out automatic tube or for 624 and will use the the transcripts of my classes along with the articles papers and textbooks.  and then eventually will expand the to other courses.  will initially focus on of the most popular courses that are 24 and 12 but it is project management the second thing that then doing second project is to use the the presentation.  Uhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh so its like the next up blow instead of having visualization.  So have plain English.  Think about the the defense industry.  You have people on the field and they need to take decisions.  They input the the values from the environment and they have scenarios.  But yes its scenario.  But at this point you have more either numbers or graphs.  It would be great to have something in plain English.  So once you have the conversational element that transform me the conversational element from written text to oral text with the an automatic reader they can read.  It is no brain.  And mean that technology is there since 10 years.  So thats something im working on.  mentioned the mixed approach very briefly.  So just want to go here for moment.  Yeah.  we are going apparently to what the sort of so on one side the you have what is called the the prompt the engineering again pattern matcher.  the better is your query.  The more detailed the more patents you are providing and the better output you are going to get.  There are jobs for prompt engineers.  So people knowing how those lms are working and on the other end the experts of the domain able to provide those input its basically like being super.  User so thats type of skill that is not deep into the technology but more on the use of the technology.  And then you have on the opposite side what call the the cognitive engineering where you have those who will develop the next generation of of large language models.  mean that the way they work now is is not efficient and its going to be changed.  So that is no representation of the knowledge that is essential if you really want to do something that with an intelligent behavior.  But we dont know how to do it.  So this discipline that will be at the crossroad between math the cognitive science software engineering coding the abstract thinking is what will generate jobs not many because it would be very challenging but very critical jobs.  So briefly.  thats the way im using chat Gpt so for your information.  im writing book that is called that mean the name is still to be fully defined.  Societal impacts of artificial intelligence and machine learning.  So th the idea is how artificial intelligence machine learning is is used right now and what the impact could be to the society.  So the first question was is this revolution So what is revolution How you measure revolution.  So in that the the history of humankind that we had several social revolution including the Industrial Revolution or the Dj.  The the Revolution are those potentially the same impact that could the AI machine learning revolution be.  So had to create somehow little bit of background.  So use the as writing body Chat.  Gpt.  created the chats.  So each chapter is plenty of information.  Each one is giving pattern to match.  So when place question over here over over here.  will get different answers from another one.  So thats the user that encourage you to do so.  If you and place query that is straightforward.  you will get an answer.  That would be not much better that what you could get from Google.  But if you have something that is more complex you will have answers that will be more complex.  So keep in mind that.  and get no problem.  If you use just gpt as sort of in your development.  Dont do copy and paste because you are doing your itself not favor.  When you will get job mean down the road.  The those boss will be so powerful that everybody and and so widespread that everybody will using it.  But if you use them now lets say for coding.  keeping in mind that the chat G.  G.  Gpt was in the on github because Microsoft invested 10 billiondollars in open AI and Microsoft is also your own of Github.  meaning all the code that is in Github but somehow was used to train chat.  G.  If you use it for coding the you may or may not get good piece of code.  how you decide that if its good or if its bad.  you basically dont unless you know how to code.  So im introducing chat Gpt now and not at the beginning of the course because if you use it now now you can even using it for coding.  But you know what is right and what is wrong.  So also keep in mind that we will apply the same concept.  The the assignments are individual.  If any of you will do the same assignment in terms of coding.  Each one will get the the to dollar divided by N.  Whatever is the tool that you are using.  If you are just using someone else or if you are using chat for it.  there is no way to detect as today to detect if an output is generated by you man or from boat.  So but again use it at this point.  Use it to do better what you are doing.  Okay.  So again.  There is not much time for its min to and erez agmoni there is not much time for the inclass exercise.  But want to introduce the the exercise and give you little bit over 150 sense of whats going on and then will give you few minutes just to again familiar with it.  So the the data set is one of the data sets and downloaded the from tweed.  So in particular its 20000 rows mean.  Tweets are more complex.  But what keep in the data set is sender timestamp and tax.  and this is what you have here.  So you have the sender.  This is timestamp but that is using what is called the epoch time.  That is mean some node that created few years ago.  That is number of seconds from the first introduction of unix.  But mean there are functions so to transform that number into real time.  and then you have in the text.  So you have rt for retweet.  You have the app for mentioning.  and so on.  So you want to print the most active sender the 10 most retweeted the tweets the most sided the screen name and the 10 most popular hashtags so retweets Again you cannot recognize them because there is Rt.  The screen name.  Its in the text is with the at sign.  and the hashtag as the like over here and there are few others here and there.  Okay.  So dont even create the the breakout rooms.  So because its 56.  So at this point just want to be sure that you have everything published.  So be sure that you have what you need.  Yeah you should have everything.  But will post the solution for this inclass assignment in moment.  So we definitely dont have time for working on it my apologies.  but hope it was useful.  So let me go into the next exercise.  That will be Exercise Number 11.  So thats basically what you have when you click on it and instead of having like that that you will have it as file.  So the file there is spring 23 wn dot Docs is is this one.  So created that this assignment today.  So if you see that there is something that it is not clear.  Let me know because may have skip something that that could be useful to you.  So one of the considerations that some of the students in past semesters had on this course was Why Dont we have more assignments that are more on how to use what what we did for managing situations so.  And thats why created the this part.  One of the things that was managing in the past few years was the scheduler courses.  So scheduling courts is in university is not an easy task.  Because you have students.  You have courses you have instructors.  and you have classrooms.  So you need to match all those components in way that you are serving the students and the best way possible.  But you are using your faculty in the proper way 150 meaning that each faculty as teaching load and you want to be sure that they fulfill that they load the they load.  So in the proper way.  A.  You need to be sure that the classrooms will be not too big so there are many moving paths.  As you know its even so.  We have platform that is used for managing the the community somehow that is called Work Day with what they we can extract the the list of courses.  and the list would look pretty much similar to this one.  So you have what is the academic units the section and bunch of other information.  distract or name or name sir.  did they anonymized so instead of the name you have numbers so its.  Tractors are those numbers.  and then that the credit our what for each one and and and then you have some other information that they added.  actually just to be very open.  So the the actual file that we download the from what they is with all the courses from all the schools.  So basically had to do little bit of homework to cleaning it.  To do this cleaning what did that was creating configuration file.  That is this where have the name of the file.  Then have the list of names over companies.  We serve.  What is the semester programs.  and then sort of widely some black lease our courses that they want to keep or eliminate.  And then the threshold for we consider as accountable courses with more than students.  So using those criteria created this script to extract from everything then what they is providing this script.  That is reduced version.  And it also added the level and program.  while im doing the calculation.  So thats the data set that that you will use on this data set.  Those are its 94 rose.  This is related to to last year spring 2022.  So those are the the the the the rules the the columns that you have meaning they attributes.  And you want to.  The overall goal is to get sense of how things are going in that semester eventually creating dashboard to make sure that we are monitoring whats going on and those are some of the elements that could that give an indication printer the courses with the highest number of students.  So the number of students is in this column here named.  The enrollment count.  Bring the instructors from this column.  Here instructors teaching assistant with the highest number of students.  Again students are from enrollment count.  Compare the total number of or students for undergraduate graduate and corporate meaning that the corporate education you will get that from level.  So level is standing.  Ug undergraduate Graduate Corp Corporation.  You will skip the mixed ones.  Comparing that means calculate the values so and describe the results in narrative in in the narrative path of the assignment.  Compare the number of courses that run at full capacity.  So you have this that is section status that will tell if its open or close the so if its closed meaning they are at capacity open their top.  create pie chat with the distribution of students supper program pie sh with the distribution of students per type of delivery.  You have a.  You have this.  this delivery mode in person or online.  and perform any other analysis that could make sense to better monitor the the semester.  So you would read the file.  You do the analysis.  You will submit the the script and the interpretation of the So again they need to be original not describing the the process but describing the the findings.  So what we are doing now is basically to use the script to get insights and eventually to take actions.  So you have programs that are too small.  You have classes that are too big.  You have some instructors that are overloaded things like that.  So all of those will give you somehow data points to take decisions all right.  Its 805.  Thats pretty much the end of the class Questions.  Hey Professor Its me again.  Yeah Can you Did you see my email regarding the quiz for module 10 think there are some issues or issues with question and 6.  It was marked wrong.  But think its right question.  10 Quiz 10.  Yeah.  Okay will check it definitely.  Check it.  Thank you for us sir.  Yeah.  When when when you send that email its again add the she you as well just to be sure that you double your chances.  The the data set is quite guess youre reviewed and approved right though the one sent you regarding the the airplane.  Okay.  And for the what do you call it Analysis Is it performed as group Or do we have to submit our in the visual analysis like what is your expectation of of that portion Well when you do group project.  There is no need to to do things different.  You want to do one single report one single script that will contain the contribution of everybody keeping in mind that that if you have more people the an at least it should be more complex.  because otherwise couldnt really compare something that was generated by people with something that was generated by one.  and and the expectation for the graphs like how many is too little or whats your expectation for that.  Well graphs are just one indication of the complexity.  So sometimes it could be metrics.  So you you saw the presentation the the the the for the tweets A.  mean if you consider the the clustering coefficient is number.  But getting there it took me several 100 of lines of code.  Okay good.  And thats complex city.  So for use Mmm more on the complexity of discrete than the complexity of the All Research.  In broad sense.  Then the number of either tables or okay.  Thank you Professor.  Sure other questions.  Scott Guetens Alright just yeah real quick.  just wanted to reiterate what Kevin said.  also had an issue with and 6.  So Im yeah have it.  Yeah yeah im sorry if didnt do much again.  We are.  But yeah no worries.  didnt even email but figured would just mention it because he had also Scott Guetens same time.  Thank you.  Sure other questions tissues.  Okay.  So its or 9.  Thats the end of the class.  hope you enjoyed the at least the part on that chat Gpt and hope that could be useful again in the future.  We will use those tools more and more.  Epola is thinking about replacing with the so we will have sort of personal assistance that would be hopefully more smart than studio or or Alexa so or whatever my likes just started.  Professor Why are your thoughts on on Chat Gbt and the future of jobs Do you think it will always be always remain as supplement or tool for developers or do you think it will replace people in the future Its great question no one as real answer.  But there are some indications.  So mean if you look at the history A.  When you have new tool you have some jobs that will go away typically are the jobs that are more repetitive jobs that are more easy to Peter Blaze.  and thats what is going to happen with the chat.  So you need to add value.  So companies will pay you for adding value If you have something that is already providing value you cannot just use it and pass the through.  So you need to do better.  and thats why for example presented you how im using it so by productivity.  In writing the book improved for coding would be the same so you can use chat gpt just to save the time that you would use the on stack overflow.  But we not replace you when you have problem that is really complex.  mean right now we also have the limitation that the chat gpt is not taking fines meaning that if you want to do processing of fine not like the one in the current assignment.  You cannot pass the file and have it process.  but you can have some help.  So you want to use that to do things better if you think for You probably saw the movie.  dont remember the name but the movie on NASA with the human calculators.  So an army of people doing manually the calculations for the satellites.  Then they introduced the computers and their job was gone.  But the job of coding started.  So once we will have Lms that that that that could be more powerful.  that will have an impact so we need to be ready to move up to be more expert of the domain if you want to go in the prompt engineering side more expert on how to improve the the quality of those things.  One of the things that we are working on is on that using those tools to provide the the call.  More knowledge representing common knowledge is pain in the neck because we dont really know what it is.  So we know things because just we know it.  how you represent it.  So one of the ideas is to use those tools based on such large data set to provide the common knowledge and then use the common knowledge coupled with the domain that specific knowledge that we create.  So you have layer that is more complex.  Another thing that that we are working on is to use those Lms as sort of dispatcher for specific knowledge so it is said over getting the results.  They will tell us what is the the island of knowledge that we want to activate Then they dial and could be another model based on something similar to an Lm.  Or something similar to my room theory and you will get the answer from that.  So again that those are the examples on how to build on top of it.  But there will be an impact so lower level jobs will go.  But that is what happened in the Industrial revolution.  So who is using the faxes anymore So people manufacturing taxes they are gone.  Who is using the the analog photo with all the chain or products that are related to that.  Think about digital music and streaming.  So we have less movies less here that we have less Cds or similar things.  So thats the way it is.  That would be an impact for sure.  And we need to be prepared.  We need to know how to use them.  Is this an answer Kevin.  Yeah Absolutely.  Thank you for us sir.  And and also read that its it.  Its really bad math.  Is there reason why heard it cant do calculations correctly.  like simple.  Well mean that is domain chat.  Gpt is not good in any domain but its good in all domains and like.  Okay.  And theres the reason mean if you ask questions on the the defense industry if you ask questions on something that is not genetic.  You will not get much because mean if you remember the sources that is being used by chat gpt.  They are very generic sources that could be good to represent the common knowledge the there are some paypal.  So on a.  mean.  what is the common knowledge So the common knowledge is what we have in our mind because we are using more and more digit.  We could assume that then everything that is available line now is the equivalent of the common knowledge.  Theres an assumption.  Now.  There are papers saying that is what is available as open source this formation or everything.  Assuming that this could be possible to do on the summation of everything that is available as an open source.  Is there presentation of the common knowledge of people we dont know for sure because we dont know we can really quantify what what is available and we can not quantify the common knowledge.  Common knowledge is very depending on the culture and and your specific culture meaning is really difficult.  But we can assume that what is available in terms of common knowledge is what is available as common knowledge to to an average.  So for those things.  those tools are good and will be even better.  So we have a.  A.  Gpt.  For our chat.  G.  Gpt.  Is based on Gtt.  Too.  By the way keep in mind that the chat gpt is based on data that that stops at 2021 meaning whatever it is after 2021 is not there meaning If you are asking dont know something that is happening that happened after that.  Its not like Google.  It is pretty much real time but its bad because of the training its.  dont know how many millions but its not something that you do on regular basis into one week.  so its batch process.  Thats another challenge.  So we need to move.  We need to have way to have more real time.  Human mind.  Its real time.  We learn every moment that every every sale on the from whatever we do and what we learn now will increase our our our knowledge.  This is not the way those tools are working.  Anyway it it it its very large topic and would be happy to address other questions You may have down the road.  That that will be all.  Thank you.  All right.  Okay.  So thank you.  All.  Sorry for keeping you till 20 and hope address your questions.  Feel free to send us an email life to anything else.  fis STEVENS lw INSTITUTE of TECHNOLOGY Excel Python for data understanding cleaning and transforming At clipizzistevens. edu SSE Introduction Excel for Data Science Excel is still one of the most popular tools in Data Science It will not cover the variety of needs Data Scientist has but when the dataset has limited size it still plays an essential role Widely used tool for data analysis and cleaning Easy to do work the data while visualizing it STEVENS INSTITUTE of TECHNOLOGY Pivot Table Excel for data organization Lets say you want to know the average actual profit by category and by calories Select all the data in the worksheet Basketball Game Sales and click on Pivot Table and create it on new worksheet On Windows the Pivot Table is on the Data menu and on MacOSX it is on the Insert menu STEVENS INSTITUTE of TECHNOLOGY Python for Data Preprocessing There are several Python libraries for Data Preprocessing including Pandas. profiling Dataprep. eda Sweetviz Python for Data Preprocessing Type inference detect the types of columns in dataframe Essentials tyoe unique values missing values Quantile statistics like minimum value Q1 median Q3 maximum range interquartile range Descriptive statistics including mean mode standard deviation sum median absolute deviation coefficient of variation kurtosis skewness Most frequent values Histogram Correlations using Spearman Pearson and Kendall matrices Missing values matrix count heatmap and dendrogram of missing values Text analysis learn about categories Uppercase Space scripts Latin Cyrillic and blocks ASCII of text data File and Image analysis extract file sizes creation dates and dimensions and scan for truncated images or those containing EXIF information SS LULU STEVENS INSTITUTE of TECHNOLOGY ft STEVENS lw INSTITUTE of TECHNOLOGY iy Test Driven Development meme clipizzistevens. edu SSE Testing code Software testing is an investigation conducted to provide stakeholders with information about the quality of the product or service under test.  Software testing can also provide an objective independent view of the software to allow the business to appreciate and understand the risks of software implementation Wikipedia Unit testing is software testing method by which individual units of source code sets of one or More computer program modules together with associated control data usage procedures and operating procedures are tested to determine whether they are fit for use Wikipedia STEVENS INSTITUTE of TECHNOLOGY What is TDD le Dont write production code without first defining unit test Dont write more code than Is sufficient to pass the test When writing code you need to address the following What do need to create to meet the requirements How can test that it does it Whats the smallest thing can code to satisfy this test STEVENS INSTITUTE of TECHNOLOGY Retrofitting Take existing code and change it so that it is more efficient Dont actually change the output of the code just how It works May incorporate significant changes STEVENS INSTITUTE of TECHNOLOGY Why use TDD TDD makes you produce 100 testable code You wont spend long time with nonrunning code Your code will better meet the design specifications STEVENS INSTITUTE of TECHNOLOGY Using TDD IN principle it is just about writing the test before the program But in consequence it leads the developer to first think about how to use the component why do we need the component whats it for and only then about how to implement So Its testing technique as well as design technique It results into components that are easy to test easy fo enhance and adapt STEVENS INSTITUTE of TECHNOLOGY Sh STEVENS le INSTITUTE of FESHN OL bey aoe GREENCNNECT Financing Sustainable Future Siemens Challenge for Researchers November 2021 Project Team Dr.  George Korfiatis Dr.  Dr.  Mohammad Ilbeigi Ms.  Azita Morteza Mr.  Hojat Behrooz The GREENCONNECT Idea Rational The transformation to circular economy The need for sustainable project financing AI and ML science is leapfrogging PROBLEM SIEMENS FINANCIAL SERVICES PROCESS FOR ACQUIRING NEW PROJECTS IS MANUAL The GREENCONNECT Platform Will SOLUTION SMART AND FLEXIBLE DIGITAL PLATFORM BO The GREENCONNECT Architecture We collect corpus representing the knowledge of the industry and Siemens view We transform the knowledge base into matrix of vectors representing the words called the Room We collect keywords with assigned weights defining Siemens points of interest the Benchmark We collect projects and GSF opportunities from crawling the web We filter projectsGSF using the Benchmarks looking up the words from the Room We match the filtered projectsGSF documents by looking up their words from the Room and calculating the cumulative similarity We perform analytics and visualize the results TUTE of TECHNOLOGY The GREENCONNECT he Proof of Concept Architecture The Room is limited to corpus we collected from the web on sustainability 450 documents The set of Benchmarks is first draft shared with Siemens 300 benchmark wordsphrases We process only project related documents thats we manually collected from the web 11 documents We match the projects using our algorithms via the available Room We use basic graphic visualizations Projects The GREENCONNECT Project Team Professor George Korfiatis with expertise in environmental engineering sustainability and research project management Professor with expertise in advanced modeling techniques of complex enterprise systems Professor Mohammad Ilbeigi with expertise in analyzing sustainability and resiliency in urban infrastructure systems Graduate Research Assistant Azita Morteza with expertise in sustainable development Graduate Research Assistant Hojat Behrooz with expertise in Machine learning and computer programming STEVENS INSTITUTE of TECHNOLOGY 10 Thank You STEVENS INSTITUTE of TECHNOLOGY We appreciate the opportunity to participate in this challenge and we are looking forward to long term relationship with Siemens Hello.  Hello everybody.  It is 630 and few seconds.  436 Just to give other people some more time is just few of us.  447 So the Class is not particularly dense meaning that hopefully we will have more time for the inclass assignment and think we can start that.  500 So the recording is already ongoing.  Welcome everybody.  518 Its 631 up.  524 And let me start as usual with what is going to happen.  527 So this is the live session that we have.  538 We will discuss the homework.  542 We will review little bit all the elements of machine learning.  545 Its some of the basic algorithms for machine learning between machine learning and data science and knowledge discovery.  554 And then we will do an exercise and classics of science.  608 will introduce the midterm and that will be pretty much the end of the day.  615 So the previous assignment was not the midterm.  625 The previous assignment was about to see if they have.  632 Its your.  As far as well.  636 Okay.  So the previous assignment that was on you but as far back as two parts.  644 So the first part that was question sir we will not discuss that.  654 The second part was on coding and was about working on COVID comorbidities.  659 And the idea was basically to account.  709 mean the file had the cases in each case with the comorbidity and the class of the comorbidity the age group and the number of deaths.  713 And few other information.  So we focus on the comorbidity the age group and mean the number of casualties.  730 So we counted the people per class age.  744 Then we have bar chart with class age where the axis will be the class age and the the number of deaths.  749 Then we have the we have pie chart with the same data and this will show the distribution of deaths per our age group.  800 And then we will bring the comorbidity with the highest number of COVID 19 deaths for the population of less than over 35 years of age.  814 So let me go into the code.  The code is relatively straightforward.  824 So you have the library the CSP file to open to open the file and then you have my block LIBOR for plotting and the new PI for some calculation.  833 So the assignment was asking to create function that will be named get index and 849 the input that will be the dataset or the rule under the all data set and the rule.  903 So this function will return the the dataset the index meaning zero.  912 If its zero 24 one.  928 If is 23 34.  932 And so on.  And if none of them meaning blank said the default value to 1000 could be zero could not be zero could be nine.  935 It could be in any other number but just number that is not between zero and seven.  949 So thats the function.  Then the counter and created counter that will contain.  mean little counter to each one is counter for the specific age group.  So where the first one would be zero 24 and the last one would be 85 and plus.  Then.  created blank dictionary that will contain the condition and the number and then account for the maximum number of deaths.  The nephews professor Yeah.  Did you please share your screen if you dont mind like you did for the last homework Absolutely.  Im so sorry.  was supposed to do it.  Yeah no problem.  Yep.  Yeah.  All right.  So my apologies.  So lets go back very quickly.  So sorry about that.  Okay.  So the.  The goal of the assignment was to create again two visualizations.  One that is an is bar chart the mighty be because can believe that they didnt remember who shared the screen by my apologies.  So bachata with the classes of age and the number of casualties and then the distribution.  So going back again here.  So we have the library that we want to import as of this year for reading the file to plot libor to visualizer and non pi that will use for some calculation.  Reading the file and placing the FILA into data that is list of elements.  Then created this function get index that basically based on the value in the the age category the age group is adding it returning zero up to seven where zero will be the category is zero 24 seven.  The category is more than 85.  Then initialize the list of counters where each counter will contain the counter for the specific age group.  initialize dictionary that will contain condition and number of that.  Initialize the counter for the maximum number of deaths and the name will host the name of the comorbidity with the highest number of deaths.  So then Im looping into the list and getting lets say the first one.  call the gate the index passing the road that Im reading to.  And then.  will get the index if the index is 1000.  That means that is blinker or is not one of the categories.  And will pass.  Also will extract the number of deaths.  And then accumulate the number of deaths in the proper index.  So basically adding over year whatever is the.  Appropriate to her age category.  So lets say that from this line 61 get zero a.  The counter in position zero will be increased by the number over thats.  So the first one that is the age category in zero 24 is what would be added.  And whats.  And as for this one then calculate the condition with more deaths.  So extracted the condition then that if the condition that is is in the is already in the counter the dictionary.  Then adding the number of that.  That they could have used the probably thats thats fine its the same value then that if the condition is greater equal than the max thats an initially we would not because well see it then will replace it.  Uh otherwise Im not going to do anything.  And then if its not in the dictionary then will add that key.  And body is pretty much the same that we did in in class assignment and was also in one of the slides.  So then will print the accounts of conditions.  Sales by age groups.  Print in the condition with more COVID deaths.  Creating the charts.  And then uh.  mean the legend that took me little bit more time because my clock LIBOR is making it little bit more complicated.  In particular if you want to avoid overlaps.  So but anyway citing where took the this piece of code then they strongly encourage you to do something similar when you use sources that are external.  And then they plotted.  So if run it.  So thats the account that by age the condition with more common deaths injuries is respiratory disease with that much and those are the charts.  So thats basically it for the.  Exercise.  Stop shedding for second.  Check if you have any questions.  Before we move on.  All right Professor Yes sure.  just had quick question.  must have misinterpreted some of the instructions on the line.  So ended up actually counting the number of deaths per age group per comorbidity.  So ended up making it harder on myself.  Yeah then then did come back and get like total deaths and then less than 35.  Theres not going to be penalty for doing more work is there No.  There is no reward but no pain out there.  Okay.  Thats right.  just want to make sure must have been tired reading the instructions somewhere along the line and thought it said needed it per comorbidity.  Yeah.  will make sure that she knew.  We will just do that.  That meaning not interpreting exactly what my what the what was asked the and matching the results and saying that is not match and meaning it is not good but in reality you need more work.  So dont worry about.  All right.  Thank you.  Yep.  All right.  Okay.  So lets move on.  Let me share the screen again.  Again pretty much each assignment is little bit more complex than the previous one.  So thats basically the spirit the know no is not going to be major jump in the next one.  That is the meter.  But the meter is pretty straightforward.  The only thing that you need to be aware of is making sure that you will allocate the proper time because there is nothing complicated.  But there are several parts and you will need some time.  mean will go back to the midterms in bit.  Okay so machine learning we mentioned last time that be sure that we are.  The right thing.  Yeah.  So.  We mentioned that at the very end the machines do not really learn in the proper way.  So Im writing several things on the machine learning next week.  That is spring break but there is unfortunately no spring break for you.  Not for me but the.  And we will have conference here in Hoboken organized by students by the School of Systems and Enterprises and these on software engineering.  And will present paper on natural language processing.  It will be actually workshop that they will give on natural language processing.  And will talk about machine learning in general following the big coverage that we have for Chad.  That is piece of machine learning in the real world by all natural language processing.  Bottom line again machines do not learn.  There is no artificial intelligence because there is no intelligence in the systems that we create or so it appears.  And so including the fact that we dont know what intelligence is.  So this is something that we already said that.  One thing that is really essential in the way we do things in.  Data science in broad sense including machine learning is the type of learning that you can provide to assist them.  So there are basically two types.  One that is supervised and one that is unsupervised.  So the supervised the that means you have previous cases are the same event that you want to predict or classify and you use the experience meaning the patterns from the past the occurrences of the event to either classify or forecast the future.  So thats supervised learning.  An example could be the weather.  know the weather in the past number number of years and use that to predict the weather for tomorrow.  Thats not going to work well but thats the overall idea.  Thats supervised learning.  Unsupervised learning is when do not have in the history of the occurrence of the event that am having to predict or classify.  Thats the case when want to just cluster her my clients.  And so want to launch new product and want to be sure that or want to launch certain number of new products or different flavor of the same product.  And want to sell the product or propose the product to the group that is kind of more similar to the potential target for the products that they have.  In that case all you do is to partition the data set in that subset.  So that will be as much homogeneous as possible inside the each of the subsets and as much different as possible one from the other.  So supervised learning unsupervised learning is something that is sort of in between is reinforcement learning.  Reinforcement learning either when you do not have supervision meaning information about the past but you have at its core that you want to maximize and still think about the game.  So you want to reach the highest number of points possible so you start playing and you want to maximize that value.  So in this case.  You keep playing till you will get the high value of the score.  The cases of failure meaning the cases where you reach the very low score will be the supervision.  The information about the past that you didnt have to begin with.  So reinforcement learning at the very end is self generated sort of supervised learning.  So the two main categories are unsupervised or unsupervised where reinforcement learning is sort of self supervised learning but is at the very end form of unsupervised.  When you have supervised learning you need to have samples that you want to learn from.  So you have your initial dataset with all the cases.  The weather for the past.  And.  Then you split the dataset into two portions.  One that you will use for training and one that you will use for testing.  So the largest of the two is the one for training.  This model for testing typically is 70 30 80 20 something like that.  So you use the 70 to create the model.  Once you have the model using the proper algorithms you test the model using the remaining 30 or 20 of the dataset and you measure the accuracy.  Models are combination of two elements that the data and the algorithm are good.  Algorithms with no data means not great models and vice versa.  Meaning if you have good data either no algorithms or inappropriate algorithms the model will not do much.  As an example Chad GP is using an unbelievable amount of data so the algorithms are pretty much standard.  They are open source.  But the data is what is making difference.  So the quality of the result of the jeopardy in this case is high because the data is so big.  Then you have the problem of the training model.  That will take quite long time.  So we will talk later on about that.  mean obviously the largest the larger the training dataset is the more complex of the algorithm.  So the more resources you will need for training.  And then the resources that you need for training are pretty much just once in while.  You do not you dont retrain your model that frequently.  So those models are pretty much in tend to be operating in better way.  So they are not operating in real time.  So you have the dataset.  My GP is working on data out to 2021.  So if you ask Chad GP for something that is happening from 2022 to today you will not get any answer because it has no data on that.  But is massive amount of data relatively complex how good it is So the combination of the two making the training phase we need resource intensive.  When you use this training set the you and then you have the mobile load lets say with good accuracy.  So the accuracy is the number of correct classifications divided by the total number of cases.  When you have your model that is performing well and then you apply the model to whatever is your target.  So you want to predict the weather today.  So you need to be sure that the training.  mean the dataset that you used to create the model meaning to train and tested the model is the same or is similar to the data set to the addiction that you want to do.  So if you have the data for winter and you want to predict the weather in day in summer most likely is not going to work well because you dont have that in that conditions.  So the way you select the dataset to create the model that its really important then the way you split between the training and the testing is also important.  So if you have dataset with the sales of apparel during the year and you have the training and youre split dont know summer and spring.  And then the testing is on winter.  So obviously its not going to work well because the Saints or some of them are different based on the season.  So.  We mention that the dataset has to be representative by even either even the way we do the split between training and testing.  Its really important.  So we want to make sure that when you do the split there is good representation of all the possible options so that you can have for the dataset.  So you want to be sure that you have the same distribution.  And going back to the umbrella all the seats for the four seasons in both of them.  Because only in this case the measurement of the accuracy would be reasonable and as much accurate as possible.  So again when you do this type of learning you need to to be sure that the distribution of values in the creation of the model in broad sense meaning the combination of training and testing and this beta between training and testing is similar to that.  This is part mean that the animal that you want to predict is part of that distribution because otherwise it is not going to work.  We mentioned reinforcement learning.  So again reinforcement learning is not uh anything completely different from.  Supervised learning but is basically self supervised meaning the system is generating cases and is getting the results as training dataset.  And then we use it pretty much the same way as it would have done if it was full supervised learning.  So thats basically the bishop is representing that.  Obviously when you can apply that you can apply that when you have score.  So if you are playing game if you are doing any task where you can measure the outcome.  If you dont have that then there is no way that you can do reinforcement learning.  Some of the examples.  So you want to move into the board where each move will give you reward and you want to reach the destination point with the maximum reward.  So based on the moves that you do you will get certain value.  So you can have system that will generate randomly options.  And then we use randomly generating options to create the amount to maximize.  Really the same thing.  If you are in network you want to reach the node aside from the energy or vice versa.  Lets say have supplemental side to the node.  Thats an example.  And there are many options that you want to minimize the number of steps you do.  So will keep those.  So you need to define your value and you need to maximize the value.  Oh pretty much see me later or an application.  All of the reinforcement learning are genetic algorithms.  Genetic algorithms means that the system is actually generating scenarios randomly and then based on the result is applying.  mean using that as supervision its they they named it the genetic because its kind of mimicking the survival of the fitness.  And that is function of the fitness function that is measuring how far you are from the goal that you want to reach.  Deep learning is something that is becoming relatively popular.  So.  You have machine learning.  You have artificial neural networks.  Artificial neural networks are algorithms that are based on linear algebra.  You have like in this chart here you have nodes that are equivalent of neurons.  So they will get an input along with the wait for the input.  Meaning that at the very end each one of those layers will be matter that extends and you go from one matrix to the other by multiplying the different Madrick seasons using the weights and using the input stats.  So you have an input layer and output layer and you have one or more hidden limits.  So in what is called shallow neural network so you have only one key delay in the deep learning.  You have very large number of dominions.  Now if you consider that you move from one layer to the next one with linear algebra multiplying matrixes any mean they can be with thousand neurons meaning thousand elements multiplied by thousand elements.  Youll have quite large combination.  You cannot really know whats happening inside the when you have million of you building.  So its called deep learning but its pretty much neural network with lot of hidden layers and is one of the problems in modern artificial intelligence.  Because what is happening inside deep learning artificial neural network.  We really cannot be exact because there is no memory of the different states.  It is just continuous multiplication.  So you only have the input and the output.  You could have another scene in network check in the first.  But then you are not really doing much in terms of explaining whats going on.  There are quite lot of investments on explainable artificial intelligence realities that when you have deep learning when you have lot of those hidden layer there is no way that you can really explain whats going on.  That is theoretical problem.  You can learn what is happening if you have memory if you dont have memory and there is no memory at each stage of this.  Large neural networks.  You cannot really get it.  So but anyway they are effective in particular.  mean obviously they are all nomadic although they are they were originally created for recognizing images.  Emojis are points are adults meaning you have large mattresses with the peak cells that are the elements in border.  Somehow that is the picture that you want to imagine that you want to recognize.  So initially they been created for that and they were nomadic outlet.  And still there is no way that you can do neural network for nonmedical elements.  So eventually you need to do transformation from a.  nonAmerican to an American.  Typical example is the use of machine learning to understand language.  So languages text so is not number.  There is no number in text.  mean it could be but its words its alphabetical characters.  Thats what Im out of it.  So when you have that and if you want to create representation that is in America you need to use an algorithm to transform text into numbers.  Those algorithms are called the vector is H.  There are several of them that are some of them.  And basically its transforming based on some assumptions.  We will talk about that each word in vector.  And that point you can work on numbers and thats the point where you can use numerical only algorithms.  So we spoke about deep learning.  And again thats what it is.  Now regardless what is the algorithm that you are using You will work with data that can be from all the possible venues.  Some of the data can be cleaner because they are generated by machines that are collecting.  Events can be messy because they are collected from human beings in different human beings.  Eventually meaning you can have some of the day that with the same meaning but different classification.  You can have street as street as to the other characters or as the daughter or as capital or as Mola.  So with the same meaning thats an example.  So there are quite lot of not clean data around us and if you want to play with it creating your models you need to transform you need to clean it.  So the data preparation its not so fine step in data mining and machine learning.  Keep in mind that.  So dont know how familiar you are if you ever knew the child GPT two train model.  They use the algorithms but they also use humans.  So humans did quite lot in different states of this of the process of creating all the training the system.  One of the steps is to remove inappropriate content so that something that new man can do and is terrible job but human can do and machine cannot.  And then tagging it to make sure that you had the right classification for the different code for the different elements that you are considering.  So large systems like Chop GPT.  What they do is basically they create they detect the pattern in the data and then they match the request you have with the available patterns compiling them with layer of compensation.  So its pattern recognition pattern matching and compensation element.  So those three are the three components of something like child that is part of the GPT class of machine learning systems.  That is right now some of the most advanced mean for large distribution.  Obviously there is always the issue of quality data.  Quality.  Its relative term.  So if you have dataset that is several terabytes.  If you have few thousand elements that are not clean enough dont really matter.  But if you have dataset that is several thousand and you have few thousand there that are good enough but then you have problem.  So quality is always in relative terms and is pretty much function of the size of the dataset you have.  The preprocessing is pretty much three phases of cleaning integration and transformation.  So the cleaning air is what we mentioned.  You want to remove outlets you want to remove missing data things that are damp integration.  You may want to have different sources for the target that that you have.  You are in marketing you are targeting potential customers and you want to be sure that you have as many points of view of your customers as possible.  So you want to have the information about the the financials the credit cards what is doing in terms of easy passage GPUs.  So all of those are all repeats visited on the Web.  So all of those are with the layer of machine learning can really or activation intelligence can really or data science can really recreate the profile of the individuals.  But the problem with having multiple sources is that the integration is rarely an easy task.  So the integration means you have elements that are that can be different but related to the same topic or individual or whatever it is.  The difference it can be just formula is different format or can be structural.  So you have one data set with the entities that are covered in certain way and the other that way are the same entities are called in different way or sometimes you dont even have the names of those entities meaning you need to extract the the name the label from the context the where the data is.  And then you have that transformation.  Transformation means you may want to combine variables if this may be appropriate.  You want to eliminate variables that are not relevant for the analysis that you are doing.  You want to normalize eventually.  They need to have more readable and usable dataset.  So all of those.  Are elements of the preprocessing.  Now.  If we go into the other algorithms we mention the unsupervised learning.  So the main algorithm in the unsupervised learning category is clustering.  Clustering is technique for finding similarity in data and putting together the elements that are similar.  So those buckets are the class sets.  So you want the goal of an algorithm.  Doing the clustering is basically you wanna one up you want to create groups that are its one with two subtasks groups that are as much homogeneous as possible inside and its much differentiated one from the other.  So thats the goal of clustering.  Ill go to typical level.  Clustering algorithm is cleaning to where you define the number of class that you want.  So that is key is and this would be decided with the combination of the inputs the data scientists but primarily the marketer or whoever is the client that you are serving.  Because if you want to clustered you are your clients you need to define how many groups you want and you define how many groups you want based on for example the number of products you have.  have ten net new products meaning need to have ten groups.  If have three products.  And in three groups cannot have ten groups with three products because then it wouldnt make any sense.  So but then there are ways to maximize or to suggest the ideal number of clusters.  And so now there are measures of that but the most commonly used is called the elbow or metal but it is not part of what we are doing.  So you define key and then you place randomly the elements into those key markets and then you measure the distance between the elements and you rearrange the placement of the elements in the buckets to minimize the distance between the centroid of those packets.  So we are centroid.  So that mean that you can have two dimension or dimension but the average of the packet.  So if is two elements that will be the element in the middle.  If the number of dimensions its 100 then is going to be three go to see it in hundred dimensional space but thats pretty much it.  So you move elements to minimize the distance between the centroid and then there is moment where you cannot move any farther the elements because you are already at the maximum or the minimum or the distance in each group.  So and at the end of the process.  So this means and thats what the algorithm is doing.  Another very popular algorithm is decision tree.  decision tree is kind of mimicking what humans are doing.  So thats an example.  Hey you want to go to restaurant you step into the first one to check how many people inside.  Then if the restaurant has no people you may decide not to go because probably is not great restaurant.  If there are some available tables then you say if is full then you ask what is the waiting time and based on your tolerance.  So for the way that you decide to see or to go based on other conditions like there are other options in the nearby how hungry am.  So those are.  Things that you do consciously or unconsciously when you take position.  So you mentally create sort of decision tree and thats pretty much what the algorithm is doing.  You have all the possible options.  So lets say that we are in binary condition.  Go no go.  So you have combination of options meaning you have some conditions for going some conditions for not going and then you apply the different conditions and you reduce the uncertainty.  So like in the previous case you ask is the restaurant cooler What is the waiting time So those are reducing your options.  Somehow the representation that you have on your screen.  So you have two options that are represented by the green circles.  And the Red Cross is reddish cross.  This pink probably dont know.  So that initial stage you have pretty much random combination of the two.  Then you applied force condition and you had more one type and less of the other type.  And then you keep applying conditions.  Still you have no impurity meaning all of the elements are on one type.  So measuring the impurity is also measuring the entropy.  So the entropy is higher when you have more chaos like in the case on the left side the entropy would be higher and the entropy on the right side would be zero.  So if you measure the entropy you will have measurement of the entirety of the dataset and the goal of the.  decision tree algorithm is to minimize the impurity meaning to minimize the entropy.  Neural network.  mentioned before that artificial neural networks are combination of single processing units that are kind of mimicking the neurons we have in our brain.  So you have bunch of input to the same number of weights.  They will go into this processing unit that will do summation and based on their value there will be function that will be on or off meaning of fighting or not fighting.  So thats pretty much how single neuron is working.  So each neuron as summation function and then transfer function function.  And then you can have an input layer.  And he then layered in an output leg.  When we have model one of the key points is to measure the accuracy.  So we generally use two main methods for evaluating the accuracy.  One is called the error matrix or confusion matrix where we measure the number of cases that the model is saying are positive.  Ah yes.  And lets say in the cases that based on its testing the subset are really positive.  So measuring pretty much the true positive and the false positive as well as the false negative and the true negative.  So in this example the question was buying computer yes or no So you have total of 10000 cases and the model is predicting yes for almost 7000 cases.  And those are actual yes and is predicting yes.  While the reality is no for 400 the meaning in this case you have very good accuracy in predicting yes for no computer.  No.  Buying computer No.  Your model is say no.  And it is yes.  Meaning its false.  Negative.  What is six know and is actual no for about 25 to 2600 cases.  Now most of the cases you dont have the same balanced performance in predicting yes or no because at the very end it really depends on the dataset you have again.  But if you want to predict the cases of cancer in the population of the United States you definitely have more cases of no cancer for centuries than cases of cancer meaning you have data set up in terms of representative mass of the two categories.  It is its really skewed toward the cancer.  It would be the same if you want to predict cases of terrorism if you want to predict the number of days of rain in the Sahara Desert if you were and so on.  So in that case its like human beings.  If you dont have experience in something you cannot talk much about that.  Then we know that there are people that are talking lot anyway.  But generally speaking you cannot probably talk if you dont know about the same metaphor if you dont have enough cases.  So in predicting cases of cancer that you can predict better cases of no cancer than the cases of cancer the days of no rain in day or rain in tomorrow.  So dont be discouraged if you see that there is disparity between predicting one or the category compared to the other.  Go back to your dataset and probably you will see the reason why there.  Another way to to evaluate the accuracy is the receiver operating characteristics.  So its comparing the true positive and the false positive.  So now you have the main diagonal that is measuring the irrelevance the flipping the coin.  So you want to have curve that is going bulb where the flipping the coin line.  So you measure the line under the curve meaning desire to acquire the error.  And the larger the area the more accurate that is going to be the TV channel the moment if you have cases that are all up to the top meaning an accuracy that is hundred percent most of the time there is something wrong.  So no model can predict the well hundred percent unless you are using variable that already has solution to the problem.  So if want to measure dont know Ukraine or no rain.  And one of the variables is the millimeters of rain obviously.  When the mm.  The value of the variables.  Millimeters of rain is above zero.  That is great though.  Meaning that variable is giving it up.  So then yes you have an accuracy of hundred percent.  But you already knew that if there is rain in the street if there is water in the street that is rain.  So thats an example.  When you see 100 accuracy this is red flag.  Something is wrong in the dataset.  When you have text things are more complicated because while the data is numbered its text is not.  So you need to find way to create metaphor and somehow to mine the text.  So there are techniques.  Then that what is main text You can mine text to extract information but it really depends which type of information you want.  You need.  If you want just to measure the most frequent words like we did then we would do in next assignments and in particular in the midterm.  Thats an insight that you can get from the attacks but statistical.  The main problem is when you want the semantics inside them.  How similar are two documents How can extract summary from text So those are or what is the opinion of people on something What is the sentiment of people What are the emotions generated by text So those are semantic meaning is the meaning of the text.  So those are obviously more difficult to evaluate and you need to have mode that you need to have metaphor to.  mean evaluate that to calculate those volumes.  But what work is being created in 2013 then Now there are other approaches but pretty much is good starting point to explain how those things are done.  So the process is called victory zation.  You basically transform each word into sequence of numbers in vectors and then you work with vectors.  So vectors are points in dimensional space.  So if you have vector with two components then this vector would be point in regular two dimensional space.  If you please mute your microphone malfunction.  So if you have like most of the time we use vector is Asian we did that 200 or 300 dimension.  Then those words will be points in three dimensional.  So in 200 or 300 dimensional space we cannot really see that the but its mean logically similar to like the were in in 2D space because they are two points in the space.  You can measure how fast they are and based on how far they are you can determine how close semantically they are meaning how similar they are.  Those two words the way we create the vectors is based on the calculation or the conditional probability of one word appearing in the text because of the other.  So the way those vectors are calculated that are using shallow neural networks meaning the neural networks with one layer and is already measuring what is after.  So there are different methods.  few years after that Google created another method that is called the transformer to the transformer.  Our victories in the bays not only on the conditional probability of one appealing because of the other but also what was before and what was after.  So its mean at that point you need neural network that is not more shallow but more complex meaning resources for training the or getting the model for system that is based on the transformer is way much more than one for work to bank.  So let me skip that and let me go to this one.  So tools for data science machine learning.  It really depends on who you are or what you do.  How long how big is your experience So its matter of fact that the people who are in data analysis since decades they use less by doing and similar lot primarily Python today and they use more tools like SAS or similar that are.  SPSS did are more with the user with graphical user interface like Excel on Steroids.  We do have faculty that are in the same condition.  So graduated as Ph. D.  like five or six years ago and to me is kind of normal to write code for faculty who graduated 15 20 30 years ago.  For them coding is not that natural.  So they probably coded at that time in Fortran or but now they are not much into that.  So the professional age group there is correlation on the professional age and the mean it is not discrimination and eventually would discriminate myself and 65 are going 66 or so but thats matter of fact.  And then obviously it depends on what you are doing.  If you are computer scientist obviously you have no problem using coding.  If you are an economist then you may be more reluctant in using those.  When you work with python you can do everything with basic python but you may want to use libraries or framework that will make your life easier.  When started working.  With machine learning.  mean at the time there was not much of machine learning or artificial intelligence in general.  So it was 1986.  Pretty much we didnt have by done that.  So we had languages that were very basic.  Meaning if you wanted to do an algorithm for dont know decision tree you need to build it from scratch.  So now you run python you call skill learner and you use one of the functions that is one function for generating decision tree and youre good to go.  So life is easier now.  So you have a.  Languages that are easier to begin with.  The bite is relatively easy.  You have million libraries of medium but you have several thousand libraries that will make your life easier.  And then eventually you have collection of libraries that are that can help you building the pipeline that you will need for your task.  So when we go into Python and the libraries in data science believe it or not the most frequent the most commonly used library is pandas because at the very end you have data and you need to represent the data.  So thats why you use PANDAS to create the somehow the data structure.  Some people are using them.  There are other options but they are very niche.  So pandas are definitely the go to solution for data science.  Its basic so its not adding lot of functionality.  There are no dont know regression clustering decision tree algorithm in it.  But in order to do them you need to have the data in data structure.  And thats whats pandas doing.  Elena is basically the next step.  So there are libraries for all the algorithms that we mentioned before and many other end is built on known by site by locally meaning all of those are embedded in the library.  Just warning.  When you work with library says that its so big.  Try to import the new code.  Only the portions that you need then not the entire library.  Because the more you import in your code the bigger your code will become.  If you then have also large dataset that you may run out of memory.  So be mindful and you can import only the portions that you need.  But again skill learner is the way to go.  Being based in Mumbai that means that is based on arrays as data structure.  And so the combination of arrays and pandas is definitely the way to go.  But thats comparison between some of the libraries and.  Now there are other options.  One of the things that Im not regretting but right now we have new Mac that is based on Apple silicon.  mentioned that last class.  The New Macs they have graphical processing unit that is working along with the central processing unit meaning that they cannot be addressed individually.  Most of the libraries in machine learning are based on TensorFlow.  That is great library but is addressing separately GPU in CPU meaning all the libraries are based on TensorFlow.  Im not really working on my neck so there are some way around.  You can build virtual machine but there are not many virtual machines that are running on those Macs or that are.  Sort of an adapter.  But those are affecting the performances quite by the law.  So mean by torture.  Its growing in popularity.  Another big fan of Facebook.  Facebook created by torture.  But the very end Im using it because can not use TensorFlow anyway.  So thats pretty much it in terms of slides.  Let me go for second here.  Let me show you just brief example of.  If dont create that using some of those algorithms that mentioned in class.  So that means.  Uh.  And then its decision trees.  So those are the two algorithms that Im using.  Knew script.  use the quite lot of comments.  Where basically copied from the Python library and the parameters that you can provide to the different modes.  So parameters are really important when you do this job because changing parameters would change quite lot of results.  So Im importing the different libraries so importing again and using Chrome because its killer and its pretty big.  want to import only means want to import the data sets and then dont pay pandas closely.  But was getting warnings and imported the library to ignore the warnings is not elegant so didnt have time to go back.  And the reason primarily the warning was generated by one of the libraries and then was using that.  So cannot go into the could buy but it wouldnt be anything intensive so Im loading the dataset is this is one of the most commonly used dataset for class setting is basically how to create class.  Thats all different types of hierarchies based on the length and the width of the sample and the length of the petal.  So the model itself is basically two lines.  So its not that much again.  And if you do it manually it would be probably good between 102 hundred lines that are in the library.  In this case means library from skill learner and it would be super easy in this case.  So then the representation decision tree similar think.  Importing the library is a.  And ordered imported.  The dataset.  So same thing.  Defining all the parameters.  Splitting the dataset into training and testing.  And then same thing the representation.  So you will have the file and you will play with it.  So Im running it.  So is generating PDF with decision tree.  So on the decision tree you have.  This is the root node.  Her.  And then you apply the different options and you will get that at the very end.  Am not saying that we are running out of time.  So you will have the difference anyway.  Then.  This is the cluster.  Oops.  Three clusters for.  The dataset that was using.  All right.  Okay.  So let me go back here and let me go to the inclass exercise.  So the reason why why created this exercise is because back in time let students pick their own final intense problem.  And that does it for strange reason.  huge number of students in relatively new age decided to go with analyzing us baby names at the very end.  couldnt be sure that what they did was original.  So decided to take this out and making it an inclass exercise.  So us baby names.  You want to read the file into pandas data structure Read the structure delete the call on unnamed zero and IED.  Determine if there are more female or male being the top five in terms of number of occurrences.  But name meaning or frequency of the name the number of names in the dataset the standard deviation of the name occurrence and some basic descriptive statistics in the dataset.  That is one line in pandas.  All right.  So let me make sure that this assignment.  Its been posted.  So I.  Published the.  that size.  And if I.  Okay.  You have it.  Let me stop shedding.  Let me start.  So there are four breakout rooms with two or three participants per room.  So in creating it lets say 10 minutes.  All right.  See you in bit.  All right.  So its 801 and we dont want to keep you too long.  So will post the solution but we will not discuss it.  So my apologies for talking too much during the lecture about really hope that was useful or at least interesting for you.  Um.  Let me uh just.  For minutes about the meter mount.  So let me go.  Right.  Everything.  Yep.  Okay.  So let me share the screen.  And.  All right.  So can we close Let me go over your.  So the midterm the midterm a.  One think that is essential.  For the regular on campus classes four and 624.  Uh they do the meter uh in 2. 5 hours.  So mean its both regular on campus and regular online.  So you will have more time.  So you will have until Sunday.  But thats less than the normal time.  So if you think about asking for an extension it is should be mean serious reason for that because you are already getting more than should normally give for the midterms.  All the other modalities we run AM 624.  So the.  The assignment has two parts.  mean apart from liquids.  One part that is choking code.  So you have some scripts.  And also copied those scripts in note by FILA so it would be easier for you instead of copying and pasting those and then there would be issues with the indentation.  So you have three different scripts that may work or may not work.  So you have the description and the actual script.  You will run it you would check it and eventually you would fix it.  So those are the three uh smaller pieces of code to check.  Then there are two more uh that are new to.  Right.  They are smaller.  So you read the the file transfer fee into list of words eliminate from the list the words that are in the stop word file.  So the so called stop order is thought is word with no semantic meaning articles pronouns things like that.  So you want to read the modified and eliminate what is in the socalled the from the original text.  Then you will calculate the least frequent words.  The average occurrence of words where occurrence is the frequency is the number of times word is appearing in the text.  The longest word.  The average word length.  Again is based on unique words so each word counts as one.  The last of the writing scripts is using the file cards.  Theyll see as we you read the file into the structure and then hes about cards.  So they have several characteristics including horsepower and average mileage.  So you want to print the three cards with the lowest average mileage the highest average mileage and the highest ratio horsepower divided by average mileage.  So.  You have the list of files you have also this one with the files that you want to check and eventually fix.  And you should be good to go.  So for.  Section one and two meaning the part with the checking code and writing code you will write one single dot by file.  So not too far.  Not enough files for each of the state of the parts but one single file with everything.  And thats basically it.  So you should have her think.  So Im sorry if always staying longer than 800.  Questions have one.  have to write one on the bequest.  That was for this module.  I.  It was on.  was the first one.  It was.  Which one of you know or is not software development model.  And happen to like chose the model because thats traditionally systems engineering model and also was the one that wasnt in your software development PDF also it was the one it was the CNN.  But arguably like model is systems engineering principle not software engineering principle.  Okay.  will review that.  And then keeping in mind that that system engineering and software engineering they share several principles.  So generally call software engineering system engineering applied to computer science but would definitely check it.  Okay.  And then my other one was.  Lets do Sunday is that you know its not measurable.  just feel nervous about the midterm date being due Sunday being that know for most of us.  Working full time having less like Saturday and Sunday.  Only two full days we would have to.  Yeah you are going to have both the days.  So the due date is the end of Sunday.  Right.  Thats thats what meant.  So having Monday evening for the homeworks is nice cushion just in case working over the weekend isnt enough.  know for me these homeworks take me at least like hours to get fully correct but just figured it was worth the shot.  Well mean understand.  really need to be uh consistent across the different modality.  So in this case it was.  It was frustrating one time.  understand that.  But mean kind of did sort of compromise meaning its kind of giving us wood and our fireworks and giving several days including the weekend.  So you can work during the weekend because mean you are professionals and you work during the week but the weekend so you have the entire weekend.  So thought that was.  Not saying genitals because that seems to be not appropriate.  Youve got the sentence guess.  Yeah.  All right.  Thank you for answering those.  Absolutely.  Other questions.  Yeah.  Gavin have question regarding the grading on this.  Oh what do you call that You know at the end of typical homework it asks us to interpret the results.  How does the grading work for that Is there like template If we missed certain words like lets say for the city situation if didnt mention that people would often ride bikes during the spring because its warmer climate versus the versus winter because its colder.  Is having points taken off What was your thoughts on that point there Well when you have questions that are more on the qualitative side mean things that are always questionable.  So think about sport.  If you have gymnastics.  So how are you apart from things that that obvious the other kids fail but how you evaluate one execution compared to another one so you have human being the very end judging the results.  Human beings are fallible as we know and pretty much every one has different opinion about things.  And in this case when you when we evaluate the interpretation we want to be sure that you are using all the metrics that you extracted in the proper way meaning you use the metrics or the metrics to make the story.  So one of the most common way to do the interpretation and is the wrong one is to describe the process.  So prepared the data loaded the data prepare the data did this operation.  And then the other operation does the wrong way because we are asking for an interpretation not an explanation of the results.  So.  Uh most of the points that we take out are for two reasons.  One reason is because there is no inside sense or elements of inside so that can be derived from the matrix.  Most of the time again that is students describing the process instead of the results.  And the second is when you have lets say ten matrix but you are actually using two.  So yes it is insightful but it is not as insightful as it could be or it should be.  So dont know in this case in particular if you send me an email just to remind me will review it.  But typically when we take points off because of one of those two reasons.  Thank you Professor Atmosphere.  Thanks for the.  Sure.  All right.  Other questions.  All right.  So thats the end of the class.  ft STEVENS lw INSTITUTE of TECHNOLOGY iy Data Analysis in Python processbased approach clipizzistevens. edu SSE Data Mining Methodologies Several non formal methodologies available.  Two more formally defined are SEMMA.  Ii is list of sequential steos developed by SAS Institute Inc CRISPDM.  Polls conducted in 2002 2004 and 2007 show that it is the leading methodology used by data miners Gregory PiatetskyShapiro WDD Nuggets STEVENS INSTITUTE of TECHNOLOGY Phases in CRISPDM de facto industry standard for data mining Created between 19971999 by DaimlerChrysler SPSS and NCR Acronym stands for Cross Industry Standard Process for Data Mining Consists of phases intended as cyclical process Not all phases are necessary in every analysis STEVENS INSTITUTE of TECHNOLOGY Data Analysis using CRISP An adjusted version of the CRISP DM CRISPDE with DE being Data Exploration Focused on extracting information from data No modeling only descriptive statistics and visualization Consists of phases intended as cyclical process All phases are necessary in every analysis Data Exploration Template clipizzistevens. edu SSE Contents Me STEVENS INSTITUTE of TECHNOLOGY Project Goals and Conditions je What are the project goals What is the key question you are required to answer Are there any conditions limiting or somehow defining the project like limited access to data data too old time constrains brief description of the expected results may be added STEVENS INSTITUTE of TECHNOLOGY STEVENS INSTITUTE of TECHNOLOGY CRISPDE An adjusted version of the CRISP DM CRISPDE with DE being Data Exploration Focused on extracting information from data No modeling only descriptive statistics and visualization Consists of phases intended as cyclical process All phases are necessary in every analysis Focused on extracting STEVENS INSTITUTE of TECHNOLOGY 19 Business Understanding offs Definition Define business requirements and objectives Translate objectives into data mining problem definition Prepare initial strategy to meet objectives You want to be sure to clearly describe the business needs and the steps to address them from D.  Larose Discovering Knowledge in Data STEVENS INSTITUTE of TECHNOLOGY Data Understanding ie Definition Collect data Assess data quality Perform exploratory data analysis EDA Overall data description sources organization key characteristics sensorhuman generated reliableunreliable source . . .  Here you run all the descriptive statistical tests that make sense for the specific case describing the different steps and their specific meanings from D.  Larose Discovering Knowledge in Data STEVENS INSTITUTE of TECHNOLOGY 79 Data Preparation iw Definition Cleanse prepare and transform data set Prepares for modeling in subsequent phases Select cases and variables appropriate for analysis First define the steps you are going to perform e. g.  if you normalize why Here you perform all the data transformation applicable to the case missingmiscalculatedmisplaced values outliers normalization Describe the final dataset format new records number new variables . . .  from D.  Larose Discovering Knowledge in Data STEVENS INSTITUTE of TECHNOLOGY 73 Data Representation ie Definition Select and apply one or more descriptive statistics to the dataset Select and apply one or more visualization to the dataset It may be an Iterative process adjustments may be required lf necessary additional data preparation may be required Explain why you selected representation to an other Describe final results Read the results with business sense and provide your comments STEVENS INSTITUTE of TECHNOLOGY 14 Contents Project Goals and Conditions LJ CRISP Business Understanding LJ Data Understanding Data Preparation Data Representation LJ Practical Results Conclusions LJ Attachments Me STEVENS INSTITUTE of TECHNOLOGY 15 Conclusions This is the final recap you briefly describe the whole process from the business need to the data collected to the representations you choose to the resulfs you obtained Describe possible limitations of your analysis and future possible develooments STEVENS INSTITUTE of TECHNOLOGY Contents Project Goals and Conditions LJ CRISP Business Understanding LJ Data Understanding Data Preparation Data Representation LJ Practical Results Conclusions LJ Attachments Me STEVENS INSTITUTE of TECHNOLOGY 17 Attachments lw All the additionalnon essential tables and graphs will go here Add only the outputs that can support the case you described in previous slides Outputs have to be either readable no 1M row table in page STEVENS INSTITUTE of TECHNOLOGY 7g It.  Im resuming the recording.  Welcome everybody Today.  Its its by day.  Its march the fourteenth so 14 016 mean being mathematician.  cannot escape from that.  So we have she you our ta for this.  029 and she will share with us some of the criteria that she is following on grading and give you some 040 comments indication directions 051 to you.  Go ahead.  055 Thank you Professor.  May share my screen And 057 im sorry because use the screen and the screen is on top of the laptop.  So sometimes you may wonder why my is brought in this area because my square is over there just 101 functions.  114 Okay.  So can you see my 120 Okay Oh.  124 dont know why.  Theres some problem when open the 127 files.  131 So need to reopen it.  Now.  133 Probably.  Yeah this one though.  137 Okay.  So can you guys see the midterm description of the word file 144 Hello.  151 just see the pie charm.  152 Read again about it.  So lets go through the 203 problem.  Other questions one by one.  So for the first one the requirement is the question.  One has string.  But 207 typically this 216 head of scripts return us list because no matter what you append.  218 they are is list.  This is definitely what the this other requirement to want so we can first around the oh im sorry Professor because you have very dense agenda.  dont want to run the 226 this file.  but we want to fix it 239 so because they requirement to once string we will give it history.  So they they normal way will do is just to 244 use John 256 to put the elements in the list together and according to the requirements 257 they are they should be characters like this one.  304 So we will add the letters 309 in that list before we join the list before we put all the events in the list into string.  313 So this is the this is my solution for this 322 questions.  So lets run it as required.  We can put the input 328 the 335 and 337 like this is.  338 Does anyone have problem with this question you can ask me now.  342 No okay.  Lets move forward.  So for the second one 349 to be honest that did not follow this wrong 355 syntax.  Oh.  359 very well.  But according to the requirements 401 can share with you guys my logic on my solution to figure out this problem.  So calculate to.  The longer is the word of text and printed them with long it to the second longest word.  So first 406 we need to open the file.  423 read the file.  If you open the file as this format and the the file the rate it will come up 425 with stream format but we can also use red lines.  dont know if you can distinguish what is read and reliance that rate will result with us.  can share with you right now.  434 So see the word list with data is string.  453 This is the format.  Its string and if we 457 with reliance it will be 502 list 506 like this but its still with the slash.  That 510 okay thats for the open the file.  519 because open the file with the stream format and then it.  524 and the 530 what it in the pure 533 where list.  538 and because we want the unique 540 one.  So we take the site and convert the site into the list.  543 So the site here is to select the unique word in the word list and the list here is to convert to the site into the list they have.  552 Yeah did have And we use Lambda to sort the list.  and we can come up with 604 Well.  618 yeah this one.  because this is 630 what happened.  637 Sometimes when you run part of the code the reading files is not working.  Okay.  659 but mean you gave us an idea.  You can just move to the next exercise.  706 Okay okay so will.  713 will share with you guys with this solution on the through the announcement.  Sorry for that.  716 and for the third one.  722 think 726 the Professor provide provide us very good solution to come up with 728 this question.  So first we want to check if the input is digit or if in the lower case or uppercase and then well put all the in the word list.  735 and 748 when you type character the file will tell you it.  750 That is consonant or it is about 757 so like this one.  If put it.  J.  J.  Is constant.  805 So 809 does Annual have problem with this questions.  811 Okay.  So lets move forward to the next one the next one.  dont think input.  Oh input the 818 numpy.  827 And the the next question is to actually this is the second section.  828 the 836 fourth question to calculate the tenth list of frequent words and the average account of the worst and the longest word and average 837 average.  What length So first.  this is the way.  open this to file because we want to remove staffwards before we calculate we do the statistics.  849 So 904 first will open these files.  906 One is our target file and the second is the stop horse file because of course use read so need to split it 910 into the wordless version.  919 So this is the stop horse stock or list and the air trend.  925 This is the strength version.  931 and we want to remove stuff for us.  Industry and taxes.  My way is to put the string into what lets first and then remove any item 934 in the stop Force List that up here in the target pocket for 948 So 954 this this is the way to split the stream format into word list.  956 so we can see this is the string format.  This is the list format.  and then we can remove the stop course from this where list the stop was like to the Okay.  So up to that Up to this step we have sort of clean list.  We can see the difference.  The number difference between these were list.  and then this is to count the frequency and this is to count the length.  And so first do not use the collection counter.  initiate counter dictionary to count the occurrence of word.  So first if the word ha appear in the dictionary keys the if they should the first time up here in the dictionary keys.  The occurrence of this word equal to one and if the word ever happened appeared in the dictionary keys.  the apparent the frequency plus one.  So this is the counter we calculated from the data have to remove.  Stop stop.  but according to the requirement we want the 10 min to frequent word.  So we need to search the dictionary and select the top 10 worse.  You dont need to worry if you have different order of the to list the frequent work.  Once you follow the procedure the procedure or the similar procedure.  they all that doesnt matter.  And next we want to count the average account of the world.  So we took the dictionary value which is their current.  Yeah which is the currents of the unique words.  And we technique of that values.  So we can see the outreach frequency is 1. 2 around this and then we use the similar way to calculate less.  So first they initiate the we put the word in the list as the dictionary keys and the length of the word as the dictionary values.  And then we saw the dictionary and use the similar pro the same procedure as the frequency we got the average length.  Oh.  they should be less.  It doesnt matter.  So the average length should be point to yeah.  Does anyone have problem with this question Hello.  Oh.  because the good job.  So in the next one is to use Pandas its basically data analysis of how to use pandas.  And use the function.  Goodbye here which is very concise and yeah.  concise way simple way.  So first we use Pandas to read the data file.  and my habit is to job other.  use the columns.  So first we need to print out the column name.  So this is the column name.  recommend you guys to copy and paste like this instead of just typing for yourself because Sometimes there will be small space between the names and you may not notice that.  And if that happens you can now to drop or you can not manipulate to the data frame animal.  Thats my experience.  Thats my license.  So we first print out all the columns and according to the requirement we only want to the cars.  which means the company name and the average knowledge and they house power to average knowledge.  So we drop all the other used call ups which make our data Freemo concise.  So no would do.  Have our data frame only have Well it has variables the company the house power and the average manage.  And dont think this is okay.  So based on we want to the cards with lowest average Malays.  So we grew by the company and take the me of the average knowledge and the one day largest one.  See this is the largest car with largest average knowledge.  This is the company name and this this is the me of the average knowledge for each company.  and the same to that smallest.  These are the smallest.  and the the last question is costs with the highest ratio has power average.  So first need to calculate the ratio of house power to average knowledge.  This is the one to calculate the ratio of them.  But want to put the put that results to the original data frame.  So need to convert.  Actually this is right.  need to convert them into list.  And at this result to the original cars data they are free.  So we can see now our data frame has fall variables.  This is the power to average knowledge and the value is the ratio of each company and for their house power to average marriage.  Its out and we follow the same function to get the cars with highest ratio.  Okay so thats all for the for the mid term great to you.  So stay on life for second that just want to show the class and you different way to do the same last exercise.  So just although curiosity.  The reason why im going to do it is just to explain the fact that pretty much everybody is different.  One of the things that we consider when we grade the the assignments is is to notice the differences.  So the assignments are individual meaning.  Each one is doing in different way.  If you stop sharing for second that will share mine just min.  So this for example is what did the for the last assignment.  So im in that did that probably in less rigorous way.  But its very concise.  So.  So read the file into pandas data structure.  pre didnt delete anything printed the the first rows then print the ratio and then the the cards with the highest ratio.  So once you have the the head thats of the of the Pandas data structure.  You may not really need to to delete those but just use the rules that that that you need.  So mean in this case its pretty straightforward and and that thats what you get.  So mean that the first rows the last rows the Cs with the highest ratio and you can do more intense over what is the highest value or or the lowest value.  So mean that keep in mind that that Pandas so has noon pie in it meaning you can do all the operations you want with the directly with Pandas.  One thing that want to stress with you is this operation here.  So in this case created the a.  new column in my data frame without going through creating list.  So it basically had the column.  Now the new column ratio by calculating the ratio between horsepower and average my larger.  Then sorted it and then printed the the the head the meaning the the ones with the highest value.  So mean again there is no right and wrong apart from the fact that they generate the right results or not.  But this is again just to be sure that you got the fact that that everyone is individual everyone is different and and if you do in different way.  Doesnt mean that that way is wrong or its right and the other by by its just different way.  Yes.  okay to you.  We really thank you.  Other people in the class.  Any question an issue any studio city Thomas Poklikuha have one question about the homemarks.  Thomas Poklikuha So for one of my homeworks.  accidentally didnt submit the pi file.  and got points taken off but have the screenshots.  If resubmit that pie sent you message on that in canvas.  Yeah mean that unfortunately canvas is not.  That is Mark meaning.  Each time you resubmit that you will cancel whatever was before.  Yeah.  So just send us an email with the dot pie.  Thomas Poklikuha Okay sounds good.  Thank you.  apologize.  But unfortunately this canvas.  Thomas Poklikuha Its my fault first.  So its all right.  all right.  Okay Other questions for she you Okay.  So thanks again to you feel free to stay if you like.  Are all things that you know quite well so and feel free.  No love your class.  pretty enjoy that.  Thank you.  Thank you.  Erez agmoni this coming Friday will give workshop on natural language processing.  will post on linkedin the recording if it will be available and the slides 101.  It took me full days to Redo.  It completely is probably the sixth of the seventh time im.  Giving workshops on natural language processing inclusive for the same conference that mean in the past it was in different location was in to you.  But what what was the same now had to redo everything because so much is changing in natural language processing that couldnt reuse what had in the in the math.  and Gbt for is released today.  know know know.  mean that im kind of skeptical mean see the good and the bad but that that thats story for another moment.  Thank you.  Bye bye.  All right.  Okay.  So lets move on and let me share the screen again and let me go into.  So that was the midterm as we we all well know.  So for today we will talk about little bit of data mining little bit of methodology.  What is data exploration And thats the methodology.  And then well be talking about the visualization.  So will go relatively fast on that because it is already almost 70clock and do not want to skip the the in class assignment.  So let me go on the slides and let me introduce the concept of extracting knowledge from data.  Its pretty much in line with what we already said few times about storytelling.  So you have data.  You have problem and you want to use the the data to work on the problem meaning.  You want to get facts that then you can explain.  But the facts you will extract them from the data.  So sometimes things are easy sometimes are more complicated sometimes some some basic statistics.  can do the job for you some other times.  You really need to find the more complex elements that can create narrative for this sort you want to tell if you consider for second that when we talk about the correlation so the correlation what we use it generate the linear correlation meaning one value is growing the other is growing or one is growing.  The one is decreasing.  Thats correlation.  and how much at what degree they degree they they increase or decrease is how close the the variables are to be identical in that case will be one and the correlation 150 erez agmoni but not always.  You have linear coronation.  So there are many other ways.  So just mentioned one example.  So if you go to the 150 that sometimes we use models that that are more complex than that we use decision.  Trees we mentioned that last time in the the class when we talked about machine learning.  So those are the methods.  Those are matrix that we extract from the data and we use as data points to tell the story.  So lets explore little bit more very fast.  mean its lot of slides but im not going to spend much time on each one.  So what is data mining data mining knowledge Discovery is all about data but its not the only thing that is about data.  So in this case is that somehow process used by companies to to gardener role data into useful information.  That is very basic definition but it makes sense.  So you mean its its its basic and its very general.  But thats what we do.  So why we do data mining.  Now we do now because we have data and thats the first point.  The the second point.  We have computational power and we have tools like python that can really help us going through the data in in timely matter and get the results.  So the combination of those things again and the availability of data.  the the computational power and the power of all the software tools like Python is making data mining possible.  But there is also market reason.  So the market environment is becoming more and more competitive and you need to find the niches where you can leverage your offer and get more satisfied customers.  So what customers or what whatever is the goal you have So now there is more need the competition.  Its more.  Im not saying that its hard right now but but its definitely more specific more targeted than it was in the past.  And then the technical reasons that was explaining before.  So what we do generally speaking in the data mining is to discover patterns so common behavior.  So in the data that we have.  Thats pretty much what gpt for that she you was mentioning or any of those large language models are doing.  discovering patterns and matching patterns.  They the mining.  Its kind of multi disciplines discipline with the several components from obviously computer science information science because at the very end that we need to write programs but we also need.  Ill do it.  So that for machine learning bid up most of the time are in data basis.  You need to know how to deal with the other basis Statistics because even if sometimes they may not be so so sophisticated but will be useful to clean the data to understand the data and to start initially working with the data.  And then visualization.  Will we talk about that little bit later on today.  And there might be other discipline based on the on what you are exploring what you want to discover.  If you are in finance you may want to be an expert in finance.  If you are in health care you want to be an expert in that care and so on.  So sometimes when you are talking about sociology.  You know when we are all social media you are talking about people like you may have sociologist anthropologist psychologist on board.  Obviously when you work with few data.  Life is easy.  When you work with on terabytes of data things will become more complicated.  was working few years ago on large database all the data collected from an insurance company using the black boxes in the cards.  and that those black boxes generated input for each car every few seconds.  So was large insurance company meaning lot of cards and you can do the map and imagine how big the data set was.  So my model was working fine in in theory but when had to scale it up to the size of the data set then issues happened.  ended up doing little bit more of parallelization at the very end that ended up working on cloud computing so moving creating virtual machine moving the virtual machine in the cloud running the model and then getting the data.  But again scalability.  the size of the data is important.  So one of the most common questions is what is the difference between data mining and and.  generally speaking statistical analysis Its its top down.  So its deduction data mining is induction meaning that you have few examples and you extrapolate what what you have.  You have bug over points and you say okay its full of coins so extracted the 20 of them and they are cents all cents tribulation.  They are all cents can be good can be not good.  But thats an example that pretty basic example of the induction.  So you are assuming that because you had the certain number of certain type.  You are established the type to the entire population you have in statistical analysis you count how many coins you have.  And then say okay 30 of my coins are of this time.  Sometimes you cannot really count because you have data set that is huge.  was working few times with social media.  You have several million data points and and mean it is difficult to do in so.  Again the main difference study signal analysis is is deductive data.  Mining is a.  In that.  We mentioned that there is huge growth of of data.  So the data we have in the last few years so its pretty much comparable with the all the data has ever been collected in the previous history of humankind.  So and its growing so because we are generating content.  We are generating content through social media to communication.  We have sense of Internet.  Of things.  Its Matt watches another whereabouts.  So all of those are continuously generating data.  Everything we have pretty much is digital now with very few exceptions and they are going to be sooner if it is not digitally.  If it is not the analog that means that its the that means that that we can use it somehow.  Now because of most of the data are in the Internet Protocol and IP for convenience.  That means that somehow they are collectable with the all the degrees of privacy.  Obviously.  But they are collectable for those with the right right to do so.  So we are leaving process that someone is calling the thatification meaning.  Everything is becoming based on data.  So the latest chat Gpt is probably the on this trend Chat Gpt is based on data.  Its based on that whatever or any AI could collect the from open source and someone is saying even something that is not fully open source.  And you dont want to argue on that.  So its process.  You go from row data to element so that we give you the opportunity to take decisions.  There are main types.  All the the think.  So the data science is is doing the analytics.  So the data science is doing so.  You have the descriptive analytics meaning you are applying the method to to get whats going on from the data.  and thats basically metrics that you extract some of the metrics.  Again mentioned the correlation analysis may be very deterministic very statistic.  Ill rather not so much.  And mentioned that the decision trees and the metrics never associated to that.  Once you have descriptive analytics you may want to go predictions.  So saying okay considering what is happening up to this point.  So this is what is going to happen.  But you dont do anything that the next step is the prescriptive meaning.  Okay considering that this is what happened.  And this is what is going to happen.  Im going to do that.  Think about the autonomous vehicles.  So you have the autonomous vehicle assessing the situation.  So what is on the road and is the descriptive.  then the predictive There are pedestrians that are crossing the street.  will see them in front of me in that much seconds.  So thats predictive.  So they are not actually crossing in that particular MoD.  They are not in front of the car in that particular moment and then prescriptive.  will stop.  So those are the faces.  Not necessarily all the analytics.  So well have all the faces but those are the T.  V.  Gala faces for analytics and the TV gala usages for data science.  Considering how much again that data we have this notification transform the and its keep transforming pretty much every industry.  So some industries are more reluctant.  So we still have quite lot of projects in the data engineering with the defense industry because some industries are more structured and they require more time to do the transformation.  Some other industry are already transformed and they already 100 digital but not all of them examples of user pretty much all the the cases where you have big use of all the data you will have the possibility to in use data science in in middle sense.  We already mentioned that the type of data that you can have.  So most of the time you have data in structure form that can be tables.  So that can be pandas.  It can be data basis so they pretty much resemble the table with rows and columns.  We are at the rows are the data points so that you have the observations that you have for your data set and the columns are the attributes of of those observations.  So if you have the weather in given period of time you may have the temperature the pressure the humidity those are the attributes and then you or variables or columns and then you have the the rules that are the samples.  So the instances or whatever you want to call them.  Thats another example.  You have the Irs checking.  If someone is cheating on taxes.  and hes collecting data like.  If the subject the taxpayer asked for refund or what is the marital status And what is the taxable income And then the result was cheating on taxes was not so based on that.  You you can do prediction.  Obviously no one would do prediction or something with so many vulnerabilities and so much at stake with only 10 observations.  But thats pretty much the sense.  So now if you want to create model to predict the who is achieving who is not.  You need to analyze the the variable you have and then create the model based on the variables may not be.  Linear most of the time is now but thats what you have.  Obviously if you had the same poll that you have.  or better if you are using the sample that you have on your screen you.  mean if you look the number of No is the vast majority.  You are only 3.  Yes meaning the 70 is No.  If you create model saying that always No you will be always right or you will be 70 of the times right Oh that means that that the all that it wouldnt do great job.  But this is something that would use to tell you.  What is the the accuracy of model So.  and most of the models they drew the line at 50 meaning that if is less than 50 doesnt really bother.  mean you flip the coin pretty much if is above 50 may be useful.  but it really depends on what is the case.  So if you have social science predicting what human beings can do is really difficult and getting high accuracy its really difficult.  If you have an industrial production.  We are all the processes are very welldefined and consistent in time that an accuracy over 85 95 its reasonable when you have something that is not on the side and you have an accuracy that is 99 95 there is something wrong most of the time you have high correlation linear correlation between the the variable that you want to predict and the variable so that you are using to create model.  So think about.  You want to predict the weather if its raining or not.  And one of the variables in the is the number of inches of rain.  Obviously if that number is different from there is rain erez agmoni.  So those variables rain or rain and the accumulation of water they are highly correlated.  So if you include that that variable in the model 150 the model will tell you things that you already knew.  meaning that the model is part of less.  So when we do this type of analysis.  So you want to remove all the variables that are so obvious that wouldnt add anything to your knowledge.  So let me skip that we already know that they are tribute.  So we know from 5.  Dont know the categorical or numerical pretty much the to make categories some examples of all the documents.  So you have on data.  You have different documents and different words.  This is document term occurrence table one.  So you have document one with the with the term team happening at times play times and so on.  So this is something that is used as sometimes as first stage to the terminology to see how much documents may be similar if they have the same words.  Whats use the the same number of times Thats red flag for possible.  Then you would do the second set but that will be analyzing the position of all those words.  So if you have the words so that record in December now the same number of times in the same positions.  Then there could be platform and obviously its never 100.  You can have degree on the first stage and degree on the second stage.  The other example is transaction data.  So when you buy something in store either online or not you have item in your basket and you have transaction Id that are meaning what you are buying.  So you have transaction.  Id and list of items.  So thats an example of transaction data.  You can have graphs.  So some graphs are pretty obvious.  Social media is generating graphs.  The electric greed is graph.  The the telecommunication network is graph.  But you can create graphs from text with the proper algorithm all right with the problem metaphor and then the algorithm so thats another example.  Like each one of those will have intrinsic characteristics that can give you the possibility to that to do some types of analysis and not that when you do data mining you actually do process.  So the most commonly use the methodology is what is called Chris the end.  Chris DM.  Stands for cross industry standard process for data mine.  It is composed by faces.  You start with the defining what is your business So business understanding Why im doing what im going to do what is the goal that they want to achieve.  So thats the first step.  If you dont know what you are going to do chances are you will fail or you will never be satisfied.  So you define the problem.  They say on the its data mining.  You need to have data.  and you need to have the data that will allow you to solve the problem that you define in the in the business understanding phase.  So this face is sort of an assessment of the data you have.  So you analyze the data.  You see if the data can provide answers.  may not because you may not have enough data or the day that may be consistent or there could be so many missing values that you are not going to get much out of it.  Things like that.  So the outcome of the data understanding that can be okay.  have what need to do.  The modeling in broad sense or dont have enough data and need the either to tune up somehow or the business question or just to table it and say cannot do it Once lets say you are okay and thats why you have the double are also here.  Once you are okay you go in the data preparation.  So you want to be sure that the data has been cleaned enough as being the most enough as being normalized enough.  So all the or you do the correlation analysis to the move variable so that are if relevant.  If you have one variable that is the double or another one.  There is no need to keep them both.  So you want to remove one of the 2.  Thats an extreme example but is in in that line.  So thats the data separation.  Once you have the the right question.  the right data to address the question and the data in great shape.  Then you start the modeling modeling means you apply.  Ill go it to the data.  So the combination of all the algorithm or algorithms and data will give you the model.  Once you have the model meaning that the algorithm for your specific case you then you can start the evaluation of the model.  How good the the model is mentioned before the 85 95 or the 50 that those are the accuracy of on the model.  Once you are okay with the valuation.  But you can also be not okay.  Say okay was doing bunch of things.  tried several different algorithms but didnt get much.  So at that point the the evaluation the accuracy is so low that they need to go back to the business question as saying with what you have can never provide you with an answer you would be happy with.  If this is not the case meaning that if the is good enough then you start with the point.  So thats the would skip the the following slides and would go but you will have them and would go with specific case for what we are doing.  So we are not doing modeling because this courses on data.  Exploration is is not in data mining but they want it to give you little bit of context in terms of broadening the goal and going more on the mining.  Besides the explanation.  So.  starting from the Chris DM created the or adopted the the methodology to something that is more for our cases.  So data exploration instead of having is per DM.  Is crisp de we are instead of data.  Mining is data exploration.  So you and you will use this.  this.  this sort of table of content as guidance for future data exploration assignments that you will have and you can use in other circumstances of that data exploration that you may have in the future.  So you start defining what are the overall project goals What are the questions you want to answer And then you start.  Okay let me introduce methodology.  The methodology is called the crease.  The we are.  There are faces business understanding.  Theyd understanding and data preparation.  There are the same that we mentioned before and they the representation.  So that was not in the the Chris DM.  That was modeling an evaluation.  We dont have modeling but we have representation.  Representation can be.  Visualization can be tabled so can be not added to consider all the sort of revolution that we are experiencing with the Chat Gpt.  One of the representations is basically conversational.  So the data are represented in terms of phrases generated by by the board.  So thats another data presentation that is still quite lot of room to for improvements.  But thats possibility.  So think for second that you are an alternative on the field.  So you dont have time to go that much into charts tables.  So if you have your system telling you in plain English what you do What is the result of the current variable so that you are considering you would save time.  So thats why can be so relevant that this new approach based on conversational data to.  So again will go fast into those faces.  So we already mentioned that when you we do your own instead of having general definition that you will say okay in business understanding want to determine how to reduce the charm rate in my client base.  want to predict the weather.  want to do something.  So thats what you do in business understanding.  and you will define criteria to define success or failure.  Then theyd understanding.  You will collect the data and you will critically evaluate whats going on.  So if the data its good enough for what you have.  So you will perform an an exploratory data analysis on the data that will be for the the for mana validity of the data.  So how many missing values.  How many outliers how much correlation things like that Then they the preparation.  At this point you will do the cleaning.  You would do all the preparation that you would do in in your data.  and then you will do the representation.  So again most of the time would be the tables or visuals.  Will we talk about visuals in moment But thats basically in broader sense data representation.  Then conclusions.  You want to have your conclusions here saying based on what have.  Thats the results.  And then you may have attachments.  So you dont want to create report with the me on tables million visualizations.  Youd want to create something that is the right combination between visuals.  So tables and narrative.  So the narrative plays the to explain tables visualizations and things like that so you can have the narrative first and the visualization then or vice versa depending on your assign.  But those will go side by side.  You dont want in your rep on to have code because thats not the point.  So we are more like consultant so like business consultants but based on on data based on facts that what we do so attachments again they need to be read Ebola and then to be is useful but not essential.  So what is essential will be in the the main part of the document what is not essential but may be relevant.  That will be in the attachments.  So thats basically it for this portion.  If you dont have questions.  will jump into the next portion that will be on visualization.  So we mentioned the visualization is an important part of presenting the data.  So lets talk little bit more about about what visualization can do for us.  Okay will share the screen again and will go and the the last part of the on the lecture before in class assignment.  They will be on visualization and how visualization can be done with private.  This this class is pretty much the first one after is the first one after the met or my and its the first is the first one that is less basic than it was in the first house.  So those of you with the experience encoding experience encoding in Python that from this point on that they maybe more engaged in the assignments because it would be more on the application than just on that.  mean that learn how to use the tool.  So we will like keep talking about how to use the tool obviously but with the specific application.  The application for the day is visualization.  The application for next class will be the text processing.  So the history of visualization is somehow related to the history of all of the computers we had.  So in the seventies in the eighties there was not much computer graphics that we can leverage on.  I.  started working in the eighties and there there was no windows so the the first one was mean larger distribution was the Mac.  and before the Mac it was it was with the subsystem that is by and the steep jobs with the Mac.  If you dont have graphical user interface.  There is not much that that you can do.  So.  In the 90.  In mid eighties we start in heading graphic and user interfaces but late eighties not the the computer.  We are not particularly powerful meaning.  You cannot do much of the rendering that you may need.  So rendering is essential to have good representation of images on your screen.  If you dont have that then graphics and visualizations will not be good.  so its pretty much sides approach on one side that you develop more powerful hardware.  On the other side you develop better techniques but you cannot develop the good techniques without the hardware and that can support you.  So if you look at what is happening now im using Mac that is Apple City on so in the past that we had the the gpu the the the CPU the central processing unit the doing all the calculation.  And then at the certain point we move the we introduce the Gpu the graphical processing unit to handle up the the video.  Now what most of the companies including apple with this apple ceiling are are blading the line dividing the to.  So when you do calculations that are more complex automatically the operating system is using one of the 2.  So the gpu that is intrinsically parallel because its its addressing the pixels on the screen and the so intrinsically parallel.  Then you use that im not saying that these are all good though is good because its more powerful.  Its faster and thats for sure on the other end.  im having really bad time using some of the traditional machine learning libraries like tens of flow that is not running on my new Mac.  But mean thats mine of things again that the history of visualization is highly correlated with the with the history of the hardware.  So now we talk about visual analytics meaning visual so that can really tell you story right away without much of interpretation.  Thats kind of media approach will never really happen reality.  But some visuals are more self explanatory than others.  So you want to be sure that you you go in that direction.  remember many years ago visualization of the traffic in Singapore.  So they came out with this visualization.  We had the map of Singaporea changed the by the hour based on the traffic meaning that the more traffic and the distance between Point and Point will be longer less traffic a.  B.  Were closer.  So thats kind of meaning stretching the the the actual map based on the the the traffic in in particular moment.  That was particularly interesting is an example very selfexplanatory visual but with the embedded analytics.  So there was the calculation of the traffic and mapping and the those metric in the the app some examples.  will go super fast whole part relationship.  Thats something that you can do.  Discovery relationships doing.  combined explored or in confirmation analytics.  merging together on multiple data types.  time view of events and analyzing the evolution in time.  So all of those are good examples of different types all visualization.  So before we go into Python.  want to go for moment to this book 202.  That is quite interesting book and posted that will pause an extract.  Its called the Out of Knowledge.  One of the things that like on this book part of the visual that are standing is the attempt of creating classification for different visualization.  So there are quite lot of different visualization.  But the certain point you need to define what are the user needs which kind of data is going to visualize What are the the interactions that you may want to have.  So the order came out with this chat.  There is one of the options.  Its not saying that is the only one of the best but its definitely good one where you have types and levels.  So you have statistical analysis temporal analysis and so on and then the level.  If its micro mes or macro based on that that you have different visualization that can serve you better.  will add also.  theres mean was intend to be for lines but you will see different visualizations based on the different.  Its kind of a.  flow chat that you can use to pick somehow the visualization and it seems to be most appropriate for your particular case.  So those are some of the options again that the book is giving way much more than that.  So its its beautiful book and then there are mean for each one of those.  Obviously there are explanations that will give you all the details.  so visualization that somehow is an So we have court.  So that is am 622.  That is visualization and risk analysis there.  Good Its good course.  Its been created by one of our engineering management professors.  and mean Im.  Mentioning that just to say that there is an entire semester just on that visualization.  So going back to Python.  So there are different packages that you can use.  So Matt Plot Li but is what we already know is very basic visualization.  Package is still the bread and butter for any visualization that you may want to have and some of the other including Cibona and in part bouquet are based on Matt Plot lab.  Its not great.  You cannot do very sophisticated things.  You can now generate right away HTML page but its doing its job.  See Borne is more he is is layer on top of that but hes also using Pandas and that means hes using the noon by meaning that you have an environment that there is more structure Gg plot that was originally developed for Oura.  There is python version no one is really using match but it it.  It is there.  bookie.  Its more recent and the main advantage of book is that its generating automatically the HTML.  If you want to do things that are more complex like dashboard blockly is probably the way to go.  So let me go now in the next few minutes on.  and you will have by the way the solutions for the midterm in canvas in moment.  So let me go into the visualization and let me start with the bouquet.  So thats how bouquet.  plain basic code that can be.  So you import the the like the libraries of sub libraries that you want to.  You create file that will be generated.  You pass the characteristics of on the graph on the visualization you want to create.  You pass the data.  You specify what is the type of visualization you want to create in this case is line with those and value thats the with of the lane.  the line and then you you mean with this statement that you presented on the screen.  So if run it erez agmoni.  So thats good point mean is generating an HTML.  So if you look at here its really an HTML page that means that you can export it.  You can use it 150 you you you can send to clients.  You can embed it in into website.  Things like that so its kind of interesting.  So have bunch of samples so so let me skip some of them.  will give you.  Then you know the the the the script.  So thats another one.  Now let me run it.  So thats little bit more complex.  So you have multiple charts.  So keep in mind that you can zoom as you like you can reset it.  You can download it if you want but it is already in the HTML format.  So just to make it more complex so let me jump to the most complex.  So that is this one.  So you are giving more complex that is the low as carve more complex points to dot on your screen that a.  And you are using the bouquet for the visualization.  So what you will get will be something more complex like this one.  So you can define again the caller.  So the shape and obviously the the values in your visualization.  So those are all examples of.  Let me now go to examples of seaboard.  So see born again that it its not as sophisticated as for something mean in terms of visualization not as sophisticated as as bouquet because its not generating any HTML but its more sophisticated in terms of the underlying.  Layer.  It is because it is Pandas.  It is known by.  So in this case is basically working on data set that is relatively large.  So let me run it up.  Thanks to my powerful Mac is going fast.  Im kidding so its pretty much what you would get with Matt Plotley but but its kind of nicer.  So finally.  let me talk for second on the about plot Lee.  So there are versions of plotley.  One is open source one is commercial the commercial as more feature.  but the open source is working just fine.  mean when you use it for commercial reasons you may want to pay the commercial fees.  So in this case Im using data set from let me just run it just to see the differences.  So in this case im analyzing schools.  So if you think for second.  mean its relatively complex script.  You you will have that and is analyzing universities by different accounts.  So and its generating the HTML so and its generating in kind of cool way.  So you have multiple.  So this is pie chart.  You have the buyer chart with the hoovering that will tell you where they are from.  and then you have line chart that is pretty much the same as the other.  So theres what rank on the top 100.  The universities in terms of sanitation in terms of teaching.  so we are not there.  By the way.  we would go there.  So another example of Plotley is type of visualization that like lot.  Because how about how much stories you can extract out of.  That is San key diagram that was originally created to analyze the the the the flows all that.  So its easier if run it and you will say it.  Its what you have.  So you have the starting point and the endpoint.  So think about the traffic.  Think about the pipes.  Think about concepts evolution.  So you can see how powerful this can be.  So we created something similar to understand that now how people generated that their knowledge in given field.  So from the very beginning to the user of that knowledge.  so it its very cool.  You will have that in you are combust.  So let me stop sharing now and let me go to the in class assignment for 10 min 1015 min and then we we go back they have me close all of this.  go here and in class assignment up.  Okay and let me share this screen again.  All right.  So then in class assignment is about working with the a.  Csv file.  That is collection of all the tweets.  collected it years ago from the whole book and you open the file.  So the tweets and the files being the file with the tweets and the file with the supports You know when that means with the so called the file into list that that tweets into Pandas structure remove the software.  So using the software list perform additional cleaning as needed and then calculate and print the the top 10 words and the top 10 standards.  So let me stop sharing.  Let me post it.  Thank you.  Okay.  Im publishing everything.  all right.  So im creating breakout rooms.  We have rooms participants each.  You have about 10 min 15 min to work on it.  The rooms are open now.  See you in bit.  Okay.  So we are coming back.  Sorry didnt pose the recording so if you will listen to the recording you would see quite lot of mapping.  So this about 1015 min of nothing my apologies so another 25 so all the rooms will be closed.  So give us another few seconds and then we will set s.  Now.  Okay so you are all back.  You want to come back.  Is there anyone who want to say something present the results or just sharing the experience All right so let me share my screen.  And this Okay so thats basically what we have.  imported pandas and counter.  Im in the Probably this is script that they did the No.  Totally recently.  Probably if would do now would have done in different way erez agmoni.  But thats the way it is.  So reading into Pandas data structure the Tweets reading the soapore file into lists 150 then creating another data structure with the the send that the screen name from this one creating list getting the top 10.  mean that there are other ways that again would have done it in different way.  But thats the totally legitimate that is is working fine.  So the top words initialize at least of an empty list.  Then started the iteration within the data structure.  little bit of transformation or lower or alphabetical.  Then created string out of the list because counter is taking list not string.  And on the list.  Then im getting the the 50 most call mona and thats going to be it all right.  So you have the top 10 centers.  So the top 50 words and thats basically it.  So questions All right.  So let me go into in the assignment.  So the assignment is going to be pretty much on working on Pandas.  So this assignment is one of the not so many assignments so that didnt change in very recent times because really want to be sure the students will know how to work with Pandas.  So you basically have types to sources of data.  So movies users rating.  So it is all about movies.  So the website is group L.  So Dot or with all the information about the movies.  And this is not the most reason the one that you have a.  As file.  So.  but you have it.  So there are some additional files to get some information about it.  But you basically have movies.  users rating.  You have occupation for the different users.  You want to replace the numbers from to 20 with the what they are.  You want to pre into the last rows.  You want to find the occupations giving the highest rating for movies in the data.  and thats basically if you want to merge the data using this form of managing.  There are several others.  You will use the txt fine that you have this moving Answer with me Dont Txt that will really drive you into how to do it.  Oh again that is it is not one of our most complex assignment but is good way to practice with pandas that are so essential for pretty much everything we do.  And was not sharing.  Oh thats better.  Okay.  help talking about that.  So thats the homework.  So again you have the Pdf.  The Txc.  That will give you additional information.  You eventually have this website.  If you want to know more.  If you want to update the device and using the files that are more recent than those feel free to do that so they are available in their website.  the structure.  Its pretty much the same.  And thats basically what you what what you want to do.  So you want to pre in to print the the rows for each one of the other frames merge it.  print the number of records for each of the the data frames.  and then you want to replace the occupation and that its originally in to 20 with those in the last rows of the data frame.  and then up in the occupation giving the the higher the highest ratings for the movies on the the the the the the the the so thats basically it.  If you dont have questions.  This the end of the class little bit over time.  My my apologies.  Its 808 and will make sure that you have everything again.  We are still having here and there are some issues with the population of the canvas shell that we are using for this course.  So if you have any issue like the previous one and the answers in the quiz that we are pretty much identical.  Send me an email and will act as as soon as possible and definitely will have no impact on your grading.  If you see that its something missing and let us know and will definitely address it right away.  Okay.  So if you have any complaints send me an email just to be sure.  Send also an email to she you.  So you have double possibilities to have your issue result.  Okay.  So thank you all.  really appreciate you being here and we talk next week.  Leona Chia Thanks.  Thank you.  SYSTEMS ENGINEERING RESEARCH CENTER Extracting decisionmaking metrics from text Semantic Approach by Dr.  clipizzistevens. edu This material is based upon work supported in whole or in part by the U. S.  Department of Defense through the Systems Engineering Research Center SERC under Contract HQ003419D0003 TO0150.  The SERC is federally funded University Affiliated Research Center UARC managed by Stevens Institute of Technology consisting of collaborative network of over 20 universities.  More information is available at www. SERCuarc. org March 2021 sera tanee The Context Scenario ENGINEERING RESEARCH CENTER Interstate strategic competition not terrorism is now the primary concern in U. S.  national security National Defense Strategy 2018 TechnologyInnovation is key factor in this competition We cannot expect success fighting tomorrows conflicts with yesterdays weapons or equipment National Defense Strategy 2018 Know the enemy and know yourself in hundred battles you will never be in peril.  When you are ignorant of the enemy but know yourself your chances of winning or losing are equal.  If ignorant both of your enemy and of yourself you are certain in every battle to be in peril Sun Tzu The Art of War Among the key capabilities Command control communications computers and intelligence surveillance and reconnaissance National Defense Strategy 2018 March 2021 Key Issues Shaping the Systems we developed ENGINEERING RESEARCH CENTER The reality we target to monitor first and evaluate then is unstructured and unpredictable topdown modelbased approach wouldnt work Majority of the potential sources are textual while we need measurable semantic insights TextNatural Language may provide different meanings for different peoplecontext Most of the insights we could get are from the evolution in time of specific elements The evolution in time may contain indications to predict future scenarios March 2021 nqeeteea Extracting Semantic Metrics from Text RESEARCH CENTER To reduce the risk of wrongsubjective interpretations when making decision based on text we need to extract metrics out of it How do we get numbers from text Statistical methods provides limited view because of their lack of semantic analyses If we use semantics how can we deal with subjectivitycontextuality of the interpretation in text that can or cannot be in given semantic structures such as ontologies Plain use of generalized reference corpus does not provide any subjectivity The task of analyzing text has bias that is related to who is readinganalyzing it.  For example if we want to detect emotions in text ecstasy may have different meanings for narcotics officer Vatican scholar or psychologist March 2021 avenue The Room Theory ENGINEERING RESEARCH CENTER The room theory is way to address the relativity of the point of view by providing computational representation of the context we want to use to evaluate the text The non computational theory was first released as schema theory by Sir Frederic Bartlett 18861969 and revised for Al applications as framework theory by Marvin Minsky mid 70 For instance when we enter physical room we instantly know if it is bedroom bathroom or living room Roomsschemataframeworks . . .  Are mental frameworks that an individual possesses mental framework is what humans use to organize remembered information Represent an individuals view of reality and are representative of prior knowledge and experiences We create computational rooms by processing large corpora from the specific domaincommunity generating numerical dataset embeddings table.  We consider table as knowledge base for the contextpoint of view The room method makes the whole approach easy to be moved to different domains The key components are How the Room Theory Works Room theory enables the use of contextsubjectivity in the analysis of the incoming documents Contextsubjectivity can be the point of of view of subject matter expert The contextsubjectivity in the analysis is represented by domain specific numerical knowledge base created from large domain specific representative corpus that is then transformed into numerical dataset embeddings table 1.  point of view for the comparison the room.  This is represented by the embeddings table extracted from largerepresentative corpus from the specific domain 2.  criteria for the analysis the benchmark.  This is list of keywords defining the what we are looking for.  Different benchmarks would provide different analyses March 2021 08 SYSTEMS The components ENGINEERING RESEARCH CENTER The Lego approach Systems are developed as growing prototypes based on components developed offline Components cover the tasks the systems have in common Components team developed 61 tasks 4900 loc Sample of tasks are pdf txt text cleaning ngramming text vectorization room theory March 2021 Case WRT1010 Title Meshing Capability and Threatbased Science Technology Resource Allocation contract HQ003419D0003 TO0150 This research was focused on providing computational model to support the planning cycle injecting relevant threatbased intelligence and operational scenarios into the more traditional capabilitiesbased planning This approach will better inform the technical communities charged with future systems developments and has been piloted in late 2016 at the U. S.  Army Combat Capabilities Development Command Armaments Center CCDCAC March 2021 Logical View of the Threat Based Decision System TBDS The system Threat Based Decision System TBDS has components Risk Decision Support System based on the competitive scenario and the threats detected from the incoming text Technology Monitoring System analyzing streams of domainspecific documents and detecting emerging technologies Technology Forecasting System analyzing streams of domainspecific documents and forecasting comingprobable future technologies The TBDS has user interface to input documents to evaluate was developed over years by team of 20 people.  The minimum viable product has been released at the end of August 2020 TBDS The Technology Monitoring System Demo ENGINEERING RESEARCH CENTER The Technology Monitoring System TMS scans the horizon using streams of domain specific documents detecting emerging technologies and forecasting comingprobable TMS is semantic radar screen for upcoming and future technologies along with technology taxonomy generator The system can monitor any other user defined topic using any given point of view for the analysis March 2021 12 Predicting Technologies ENGINEERING RESEARCH CENTER The future cannot be predicted as such but in areas such as technology and science most of the new is based on an evolution of the old Leveraging on the room theory to provide the point of view we represent in time the technologies as either points in space or as network of technologiesapplication Using predictiveML algorithms we can predict the new interactions and relevance of the technologiesnodes meaning the new applications for technologies or upcoming technologies Support Vector Machine 2012 March 2021 13 TBDS Use Cases The Questions We Answered ENGINEERING RESEARCH CENTER Horizon scanning Radar Screen for emerging and upcoming technologies What are the technologies that are emerging that may have been missing How are the new technologies related to the older ones How is given technology in terms of life cycle is it growing or fading out How has given technology been applied Considering the past and present technologies what are the possible technologies in the future Considering the use of the past and present technologies what are the possible uses of the same technologies in the future March 2021 14 ee TBDS vs.  Commercial Solutions ENGINEERING RESEARCH CENTER TBDS is the result of an applied research and is optimized for the specific need It is based on the latest academiclevel researches The focus for commercial solutions is on text summarization keywordsconcepts monitoring and traditional topic detection There are no available commercial solutions that can analyze text by extracting semantic insights according to predefined point of view March 2021 15 Case WRT1023 ENGINEERING RESEARCH CENTER Title Analyzing and Assessing Contracts for Embedded Risk The goal of this research effort is to apply data analytics to understand the assessment processes undertaken by contracting officer.  The intent is to bring significant efficiencies to these assessment processes and develop prototype tool covering relevant parts of the DoD contracting process from beginning to end March 2021 16 everems WRT1023 Key features ENGINEERING RESEARCH CENTER Leveraging on current MO and literature create logical framework to classify requests based on given Contract Types Create computational model for the logical framework Create visualization systems to present the results Deliver the results with an agile approach developing prototypesproofs of concepts with increasing capabilities As per our contract during the first year we developed an early prototype to prove validity of the approach.  The prototype covers the basic functionalities highlighted above but with limited robustness interactivity proactivity and reusability March 2021 17 The context scenario ENGINEERING RESEARCH CENTER We have been informed of the existence of 10 different contract types some of them with relevant degrees of similarity Working with the Sponsor we identify keywords that are characteristic of each contract type.  No plain combination of those keywords leads to an exact classification The classification is rarely black and white decision and is mostly based on the knowledge and experience of the contracting officer March 2021 18 eee eee ee ee The value of the knowledge base Coverage of the room We started with 200 documents corpus that generated knowledge base not able to identify the keywords either properly or at all The updated knowledge base is based on 537 documents and is performing much better Differentiation capability With the new keywords and weights the system can better differentiate between contract types Classification results The ability of the system to differentiate between contract types is calculated using PCA and performing tests for within group distances vs.  between groups distances and then running MonteCarlo Simulations to generate validity report RESEARCH CENTER afs STEVENS INSTITUTE of TECHNOLOGY THE INNOVATION UNIVERSITY Thank you sy Dr.  NLP clipizzistevens. edu httpsniplab. sercuarc. org Assignment live session should be this one.  Okay.  So theres assignment is the inclass access is 39.  So you have about 15 min to work on it.  So you have you want to go into any newspaper online mean New York Times can be anything.  And you copy and paste.  So you select given text.  You copy and then paste it into so you create text file.  You can use word or any other and then once you have the file you already have the soap war file.  You open the file the files you read them into.  Later you remove the So ports you eventually remove other words that are very frequent like remove the Facebook in the previous and then you calculate and pre into the top 10 words and you will generate word cloud using cloud that should be in right here.  Okay so let me stop sharing and let me create breakout rooms.  So we have for breakout rooms.  We too participants each room.  will pause the recording.  Once create the rooms create an opener and you have about 15 min need to work on it.  Okay all the room Sarah Opener.  will make sure that everything is available in terms of files.  Were talking 15 min.  Alright Welcome back Let me resume the recording.  So we have another 30 before the rooms will be officially closed.  So lets wait there.  So what we are going to do now would be.  will ask you if someone what to book about what you did.  If not will present possible solution.  Then will introduce the assignment for next week.  Alright so all the rooms are closed.  Any volunteer anyone want to talk about what you did Hey You dont have to but just to share the experience.  Session issues that you may have had.  Alright.  Okay.  So let me share the screen.  Let me go here and.  So we are recording.  And thats fine.  So mean skip the step where take the text and create the txt file that because otherwise we wouldnt have time.  So use the same Russian agent that they use that in the other example.  So what they did there was basically importing the libraries that they needed.  Open the files.  So Russian agents and stop words initializing the empty lists with the the soap that well contain.  The stock ports and the text reading the stop words into the.  So what list Adding some of the work so that know that are very frequent.  Than doing importing the file and doing little bit of cleaning so meaning and removing the Hmm.  And the special characters and the spaces left or right with strip splitting meaning and generating for each line that Im reading list and then Im looping up into the list transferring the word into lowercase and then im looping into the list transforming the word into lower case and removing the stopwards.  So mean if it is not in store port.  So then will update the the word into the empty list.  So at the very end have in in my list this txt words would have the list of elements.  Of words.  Then removing the non alphabetical with counter function that they imported right here.  calculate the the most common.  10.  Then generate in the work cloud the same way did in the other example.  So if Thats me If run it.  So you have the what cloud and you have the top the the 10 words so that are more frequent.  mean that obviously its the same information in this sort of table and in the workplace.  So you have poster.  That is the biggest you have rush on video and account.  So that are the the segments even if accounts doesnt seem to be so big.  But thats the way it is.  Alright.  Okay so let me let me close this and let me go.  Oh possible questions Okay.  So if no questions.  will share again the screen and.  want to show you this website.  So this website mentioned is before is .  That is an interesting website analyzing controversial issues in societies.  So every something they update with the issues that are more controversial at that particular time in the.  So you have some issues that are kind of here since quite while and some that the seems to be more new topics.  You can pick.  mean there are several categories.  So lets say artificial intelligence.  So you have description of the concept and then you have pro corona for the question is artificial intelligence good For society.  So you have pro corner and youll have several.  All those opinions.  So thats basically where we are going to get the data that we will need for.  So you can pick anyone.  All the issues.  So.  So was showing aificial intelligence.  But as you saw it there are many other you can pick whatever is resonating the most with your interest.  The goal of the assignment is to compare the texts.  What comparing means that means that you want to extract some matrix that will give you somehow way to make the compiler.  So you want to clean the text removing software whats shorter than characters words and characters that are not relevant with like we removed the Facebook or Russian in the previous example Because we know that it was very very popular.  You want to remove the punctuation you want.  You want to remove that end of file and black line.  So using strip then using the library.  Rather you want to calculate the sentiment for the texts you want to extract backgrounds.  So you have the example.  Using an SDK you want to create the work clouds for the texts.  So at this point you have the sentiment.  The backgrounds and the word cloud meaning.  You have elements that you can use to do comparison.  What you are going to do will be to write brief report.  Couple of.  With the URL visuals meaning the backgrounds the word cloud and the results of the sentiment.  Analysis and your interpretation.  It is not description of the process so dont write down.  clean the text.  Im imported the libraries applied by those are the results.  So is an interpretation.  You need to tell me the story.  You dont need to tell me the process because the process is already here.  mean know that.  So want your take.  want your interpretation of the sentiment.  The biogram sir the word cloud.  Why there are those diagrams that are more relevant.  Why there are those.  Whats that Theyre more relevant.  So its brief report.  couple of page would work.  You will submit separate files.  The Pydor scriptor and the record.  And thats basically it.  Questions on that.  Alright.  Okay.  So thats basically it.  Its 807 slightly later.  But not too much so if you have any question if you have if you feel that there are some open issues send me and see you an email just reminding us that theres still something that we didnt do mean we are receiving quite lot of emails.  So overall.  have.  dont even remember if 75 80 students.  Okay on top of other things.  So we may just hmm have left your email in the mailbox without processing it.  We apologize for that.  So send us reminder.  Please.  Otherwise we will talk next week.  wish you great evening.  Oh do we have class today 441 Yes believe so.  446 Hello Hello anybody.  504 Its 508 30.  509 So lets start the class.  511 First of all.  515 Is there any open issue any something that you want to bring up and 516 review discuss 525 Scott Guetens Yeah Professor had couple of questions about the quiz for this week.  527 Yeah.  Question 5.  531 Scott Guetens was little confused.  What specifically was asking.  Like it It seemed like so it says the answer was none of the above but it it seemed like from like when was researching.  534 Scott Guetens It was asking about the like 544 Scott Guetens classification models.  Svm naive base rainforest and none.  548 Scott Guetens And it said the answer was none but 554 Scott Guetens from what was reading it seemed like any of them could have been applicable.  557 Okay what was the question just reminded me 600 Scott Guetens it was.  Assume youve collected 5000 textual social media posts and your objective is to develop classification model that it classifies into categories positive negative and neutral.  606 Scott Guetens and then which model can be employed for the task.  619 Scott Guetens And the options were none of the above Svm.  Naive bays and random forest.  And said Svm.  623 Yeah mean strictly speaking that when you want to do classification.  632 mean either classification or class setting it because in reality the the question was more on clustering than in classification.  If you want to do class setting.  643 you may not want to apply models requiring supervised approach.  656 So if you have your social media data set.  705 and 711 mean that all those methods the the the options are on the supervised the approach.  713 But you dont have supervision that in a.  In that case if you had supervision and then you can apply pretty much any one of them.  725 because you dont the approach has to be unsupervised.  and none of them.  Its streetly unsupervised.  736 Then mean you can stretch things so little bit.  748 but the straight answer is none of the 754 Scott Guetens Okay.  All right.  758 Scott Guetens also had question on Number 7.  Im sorry dont want to take up too much time.  800 Scott Guetens and the options are sentiment analysis speech recognition machine learning translation sorry machine translation and advertisement matching.  810 Scott Guetens So it says the answer is speech recognition.  But dont see how speech recognition is not an application of national language processing.  823 Scott Guetens Well again its one of those cases so that there is no real black and white because it really depends which kind of speech recognition you do.  831 meaning that in strict terms it is not really processing text.  When you do the process in text.  846 You do some of the things that we mentioned last time 858 in the speech recognition.  You basically are mentioning words 902 that you you here with words that are in in sort of cross reference table.  910 Then things are never black and white meaning.  There is no one to one 920 replacement for the world for the for the sounds as the world 929 meaning.  would advise the number and will get more answers because 935 you are right.  Its its board the line.  It really depends how you do the speech re recognition.  If in the speech recognition you apply semantic rules.  945 then at the very end meaning that that you do one step.  That is kind of mechanical.  But then the th that is set that is more semantic and then is more on the Nmp side.  So that thats great points call.  Yeah appreciate that.  Yeah all right.  Thank you very much.  appreciate you taking look.  Sure Thank you.  All right.  Other questions issues.  Okay.  So lets move on.  Now let me start sharing the screen and let me go here minimize this windows here and okay.  So what we have in the agenda is reviewing the homeworker.  We already spoke about the quizzes.  Then we will talk about what mining primarily and we will.  We will talk little bit about the final project.  250 and we will do an inclass exercise.  We will talk about web mining webcrolling whatever you want to call it.  mean the the topic is not as wide the for sure as natural language processing.  but it can be pretty wide.  It really depends on specific cases.  200 not all the websites are created.  Well mean you may have crawling that in some cases its kind of straightforward but in other cases we really require some sort of strategy erez agmoni.  We are not going to do that that way.  We will mention it but we will not do it.  250.  We Dont offer courses on web mining the school of business does.  Im.  Not totally sure that mean that the topic would require an entire course.  But this is just to say that there is wide topic while natural language processing it it.  Its really wide and im creating courts on an Mp.  But on web mining we will use some of the approaches.  We will do any class exercise and you will do an assignment at home on the same topic and that could be pretty much it and then you can use it for dont know for the final or something that you may want to do but anyway.  So the previous assignment was about analyzing the the website Proconn Org and compare the sides.  the pros and the on given topic.  So im using the same assignment since while because it its pretty generic and it really depends on what are the topics that you are picking.  So the example that you will see in my solution is not the most recent one because dont even sure that the same topic is still available about the concept that will be exactly the same.  So you basically copy and paste the the sides of the opinion.  Then you do some cleaning.  Then you you calculate the sentiment.  diagrams and the word cloud and then you will write brief record.  That was the previous assignment.  So let me go to by charm.  and thats the code.  So im importing the different libraries.  So the counter for counting elements.  We will use couple of times in this script.  but thats sentiment for the sentimental analysis work cloud.  and not clock but because its required by water cloud.  use the function we already mentioned the opportunity of doing so.  But for a.  When you do any form of natural language processing you may want to have you.  You want to create your own function for cleaning the text because its something that you will do over and over and probably have it once you can reuse it.  This function in particular is not the most sophisticated way.  wouldnt use it alpha that much because we know that its not the most reliable or the detecting.  If the content is no medical or not but is an example of function for cleaning text.  then you have little bit of explanation.  The way is mean the the comments sort of shaped in this way because there there is library in Python.  They can go into the code and create the documentation out of the code using the comments in the code posted with this specific format.  But mean you Dont need to do that but its kind of useful lot to have description of what what are the the parameters in input and what is going to be the parameter for the output.  because down the road that you may not remember what you did.  But you have clearly as stated here.  So thats function for cleaning text opening the files.  but mean at the pro and corner that previously created.  Then opening the stop or file.  initializing the the lease so that we like contain those elements.  So the list of stopwords to the list of Pro Ancona created different variables for the entire line or for the single words setting the parameter for the cleaning.  One of the parameters is the minimum length for the word.  Assuming that words that they are shorter than characters.  They they have no semantic meaning.  So you send minimum length.  Then loading the stop word the added the some of the words so that they know that they are going to be there because this was pro corona marijuana.  and obviously cannabis.  So marijuana drag.  Legal legalization is going are going to be popular and mean they are.  They may hide so that they want to stress more.  Then Obed in the files im cutting.  so that are not on the proper length.  So in this case.  if its not an empty one and the len is more than 30 because it im not considering comments that are too short to get real opinion.  But mean that could have parameter to make it more flexible but the same concept.  So this is pro and con.  then im doing the cleaning for both of them using the function.  Then calculating the the common the most common 10 for each one printing them.  Then calculating the diagrams created the that will hold the the values well.  Then doing im creating.  mean this is definitely not the most optimized and the most rigorous way to calculate the diagrams.  So dont know if mentioned it to you.  brought paper on how to Create diagrams.  So it is.  Its not exactly an easy task if you do it the right way.  So in this case Im.  Just taking all the awards that are one next to the other and then this this would be largely and then taking those that are most common.  So thats basically what Im doing.  And Im adding mean im joining the words with an underscore.  And then taking the most common mean on those candidate playgrounds.  and im printing them.  Then.  Sentimentalities.  sentiment analysis.  The the library is taking strings and not least have list and transforming the list into string calculating the the components of the sentiment positive negative and nutral.  Then for both.  could have use the function for that but mean just to repeat it.  Its not elegant but mean its just too but could have been better then printing it then generating the world cloud so same thing.  joined the pro cones.  could use the the same that did before but thats fine.  And then setting the param the parameters for the what cloud generally in the world cloud and printing it.  So if run it.  have the top words with the quotants.  if most common biograms.  that kind of make sense so sentiment analysis.  and then the word cloud here.  So now in terms of the interpretation that mean.  Obviously everybody has their own interpretation.  So when you see something like this you take out the new parallel because its not giving you much of the the insights.  So you have the pro that is more on the negative mean both are more on the negative sentiment analysis.  Its kind of very row.  not very reliable measurement.  When need to do something that is more mean sensitive.  use different methods.  use more than the sentiment the the emotions.  have classification of motion and calculate the the similarity the words so or the the phrases or the documents may have with those emotions.  Emotions are are better defined.  So we know what an anger is.  We know what joy is sentiment is kind of its combination of things.  So positive sentiment makes by joy.  But it really depends who you are.  So and thats the point.  So you have both with more negative meaning.  The people supporting the legal use of marijuana are stressing more the negative aspects that doesnt mean that the pro is actually corner.  But is they are using more negative arguments to support the the pro marijuana that could be.  If we do not legalize marijuana there will be more illegal news or more criminality.  So those are negative concepts on the corner.  Yeah and meaning against marijuana.  They may have used the arguments like it would be sort of endemic user Everybody will use it.  There will be no control things like that.  So what is interesting is the fact that the against marijuana they use more of positive arguments than the the pro marijuana.  Then that the what the cloud the mean its probably mean dont know how to interpret the State.  That is so big.  But probably the argument was the legislation should be at the State level.  The being so big in Washington could be Washington should take format position in one way or in the other.  Then alcohol.  Its probably saying the user of marijuana is not going to be that much different from the user alcohol alcohol.  Its legalized.  We dont see why we should use we shouldnt we the marijuana or vice versa someone could say the number of diseases or casualties related to alcohol is pretty high.  We do not want to do the same with marijuana so this could be reason legalizing should go.  Then you have Colorado.  That was one of the first seats legalizing marijuana crime could be related to the fact that on the pro and the call the the pro legalization could be.  It will reduce the crime.  The code now could be.  People would be less in control of themselves and there will be there could be more crime whatever you read them mean in this case im.  Using just one of the dont remember which one it was.  It was and the pro.  Okay.  So thats basically the all assignment that you saw the python.  We verbally analyze the results.  So if you go in analyzing the diagrams mean the by Grams are not telling lot.  Probably you may have wanted to remove the United States because it is so popular.  So the pro the fact that it is economic activity could be related to the fact that then having legalized use of marijuana would be good for the economy creating Jobs emergency room.  could be in the call and could be.  There will be more people in our emergency rooms.  Heavy users so it could be could point to our individual.  So.  having and heavy use of the Madijuana Black Market.  dont know how interpret it but would expect more on the pro saying this will reduce the Black Market.  but probably could be related to the fact that some people can think that the people may become more prone to the use of or recreational drugs and may get additional drugs from black market for drugs that are not very well.  So mean that those are all examples of how to interpret the data on at the Topwards states Washington mean those are the same that you saw in the the what cloud the world cloud the the sizes of the words are based on the frequency on the awards.  So in the document.  so.  And we have the same thing that we had in the what cloud So States.  Washington alcohol.  Those are united is probably part of the United States that should it be removed.  meaning we should have removed the If you go all the way here we should have standard that the so forth.  So with the United that because probably mean not States because United States we want to remove it.  We do not want to remove so when they are by itself.  anyway.  So thats all about the the assignment questions issues All right.  So lets move on and lets go to the web mining there.  So the reason why you saw this presentation for the engineering management program is because we are introducing the program in the Chinese market with the format that it is one semester in China to some assets in the Us.  And and Erez Agmoni and we were reviewing the material.  One of the things that was kind of interesting in the conversation we had today was the fact that the school of systems and enterprises as the highest one employment rate across Stevens is 98 so the average on stevens is 95.  After graduation from master degree so the average is 95.  We have 98 in in terms of salary.  We have one or what program so that is software engineering with 105000 as for salary.  That is the highest in Stevens we are.  The average is around 95 97.  So mean just give you some background information.  all right.  So what mining using Python We we talk little bit about the what web binding is and then we will go in python to see how to do it in practical cases.  So what is web binding web Mining is basically going into into webpage and download the scrape content if you think for second this is what.  in sense the different web such sites are doing what Google is doing what being is doing.  So they go into the page.  So what they actually do is to read the content.  tag the content and then match the tags with the requests that you may have.  we may want to do something different because mean the goal of so changing is just to let people go to the page.  This the specific page that is matching the the specific request.  We may want to do something more.  We want to extract the the content to do some semantic analysis.  We want to extract some metrics so to do some combined the calculation.  Erez agmoni.  There are sites that are collecting information from different sites aggregating and adding layer of integration and some additional analysis.  You may want to do web mining for optimizing the performances of your own website for seeing what is the distribution of content to analyze if there is any problem going.  So for several of those examples web mining is useful that even if mining mining what mining data mining that those things are really different.  So data mining is is more on that working on the even if sometimes theyd be not so much the being text or or similar but its more confined.  So you know pretty much what you are going to get with web mining.  You dont know what you get because you dont have control of the content.  You may not even know what the structure is because the owner or the website to change the the the structure overnight.  And your beautiful script that was running yesterday is not running today anymore.  So when you do web mining you really have quite lot of issues and obviously the owners of the websites and in particular if they offer the content as as service for money they want to avoid that.  You just go there and scrape the content.  This is the case for news.  This is the case for sites like linkedin so meaning that they are really doing their best to to make the life on the web scrab or as much difficult as as possible.  Nevertheless there are cases where this could be useful anyway.  So there are sites that are open.  think about all the sides that are from the government.  You want to download the all the facts or the official filing of companies.  Those are those.  Those are information that are publicly available.  You want to have the list of patents.  Things like that that they are mean not saying it is easy to get them but those are public and you are not infringing any or limitation just downloading it.  Youre just doing it in an an automatic way.  What is the web that we want to Mine is huge number of page so so no one can really count it.  So 63 Leona it could be 100 threed on and we wouldnt notice the difference that there is lot of duplication and some of the page are not indexed.  If they are not indexed they they are part of the so called dark Web.  Not necessarily.  The dark web has to do with the illegal activities and Doesnt do.  It only means that you cannot.  Google them.  So Sometimes people do not want to be googled because you is is pager that is restricted to the people.  know people.  will ask the the URL at the address by myself.  And thats it.  So thats possibility meaning that those are not indexed by by Google.  So again not all the page.  Someone was saying that.  using the metaphor of the people the iceberg.  So we see the tip of the iceberg.  But there is the rest of the iceberg.  That is the rest of the web.  So when we want to do web mining.  few years ago was teaching this topic to an undergraduate class and certain point.  The students were asking me questions.  Why do you want to do it First question and say on that Is that legal So on the first one.  Why you want to do it when there is Google Google is not giving you the content but is giving you the point to the content.  So if you want the actual content because you want to do something with the content then you need to go into the specific page.  If there is more than one page then more than one site then mean if you do it manually well take quite some time.  and then if the content is changing in time you want to create system that will automatically go there and get the content for you instead of doing it each time manually.  So thats why we want to do it.  The E.  Is it legal Well mean companies like Google made business out of it.  So if they are doing it the the planetary level.  why shouldnt be able to do it The at Mini school level Why we can do with the our own web mining.  So it is legal.  Up to certain point there was case few years ago between linkedin and small company.  So this is small company.  was scraping data from linkedin analyzing people up with the sort of abnormal user of job search in linkedin.  Assuming that if someone is changing the path of looking for jobs most likely is looking for job.  and the employer may be interested to know just to either make counter offer or just let them have the employee or if so.  This small company was collecting the data adding value every selling the the result.  Linkedin.  send legal note saying.  Erez agmoni what you are doing is an infringement of the terms of use because you are supposed just to look at the results not to use 150 to create business.  So it the the company was teeny tiny and compared to linkedin it to take the case for the small company pro bono just because he or she didnt like the fact of the big giant linkedin suing the teeny tiny company.  So the litigation that went on for quite long time.  couple of years.  So in the meantime and and theres more company one.  but in the meantime they lost clients.  They lost key employees.  They couldnt do Dave job in the proper way and they went out of business.  So the model of the story is you really need to check.  What is the thermal use of the web mining that you are doing May not be illegal but maybe some restrictions.  Some companies created the their own business out of web mining.  So indeed that now is one of the giants in job search along with the Linkedin.  Initially.  the only thing that we are doing was to collect job postings the from different websites and integrate them in the website adding layer of all the analysis mean filtering and analysis.  So that was the the initial web model or business model that they have in the business.  Then at the certain point they became pretty big.  They started the accepting the accepting sponsorship for specific job.  So and some people play their jobs in sort of an exclusive way into indeed meaning that they didnt have to scrape the the content.  But they have.  They had their own and they still have.  But the initial business model was no data that we are they own just integrated the content its great from and other websites.  So when we talk about web mining there are few things that we want to consider.  So first of all how web search is is working.  So we mentioned Google we mentioned being so you basically had the web with the all the paid.  So and they usual links that we havent on on the web.  You have this piece of software the web that is going into the different page and indexing them indexing means tagging by given keywords.  So each page will have several keywords that are defining based on the taxonomy that was created by the Google people or the people whoever they are to classify somehow the So once you have the the page index in the then you have data set with the all the page and all the the indexes.  mean that the keywords the tags.  Then you have the user placing up the equity.  and then what the search engine is doing is basically matching the keywords.  So and hes pretty much an exact match between the the keywords.  So in the queue and the the tags from the page.  and then the result will be presented.  Then things can be more sophisticated so can automatically correct misspelling just to be sure rather than getting what the user really needs can have synonym.  So thats an additional step.  So when the user is placing query then there is an intermediate piece analyzing that kind of natural language processing mean low level but sort of analyzing the towards the keywords eventually little bit of context.  So thats the basic functionality.  Google being another.  They also have the placement meaning.  We mentioned that you have the tags for the page is tagging the query from the user and basically what the add the index is doing is okay.  have one tag from or in tans from the greedy.  will match those stunts with the the list of advertisers with the same tang.  and then based on who is paying the most.  will place that piece of add on top of the list.  So the basic search engine as no AD management component but pretty much all of the search engines do have one.  So search engine as crawler that will create the the corpus of those tagging.  Obviously again you need to define what are the tags.  so meaning that you need to create sort of taxonomy of the page before classifying by the specific tags.  Then you have something that is the indexing.  So the spider is just collecting.  But then the indexer is creating the cross reference.  So you have tags and page and you need to be able to go back and forth from one another.  and then you have query processor that is getting the quidies from the user and matching with what is in the indexer again.  already mentioned that you may have query process or that is little bit of intelligence in it being able to work on like visualization on using bul.  So operator.  So so in Google you can do and or you can have must include the with the quotation.  So all of these are additional functionalities to the query process.  So but not the the core ones.  So the data on the Internet as we know are based on the concept of hyperlink.  So page with plain basic content that dumb content.  And then you have content to where you can click on it and you will go to different page.  So those are the hyperlinks and the hybrid links are linking page one to the other.  Thats an example of how our we is going back and forth.  So the they are based on language that is called the HTML hypertext markup language that is like structure with the mean header and food or that will be the same HTML.  And then you have the different components like chapters like paragraphs of document and each one as tanks that are on in brackets with either the tag or the content and all the content.  When you send the the request that could be just open page or or doing something more elaborated that you use protocol for requesting the page.  So when you go to dont know Cnn you write http call on So this Http is basically telling the browser and then the the server to send your request in format.  That is Http.  so and that in the Hdp.  There will be Ww.  There will be name Dot and domain family.  and thats the standard for Http and its pretty much the same if you are sending different types of request.  The request its that will go from your browser to the server as more information that you may expect.  So the server will see in this sort of back at the request for for the page.  But well also see information about the who you are.  So what is the the browser you you are using What is the type of encoding that you are using If there are cougis what are the cookies that can be used.  What is the type of connection you have eventually What is the the IP address that you are using the response The you see as page meaning an HTML file that again as more features in it.  So you also have what is the opening system on the server What is the the type of software that this is in It is being used.  What is the type of the release of the version of Http.  So those are additional information that 99 of the time so we do not use.  But if we want to have more information about either the sender or the receiver.  Then those are are available in the back and forth on the request Oops So thats another information.  will skip that.  So the spiders the crawlers.  Again.  We can bite them.  We need to be sure that we are using the the right protocol to go to the server and we have the right level so of the authorization to do it.  Keeping in mind that that when we work on on web page can change meaning.  We are not the owner on the page and the owner on the page can change it the way they want.  So if we go into the HTML and we are looking for one particular tag and take the content.  After that tag.  Yeah well the owner can change it if they change it.  Our roller is not going to work anymore.  Some other times information on on multiple page meaning you need to click on something to go to the next page and then you need to stop when you reach again on the page for that particular information.  So as you may not we can do that because we see we understand and we act for playing dumb cooler.  So thats not possible.  You cannot go to the page and get it the content if the part the content is on multiple page.  so there are ways of doing it.  So one of the ways is to have system that can sort of simulate the the user so there are the Erez Agmoni mean there are libraries in Python where you can download the an executable version of browser and your python will run this digital browser and it will act as it was human.  So those are little bit more complex so.  But its what we do when we have file with the higher level or complex it erez agmoni.  When you do search it really depends.  What is the strategy on the search So you can do Bradford meaning you go 150 from the root node to the first node.  Then you move up horizontally until you reach the end.  or you can go all the way down and then go up so bathes.  If we use fi or alli full meaning per scene for south or or last team for south approach there are pros and cones.  So if you use this approach for example you can get lost meaning there could be quite lot of all the levels.  and you will never jump to the next one if you use this one while you are completing one level.  things can change in the meantime and kind of will lose the initial relationship they had with the the higher level node.  So again it really depends on the type of search that you are doing.  When you get the data from server you use protocol that again one side is HTML in terms of page that that exchange.  But then you use protocol to get the page.  So in Python we use there are several options mean in Python there are always several options.  You can just ask Python to go to certain page and get the HTML.  You can use libraries that are specific for one category of page.  So there is library or newspaper that is called the newspaper.  and if you want to download it.  you need to install as newspaper K.  dont know why theyre using this notation.  Probably there is newspaper that is different one and they do not want to be confused.  Whatever is there is.  So one of the approaches is this one So let me stop here for second on.  and the let me go your.  And then when we go to Sharma with an example so beautiful Super that is from Ellis in the Wonderland is the Python library that is taking like structure like HTML like Jason.  ex Amanda.  and parts of the structure in that its easier to navigate.  So generally speaking you download the the HTML.  You pass the the HTML to beautiful super and then you start processing it.  So thats basically what we normally do.  So before going to the actual code let me spend min on the Apis.  think we already mentioned what an Api is.  The Api application program interface is protocol for exchanging information between the service.  So when you want to download the tweets.  and you use protocol created by Twitter to get or do something on the the tweets that are in date service.  Either they are to the website the the the web server or store in the in the server.  The Api is better option compared to web coding because its like contract that you have with the owner of the website.  So you are saying okay will give you my credentials.  So using the credentials so can do several things.  So some of the Apis are free meaning you just need to create the the the the credentials for the authentication process.  But there is no cost associated with that.  In some other cases you pay for you getting the data using the Api.  If you have subscription to news service you can download the certain number of news based on the contract you have through Apis so you will specify what are the mean the the the page you want to kind of based on the contract you have and you will get everything that you requested.  subject to the contract you have.  So if you have an Api either with free or paid access is definitely better option that just scraping the content.  Sometimes you dont have the Api and you need to do the the scraping we twitter.  You have limitation in terms of number of quidies you can do because the Api its free in that case but with the limitations they dont offer directly paid Api.  Probably you know mass will change something.  Yeah.  But in the past it was not possible and think it is still not possible.  My dissertation was on analyzing Tweets meaning.  spend quite lot of time on the and in the past it was free with limitations in terms of number of tweets that you can download in an interval of time unless you do things in different ways.  then that mean the way out is to create time based script meaning you download the the maximum number of tweets for the time you have.  Then you place your system in holding mode for few seconds and then you start again.  In In that case you will never reach the the maximum number that is allowed and you will continue.  mean.  We take longer obviously but you will get the tweets you want.  So again thats an example.  There is an Api.  You have a.  So those for our the that you are asking.  So the the credentials.  So there are credentials in Tweed.  You can do it directly using mean creating the script.  mean bomb with the query asking all the elements what you can use.  library in this case is that Twitter That will do in this case the authorization for you passing the the the credentials that you created.  and and then eventually you can use the same library to get the tweets you want.  So let me go now on the example.  So in this example im working on the the New York Times.  So if we go here and we do so.  Thats what we have right now on the the New York Times.  So if go here so im importing beautiful super and this library that is the one that we use to go to the website and get the the HTML.  So im getting in body the HTML page.  Then im using beautiful soup to parts it in tree like structure.  and then think printing the the content.  So if run it.  thats what have so have everything that is the the ruling was and so on that this one the shooter and this this one.  and so on.  So mean we also have things that we may not need that this min rate min speed that is those pieces of information is not something that we really want.  So anyway.  he is 32 before we go to the in class exercise want to spend few minutes on on the final project.  So will publish shortly the Thats it.  There we go.  The ideas for the final project so the ideas for the final project will be on this document that you will have online.  The final project is basically defining problem having data set to address the problem and then do all the data preparation for and then using scripts getting insights from the data set mit Ctl.  And that can address the questions you had in the problem definition.  and then they can explain your findings.  Thats basically it.  Now the level of complexity of the script has to be at the same level all the mean not less lets say than the level of complexity or the last assignments.  So if you go and see there are that right here we have about the 200 lines.  You want to have something that is at least Erez agmoni 200 lines 100 5200 then obviously not all the lines are created equal.  So there are lot of comments some blank lines 152 additional comments.  There is sort of redundancy here the dimension before.  So those could be combined in one single creating function ere mean that yeah If you optimize this code from under the 90 you can go easily to little bit more than 100.  Lets say 120 something around that so You want to have something around the 200 Why Im measuring the complexity by lines of code.  mean im assuming that there is direct correlation between the number of lines and the complexity.  Thats not always true.  but its true most of the time.  So you want to be sure that you have code that is with the mean complexity enough to go into the data creating enough insights.  So thats the goal that you have problem.  You have data set.  You clean the data.  Either.  W.  Whatever is the way you want to do it and then you create your your script to analyzing it.  Then you use the outcome to write the paper that could be around 10 page 15 page or included.  Its like some of the last assignments that we did think about the pro con but expanded.  Im.  Suggesting topics.  You dont need to to use those if you have better option if you have something in your mind that you want to analyze keeping in mind that you need the problem.  But you need also the data and getting the data sometimes is not so easy because either they are not available.  They are in format that is not usable or is not enough data so there may be quite lot of issues.  but leave it in open.  So for this class leave it open for the other classes.  Im teaching on Wednesdays.  dont give that students the option because this class is more and can have can manage multiple searches problems that you may have in class with 55 people.  It wouldnt be possible.  So we did in the past but it was complicated because you have data set then you didnt attach the data set and need to chase you.  What is the data set But it is this one.  But this is not what you use.  mean that if you multiply by 55 it will become really difficult to handle giving in mind that that we need to the final grade within 72 after the end of the final Erez agmoni meaning we dont have time to all the back and forth on mean then there is flexibility.  But the rule is 72 2.  So to shorten up on the time im giving you options.  So so analyze people.  Migration data is one that you would read it.  There is no need for me to go through that analyze research projects.  analyzing COVID19 data.  So each one as challenges.  they are pretty much equivalent.  So you will have all the the data set here.  So thats basically on the final think already published some of the examples.  If not would do before next week.  Okay.  So let me now go into what is it Yeah.  So the inclass assignment you will write program that will extract data from web page and perform some analysis.  So you can go to New York Times or anyone that you want to do it.  You want to print the headlines generate the word cloud the for the whats in the headline.  so will post.  Why you will reaggregate in.  mean.  in the different rooms this small script to be sure that you can use it to.  mean write the code for the inclass assignment.  and you will have lets say 15 min to work on it.  So let me open that the breakout rooms.  so there are breakout rooms with participants but each room created it.  Im open it.  will pose the the recording and will make sure that all the content that you need that will be available through canvas.  See you in 15 min resuming the recording up.  So its 58.  All the rooms are closed.  and people is coming back.  So questions issues.  Okay.  So let me share the screen and let me go through possible solution.  So for this case use the library that was mentioning before that is newspaper.  So when you import the newspaper you need to make sure that that you import the the library as newspaper 3.  K.  So even if when you use it in pydon you will just write in port newspaper.  If you try to install newspaper you not going to get it.  but mean once you install it up.  Its its little bit more as smart than the in way or doing it using request and beautiful super one.  So anyway imported this library.  imported.  What Cloud and Matt Plot lib.  specified what the the the is.  Then im extracting using this library.  Those are the parameters that that are required.  and mean that the library is giving little bit more feature so than the playing request.  But you you are with size.  You have the number of articles.  Then you have in that with with paper you basically have the content.  And then what you are doing here is downloading the the Rt.  Also and passing it.  and then printing the mean created the some.  So so if the article is now in August then some mean im reducing the the mean that title so that im getting you not me to do that.  So running it 131 articles.  Those are the titles and as the word cloud and will pass this would do it right away.  Yeah.  So okay need to post it 7.  Okay.  all right.  So for next week exercise Number 10 mining webpage surprise.  So you you will get any news website.  You will bring the headlines so generate the word cloud for the words and diagrams.  Calculate the sentiment to write an interpretation of the results.  Again write an interpretation.  so you will import the libraries.  You will remove what is not essentially using the the software file.  you will clean using soap for fights and other the headlines.  You will extract the diagrams just as in the previous assignment you will merge the list of single words and diagrams.  You will create what cloud you can or cannot calculate the sentiment keeping in mind that when you have diagram with the underscore it will not match anything in the sentiment because its not world that that is known by the and then you will write a.  What Pdf.  Document plus page with the interpretation.  So be sure that the interpretation is the original that there are comments that mean that the document is important because of the very end.  We are not in computer science.  So we do not write code.  But we use code for doing something.  Okay so thats basically it.  Its 803.  Again my apologies to be little bit late instead of 8.  So let me stop sharing.  So if you dont have any other question will make sure that you will have the in class except size.  So the solution on the in class exercise on your canvas just to use it eventually for next assignment.  And as usual if you have any question send me and she you just to be sure that you have more chances to get an answer.  We will get back to you all right.  Yes Good question for the final.  Is it group assignment or individual Well its typically an individual assignment that considering the type of class we are would be okay with doing group assignment.  small groups meaning not all of you as single group.  So in the specs wrote people could be people.  And thats absolutely fine.  Okay.  thank you Professor.  Do do we have to let me know through email if we form in my group.  Yeah mean we want to avoid the the the certain point.  We will grade it.  And then we would say you did the an identical the final and the other and you cheated.  So thats obviously not the case.  Yeah.  Now we go so its Wednesday April the nineteenth and its 33 001 and let me start sharing as usual the roadmap.  008 So we are.  019 So thats where we are.  So we are 022 April nineteenth.  So we will do sort of review of projects.  So this visualizing social webc.  That not necessarily is what we will focus on.  But we would talk about the things that are related to that 028 would introduce except Size Number 9.  Its size.  Number is going to be lets say the most complex of the assignments that we did so far 046 erez agmoni.  So thats what we will we will talk about.  We will do an inclass exercise and would be happy to address questions you may have on the final or the other.  100 Again will introduce the that size that is on the management side that lets say somehow similar to the one that you did the on the faculty courses.  115 Exercise that you did last time or times ago actually.  135 and and thats would be it so the in class except size.  would be the usual 20 min or so.  We may finish little bit earlier.  would see how things will go.  141 Okay before start.  Is there any question 157 on dont know the final the timing of the final the topics of the final 205 priyanka marwaha Hello.  216 Yeah go ahead.  217 priyanka marwaha Yeah this is had question like had mailed 219 priyanka marwaha proposal for the 223 priyanka marwaha wanted to because of the project.  231 Okay.  on Monday some kind of like waiting on your feedback on the same.  235 Okay.  So your voice was chopped but guess that you send me proposal for final and 242 will get back to you.  Keeping in mind the the generally speaking there should be good reason for doing project that is not in the list of projects that that sent you.  256 meaning If the project is somehow relevant to you because its something you are working on already is something from your job by something that you want to do for specific reason.  It will be approved 310 if is genetic project that eventually has been already 326 analyzed on cargo and there are several submissions already on cargo that that would be denied.  So dont remember quite honestly the project that the proposal that you sent to me.  will review it.  332 But keep in mind that the general approach is unless you have compelling reason for doing something different.  The projects you have are the projects mean in the proposed projects are the projects that you are supposed to choose from.  350 So okay.  410 01FB15EEC157 thats the 414 all that thing does make them 415 all right.  So let me 421 move on.  And 424 again the class today is going to be sort of an overview of some of the research projects that they did so far.  Just to give you little bit of an idea of what you can do 430 with an extended version of what you learned in this course.  so sharing the screen again 446 and let me go here 456 and let let me start with the this project up.  That was somehow 459 in Mystone in my research.  So in my research there were mystones.  One was during my Phd.  When addressed the social media.  509 and the second was 40 years ago little bit less when started working in Dod sponsored project that was pretty large one was over 526 about years about million dollar about 2025 people working on it with the combination of all the 545 students 556 faculty and external contributor that they high as the as full time or part time employees.  558 So whats up 611 large budget 613 And was relatively large project.  615 So the the project was with the within circ within the software engineering research system engineering Research Center and was sponsored by 619 the departmental defense and in particular by the Picadini apps now.  So the official title was meshing capabilities and threat based the science and technology resources allocation.  637 So what does it mean 652 The Picadinia Its doing 657 the national.  So they are developing new weapons.  702 so they do hembel the weapons meaning no tanks and all submarines things like that 707 and they develop somehow the new generation of weapons.  715 So the the way they are doing it normally is based on my capabilities meaning having weapons so they are more and more effective.  725 but they dont have real sense of the competition and they dont have the way to evaluate the how the current threats can change the the of the of the weapons.  738 So that was the project.  The for use was on technology meaning how technology.  758 all right.  812 science and technology.  But lets say how technology is used by the the opponents and and how the different use of our technology can impact the the 814 balance of forces that we have in the world.  829 So as you can imagine.  The the project was quite an issue so mean that the the budget for some issues and 835 we face the several challenges.  846 So 850 the Picadini Arsenal or Us.  Army combat capabilities Development to man Arm and center.  Ccdc.  AC.  852 It sounds like rock band.  905 They developed framework and the idea was to consider that framework and expanded the creating more capabilities.  909 So we 924 again in the first phase in the the the first part of the project for Sierra.  We kind of replicated the the process that they highlight was very high level.  926 mean sketch of the project and creating the model to do in different way.  So thats as napshot in certain moment all the size and the type of people within the the project.  So 943 lot of students faculty one post Doc some employees the good portion with the Ph.  D.  Some Phd.  Candidates some and the rest master or master candidates.  We wanted to use an approach that was bottom up.  meaning using text and extracting from text based on given profile the the information that we needed that challenges where many one of the challenges was how to extract the numbers from text because at the very end what we needed was to create sort of this panel that was able to to mean based on parameters.  So to determine how the balance of forces can change based on the different conditions or the different uses of the technology.  And this was the first challenge the second challenge.  Let me stop for moment here.  The second challenge was we will go back to that was on selecting the right domain.  So we were in the condition that that and most of the people in the team we are not in.  Were in international students meaning they could not have access to the actual hold on just s.  Sorry.  There is some background noise that We want to stop for moment.  Okay my apologies so and the the project had some levels of of security related issues.  A.  wanted to have graduate students working with me.  Stevens like the majority of STEM universities or colleges so has 85 roughly of international students at the good outlet level.  That means that they are not us persons.  Us.  Person is defined as as someone either citizen or green card holder.  and obviously they cannot get any security clearance.  So in the project was the only one with the security clearance.  But obviously cannot develop the the project by myself.  So follow the an approach that was on to assumptions or to basic choices that they made one to change the domain.  Instead of talking about countries and kind of opponents of potential opponents.  changed the domain and the new domain was security companies.  public security companies meaning companies that are working in an area that somehow is similar or its related the strictly related to the defense industry.  but with information that are publicly available because we are talking about public companies and meaning the companies that are publicly traded meaning that they have all the information available online and all the news eventually related to them and that are available.  So that was the the first step and obviously discussed with the sponsor what the best scenario could have been and that we decided that that this security industry was way to go.  And again the security industry.  the private security industry publicly traded companies.  Anyway it is an industry that is big.  Its technology driven as some semantic proximity and is measurable.  so those are some of the numbers that are pretty big.  So those are.  or where some of the trends so that somehow we are similar to the trends that the Dod was seeing in domain that the other approach.  So this proxy domain again.  Obviously.  it is not the perfect choice meaning that there are differences.  So when we talk about creating competitive scenario creating risk panel in the countries.  What you want to do is to check for so to change the world wide balance.  So mean that the Department of Defense is not the Department of War.  So its defense meaning Their goal is to keep the status quo avoiding that there are reasons to start the war but be prepared.  The based on what the others are doing to reestablish the equilibrium between the forces.  So the the equivalent in our proxy domain was the market balance.  So you have those companies with the the market share.  So market shares that can change.  And and if there is new technology.  the new technology can change the balance all the forces.  Or you have one company taking over one key technology.  That was the the coordinates or not another company changing the all that balance.  So mean that we had to do some sort of adjustment and that was critical we for use the on the layers.  So companies market segments and technologies.  So we basically analyze the those components.  So data about companies data and texts about companies market segments.  So Erez Agmoni mean those companies are are big some of them.  They are several 1000 employees and they have market segments so that can be 150.  Strictly security can be.  and technologies so that are enabling or this enabling some of those offers that those company may have.  Oh the analysis is dynamic because things are changing over time.  another component that we use the in the approach was to create sort of separation of duties.  basically identified the main projects one that is this risk panel and the other one that is just analyzing the technologies like monitoring the the evolution of the technologies all over time.  assigned those projects to to people with green card.  meaning they are Us.  Person so meaning they have access to information that are restricted to international people.  but not to information that are recovered by other restrictions.  All the other the the large portion of the team was developing components.  so called it the the the the legal approach.  So this largest part of the the team was working on specific tasks components that are independent from the user that they will do but they can be integrated just as legal Erez agmoni.  Then the people in charge for the development of the main projects.  They will take those components 150 and integrate creating specific system.  So those approaches the proxy domain the alternate reality the and the the Erez Agmoni development based on components where the ways to kind of overcome the issues that we had with the not having U.  S.  Persons.  Each team member went through required Dod training anyway.  But mean again the majority had restrictions.  The the technical problem still state.  So the the first approaches are more on team management and project management more than on the technical side.  On the technique outside the we we still had the the problem how to go transform text that we can collect from different sources.  We use the news but and some papers for that.  So how you collect the how you transform the information that you can get from one of those sources into number so that you can use in dashboard for risk analysis.  So that was the the real issue to do that.  created that already mentioned it but would go relatively fast on that just as recap what call the room to.  So the room theory is knowledge based approach to develop system for evaluating the documents based on given characteristic analyzing text.  As we know from other classes its complex task.  Its becoming even more complex now because the communication that we use is shorter.  not much structure is chopped the meaning we cannot use any strag any formal structure to extract the knowledge.  Now we are developing methods to get the formal structure from unstructured text.  But that thats another story.  So then you have the issue with the language that is evolving meaning.  You cannot really rely on taxonomy or existing to represent the language in broad sense.  And then there is the mother of subjectivity.  So the tibi gala example that they use million times.  So we did the classification of the emotions.  So using that classification you have certain number of different emotions one of them being joy.  In this classification.  Each motion has grades joy the the extreme.  shade of joy is but if you name the word ex to see if you are into emotion then you say is shade.  That joy.  if you are into narcotics then is drag.  If you are into religion then its stage to one the so its the same word with completely different meetings erez agmoni.  So the subjectivity along with the the dynamic evolution of the language and the lack of structure 150 make the all the traditional approach not usable so.  And thats why we think mean that mentioned medium time.  Im working in AI since many years.  So back in time Marvin Minsky was one on the points of reference in and might be Minsky use the schema theory that was developed century ago more than century ago and renamed the mean elaborated the concept renamed it the the framework theory.  the basic idea of the framework to or is that whatever is the element that that that we want to either analyze and understand express an opinion on on is based on mental frameworks.  So things that are how we see things.  and you use the as an example when you enter in physical room you know if its bedroom bathroom living room but not because there is label on it saying bedroom but because of.  There are things in the bedroom that resonate with your ideal bathroom.  so use the the example on the room so to rename the approach room theory and added the layer that was computational because mean the the original version by my There was no computation outside.  That was just it theoretical approach.  wanted to have computational representation of knowledge base of point of view.  So to do that use the vectorization.  So now the type of authorization that use that may not be the best way to go.  But is it still good base for this kind of thing.  So its what to back create in 2013 by some Google people.  Interesting that pretty much no one of them is still on Google and what to back is creating a.  But yeah its creating back to us out of each one of the words or engram.  So in the text.  The way it is done is based on the conditional probability of one word the upating because of the other.  So thats the and that assumption is that if they appear together they are related.  or close one to the other they are related from the conditional probability.  You can reduce the the dimension on the matrix.  On given number of components.  Generally we use 200 or 300 and at the very end at the end of the process.  So you have each water or engram that will become sequence of numbers meaning vector and thats the name.  So at the very end that you do for all the words.  So and you basically have matrix that is representation of the text.  So If you have large data set then you can.  You can.  mean data set of texts.  Then you can victorize the the text.  And this data set this large matrix will be the computational representation of the knowledge base.  So that would be the point of view.  Then you have the document that you want to analyze and what that your points of interest because mean with the same knowledge you can do multiple things.  So you want to have keywords defining what you are looking for.  Keywords can be.  single words can be and grams.  but you may also want to have little bit more.  You want to have scenario.  You want to have misspellings and you may want to have wait for the different keywords.  So what you do is basically you start the victorizing this corpus.  So this is set of text that you collected creating the matrix.  Then you have the text that you want to evaluate and you have the list of keywords.  You basically take one one word at the time from the text you want to evaluate and you compare the text.  mean the the word in the text with the each one of the benchmark.  And you do that looking up in the madrics.  What is the vector representing those words And you calculate the the singularity between those words By measuring the distance between the back to us.  We use the initially the cosine similarity other for so of similarities it could be analyzed can can can be used.  So you do for each one all the words here with the each one on the benchmark here and you will have for each benchmark the similarity.  or for each document the similarity for each one of the keywords.  Then you normalize.  You would use the weights for each one on the keywords.  mentioned that the keywords have waiter because not all the keywords are at the same level all relevance.  And then you have overall number that is going to be all mean.  The similarity between the document and let me go back for second.  The similarity between the document.  the benchmarks based on the point of view that is represented by the computational version of the knowledge base.  You change the knowledge base.  Yeah.  you will have different backwards and the result can be different.  So this approach works well because its knowledge dependent that replacing the knowledge you have something different.  So there are main variables the benchmark meaning what you are looking for and the knowledge base the core post that is Who are you So if you change one of the is the same.  You looking for something else is another new looking for the same thing on the previous one.  The same documents will have different results.  and thats why we applied this approach to different cases so that they will and just go through with you.  So then obviously there are bunch of things that are making deal process more complex.  So you want to do they programming in the proper way.  and use the same way of doing the programming for the components from the for the room meaning the knowledge base for the benchmarks and for the documents that you are analyzing.  We wrote paper on how to do this chunking this programming in the proper way.  Generally speaking you are required the to remove the the software so.  But if you remove the software so when you are analyzing keywords at Stevens you remove all of that.  Then you dont have this call of business.  so you may want to delay the removal of so forth.  So after you do the first round the all the the and grand generation and then eventually remove the so forth so that they are either at the beginning or at the end of each one of the engram so that you created.  then the generation of the room was create was requiring quite lot of time because it its.  Its its long process.  When you have large data set.  its pretty much the same problem that Chop Gpt is having mean creating the model.  What to back as form of victorization that is easier and less accurate than Gpt.  Gpt.  Is based on transformers and the number of he delay as goes from one in world to back to many.  We dont know how many and the different GPS for those GPS each time you have more on those either layers.  So in the neural network analyzing the text.  The more resources the more time is required in our case on our computers was still matter of day day and half so was still not substantial.  We use that for different approaches.  We will go back to that.  So thats basically the how we process the the information.  So we had.  We.  We collected the data from news but in some papers for patents and papers was relatively easy for news.  We initially told that was convenient way to do it with the we failed because the roller couldnt really get match after certain number of downloading because that the sites are blocking after certain number of queries and we ended up paying for service.  So then we we added the level of security before entering the actual system.  We could then all the those news but and some papers that we are.  Jason files into Mongodb database and then we use the those entries into ways one to in the longer term creating updating the room meaning getting more knowledge of how things are going and its more like smaller match that would be analyzed.  Then you have the preprocessing in both cases if erez agmoni mean every few weeks we regenerate the room the embeddings and for the analysis we mean in both the cases we placed everything in international database one.  the systems.  So the technology monitoring that is panela are seeing the only what is in the rational database.  So meaning they dont know what is happening before that.  And mean that each one the the technology monitor and the use the room theory for extracting the the metrics.  So that was basically what was there The the system is not running any more.  will not check if still have some snapshots or the dashboard based on that.  We created the several other systems in the different projects that we did Later on this project was again for the the Department of Defense and was for analyzing contracts.  So one department of the Department of Defense is Dau and that is defense acquisition at University.  They have missions one that is the University teaching Dod and people within the deal.  The universe elements is is more training than education but they train people on given topics.  So we are currently working with them to redefine the the training in AI machine learning and data analytics.  So the other portion is the acquisition.  the opposition.  Its huge.  So everything that is quiet.  By the Dod we go through them.  It could be so.  new computer.  It can be so based on the on the type of request that they have the different types of contract that will protect them more against issues that they may have down the road with the provider.  There are dont remember 1015 different types of contracts but the the people in charge for assigning project to contract our contracting offices.  They are that there is high number of contracting offices that.  and they tend to use the same types or contracts because they are more familiar with them.  So the idea was to use to create system replicating somehow the knowledge of the contracting officers and use that to evaluate the what in theory it could be the most appropriate form of contract.  So that was the overall idea.  So let me keep most of that.  So we created the room for that particular domain.  Initially we had about the 100 key words defining the benchmark.  So this portion here.  and let me go in presentation mode.  and initially we had about 200 documents creating the knowledge base.  Again whats our single words and good We didnt have weights initially and it said that the way to calculate the similarity was between the vector so whats the cosine similarity The system didnt work well so was not really able to to create separation between the different documents.  When you have knowledge base that is mole then you have several of the words so that may not be present.  The in the knowledge base works from the documents of the benchmark that may not be in the knowledge base.  And at that point you dont have any input in terms of similarity.  And then the lack of keyword all that weight so on the keyword.  So it was another element.  So we expanded the the number of key words working with the the the sponsor.  So from 100 to 400 and and 64.  Then ask them when you hire someone for the position or contracting officer what are the requirements you have Do they need to have an equivalent on an Mba.  Do they need to have low degree So we we ended up with the some of the academic background or educational background they should have.  And we use the some of the textbooks from those areas.  So we went from 200 documents to 537 documents and and from about 30000 unique words or and grams to almost 120000 unique words.  And then we added the the the weights and then we changed the the way we calculate the distance between worse with the man approach.  It is called the what mover up.  That is not an original one there.  There is final library for that.  So thats basically comparison between the the previous approach and the new approach.  Where the difference is is the number of documents and the number of key words.  This is to say that this approach is data driven.  So you need to have enough data to make it work.  So thats another representation.  So is principal component analysis.  So the mean we have 300 the components.  This is down to to meaning is it to the vision of 300 The the dimensional world So its.  Its not exactly good representation but it gives you give you an idea.  So you have the different form of contracts for the the documents that the projects that we are analyzing with the preuse version that there was not much of separation with the second version with the larger data set both in terms of knowledge base and in terms of of benchmark you have definitely better.  So the output is something like that.  You have the name of the document the different types of contract.  and how close they are how close each document is to each one of the types of contractor and then that you have as last column.  Now the value mean the the formal contract with the highest value contracting officer can eventually consider the first and the second mean in the first line there is not much to say but in the other line like in this one you have 2529 and 25 and change meaning.  Yes the the largest value is the 29.  But you may want to consider the other 2.  So that was the project on analyzing contracts one more example.  That is more recent.  so that the project is for Siemens financial services.  and we work the initially within an international competition that they created.  The international competition was with the 1400 participants across the world on tracks.  One of the tracks is funding sustainability and the idea was to develop projects that could help Siemens financial services to fund the projects within sustainability.  We won the track with the project that we named Green Connector.  and the idea of the project is to create tool that can help Siemens financial services Extract from the web projects potentially in need to be funded to send to Siemens for 200.  mean proposing to be funded by that.  So thats basically is matchmaker is in theory similar to any search engine with the main difference that in this case its based on what Siemens financial services people would do so.  The architecture is pretty much like this one.  So you have benchmarks defining the points of interest.  You have collecting documents then you have the projects that are evaluated based Same room theory approach and you have at the certain point at least of projects.  And you will have some visualization.  So the idea its basically being based on knowledge.  So the knowledge is really the the the core of the system and the knowledge is represented in ways.  One is in the room.  There is knowledge of the operators in the Zeemans financial services and the second on the benchmark representing the elements that they are for you.  One of the issues we had was that when you have large document how you evaluate what are the elements that are more interesting because the same concept can be scattered in different places.  And then you have large document that can be interesting in part.  What are the parts of that of interest.  So we developed way to chunk large document in parts so that are semantically and independent or less related and then reassemble the document into digital paragraphs that are aggregated based on being semantically similar.  and we use different and and then you evaluate each paragraph using the same room theory approach So in that the first stage there is smart paragraphing.  The victorization is at the document level.  Then once you move to the evaluation of interest then you use the the other traditional approach on the wrong theory.  Those are the paragraphs representation of the paragraphs.  This is representation of all the benchmarks.  So you have of benchmarks.  You have again misspellings things like that.  and then you have wait.  We didnt use the time but result is basically the documents will be placed in in in space representing the similarity.  So you have a.  At the paragraph level you have an index of similarity.  You have mean point of reference to go back to to the both our actual position of the paragraph in the document.  and then and now that result.  we can highlight in yellow the original Pdf so this is giving us way to send back to the user and highlighted version of the representation.  Then we developed webc.  That so far is a.  A.  one so its not doing much it working on keywords.  We provide the keywords and its getting all the results.  The next stage would be to add the little bit more of intelligence in that.  The So those are examples all the applications.  want to go now into something that is completely different.  Few few years ago we developed the we.  We wrote paper with the in collaboration with Unicef on the impact the of the lockdown to domestic violence and children abuse.  We wanted to create sort of awareness on the problem through the paper having unicef as partner was great because we had the expert in the domain and we also had the the possibility to reach wider audience.  So we use the social media to detect the to measure somehow the impact.  and we use the red.  It and twitter for different cases and will show you how.  So those are are the units of great working with them and the for us.  so myself.  that you may know from other courses and Fernanda that we are of our Phd students.  Now both are senior data scientists in their companies and Polya is working in one of the lab just the financial companies in us.  But now that is working in larger consulting company.  so let me keep all of that.  So again the goal was to for use on children exposure to fire to family violence cyber bowling.  and we focus on us but also other countries.  So South Africa Indonesia we have data for Indonesia and Brazil.  Fernanda is from Brazil so whole or was kind of easier.  There are many issues as you can imagine.  So we collected the tweets from 15 different countries over different timeframes.  Its completely different anymore.  You have more domain specific messages meaning it.  It.  Its kind of easier to work with ready data compared to Twitter and that can be all over the place.  The the first application was analyzing Twitter.  so Twitter has some J.  Location so its not 100 reliable but as some your location capabilities.  So we collected the the the data filtering the data for abusive or hateful language map by community it can be geographical or not and then analyzing and interpret the results.  So thats us.  So you have yeah.  What is the before and after we created software in index before and after in terms of hate speech.  So some of the either our States or districts had really large increase.  So it visually.  Thats what we have.  So its tweets per 100000 population before and after the lockdown number of tweets for different countries abusive non abusive.  speech.  So so some countries really standing then the the the Scandinavian people are always good as we know but the rest of us.  Not so much.  Then we we classified somehow those speeches.  So using either more strict index for hate speech and less to index and then you see those that are above the the are below.  So that was on analyzing tweets.  All right it again that it.  Its kind of be easier in sense.  So because we went into subreddit that was more for use on on the on the topic 18 months in interval.  Majority of the red.  Its were from the Us.  So thats limitation.  So thats an example on the the subreddit the abuser and collected the data doing temporal analysis extracting topics and try to classify them.  So number of active users in the the subreddit related sub that its related to our views and you see what is the growth.  then The the number the ratio of of number of daily posts before and after A.  So you see that there is growth of some of the elements that that seems to drive toward abusive conditions.  We created using lda.  That is what it is.  Clusters somehow and we try to make sense out of it and try to label them in way or or in the other.  we identified the different intimate partnered abuse physical abuse sexual child the practitioner support that is the the good one.  So and each one based on that was with certain percentage.  And those are the keywords that are more related to each one on those topics.  And thats basically what we had.  So if you look at the the the the the time evolution of the elements mean overall that is growth each one of them so.  Unfortunately one that grew.  The list was the practitioner support all the rest.  So 33 more exposure to abusive language.  37 us states so large and increase in tweets containing abusive language thats an overall key results 94 more child abuse what read it during the lockdown.  88 more intimate part am used by work on red it during the lockdown.  So thats basically another way to use data to analyze data.  the the paper at the this the last one with unicef and quite lot of citations.  Quite lot of views.  mean.  Its an important topic and it is definitely driving quite lot of attention.  All right.  can go on and on but not totally sure that you would benefit the Erez Agmoni.  That much giving you other examples and just to give you an idea on what Im working on right now 150 in kind of following the craziness on chat Gpt.  And then doing the projects one that is on creating an Ssc.  Gpt that could be based.  most likely not on Gpt itself but will be based on on the same the transform of the and I.  will use the transcripts from our classes and in particular for 24 as the knowledge base.  And then will use the the question answers that you and the through emails to myself or the ta to fine tune the system initially.  will be sort of with you Dora for 24 and then if the project will go well then we will expand the to other courses.  The second would be to leverage on the language generation capabilities of those large language models to have sort of visualization so.  But instead of visual you will have narrative.  But you will have language base reading of the results so it will be sort of visualization but not and visual but compensation.  So those are of the projects im working on.  Im.  Continuing working with zoom and the system that show to you.  Up to about month ago we were working on creating company out of that.  The idea was the Siemens idea was okay.  We developed the proof of concept in the hack upon Then we are now developing prototype.  The prototype will be ready by the next by the end of the year.  But we would like to use the system at that point as university.  We cannot provide services so we can develop prototypes proof of concepts but not systems.  As service.  created companies in my in my previous life.  and want to use that experience to create company that would serve as first client to cens up down the road.  The other companies mean no company can survive with only one client so we will need to diversify.  Siemens wanted to invest in the company but then our our point of contact left the company.  So now we are remapping the entire involvement that they have and for the time being put on all the the idea all creating the company.  but the levels up the person who left the Siemens there was an agreement.  So we just need to recreate your chain.  My idea with the company is basically to give students the opportunity to work in the company develop skills eventually if the company would be up to that and being hired by by the company.  So it its like adding level to the education that we are providing at Stevens.  presented the idea to the pros.  The browser was happy.  But now we are on all the because of the changes at Ciem.  But im still pretty confident that this will happen.  So thats basically what im working on now.  All right.  So lets move on now and lets go now to the in class assignment.  So is 43.  Let me share this screen.  Again.  Let me go here.  So thats the in class assignment.  So you will read the some preprocessed tweets so they will look like like this.  so you will have list of send us time stamp.  So the time sample is on epoch time.  That is the number of seconds from the moment the unix was created.  So dont know why they are using this way.  but in most of the geek it think so.  Thats the way to do the time sample.  and then you have the actual text.  So there are columns center time sample and text.  So there are 20000 Rosa standard times 10 texts.  which being collected during Presidential debate using Trump as keyword.  That means most likely the the comments are related to the to trial.  The output that is required is you want to print the the most active Send us that.  Then most we we did the tweets the most side of the screen names.  and the 10 most popular stark words so retweets can be determined by checking if they start with the Rt.  And that our few of them you can probably spot it somewhere.  Then here we go like.  In this case you have rt.  then the the screen name wed be determined by looking at the at the symbol.  like in this case they are.  This subject here is citing people with those screen names can be determined.  If they start with the the there should be somewhere or something.  Okay some we have that there should be an if you use Pandas setting coding parameter to encoding.  You will like unicode escape.  When you read the the file.  Keep in mind that the when you work with weeds things are always massive.  because because people is sending tweets from all over the places.  each place is come each country as given character set.  So we already mentioned that when you have dont know from Germany you have so with the double dots on it the in Italian you have the apostrophe that is using different way in Spanish.  You have this idea under the sea sometimes and so on.  So when you read the those messages with an encoder that is based on English American language.  Those characters will not be recognized as such meaning.  There is the risk that those characters will be considered in different way.  The different way it can be end of file and of line end of file that meaning it will stop at the point and the entire processing and the line that means that well skip to to the next line.  So thats why is important that you set the the encoding in the proper way.  All right so let me publish the material.  So my the material is published and let me.  create the breakout rooms.  So created the breakout rooms participants per room.  creating opening.  You have oh 20 min 20 and change minutes to work on it.  Then we will come back and will talk about the the solution.  You will present your results if you want and then will introduce the the next assignment and thats going to be the end of the class.  So the rooms are open now.  See you in about 20 min.  So im resuming the recording.  How was it anyone want to share the experience All right.  Okay.  So let me share the screen and let me good to.  Okay.  So E.  C.  You read the file.  the the the so forth.  You load the the words into list.  then you find and print the top standards.  so you do not really need to create another data structure but thats the easiest way to to do it.  And then most common retweets create another data structure most call mona.  and this case its little bit more complex because im im looking for specific character.  There could be different ways without the loop just working on the capabilities of palm do but mean that thats the the easiest way to do it.  So in looping into the text.  And then if find the and at then hi.  and not checking if there is column.  if there is im taking the character that is next to it Same thing for the app.  Yet im not the phone sign.  And then and in the words calculate the the top screen names hashtag words printing it.  mean it was relatively straightforward to send that top weeds most cited names.  There was glitch here.  most popular hashtags.  most common words.  So again.  There is glitch in the text so will not check it.  And the updated version.  All right.  Okay.  So the assignment for next week.  So thats the last assignment.  Apart from the final meaning it does to be the most complex.  So in the past use the as last assignment an assignment that was on combination of Oh the webcalling and text analysis on multiple page website.  It was complex realized.  do something with the different type of complexity.  So we are engineering management.  There is management in the name.  Whatever we do has to be somehow in tweets that is related to management.  So one of the things that we do in the universities is managing courses.  So in particular at events we use work day.  what they can generate ere mean extract only those that are related to specific school and we need to add some other you know capabilities.  So wrote python script to cleaning and to add the features like level up program and and suffix.  So thats basically the the the output of of my script.  So you have this pretty large data set from work day.  Then there is my script doing the cleaning and then you will end up with something like that.  sanitize the the data set with the removing the names.  So on the tractors and replacing it with numbers just to protect the privacies.  amend that the privacy of the instructors.  But anyway you have academic unit like engineering management program systems and enterprises in broad sense and so on software engineering.  Then you have the sections of those so open or close close.  The means that there are no more seats of all Ebola open there are still seats of Alabama.  Then this is sort of duplication.  You have the full name of the courts and only the the first part of the name the title.  the meeting.  the building.  the campus can be online.  the name of instructor credit ours number of students abroad the capacity of the section so the enrollment is the actual number of students in the class.  The cap is the the size of the classroom.  so in this case there are more seats available if we go like.  In this case this section is closed.  So there are 130 students.  We did.  They already got capacity on the classroom or 24 and thats why it is closed.  Then you have what is the academic period that they are all for on spring 2022 one year ago.  Its update and data the type of its fraction of format.  Most of them are like shirts.  the delivery if in person or online.  then pretty like we see it somehow.  Then you have academic level.  graded them not.  and then you have additional value so that calculated they are labela program and suffix.  So thats basically what you have based on that what you want to do.  He is reading the data set with all those Rosa.  You want to print the courses with the highest number of students from the enrollment counter.  The instructors with the highest number of students.  Again its the role my count.  Compare the total number of students for undergraduate graduate and corp from level.  We are comparing.  That means to calculate the values and describe the results in the narrative part of the assignment.  compared.  The number of courses that run at full capacity marked as close with those that not comparing same thing.  then that create pie chart with the distribution of students per program.  create pie chart with the distribution of students.  So per type of delivery.  So the first one is program meaning engineering management system engineering software engineering and so on.  The here is for delivery mode meaning in person or online.  Do other analysis if needed you do not need to do it.  But if you think about other analysis that would be great.  You read the file perform the analysis and you will submit with interpretation.  All the usual rules would say meaning cheating would be considered again after 4.  Lets say ha After the fourth cheating and some of you are on very few but some the fourth will trigger the reporting to the owner board.  Those who are not in that condition will be penalized in terms of point reduction.  So thats Basically it.  will posts the description and the assignment.  And thats basically it.  Just to remind you Dont forget that on the final you have let me share again the screen on the final.  You have options.  Analyze people percept.  Im sorry they go from the beginning Analyze people migration data.  analyze the research projects the COVID19 case and then the fourth one.  analyze people perception of AI.  So you can pick any one of those follow this fraction and do your final in very special cases would be okay.  giving you the opportunity to do the final project or something different.  But you need to convince me as will say in the very beginning of the class that there are good reasons for that.  Its something that is part of your work.  Its something that you want to do to write in your resume because you are going to apply for certain positions and you want to have something that can resonate better.  mean need to have good story for that.  And please Dont use data sets like those on cargo that is being used million times and will never be sure that the the the code and the analysis that you are doing its really original.  So will check if what you are asking is on cargo.  If hes on cargo its quite likely that they will deny the project.  So thats Basically it.  Next week wed be office time.  So the only thing that would do would be to present the the solution for the current assignment that there will be no extension for that.  no extension for exercise 9.  So unless something that very relevant is happening and hope that that it would be not the case for any one of you.  but apart from that the no extension will be granted.  So take the time you need.  The the the assignment is not particularly easy.  and for reason so its the last assignment as to be mean we said medium time so the the course is very gradual.  So but now we are at the top.  Meaning is it has to be the most complex of them all.  anyway.  So does the end.  Im stopping the recording.  ft STEVENS lw INSTITUTE of TECHNOLOGY iy Machine Learning using Python clipizzistevens. edu SSE What is ML lw Most of the methods and techniques used in Data Mining are used in Machine Learning Some of the definitions associated to Machine learning include Automating automation Getting computers to program themselves From TechTarget Special Report Artificial intelligence apps come of age Machine learning provides computers with the ability to learn without being explicitly programmed.  Machine learning focuses on the development of computer programs that can change when exposed fo new data.  The process of machine learning is similar to that of data mining Data mining Is extracting knowledge from data Machine learning is broader discipline focused on creating systems able to show data driven intelligent behavior STEVENS INSTITUTE of TECHNOLOGY Al ML and learning we AIML systems need data to perform behaviorstake actions Based on the type of data available they can perform category of task or an other PredictiveClassification systems like humans need information about past behaviors on the same problem Quality and quantity of the information about past behaviors determine the quality of the opredictionclassification where quality is the ability to oredictclassify situations in comparable or better way as target sample of humans In all the cases when no data about the past is available the learning is either based on reaching target or on creating criteria for clustering data STEVENS INSTITUTE of TECHNOLOGY Ss Supervised Unsupervised and Reinforcement Learning Supervised learning Supervision The training data observations measurements etc.  are accompanied by labels indicating the class of the observations New data is classified based on the training set Unsupervised learning The class labels of training data is unknown Given set of data the task is to establish the existence of classes or clusters in the data Reinforcement learning It is based on the goal of maximizing cumulative reward Inasense it is form of supervised learning with the supervision that is created by randomly generated behaviors with results measured by the values of the reward.  The values of the reward and the values of the variables leading to that result create the supervision STEVENS INSTITUTE of TECHNOLOGY Supervised learning process two steps We split the dataset into subsets one to train the model one to test it Step We apply the selected algorithms to the training data to get the model Step We test the model on the testing subset and measure the accuracy STEVENS INSTITUTE of TECHNOLOGY Fundamental assumption of learning le Assumption The distribution of training examples is identical to the distribution of test examples including future unseen examples In practice this assumption is often violated to certain degree Strong violations will clearly result in poor classification accuracy To achieve good accuracy on the test data training examples must be sufficiently reoresentative of the test data STEVENS INSTITUTE of TECHNOLOGY Reinforcement Learning Learning from interaction Goaloriented learning Learning about from and while interacting with an external environment Learning what to do how to map situations to actions such as to maximize nuMerical reward signal STEVENS INSTITUTE of TECHNOLOGY Sl Reinforcement vs Supervised Learning STEVENS INSTITUTE of TECHNOLOGY Reinforcement Learning Key Features im Learner is not told which actions to take TrialandError search Possibility of delayed reward sacrifice shortterm gains for greater longterm gains The need to explore and exploit Considers the whole problem of goaldirected agent interacting with an uncertain environment STEVENS INSTITUTE of TECHNOLOGY Reinforcement Learning Example Reinforcement Learning Example jw Consider ag complex graph and we want to find the shortest path from node to goal node Traversing an edge will cost you length edge dollars The value function encodes the total remaining distance to the goal node trom any node . e.  Vs distance to goal from If you know Vs the problem Is trivial.  You simply choose the node that has highest Vs STEVENS INSTITUTE of TECHNOLOGY 11 Reinforcement Learning The task To learn an optimal policy that maps states of the world fo actions of the agent.  Examples if this patch of room Is dirty clean It.  If my battery is empty recharge It The agent tries fo optimize the total future discounted reward oO STEVENS INSTITUTE of TECHNOLOGY .  Reinforcement Learning Value Functions The Value Function estimates how good It is for the agent to be in given state The how good is defined in terms of future rewards that can be expected in terms of expected return The rewards the agent can expect to receive in the future depend on what actions It will take.  Accordingly value functions are defined with respect to particular policies Value Function Is the statevalue function for policy We also define function that is the actionvalue function for policy The function is the value of taking action in state under policy STEVENS INSTITUTE of TECHNOLOGY 13 .  Reinforcement Learning Value Functions Two basic approaches to compute the optimal actionvalue function are value iteration and policy iteration.  Both algorithms compute sequence of functions Qk that converges to optimal actionvalue function Computing these functions involves computing expectations over the whole statespace.  In reinforcement learning methods expectations are approximated by averaging over samples and using function approximation techniques STEVENS INSTITUTE of TECHNOLOGY 14 Genetic Algorithms Genetic algorithms are inspired by natural evolution.  In the natural world organisms that are poorly suited for an environment die off while those wellsuited for If prosper Each individual is bitstring that encodes its characteristics.  Each element of the string is called gene Genetic algorithms search the space of individuals for good candidates The goodness of an individual is measured by some fitness function.  Search takes place in parallel with many individuals in each generation STEVENS INSTITUTE of TECHNOLOGY 15 Genetic Algorithms lw The algorithm consists of looping through generations.  In each generation subset of the population is selected to reproduce usually this is dg random selection in which the probability of choice Is Proportional to fitness Reproduction occurs by randomly pairing all of the individuals in the selection pool and then generating two new individuals by performing crossover in which the initial bits where is random of the parents are exchanged.  There Is small chance that one of the genes in the resulting individuals will mutate to new value STEVENS INSTITUTE of TECHNOLOGY 14 Deep Learning lw Deep Learning Is machine learning subfield of learning representations of data.  Exceptional effective at learning patterns Deep learning algorithms attempt to learn multiple levels of representation by using hierarchy of multiple layers When the system Is provided with very large amount of information It begins to understand it and respond in useful ways Machine Learning Input Feature extraction Classification Output STEVENS INSTITUTE of TECHNOLOGY 17 Deep Learning lw Deep Learning means using ad neural network with several layers of nodes between input and output The series of layers between input output do feature identification and processing in series of stages just as our brains seem to Multilayer ANN have been used for while.  The new ones use algorithms for training manylater networks that were not in place before primarily due to HW limitations Those algorithms are based on weights adjustments using clustering methods STEVENS INSTITUTE of TECHNOLOGY jg Training Deep Network lw Weights are learned layer by layer via unsupervised learning Final layer is learned as supervised neural network All weights are finetuned using supervised back propagation Hinton and Salakhutdinov Science 2006 STEVENS INSTITUTE of TECHNOLOGY 19 Data Preparation we Data in the real world is dirty incomplete lacking attribute values lacking certain attributes of interest or containing only aggregate data noisy containing errors or outliers inconsistent containing discrepancies in codes or names No quality data no quality mining results Quality decisions must be based on quality data Data warehouse needs consistent integration of quality data Assessment of quality reflects on confidence in results STEVENS INSTITUTE of TECHNOLOGY 99 Forms of data preprocessing STEVENS INSTITUTE of TECHNOLOGY 94 Clustering Clustering is technique for finding similarity groups in data called clusters groups data instances that are similar to near each other in one cluster and data instances that are very different far away from each other into different clusters Clustering is an unsupervised learning task as no class values denoting an priori grouping of the data instances are given Due to historical reasons clustering is offen considered synonymous with unsupervised learning STEVENS INSTITUTE of TECHNOLOGY 55 kMeans Algorithm STEVENS INSTITUTE of TECHNOLOGY 53 cfs Decision Tree we It represents human like thinking pattern.  We take different attributes info consideration one by one and arrive at conclusion for many problems decision tree reaches conclusion by performing series of tests Each internal node in the tree corresponds to test of the value of an attribute The branches from the nodes represent possible values of the attributes Each leat node represents the final value to be returned by the function Decision trees are popular for pattern recognition because the models they produce are easier to understand STEVENS INSTITUTE of TECHNOLOGY 54 af Decision Tree Example eS STEVENS INSTITUTE of TECHNOLOGY 95 Impurity Very impure group Less impure Minimum impurity STEVENS INSTITUTE of TECHNOLOGY 36 lw Neural Networks An Artificial Neural Network ANN consists of pool of simple processing units which communicate by sending signals to each other over large number of weighted connections STEVENS INSTITUTE of TECHNOLOGY 57 Elements of ANN Processing element PE Network architecture Hidden layers Parallel processing Network information processing Inputs Outputs Connection weights Summation function STEVENS INSTITUTE of TECHNOLOGY 59 Model Evaluation Evaluation metrics How can we measure accuracy Use validation test set of classlabeled tuples instead of training set when assessing accuracy Methods for estimating classifiers accuracy Holdout method random subsampling Crossvalidation Bootstrap Comparing classifiers Confidence intervals Costbenefit analysis and ROC Curves STEVENS INSTITUTE of TECHNOLOGY 99 Classifier Evaluation Metrics Confusion Matrix Actual classPredicted class yes no True Positives TP False Negatives FN False Positives FP True Negatives TN Example of Confusion Matrix Actual classPredicted buycomputer buycomputer Total class yes no buycomputer yes 6954 7000 buycomputer no STEVENS INSTITUTE of TECHNOLOGY 39 Model Selection ROC Curves ROC Receiver Operating Characteristics curves for visual comparison of classification models Originated from signal detection theory Shows the tradeoff between the true positive rate and the false positive rate The area under the ROC curve is measure of the accuracy of the model Diagonal line for every TP equally likely to encounter FP The closer to the diagonal line i. e.  the closer the area is to 0. 5 the less accurate is the model STEVENS INSTITUTE of TECHNOLOGY 31 Shl3slCUri ft Mining texts lw Mining text is one of the applications of Machine LearningAl being focused on creating systems mimicking one of the most human characteristics communicate via natural language Python is one of the best tools to mine text.  There are many Python libraries focused on this topic some of them will be addressed later on during this course One of the non traditional but increasingly popular methods to extract topics from text is word2vec that is group of models that are used to produce word embeddings Mikolov Chen Corrado Dean 2013a Word embedding Is the collective name for set of language modeling and feature learning techniques in natural language processing where words or phrases from the source are mapped to vectors of real numbers Mikolov Sutskever Chen Corrado Dean 2013b tis based on Artificial Neural Network and it represent an application STEVENS INSTITUTE of TECHNOLOGY 35 Word2Vec lw Published by Google in 2013 Python implementation in 2014 gensim library Generates distributed vector representations of words word to vec using neural net In those distributed vector representations of words each word is encoded as vector of floats VECgueen 0. 2 0. 3 . 7 . . .  . 3 VECwoman 0. 1 0. 2 . 6 0. 1 . . .  . 2 length of the vectors dimension of the word reoresentation key concept of word2vec words with similar vectors have similar meaning context STEVENS INSTITUTE of TECHNOLOGY 33 in Why this approach is relevant how is structured lw Zellig Harris 1954 oculist and eyedoctor . . .  occur in almost the same environments If Aand have almost identical environments we say that they are synonyms.  Firth 1957 You shall know word by the company It keeps Intuition for algorithm Two words are similar if they have similar word contexts The meaning of word is vector of numbers Vector models are also called embeddings STEVENS INSTITUTE of TECHNOLOGY 34 Sls nie From words cooccurrence to embeddings lw Word cooccurrence measure how often word occurs with another within given number of words of separation Using cooccurrence we can create wordword co occurrence matrix where rows and columns are the unique words in the source text Each word Is represented this way by vector that Is soarse and with most of the values being zero The whole approach is based only on the actual words proximity STEVENS INSTITUTE of TECHNOLOGY 35 Tools in Data ScienceML STEVENS INSTITUTE of TECHNOLOGY 36 Using framework we How do we express machine learning models General purpose computation Machine learning Deep learning STEVENS INSTITUTE of TECHNOLOGY 37 Python Libraries for Data Science Pandas pandas adds data structures and tools designed to work with tablelike data provides tools for data manipulation reshaping merging sorting slicing aggregation etc.  allows handling missing data ScikitLearn lean provides machine learning algorithms classification regression clustering model validation etc.  built on NumPy SciPy and maftplotlio STEVENS INSTITUTE of TECHNOLOGY 39 STEVENS INSTITUTE of TECHNOLOGY 39 Hey did anyone else get message from the professor saying the class was ongoing Please join.  Yeah just got that.  But think hes in the wrong one.  Where am Where are we Joining me also just got that.  But we all like the one for like todays date assume right Yeah tried to.  And those arent working either.  Oh fabulous.  Great.  So where is he dont know.  He must have known.  The code is the same every time.  Right Yeah it should be the same.  Meaning he must be in the wrong class.  Is somebody going to message him back Yeah just dont know.  Okay cool.  Because kind of hope hed figure that all of us didnt just totally not show up.  Yeah.  Maybe we should copy and paste the meeting idea and just send it to him.  Yeah.  Thats not bad idea.  Lets wait third zoom.  No he said go to the left hand side and.  Yeah.  Ive been joined in meetings the same way for the past three other classes.  Yeah just.  Oh he does have cell phone.  If anybody wants to call.  tried to tab the tab in canvas and it just takes me right back.  You.  Yeah.  And tried to join one for like next week or whatever.  Its all the same meeting so.  In the calendar link is the same.  just tried it.  Yeah tried it all to.  He must joined like the wrong class or something.  It didnt respond to my message.  sent them to actually.  Do we know how many people are supposed to be in this class would assume like high teens.  think theres 11 if you go into canvas and check the people who are trying to join.  Oh right.  So 34.  But the trouble is we go.  Okay.  So.  Im really sorry for the trouble.  So was explaining to Dean before.  Im in Washington D. C.  for meeting with the D. O. D.  realized yesterday late evening that most of the content on campus didnt work well so had to replace the entire content and some of the links.  Uh its kind of evident the not working fine so my apologies.  So apart from zoom that is the link to the check your knowledge.  That is not working.  So again my apologies.  My train was 725 this morning and couldnt stay up the night to fix it.  So my apologies.  Next week uh everything will be fixed promise but.  Again apologies.  So we were just starting on the other room and uh we were surprised that no one was there.  So send he left saying Where are you So its nice to see your faces.  Okay.  So brief introduction to myself.  My name is currently pizza the full time faculty and students at the School of Systems and Enterprises.  Im also the program director for Engineering Management Graduate Programmer and Systems Analytics Director for the Center for Complex Systems and Enterprises.  Uh teach data science machine learning.  An LP to about between 150 and 200 students each academic year.  manage research projects for primarily for the D. O. D.  but not all for D. O. D.  the same field.  So.  So machine learning natural language processing.  Uh before that joined Academy uh six years ago pretty much before that.  My academic background is in math.  am master in math from the University of La Sapienza in Rome Italy then an executive MBA from Amba in Switzerland and then age of 50 and change.  went back to Academy got my Ph. D.  in system engineering at Stevens and then started this sort of second career.  So thats basically my story.  was mentioning to Dean on the other room that when joined Academy and this second career began the goal was to work on social media and find ways to analyze the social media.  mean it was at this point more than ten years ago and that social media was becoming as popular as it is today but was not there yet.  My idea was not to use not to code because was coding medium years ago coding with the quarter and COBOL language and that now know that nonactive even if several places that user didnt want to code again and then realized that if you want to work with data you really need to code.  There is no other way in that.  Working with data its really essential for pretty much everything we do.  One of the issues that have in several classes in that in 624 so 624 its pretty much hundred and 20 roughly between hundred and 20 under the 50 students each year when teach in particular to professionals.  So one of the strongest reaction that they have the negative strongest reaction that they have is dont want to code.  The code is not essential for me.  Im so sorry that coding is required mean its core code.  Sam 624 for the engineering management program and wish wouldnt have to.  mean that.  mean on 100 and 2050 its probably five or six people doing that.  And dont know.  What is your opinion on that And will open the floor for your opinion.  But quoting again that is an essential part of working with data.  Whatever we do today somehow we need to deal with data or we should deal with data to have more leverage on what we are doing.  Also as an engineering manager we are exposed to people coding in our company in our division in our team and that point knowing how to code not just because you read the table of content or the book or coding but because you really send the code that is really essential to better understand the problems that the coding people may have and eventually even the potential that coding can have for you and push eventually the coding team to do something more.  So very briefly let me ask you is there anyone strongly against the coding mean there is no judgment there.  Im not against it.  just dont know anything about it.  Okay.  Any other comment on that do it for living.  Its not my bread and butter but its you know its okay.  Okay.  All right.  So and then another question or concern that they have from several students.  So were up five seats in the first group in the segment.  The second group probably its good 20 even 30 of my students that have zero experience including Im scared of the think will fail.  mean even 624 is one of the most popular courses we offer at the School of Systems and Enterprises.  So this semester Im teaching two classes over 620 for this class.  In this modality with the core approach is small one.  The other class that is online is about 60 people and thats normal size on my glasses.  Most of the people have no experience including some of them we are from.  Completely different background.  The example that they generally use couple of years ago.  student of mine she was working at CDO Montclair as clerk at the city of Montclair and she said have bachelor in Arts.  know nothing about coding but Im afraid that will fail.  So we started the again very low with just installing installing Python copying code adding little bits.  By the end of the course you will be able to write scripts that are few hundred slides so with certain level of complexity.  So that student ended up getting job as data scientist in technology company.  So she left the city of Montclair to get job initially as developer in Python and then became data scientist.  So mean obviously everyone is different but this is just to say that even if you have zero knowledge it doesnt mean that you are at risk of failure in the codes.  One thing that is very essential is dont fall behind.  So the course is very gradual.  Initially assignments may be easy if you kind of skip overlook the first two or three assignments.  Catching up its really complicated.  So another issue that we have in this course is cheating.  Speeding means using external sources or working with other students so that the most popular form of cheating that experienced so far.  Now we have chat group and cheating will be completely different from now on.  But sharing doing the same assignment.  Its something that.  Happen Probably.  Each course large classes.  have four or five that are cheating at least once when have an students doing the same assignment.  But lets assume that the assignment that what the hundred each one that we get hundred divided by eight and there is no second chance.  mean that you did it that you will get fraction of the points.  When you do more than once you are losing quite lot of points and there are chances that you will train the courts.  So you definitely want to avoid that.  If you cheat the cheat.  Well cheating well is complicated.  So the most common form of cheating its kind of maybe arranging the statements changing the names or the variables.  mean thats low key cheating and its very easy to be detected.  So you are paying for an education.  You are not paying only for degree.  Thats chance to get an education or something that you may not know but may be useful in the future.  So cheating youre not doing good job to yourself.  Obviously its your choice and you can do whatever you want to do.  But keep in mind that those are the rules.  In theory we should report the cheating to the ethical committee once the issue is at that level.  There are chances that the student will be expelled by the university.  If this is happening then you will have issues getting another admission.  You may have student loan that could be more difficult to repay.  So we dont want to go there.  But again because that is something that is happening not say frequently but is happening to degree mean and to some extent on significant portion of students in class.  want just to tell you to be sure that you will avoid it.  All right.  So let me start sharing this screen and let me go.  Here.  So again we will start on Tuesday 630.  My office is Bible of his number of five or seven on the fifth floor.  That is the floor when we are most of the SCC faculties are.  We do have DEA integrator.  They are working on both the classes.  wouldnt have either DEA integrator or class that is as small as ours.  But the combination of the two classes is more.  Its about 70 students.  We will use Python.  So there are several versions of Python.  One of the advantages of Python is the library is that you can integrate in your code.  Not all the libraries are compatible with all the versions.  So the most recent version may not be compatible with some of the packages that we will use.  So up to 3. 7 3. 8 eventually 3. 9 is working.  If you do three point then may not work.  We do have virtual office out.  It is better if you check with me sending me message an email if you want to meet me during the office hours or at any other time.  Um.  Assignments do they eat Generally speaking present the solution the following week.  So if give you an assignment for this week will present the solution.  Next Tuesday 630.  Meaning at that point cannot be sure that the submission.  mean your solution will not use what presented.  So the deadline is p. m.  the Tuesday following the assignment.  So by next Tuesday at p. m.  that will be the deadline for the assignment that you will start this week.  You have video with the introduction.  You have syllabus.  So the syllabus is pretty straightforward with not saying that much.  There is formal structure with the outcomes.  And mean those are just details.  No deadlines on.  So again that are labor assignments deadlines mean p. m.  on the following week deadline.  If you go.  mean if you submit after that time there would be some penalties.  Then obviously there are exceptions.  Life is life and the things can happen.  If you know that you will be late.  Theres not big deal.  But you need to let me know.  And me and.  And she knew that you would be late.  And you are going to have late submission.  mention the.  The issues with the cheating death the distribution of content.  Lets say that pretty much up to the midterm.  You have basic python and some general information on data exploration and kind of introduction to software engineering because again its something that may be useful down the road.  After that is more on the application.  So if on the other side you already have experience in coding then at that point for the first part of the course you will not be that much engaged because you already knew that.  But after that you definitely would be more engaged with natural language processing or web mining and some other machine learning little bit.  And then will present some of that projects there to give you an idea on how to use it how to use Python to do things that may be relevant for what we do or what you could do.  Course material.  Back in time had the textbooks and then realized that students do not really read books anymore.  So the slides that they will present the material that we are providing should be in.  There are sort of textbooks that are available on canvas as PDF.  Use them as sort of reference.  There are quizzes.  Im never big fan of quizzes but Im in there.  Useful to fix some points lets say.  And.  Thats general distribution of points.  We do have mean we have students to participate to be in the synchronous classes.  Uh.  Midterm is an open book so you can use all the sources you want.  The final is project that you will do.  You will have few days and will give you some options on mean that it will be centered on data exploration.  will give you dataset and the problem more than one and you will pick the one that is resonating the most with you on into this.  Apart from that there is not much to say.  But we dont use Latin bloodaxe and really dont like it.  So word is doing good job.  Theres the distribution of crates and thats again the cheating part.  And thats basically.  So we are in the live session.  So does the pre work.  So hope you had the opportunity to go through the material again.  Im sorry if this link is broken.  will fix it.  This one on complete check your knowledge quiz.  We are the two most relevant questions are are you familiar with the coding in general in scale at to 10 zero nothing then professional level.  And the second question is are you familiar with coding in Python saying that to 10.  Um.  And thats it.  So what we are going to do is basically just go through some of the rules of the game and then will use some slides just as base for the compensation and then will post this lights online.  Let me go back here for moment.  The philosophy of this type of course is again that at the School of Systems and Enterprises we offer courses in different modalities.  The different modalities are on campus.  Obviously online we offer all the courses we have at the school all systems and enterprises online.  We also offer courses to corporate.  So the corporate education is good portion of our business in in India in broader sense.  And then we offer up the format of online that you are taking now.  So this format the online in theory will become the only formal online that we have.  We partnered with consulting company working in education and we devised the entire program.  So within the School of Systems and Enterprises we have only one programmer that is available in this modality and is engineering management.  This modality has pretty much the same content as the older version of online that we call the webcam.  So its not.  But there are some differences.  There are more videos quizzes.  Most of the material is posted upfront.  Um.  Why like the idea of being fully transparent but the transparency sometimes is working against the gradual approach to learning that when you learn language its really essential.  So jumping from class one to Class ten would not serve you that much.  Well so Im posting one class in advance meaning you have module one and you also have access to module two.  So there is no need to go to module to.  Before next week.  But if you want that you can go through that and you can read the material eventually do the quizzes and so on.  If for any reason you need to go more down the road meaning more than one class in advance let me know and will make it available.  Okay.  So let me stop shedding.  And let me check with you.  There are questions.  Issues.  Nope.  All right Yeah.  Great.  Sorry.  have question.  Hey I.  Im not sure if everyone else is having issues.  Im having issues finding like 3. 7 3. 8 version of Python.  It looks like it was decommissioned or not available.  Well think 3. 8 should be still available if not go with the 3. 9.  Okay.  mean the main difference in Python was between the two point something and three point something that was major change.  Uh after that that the differences were more on the performance side than on the syntactic side.  So dont go with 3. 10.  But apart from that whatever is available thats absolutely fine.  The one Im using is dont remember if use in 3. 9 or 3. 3 you in the moment.  Im using 3. 9.  All right.  Okay.  So let me go now.  Let me share the screen again.  And let me go to this presentation.  Its not many lights but really want to go through.  Here we go.  Some of the points so builders use.  We are sometimes users sometimes builders of technology.  So we use the television but we may not be able to build our own television or repair the television.  We are using computers but we most of us cannot building computer.  So but then we use it.  We build some we may build some of the components of those technologies.  So sometimes we are moving somehow somewhere in this continuum between being user and being builder.  When you are on the code inside the build that are programmers or coders developers or whatever you want to call it so you basically write code to do something and.  You are building tool that somehow will help you doing things in more efficient way.  In faster way.  Whatever is the reason.  Writing code.  That means writing instructions for your computer.  Then you can use different languages because different languages will be interpreted somehow by or filter by that language.  That is piece of software.  Taking whatever you write and transforming it into action for your computer.  Computer.  Its told you we started from the very beginning.  You have input output devices whatever they are.  You have the processing part of the computer that is central processing unit and the memory that is used to store the information and to.  mean they handle the information while they are processed.  And then eventually you have memory that is outside of the mean the core computer.  You have devices that can be hard drive can be thumb drives and things like that.  So thats basically the basic schema of computer.  Now nowadays for processing most of the computers we have they are processing through two different units.  One is called the Central Processing Unit and the other one is called graphics processing unit.  And so the GPU the graphics processing unit that was originally developed to work on on the pixels that are on display because the peak sets up in mattress.  The way the computer is dealing with the Mavericks is in parallel way meaning the GPU is giving the computer the possibility to work in parallel processing that is way faster.  So the development or GPUs started with computer games with Nvidia being the largest provider of those GPU but then theyve been used in machine learning because most of the machine learning algorithms are based on neural networks that are based on operations between matrixes meaning lot of the potential parallel processing.  Some of the most recent computer architectures like the most recent Macs with the Apple Silicon M1 and two.  Uh they have no.  mean the architecture of the operating system is done in way that there is no separation between CPU and GPU meaning the computer is actually allocating the resources.  So the best way possible that makes the computer faster.  But then if you have particular software that is addressing either the GPU you or the CPU then that particular software would not work.  That seems to be trivial problem but one of the libraries that is working this way is TensorFlow that is the most commonly used library for machine learning.  And TensorFlow developed by Google is not working on Macs unless you have sort of intermediate piece of software that is unfortunately slowing down the process.  So its kind of defeating the bugs.  So we were talking about machine learning.  So machine learning is one of the buzzword so that its going on since few years.  Machines do not learn.  There is no artificial intelligence because we dont know what national intelligence is.  That seems to be mean raining on the parade but thats the way it is.  So Im writing book on the society the application of and machine learning.  Uh started working in AEI in 1986 so not saying that Im against either machine learning or artificial intelligence but we should mean give the words the proper value.  So what is normally called the machine learning is basically.  way to use systems that can leverage on data and have different behaviors based on different data.  Pretty much discovering patterns on that large amount of data and matching those partners with your request.  So what is the pattern now that is the closest to the one that the machine has and then that will be the answer that you will get.  Seems to be like not big deal.  But when you have mean right now one of the largest models based on this approach that we have is called the GPT three.  GPT three is based on deep learning that is pretty large neural network meaning the algorithm itself is complex but then the data that is using is pretty much all the data that is available on open source there is out there.  So machine learning has two components.  One is the data and one is the algorithm complex machine learning system like GPT three that is based on that GPT too.  So an earlier version can really run only on systems that are huge system computers that are huge but they are so big that for training that GPT they needed as much energy that the energy to run few thousand medium size CDs for week.  So thats how much energy is required for running those things.  GPT two is based on roughly half billion quarter of billion parameters meaning those things that are inside of the neural network in GPT three four that will be announced shortly.  Its several billion parameters.  So those are huge models that based the on machine.  Again machine learning is basically system based on data and algorithms.  The algorithms what they do is to find patterns in the data and match the pattern with your request.  You have different data or you have better data.  Then there are more partners that will be discovered meaning the system will be smarter whereas this madness is just the ability to match those patterns.  So when we talk about machine learning or artificial intelligence in general we talk bunch of different competencies that you need to have at work on machine learning or it can be involved in machine learning.  You have little bit of cognitive science unique skills more on that side.  We will go back to those things you need to know how to do all the work with those algorithms.  So mentioned neural networks in one and there are adults and then there are few other disciplines.  Getting some context.  So is in broader sense part of automation.  So not all the organization as an intelligent behavior it should consider machine doing only one job typing.  Uh dont know.  Bolsa is not exactly intelligent but is an automation because instead of doing manually you have machine doing it.  The.  There are robots some that like the one who was mentioning before that are an example of organization but they may not be intelligent then that artificial intelligence is in the real world of automation and may or may not be related to autonomy.  So selfdriving vehicle is an example of robot of organization and of artificial intelligence.  Artificial intelligence is broader discipline containing machine learning.  So there are two ways of dealing with artificial intelligence.  One is called symbolic meaning you have symbols representing the knowledge that can be.  If you do this then you do better.  Those are statements that can represent knowledge.  You can have what is called taxonomies like the classification of the animal kingdom.  So you want to see how close the two animals are.  You have mammals not mammals.  And then you have dont know birds.  You have cows on the outside and so on.  And then you expand those trees and then you may want to know how similar to animals are.  And you basically measure how far they are up from common parent in this sort of thing.  So thats an example of symbol.  So if the males are one example other example does taxonomy.  So those are not part of machine learning but they are part of artificial intelligence.  Machine learning is the one based on data in the statistics on steroids both the user some data science.  So in particular machine learning.  For preparing the data.  Getting the algorithms.  All of those are in the area of data science.  We use Python.  So why we use by them We use Python because its the most popular programing language.  So.  Obviously not all the programing languages have the same scope.  So there are languages like Java that may have different rules.  So is faster is using less memory meaning if performance is essential for whatever you do probably Python may not be the best solution even if right now.  mean our computers are fast enough to run even.  Critical but not super critical systems in Python.  On the top writer.  will briefly talk in moment about Stack Overflow.  Stack Overflow.  You have the link on canvas is website with quite lot of aura.  Thats huge amount of questions announced.  So its related to coding.  Coding in general meaning all the languages.  The number of items that are related to Python is the highest among all the languages.  Then on the bottom right the number of jobs mentioning Python.  So again you may not be interested in job site in Python not because you do not want to be programmer but thats an indication of how popular language can be.  There are several reasons why Python is so popular.  Probably the main reason is the amount of libraries that you can use to add functionalities to the basic language.  And then mean its relatively easy to understand.  The syntax is relatively simple.  Even the basic python lab is pretty powerful.  When started working in visual intelligence.  So again we are talking 1986 or around that.  There was no python.  So we wrote our assistants that we are based on what we now call artificial intelligence or the symbolic artificial intelligence of writing their names statements.  So conditional statements in broad sense and we use the languages that we are mean just developed for that but there was no library meaning if you want to do an algorithm.  So we will talk in few classes about some of the algorithms in the data science.  In broad sense of one of those just pick one is decision trees.  So now you call library and you pass the parameter to the function within the library and you have your decision tree calculated.  In 1986 we had to write the algorithm for the decision tree.  So you basically start from the raw ingredients and you dont do the thing now.  So meaning you are moving up the level of abstraction or complexity of what you doing.  So in Python is the best example of up to few years ago Python and we are kind of for second second fourth but then mean for several reasons.  Some cannot really explain.  Python became the winner of this competition.  So right now definitely Python is the most popular language that we are using.  There are two ways of dealing with coding or languages.  One type of language is interpreted like Python meaning you have the code and the language Python that is the software and most of the time is written in by the story you can.  Analyze that each line starting from top to bottom each line from left to right in real time.  So.  On the opposite side that youll have program set with the compiler meaning you have your code up in whatever is the language.  You have the compiler translating your source code into machine code and then the machine code the order mean the code that will be executed that will be in detail one in machine language that will run on your computer and it will be faster because its detail one.  The drawback is that if you have to debug it then things will become complicated because you need to go back.  You dont have real point of failure.  So debugging is more complicated.  In the past it was more important to have the compilation step up because computers were lower.  Right now the computers we have are pretty fast and there is really no need to do the compilation.  Python is not from the snake but is from Monty Python.  That is movie Broadway show from the late eighties.  And Theodora was most likely fan of those movies and named the language Alphabet.  So thats the example of how to download 3. 7.  11 app.  Obviously there are different.  What else For different versions.  And let me go now to.  To Pi.  So we use the.  What is called the Integrated Development Environment.  So there are several of them.  The idea that we are using is called by Sharma.  You are the link on your canvas.  You can download the either the free version or the academic version or the commercial version that is also available for academic use.  And thats the one that Im using now by the way.  It has few more functionalities.  So if you do not need to use pie chart.  Uh.  In the past didnt use any I. D.  just used an editor text editor for grading the code and then ran it on on terminal window.  So thats kind of coding like caveman has lot of Alexa so that IDs are giving you way more amendments and more options to do things in faster way.  But there are other options in the realm of what is called notebooks and in particular call out.  But that is the version from Google.  Uh we will talk about that.  Um encourage you not to use those solutions.  mean if you dont know what Im talking about dont waste your time.  We will.  We will talk about that.  If you know what Im talking about.  The meaning that you use the OR are using notebooks.  Keep in mind that when you use notebook notebooks cannot be integrated in process.  So if you have some software doing some things generating the file so that your software your python code will do and then you will generate other results that will be passed to the next module.  So if you have this pipeline and your code is running on on notebook you cannot really do the integration.  So you really want to have separate file until the python scripts have suffix.  Dont be why you want to have adobe WIP file to be integrated in your pipeline.  Again if you dont know what is notebook.  Just disregard what said.  Thats fine.  In Pi Sharma like in that many other I. D.  you have an area with your files up.  So you will create directory or folder or whatever you call up the equivalent of folder in your operating system and you will point your python to your pi sharma to that folder.  In this case created on these directories the 624 and have all those files and then you have right here and inibitori so is text editor.  You can write whatever you want to write on your program on your script and then you will save it.  With the proper name making sure that we go in the direction that you want then.  And this one is the python console.  So the python console is basically what you can use to do basic operations like 33 multiply by four 333 whatever and you have the result.  You can assign variables equal to oops.  Meanwhile to.  And you have to.  The six.  And then you do multiply by B.  And you had the result keeping in mind that.  Python is case sensitive meaning if instead of using more is more be user.  Lets say you do capital plus b.  So.  But be.  will go than ever.  So because the COVID delay has not been defined.  Only the small one.  So could continue doing.  dont know whatever you want.  Like six.  And divided by a.  2. 3.  Then you will have the results.  So you can do all the operations in the in the Python console.  But obviously you can write an entire program here.  But then when you close this section it will be lost.  So thats why we want to do.  We want to write scripts like this one.  Few other things.  On by Sharma.  So Impi Sharma you have said things.  And you have your project.  mean this is directorate.  Its this M6 24.  Those are the libraries that are within this project.  One of the nice things about biopharma is that you can have multiple interpretations so you can have 3. 9 for one projector at 3. 8 and another one at 3. 10 for another one.  Then you can associate the.  Different projects two different versions of Python even different packages different alignments.  So in this case and million libraries that are associated with this project using 3. 9.  Mm hmm.  When you have these smaller row is telling you that currently have in this case 3. 1. 1 but 3. 1. 2 is available.  So if want to update and just select whatever you want to update and then click on the arrow and will upgrade.  The reason why you can do something like that having multiple versions is because of Pi.  Sharma is working on what is called virtual environment meaning each project as the directory.  With all the packages associated to that particular project you change project that you have another virtual environment and that in the sense is good because if you do something wrong it will stay in that particular virtual environment.  So thats something that you may want to do.  You can add packages.  But you can also manage packages using Python packages here.  So if click on one you will have here eventually little bit of.  Explanation should be right here.  dont know why its not showing up but thats basically the way it works.  So you can install the new packages you write the name of the package and it will do in that you are line that you set.  That is the default anyway.  That is the paid on or website.  And you will then download the package that you want to download.  You also have.  The terminal window.  So in the terminal window if youre familiar if you know where the doors are in the operational part of Windows thats pretty much the same in MacOs.  Its called just terminal.  So you can interact with your computer directly already.  This is not by bypassing by.  So.  Let me leave things here and let me jump back.  On the presentation.  So.  We saw some of those.  You can also do printer and let me show you that before we blog.  So we saw that you can do.  Again you can do like operations like that but you can also do print.  Class B.  And you will get the same result.  So in Biden on three point something you need to write the parentheses on what you want to print.  So you can print variables like in this case you can print values you can print nothing.  Like if you do print.  Nothing you will get just blank line sometimes may be useful.  If you want to bring the even stronger.  You need to use either single.  Or.  Double quotation.  And for Biden is the same thing.  All right.  So.  Again we saw several of those examples.  You can assign again.  We saw that by the user to body of both variables.  You can use any name any combination of letters.  Numbers underscore names are case sensitive.  Keep that in mind.  You cannot use some of the what are called reserved words so you can not call the variable print because print is result of what When you name body of bolts you may want to use names that are representing the content somehow.  So if you want to calculate the body mass index the body mass index has weight and height as variables.  So you can call those variables and and then do the operation and the result would be the same.  But next time you will read the script assuming the script is larger because otherwise you will remember it.  You may not remember what and means.  So calling them height weight and BMI would be really helpful for maintaining the software down the road.  So those are what is called the mnemonic naming of variables meaning helping.  Remember the role of the variable in your pronoun.  Um we worked little bit with the interactive approach to meeting right.  In the statements that actually in the pilot console and then.  We mention that writing and using the text editor sequence of statements is the best way if you want to keep up.  The statements for later news.  Okay.  Let me stop here for second.  Questions.  All good.  Okay.  So lets continue.  Let me go back here and let me introduce the assignment.  So the assignment is on installing python and pie shop to do some of those operations on the python console.  And then we added the except side zero that you will find the on your canvas.  So for the time being dont worry too much on the syntax of the program.  will go through the syntax but again we will go back to all all of those.  So when you have this number sign up that means that everything following the character will not be interpreted by Python.  Meaning those are comments.  There are other ways to add the comments.  But thats pretty straightforward way.  So order is comment that accepts zero and so on.  Those are all comments.  So this wild group is what is called loop.  So one of the tricky part of Python is the use of indentation meaning all of those statements.  Are all part of the same loop.  So they are indented the kind of creating separation from the rest of the code meaning everything on this indented portion will be executed the one through.  So while true it is statement that will mean its loop that would be broken when there would be the break condition.  So in this case you are asking the user to input number or done to stop.  If the user type done you break meaning you go out of this loop you go here and you will print that.  Thanks for using this tool.  If not meaning if else you are else.  Now you are asking for second number and then you do calculation that is adding two numbers and you will continue indefinitely until you will type down and you will exit.  So when you do loops like that you want to be sure that there would be an exit condition because otherwise they would be infinite loops.  So let me run it.  To run it.  There are several ways to do it.  One of the ways its right click on the tab.  Run.  But now hes running for center chair 20 to thank the juror for.  And you have the sum of 22 plus 44 is equal.  66.  Lets assume that they do then.  Im exiting the loop and have.  Thanks for using this tool and thats it.  You would see those signs.  So those are what are called special signs.  So those special signs.  Ah with the backslash and then character.  And that means new line.  So when Biden is reading it that is keeping one line.  Writing whatever is here and then is keeping another line.  And thats why you have all this space here.  So let me go here and.  Let me recap what you are going to do for homework one.  So you want to set up am6 24 folder.  You want to obviously download the homework one and that will be the instructions.  Thats the link that is working at this.  And then you will prepare the environment meaning you will download the python you will solve by following the instructions.  Then you do pretty much the same things that you did on the by the console here.  So those are sample of operations.  You will take screenshot and you will posted the.  And then.  So thats basically the detailed version of it that you will have the print run by your name that is missing here.  Im sorry.  Then you will bring the.  mean you would run.  The code again.  To run the code the right click the prime.  Or you can just the name of the script is here.  You just click this run here or you can go here and run or just run and specify what you want to run.  So there are many options.  Them or just do this and we run again.  But mean.  Again doing.  Right click around.  It will keep in mind that there is also shortcut.  So control.  Shift control Yeah.  Shape control are our control option.  Are we running Thats pretty much it.  So let me stop sharing.  And thats pretty much it.  Oh its about 800.  Some of the classes down the road may last little bit longer.  So uh normally its 630 800.  will do my best to say in the 800.  But if there are would be questions we can say little bit longer.  Generally speaking the structure of the class would be we will start with comments on the material that was posted.  And in particular would like to have your comments and then that start the discussion.  After that will introduce the content of the week and will use some.  PowerPoint to kind of highlight some of the key points that those power points that will be posted and then there will be some inclass exercises that can or cannot be four points but is for practicing.  Then will introduce the assignment for the following week.  Comments.  And thats the end of the class.  So those are the normal components of normal class.  So again comment on the material.  New material presented in class.  Exercise introduction of the new assignment.  End of the class.  There is not much that you can do today as an inclass exercise because we really just that.  But from next week we would do it.  So thats basically the end of the class.  Uh if you dont have questions.  If you have questions feel free to ask.  am happy to address it.  fis STEVENS lw INSTITUTE of TECHNOLOGY is fi Visualization Python clipizzistevens. edu SSE History of Graphics and Visualization 70s to 80s CADCAM Manufacturing cars planes and chips Sr STEVENS INSTITUTE of TECHNOLOGY Visual Analytics Definition Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces People use visual analytics tools and techniques to Synthesize information and derive insight from massive dynamic ambiguous and often conflicting data Detect the expected and discover the unexpected Provide timely defensible and understandable assessments Communicate assessment effectively for action STEVENS INSTITUTE of TECHNOLOGY What is not visual analytics ie Large graph structure with no labels Heat map with no labels Search and retrieval systems Chart with no interaction Image with no semantic interpretation Stand alone image that does not tell story STEVENS INSTITUTE of TECHNOLOGY Whole Part Relationship ws Scale independent representations whole and parts atsame Time at multiple levels of abstraction offen al ke qd meer selected more from groups eles STEVENS INSTITUTE of TECHNOLOGY Relationship Discovery te Explore high dimensional relationships theme groupings outlier detection searching by proximity at multiple scales STEVENS INSTITUTE of TECHNOLOGY Combined Exploratory and Confirmatory Analytics Develop and refine hypothesis Evidence collection management and matching to hypothesis Tailor viewsdisplays for thematichypothesis focus of interest Often suggestive of predictions enabling proactive thinking Select document title to view the contents STEVENS INSTITUTE of TECHNOLOGY Multiple Data Types Supports multiole data types structuredunstructured text Imageryvideo cyber Systems of either data type or application specific STEVENS INSTITUTE of TECHNOLOGY ji .  Temporal Views and Interaction Most analytics situations involve time pace velocity Group segments of thoughts by time Compare time segments Often combined with geospatial STEVENS INSTITUTE of TECHNOLOGY Neen Reasoning Workspace eS Workspace to construct logic and illustrate reasoning Flexible spatial view of reasoning stories STEVENS INSTITUTE of TECHNOLOGY 10 Grouping and Outlier Detection Grouping and Outlier Detection Form groups of thoughtdata Labels and annotation Compare groupings Find small groups or outliers Labeling Critically important Dynamic in scope number labels size color Positioning Almost everything has labels Labels tell semantic meaning Multiple Linked Views Temporal geospatial theme cluster list views with association linkages between views 13 Reporting Capture display segments in graoh modes for putting in reports PPT etc Capture reasoning segments of analytic results Capture animations STEVENS INSTITUTE of TECHNOLOGY 14 Major Python visualization packages ie matplotlio httomatplotlib. org Gallery httomatplotlib. orggallery. ntm Frequently used commands hitpmatplotlib. orgapipyplotsummary. html Seaborn httpstantord. edumwaskomsoftwareseaborn ggplot version httpdocs. ggplot2. org Python port httpggplot. yhathg. com Bokeh httobokeh. pydata. org SS LULU STEVENS INSTITUTE of TECHNOLOGY 15 Seaborn Seaborn is library for making attractive and informative statistical graphics in Python Itis built on top of maftplotlib and tightly integrated with the PyData stack including support for numpy and pandas data structures and statistical routines from scipy and statsmodels httpsstanford. edumwaskomsoftwareseaborn STEVENS INSTITUTE of TECHNOLOGY 16 Bokeh CONTINUUM le Interactive Visualization Novel graphics Streaming dynamic large data For the browser with or without server No need to write Javascript hitobookeh. oydata. or Sr STEVENS INSTITUTE of TECHNOLOGY 17 Versatile Plots STEVENS INSTITUTE of TECHNOLOGY 18 Novel Graphics STEVENS INSTITUTE of TECHNOLOGY 19 Linked Plots Notebook Easy to show multiple plots and link them Easy to link data selections between plots Can easily customize the kind of linkage straight from Python without needing to fiddle around with JS STEVENS INSTITUTE of TECHNOLOGY 20 Flexible Tools Notebook Many useful tools with builtin functionality Easy to extend with Javascript if so inclined SS LULU STEVENS INSTITUTE of TECHNOLOGY 21 Traditional Web Viz Interaction Simple dashboard Server language generating HTML JS CSS styling subset of data Handling user interaction Custom Javascript calling Server endpoint which generates updated JSON or JS that gets pushed back to client via websocket STEVENS INSTITUTE of TECHNOLOGY 22 Bokeh Conceptual Architecture Simple dashboard Single language no need to write HTML JS CSS Handling user interaction Single language that you already know interactive data updates feel seamless to the user STEVENS INSTITUTE of TECHNOLOGY 23 What IS Plot. ly Plot. ly is an opensource data visualization tool lth . .  was built using Python Django JavaScript . .  Offers web application for visualization analysis . .  provides plotting APIs for many popular languages . .  plots are fully interactive and rendered with D3. js or WebGL for 3D . .  free paid and onsite offerings Compose Plot Figure The Plotly Plot Object Composed of two parts Data and Layout Data Contains the information to be plotted.  Composed of traces Layout Contains information about the plot i. e.  title labels fonts annotations etc.  Figure Combines Data and Layout STEVENS INSTITUTE of TECHNOLOGY 25 oft STEVENS INSTITUTE of TECHNOLOGY Mining Social Media 2016 clipizzistevens. edu SSE Why Mining Social Media How can we discover interpret and use what Is relevant in the volumes of available information generated by social media users using streams of messages Semantic Analyses provide only part of the answer Potentially relevant role for text mining BY with specific issues Social network metrics Time Sensitivity Short Length Unstructured Phrases STEVENS INSTITUTE of TECHNOLOGY of Aspect Time Sensitivity Social medias realtime nature Example some bloggers may update their blog once week while others may update several times day Large number of realtime updates from Facebook and Twitter contain abundant information Information detection and monitoring of an event Use data to track users interest in an event user is connected and influenced by hisher friends Example People will not be interested in movie after several months while they may be interested in another movie released several years ago STEVENS INSTITUTE of TECHNOLOGY Aspect Short Length Certain social media websites have restrictions on the length of users content like Twitters 140 characters rule Short Messages people become more efficient with their participation in social media applications Short Messages also bring new challenges to text mining STEVENS INSTITUTE of TECHNOLOGY fs Aspect Unstructured Phrases Variance in quality of content makes the tasks of filtering and ranking more complex Computer software have difficulties to accurately identity semantic meaning of new abbreviations or acronyms STEVENS INSTITUTE of TECHNOLOGY in Extracting meanings Using combination of semantic and topological et analyses we can extract dynamic concept maps Conversations are characterized by structural patterns whose properties can be assessed through quantitative metrics tool has based on this approach can be used as backchannel for real life events Conversational patterns can support sentiment analysis and provide dynamic insights on what people say about the event Conversational metrics potentially contain early signals to predict users preferences and choices STEVENS INSTITUTE of TECHNOLOGY Classes of application we Extract concept maps from message streams to detect elements to screen conversations for two classes of events Classes of application Events non evolving in time such as launch of new product or new movie.  Final goal is to ascertain whether differences in streams patterns are correlated to relevant KPIs Events evolving in time such as politicalmarketing campaigns.  Final goal is to detect people reactions to evolving stimula STEVENS INSTITUTE of TECHNOLOGY unit of analysis Social streams originated by Twitter microblogs because Twitter popularity Microblog is the main social medium to share broadcast opinions Reduced semantic complexity due to the 140 character format cf.  Perspective Conversational analysis The research uses conversational metaphor and assume that in backchanneling applications microblogs stream exhibit some properties of conversations According to the Common Ground theory conversation is form of collective action requiring participants to coordinate on content and on process Brennan Clark 1991 STEVENS INSTITUTE of TECHNOLOGY Perspective Conversational analysis Twitter streams as looselycoupled conversations Common ground accumulation generating shared knowledge Exploit adjacency pairs Clark Schaefer 1989 fo connect tweets into collective knowledge map evolving in time STEVENS INSTITUTE of TECHNOLOGY 10 ts Methodology Ye STEVENS INSTITUTE of TECHNOLOGY 11 fs Methodology in action Step Extract messages create the dataset Step Extracting the social network to get social metrics Step Create bipartite network keywords senders STEVENS INSTITUTE of TECHNOLOGY 12 Methodology in action semantic basics Step Extracting 1mode with words only GWG GTWAW where AWpq xU pxA and qxA Step Detecting clusters topics using Sn en Sm combination of kcore decomposition and cae Louvain community detection method Step Interpreting the results Using combination data mining and visualization ME STEVENS INSTITUTE of TECHNOLOGY 13 eee Test refine through Case Studies Obama Romney Presidential debate in October 2012 with about 30000 tweets collected from swing county the Tampa region in Florida Kenya general elections in March 2013.  To analyze occurrences of violencerelated conversations.  About 50000 tweets collected Boston marathon bombing in April 2013 fo analyze people reactions.  About 30000 tweets collected Five non eventful days in Hoboken in November 2013 fo analyze streams not related to specific events.  About 100000 tweets collected Several Apple and Samsung events in September and October 2013 June July August September and October 2014.  Tweets collected in each event in 2013 were between 40000 and 60000.  At the latest event in October 2014 about 600000 recent change both in Twitter policies and in the tool sample of outputs in the following slide Super Bowl in February 2014 to analyze people comments.  About 40000 tweets collected Oscar night in March 2014.  About 60000 tweets.  From this stream extracted the companies people talked more about.  Monitored one of them Samsung and collected tweets over the following months for total of about million tweets to compare the average and peak people opinion on the brand Movie Openings from 102014 to 22015.  total of 21 movie opening has been monitored so far collecting movies performanceKPIs to validate the model AppleWatch event in March 2015 to face validate the representativeness of the method.  About 700000 tweets collected total of more than million messages related fo 35 different events ME STEVENS INSTITUTE of TECHNOLOGY 14 ft.  Applying the Methodology Case monitoring ongoing events Those are events whose evolution in time can provide insights that we want to monitor such as in ongoing marketing or political campaigns where messages sent by the campaign managers can be adapted based on people reactions Subject of the search can be combination of geographical location and keyword such as in monitoring the needs of citizens in region no keyword required or regional political campaign combination Methodology in this case will have Dynamic visualization No data mining steps STEVENS INSTITUTE of TECHNOLOGY 15 Empirical study One of the key events In consumer electronic In 2015 Over 700000 tweets collected Full press coverage with by the minute event logs available Possibility fo overlap event log with data from our system STEVENS INSTITUTE of TECHNOLOGY 16 Case study on Monitoring Networks Extraction STEVENS INSTITUTE of TECHNOLOGY 17 Case study on Monitoring Case study on Monitoring Data Preparation Data have been pre analyzed to increase quality applying exploratory statistics and preliminary data mining El STEVENS INSTITUTE of TECHNOLOGY 19 cfs Case study on Monitoring Visual Interpretation Reconstructing the event narrative through Twitter users reaction Size is based on number of tweets in given time frame Colorblurring is based on the focus of the conversation in given time frame.  The less blurred circle is the more focused the conversation is Focus is calculated by number of clustersnumber of word in the cluster Words on the globes are the most relevant for the time frame Globes are connected based on semantic similarity between clusters STEVENS INSTITUTE of TECHNOLOGY 20 cfs Case study on Monitoring Visual Interpretation Reconstructing the event narrative through Twitter users reaction Positive and Negative sentiment polarities are by the sides of the globes STEVENS INSTITUTE of TECHNOLOGY 21 Case study on Monitoring Visual Interpretation Identifying homophily Relational Network Words Network Homopbhily is the extent to which actors form ties with similar others It is calculated using clustering coefficient The top peak shows highly related people talking about focused subjects Isolated relational peaks shows highly related people talking about unfocused subjects STEVENS INSTITUTE of TECHNOLOGY 22 Case study on Monitoring Interpretation The different visualizations display consistency in their pattern The different relative peaks are in sync with topical moments in the events There is noticeable overlap between the changes in the metrics and the actual events Even if the key announcement was the Apple Watch the most intense reaction has been for the new MacBook STEVENS INSTITUTE of TECHNOLOGY 23 ft.  Applying the Methodology Case Predictor detection Those are events whose evolution in time is not as relevant as gathering collective opinions that can be analyzed to determine factors with predictive capabilities for given KPIs as in finding patterns for successful product launches Subject of the search are several with homogenous characteristics such as in the launch of new movie where subjects are the different movies opening during the period of observation Final goal is to ascertain whether differences in streams patterns are correlated to relevant KPIs This is data mining task where the dataset to be mined is composed by the values of the metrics for the different subjects such as the different movies and selected KPIs as target variables such as box office revenues STEVENS INSTITUTE of TECHNOLOGY 24 oo Case Study on Predictors Detection New Movie openings in 20142015 The data We collected data during the weekends of opening of new movies total of more that million tweets related to 22 movies that are 22 different datasets Each dataset has been split into 1h long time windows.  Each partition has been analyzed using the methodology Base Pe in the previous slides and then consolidated in matrix with datapointrecord per movie with 50 variables each STEVENS INSTITUTE of TECHNOLOGY 25 Case Study on Predictors Detection KPIs We are using indicatorsKPIs First week box office revenues weighted by number of theaters Critics score from Rotten Tomatoes Tomatometer Audience score from Rotten Moto STEVENS INSTITUTE of TECHNOLOGY 26 Case study on Predicting Independent variables Sentiment polarity Traffic metrics tweets per unit of time Social network metrics centrality density and clustering Semantic metrics lexical re CUHULGS diversity and topological metrics based on the concept maps STEVENS INSTITUTE of TECHNOLOGY 27 Case study on Predicting Networks Extraction The relationsocial network STEVENS INSTITUTE of TECHNOLOGY 28 Case study on Predicting Networks Extraction semantic clusters network for Kingsman for the 1st time window STEVENS INSTITUTE of TECHNOLOGY 29 Case Study on Predictors Detection Preliminary Processing We apply all the We apply all the topological and statistical analysis we use in the Monitoring ongoing events case Instead of considering the single partitions for the next steps we collect in one dataset aggregated values from each of them Case Study on Predictors Detection We used Decision Tree CART Random Forest Linear regression and Artificial Neural Networks for the modeling We targeted the first week box office revenues as KPI because the results with the other KPIs are poor We tried several combination of variables to determine the one with the highest prediction value Case Study on Predictors Detection To evaluate the performance of the model we applied Predicted vs.  Observed analysis using subset of the original dataset as testing dataset Sentiment variables performed poorly with the best result being 0. 47 using Linear Regression bottom left The Model Evaluation Case study on Predicting we Data Mining Evaluation STEVENS INSTITUTE of TECHNOLOGY 34 cfs Case Study on Predictors Detection The Model Interpretation Each group of variables when used in isolation does not make good job in predicting early sales for new movies This is particularly true for the sentiment metrics which achieve by far the worst oredictive performance In general the topology of the keywords network and the traffic values seem to play key role The model does not work well in oredicting what people think critics and public reviews but works to predict what people do sales Tyt gly STEVENS INSTITUTE of TECHNOLOGY 35 ft.  Applying the Methodology Case Emotion recognition in crowdsourced text This application is about classifying text from public sources on given subjects based on detected emotions It can be applied to cases like Product and service reviews Forecasting election pools movie theaters It could increase the humanmachine interaction for example in consumer electronic STEVENS INSTITUTE of TECHNOLOGY 36 EMOTION CATHEGORIZATION THEORY lw Plutniks Emotion Wheel Eight Basic Emotions inside dark red ring pairs of opposite emotions Joy Sadness Trust Disgust Fear Anger Surprise Anticipation 3dimensions of intensity Annoyance Anger Rage STEVENS INSTITUTE of TECHNOLOGY 37 DATA SELECTION SongMeanings encourages users to discuss on the meanings of songs.  110000 artists 1000000 lyrics 14000 albums 530000 members Artists Pearl Jam Madonna and Muse STEVENS INSTITUTE of TECHNOLOGY 38 DATA GATHERING API documentation JSON files Convert to CSV Filter fields of interest Comments content Comment rating weight Replies weight STEVENS INSTITUTE of TECHNOLOGY 39 DATA PREPARATION 565 CSV Files One file per song One comment per row Script Python Lookup table replace internet slang Clean nonEnglish words nonstop word list Delete contextspecific words stop word list Tokenization list of words STEVENS INSTITUTE of TECHNOLOGY 40 hl33slUui aft NATURAL LANGUAGE PROCESSING Natural Language Processing Tools Natural Language Toolkit for Python Accessing Corpora Information Content String processing Tokenization PartofSpeech Tagging WordNet Semanticallyoriented dictionary Organized in collections of synonyms synsets Based on hierarchies word tree nodes correspond to synsets edges indicate the hypernymhyponym relation STEVENS INSTITUTE of TECHNOLOGY 41 SEMANTIC SIMILARITY lw Similarity Common Information Differences Senses and Information Content Bank financial sense is more similar to fund Bank river sense is more similar to slope SIMILARITY WITH EMOTIONS STEVENS INSTITUTE of TECHNOLOGY 43 FINAL DATASETS Pearl Jam 11 albums 158 songs Madonna 16 albums 160 songs Muse albums 102 songs STEVENS INSTITUTE of TECHNOLOGY 44 VISUALIZATION Scatter Plot Pearl Jams Backspacer Album Emotion Map Each song has eight points one for each emotion Songs that stand out are identified and labeled.  STEVENS INSTITUTE of TECHNOLOGY 45 VISUALIZATION Emotion Wheel Pearl Jams No Code Album Emotion Wheel Overlay Radar Chart and Plutchiks Emotion Wheel No Code by Pearl Jam STEVENS INSTITUTE of TECHNOLOGY 46 cfs Case Study on Emotion Detection The Model Interpretation In this case study emotion detection can be used for example to determine what makes an albumsong from given artist more or less successful using the number of units sold as KPI Some of the emotions like SurpriseAnticipation do not play relevant role in songs Artists generate moderately distinctive emotions Tat aly STEVENS INSTITUTE of TECHNOLOGY 47 Beyond Twitter Other potentially relevant Social Media are Facebook and LinkedIn Linkedin is more complex to mine due to their strict privacy policies All the media can be mined via htmlmining but this process can be very time consuming with APIs being always the best way to go Imagevideo based media are still by the technology frontier in terms of mining due to the complex task of extracting semantic from pictures when the subject is not human El STEVENS INSTITUTE of TECHNOLOGY 48 Mining Facebook Private pages in Facebook are protected by Facebook privacy policies and cannot be mined via their API Html web mining is always possible but quite time consuming you need to go to the page you want to download save the html and mine It.  If info are in multiple pages this can take while Public pages are accessible via Facebook API STEVENS INSTITUTE of TECHNOLOGY 49 Mining Facebook Case Comparing Democrats and Republicans in 16 We compared Facebook comments on Hillary Clinton 07242016 07302016 week of the Democratic National Convention Donald Trump 07172016 07232016 week of the Republican National Convention The quantity of comments mined per day varied from 10000 to 50000 STEVENS INSTITUTE of TECHNOLOGY 50 Mining Facebook Case Comparing Democrats and Republicans in 16 Trump relational network right is more Trumpcentered than the Clinton one being Clintoncentered left STEVENS INSTITUTE of TECHNOLOGY 51 Mining Facebook Case Comparing Democrats and Republicans in 16 Those are the semantic networks extracted with Clintons one on the left Trumps on the right STEVENS INSTITUTE of TECHNOLOGY 52 oo Comparing Facebook and Twitter lee Case Comparing Democrats and Republicans in 16 We compared results extracted from Twitter and Facebook on the same subjectperiod The two media appear to be used in very different ways Despite possessing features and capabilities allowing for prolonged conversations between users Facebook is instead used as soapbox and microphone for each user to proclaim his or her message with no regard to if anyone Is listening In contrast Twitter relies heavily on the relaying of information about topic via highly influential users who are retweeted over and over El STEVENS INSTITUTE of TECHNOLOGY 53 Hello.  Hello everybody.  Its 629.  113 Hey.  Lets wait.  121 Two more seconds.  So hope the assignment was not too bad.  126 And hope that you have time to review the material for this class.  135 But we will have plenty of time for going through all of it anyway.  142 And.  think we can start.  148 Its 630 now.  Oh right.  153 Okay.  So its February the 14th and the Happy Valentine.  200 If you celebrate am not particularly in to death but thats fine.  208 Too commercial.  But thats me.  Happy Valentine anyway.  215 631 Now.  So we are starting.  We will cover the usual topics.  223 So we will talk about little bit more by Donna.  232 We will add some elements that are more related on the management side 238 but we will talk about the themes in software development and will share some experience and then we will do an inclass exercise.  244 So we will review that.  257 We will discuss the new assignment that is going to be little bit more complex but thats basically the spirit of the course.  300 So the idea is to start the very low profile easy assignments 312 and then build up class by class up to the midterm when after that it will be little bit more challenging 319 also for people with some background in coding because well be more on applying coding to cases 334 situations problems topics and that would be more the real goal of the entire course.  346 All right.  So let me start sharing the screen.  356 And let me go first as usual.  402 Cause this wouldnt go here.  Okay so we will.  409 We are.  In Module four Software Development Lifecycle.  417 dictionary is another structure.  In Python you had some material to read.  428 We will we will talk about those up in with the support of some slides.  439 hope you are not having additional issues with the material.  448 Again it was little bit of messy.  453 The canvas shell that we use and in part was my responsibility.  458 mean it was my responsibilities my course.  But physically messed up little bit thinking that youre replacing mean 507 the new material that was kind of replacing what was there and what not.  520 Campbell said that he did it.  He did not.  But anyway so really hope that now is working well.  528 If its not working send an email to me to show you and that we will address that.  534 All right.  So lets start with.  542 With the previous assignment.  549 So the assignment was pretty straightforward.  That was actually there was two components of the assignment.  554 So one was the coder and the other one was the.  602 So that was those things was on testing.  613 So on the testing thats pretty much always little bit of an issue with some of the students because they dont really get that what was asking.  620 So try to be more clear up in the way introduce the exercise but sometimes students still have little bit of issues.  634 So just to be very clear the testing is for testing.  654 The script that you would write.  So hes not genetic theoretical testing but hes testing the program that you are going to write for you Europe.  702 Excuse me.  Oh right.  Okay.  718 So.  So using the template that gave you.  722 You have program goal that is mean that description that you already have 734 the program will check that user input if it is number that is multiple of five.  739 The strategy meaning what are the logical steps that you would write again 748 Its defining the logical step that will be translated into the language that you will use.  800 Meaning it could be python it could be could be any language.  808 So the program will ask the user for input.  814 The user input will be checked first for the willingness to proceed.  817 If the user will type done will exit the program will then test if the input is an integer.  824 If not the will go back and then it will check if the input is multiple of five.  834 If not the will go back.  840 Otherwise we print positive message.  846 This is flowchart.  Is the representation in the blocks the logical blocks of the logic of the program.  851 So generally speaking you have the square blocks that are assignments things to do.  902 So ask user input.  Those robots are the question that you will ask.  912 So the conditional statements.  So as user input is done.  920 Yes.  And goodbye.  And is the end of the program done 928 No.  am asking if is integer.  If not the you and the message will be you enter non integer value and you go back to EPS.  932 You ask is this multiple of five 941 If no you the message will be you enter number that is now the number of five multiple of five and you go back if yes you print.  944 Okay.  Uh.  In reality there should be going back here that is not in this chart.  955 So for each one of the alternatives you want to have value that will test that particular branch of the shot.  So if the input is done in testing this conditional here if the input is done is done then the output will be good by.  If the input is then the output and testing this the output will be under non integer value if it is 61.  And testing this condition here you enter number that is another multiple of five.  95 will be okay.  So with that tested every single conditional branch of my chart that its basically in plain English this testing strategy.  So that was the testing portion.  Questions on this.  All right.  So let me go back to sharing it and let me go to the code.  So does the code.  The usual while true.  Lupo.  So Im asking the user to enter number or done to quit the.  Im checking if the input is done.  It doesnt break.  If it breaks it will go here and it will print goodbye.  If not the will try to transform the input that is stringer into number an integer.  If we get an error we go into acceptor.  Will print that your input was not valid number of cents.  Please try again and then continue.  Meaning we go back to the beginning of the loop.  If there is no except no error Im asking if.  The value is less or equal to zero.  mean thats something that is not in the flowchart that is an additional check was not required.  But if it is negative please enter value greater than zero.  Then Im asking if is multiple of five.  If is not multiple of five then you will get the message and go back.  Im checking also if its more than 1000 again youre not being asked to do that.  If it is print please enter value thats more than 1000.  Continue.  If mean that all the ifs are negative then you will print under that amount of sense.  If you run it.  So if you have 22.  You have not enter multiple of five.  If you do.  certain number of hives.  And if you do minus two.  And then if you do 55 you will get the message.  And if you do quit the.  Oops.  Its done.  It will be goodbye.  Sorry about that.  Okay.  So thats basically what was in the in the code the questions on that.  All right so lets uh.  Anyone has any question on the assignment have question Professor.  Go ahead.  For the homework.  Are we.  Are we required to test of floating number like decimal Well try to be as much clear as possible in the requirement.  If it is not required by the requirements you dont need to test.  So in this case the two tests less than zero greater than 1000 that we are not required and you are not requested to do it for the floating or the integer Well its pretty much the same in this case.  So that being said again.  So in this case use the integer but could do the same with floating.  So you dont.  mean that either one is fine.  mean there is no difference.  In this case know that is.  mean want to have an integer because if it has to be multiple of five it should be an integer.  And thats why used integer.  But mean that the problem would work as well if instead of Integer would have float.  Oh guess my question was do if used the intention.  Well but didnt wasnt explicit in the guess that the testing portion in the bottom didnt put like 10. 5 or anything like that.  Is that is that fine or would we have points off taken for that No no thats okay.  Is absolutely.  Because got points taken off for for not testing like 10. 5.  will check that with you.  mean again if youre not required to do test you dont you dont have to do it.  Then if you do it and its working thats good.  If you do and its not working and it is not good then you will get some points off.  But mean in this case no one was asking for shaking her.  If her assertion not meaning.  will take your.  Great.  And actually thats not the best.  All right.  Still Im Professor.  Yes.  just want to make sure had the same thing.  had note that said Float not tested and had to take it off as well.  Okay.  Im not sure if anybody else had that same issue myself also.  Yes.  Okay.  will review all of you.  Okay.  Thank you for telling me.  Yep.  All right.  Okay.  So that will be fixed.  That again.  If is not in the requirements you dont need to do it.  So really tried to be as much clear as possible in the requirements just to avoid the misunderstanding of any kind.  But things can happen.  All right so lets move on and lets go now.  To the lights.  Its 647.  We are definitely on time.  So we will cover two different topics two very different topics.  So one will be on working in teams.  So all of you most of you are professionals.  You most likely work in teams.  You know what the dynamics are.  But just want to revise to review with you some of the key points of working in teams in particular when you are developing software is engineering management.  You may be in position of managing people and in particular managing people who are developing software.  So knowing how those environment may work and what are some of the key elements could be useful to you or to some of you or for most of you.  When you develop any organization you have pretty much the same problems.  So you need to hire people.  You need to keep people on track.  You need to motivate people.  You need to eventually replace people.  You need to solve the issues.  mean the most recent software team that managed it was few years.  mean apart from research in company so was few years ago was managing as coCEO and CTO.  Not huge but sizable team of developers in technology company in Central Florida.  But the mission of the company was managing the tickets.  So we manage the tickets for bunch of clients including Disney.  So Florida.  Orlando.  Disney.  Thats why we were there.  And some of the issues are.  So use that example because had situations that are very common and they are kind of good example on how those things can happen.  So will use that example few times in these presentations.  So when you have a.  An organization on project you may want to have project manager or team are doing the the management of the project.  That can be called million different ways but pretty much in the one setting the time being the drummer of the rock band wrote for Up with McKinsey for about two years.  The company was very very focused on organizations.  Typically what they recommend the most is mavericks organization meaning you have people teams committing certain functions within the company and serving across the organization as subject matter expert on that particular field.  Thats the Mavericks organization opposed to the hierarchical organization where you have each team with all the components.  So lets say you have team developing user interfaces each team meaning each group working on one particular project within the company they have their own sub team working on the user interface.  The two organizations.  They have pros and cons like everything in life.  So the pros of hierarchical organization is that you have more control of the resources you can use because you have your entire structure.  The cons on the company side is that you have duplications because the same user interface expertise is in that the multiple teams.  So.  Hierarchy is okay in some cases but you lose in terms of the optimization of the resources.  The Matrix organization on the other end.  Its great for optimizing resources but the very end that each unit will become it will serve multiple teams meaning each team does not have full control of all the components of the project but they need to rely on an external to the team internal or the company part for function.  One of the advantages of the Mavericks organization is that at the certain point you can outsource some of the components meaning the you have more lets say cluster of competencies than then in second round out of reorganization Id say you were hierarchical.  You move to mavericks.  But people look.  Wed say in competencies that we stay within the companies.  And the certain point you may decide that some of the functions are not core functions for your organization and at that point you take them out.  So was working in telecommunication company and in certain point they outsource good portion of the information technology because they decided that was not strategic.  So they pretty much kept the the network and the marketing not so sure that they would be good choice because I. T.  is developing software that is developing the real differentiation elements for your company and outsourcing that is cannot be easy.  And now that issue is also.  mean when you outsource something you want to reduce the costs meaning the vendor providing the service will have very strict policy of what they can do for you.  If you are for anything cut.  It is outside of the scope of work or they will charge you more.  So at the very end you may lose control on the budget.  So mean you dont need to go all the way to outsource everything that is outsourced by the Mavericks organization.  That could be preliminary step toward not the outsourcing.  Thats another example.  When you develop software you may want to have teams with high specialization in one particular area.  So you always have project manager setting the time but then you have the different competencies.  little bit different is a.  The support team or customer care.  So the structure of customer care is pretty much the same in many organizations so not all and is in that honor on three levels.  So the first level of the customer level one is basically the customer is calling and you have someone or something or you can have both doing that will provide answers based on script or flowchart.  So thats basically what you have at level one.  Level one no the three levels is the one with the lowest cost because you can have an automatic system you can have people with no particular training.  But the answer is that this level one can provide that may not be enough.  So if they are not enough then at that point that you go to the next level the level two where you have people in the team that are with better training and they are trained to functionally address the problems.  So they dont know the code but they know of functionally how the code is working.  So when you go to level two you have more course meaning.  If you measure her the course by the time spent on each case multiply that by the cost of the resort itself.  Then that level to add will have more time and resources that will cost more.  So.  But they can see the meaning.  They may not be able to address the problems that the user may have at the point that you go to level three where you have people trained on the software knowing the software and they are able to check if there is bug if there is something that was supposed to work in way but is not working the way supposed to be.  So obviously at that point it will require more time and resources that are more expensive.  So obviously you want to have up in level one as much powerful as possible but thats basically the way it is generally organized.  When you set up.  Um software development team.  Uh you go through the recruiting phase that can be intense sometimes.  So you want to check obviously the technical skills but you want to check also the compatibility of the candidate with the rest of the team and with the culture of the company.  always use an example of the same people that it was mentioning the experience in central Florida.  will.  Im hired.  mean set up the hiring process looking for hiring.  The team leader of the developers and went through several candidates.  At certain point the one candidate was my favorite.  We had other people doing interviews with the candidate and then we hired him.  From the technical standpoint he checked all the boxes but then at certain point his starting asking questions like all the people in the team are wearing shorts.  dont feel comfortable wearing shorts.  wear khakis.  Is this problem said you know lot at Central Florida people tend to do that.  Where would you feel more comfortable with Then the second time was a.  came to the office very early 630 700 but then want to leave.  330 400.  But the rest of the team is coming late.  The 930 even leaving late in the evening.  Can we fix that said you know what Again you are the team leader.  You are supposed to be the first to come and the last to leave.  So you want to be as much as possible.  You want to spend as much as possible time with your people.  So all of this is to say that you have the technical skills and what we call the soft skills.  So in this case this individual was not really compatible with the way we were working.  So fortunately we had probation period.  We used that period to replace this candidate with another one.  So again we had dont know probably total of five or six interviews but we were not able to spot it.  So right now it is see it sequence.  We are hiding faculty and we are having the same issue think by the way researchers and are having the same issues.  So the technical aspects are important but not the only important factor.  So when you set up theme.  Its like life cycle.  So you have the formation of the team and the development of the team and the maintenance of the team.  Its basically again like life cycle in software development or in any product development.  Each one of those faces has issues as critical element.  So when you create the team you need to be sure that you again check not only the technical skills but also the compatibility the social skills that the individual needs to have.  And when you work in consulting company worked in consulting for quite while.  You may have lot of projects coming and going and you have teams that you need to create each time.  Sometimes Sir is small team.  Some other times depending on the size of the contractor there can be large team.  So at that point the time can be from few months to several years.  mean if hes serious you will have the same problem over and over because again people can leave the company for any reason and replacements.  They contract with the client can change.  And you need to adapt somehow.  When you create the team in particular if youre working for consulting company you want to be sure that you maximize your revenues or your networks and you maximize the quality that you are providing.  So you want to have people with the right technical skills at the lowest cost possible with the maximum compatibility within the team.  It can be difficult problem.  So some of the company KPMG is one that developed software sort of creating the teams.  mean keep in mind that if you are small consulting company thats minor problem.  But if you are large consulting company international sometimes you have team members that are coming from different countries because there are skills that are very specific and you dont have many of those in all the places across your what we call manage.  So developing software for that information may be good investment that.  We mentioned soft skills.  That is something really important to keep in mind that there are other elements that that on the soft skills side but not probably skill.  So you need to read the candidate.  You need to understand what are their personal ambitions and lets say longer term goals.  And you want to be sure that those goals are aligned with what you can offer in that particular case.  We have case it can be general higher in the company or hiring someone parttime on one particular project.  So let me keep all of that.  So really hope that this gave you little bit of insight on working in teams.  Again the assignments that we are doing in this course are all individuals.  The reason why use individual assignments instead of team assignments that seems to be more in line with what Im talking.  Todays is because want to be sure that each one of you as exactly good knowledge of what we are using in this course meaning Python and the use of Python for some verticals or applications.  But generally speaking when you develop software you dont develop software by yourself unless it is something as more or less specific and.  And amendments apart from special cases doesnt really happen.  Okay so lets move on and lets go now.  Its seven on seven and lets go to.  The second part of the lecture that is on Python that we will talk about the input output dictionaries and tuples.  So two different topics.  One handling files and the other other types of variables that we are going to use in our coding.  So uh unless you do something very specific unless you ask everything to be type the by the user that you need to read.  Five.  So you need to take that data from the outside world bring it to your script process it and then generate some output.  So thats normal way of doing things.  Defiance that we will use the most.  That would be text files or comma separated value of the files.  They are both in essence text files with the different skills we find so it can be handled by Excel or similar province.  So they are intrinsically matter that exceeds while the text files.  mean that proper text file is like what you have in your screen that could be in file and that would be at the five.  So where each line is record.  So when you start working with the file with Python you start with statement that is open.  So the open function in Python is the one creating and handle pointer to the file that is in your computer.  Thats an example of text file.  So you have each line that is recorder in the file.  And each time you read one line you will read for example the first line is this from Steven whatever that 2008.  And the last one will be this early.  So each one is line when you read it.  When you open if let the statement that open that is required.  So you create variable that will contain the pointer to it to define.  So we call it handle.  So is actually pointer and the statement that Auburn has two parameter.  One is the name of the file.  The name of the file can be variable or can be string.  And then the mode meaning how you want to use the file can be for reading for writing.  So if its reading its our writing is surprise.  And if you are reading the file you dont need to specify.  Ah because the default for the reading for open is reading.  But if you open for writing then you need to specify that you.  So thats an example you have open.  This is the FILA.  That was something similar to what you saw in the previous slide.  You printed that what you get is really this obscure value.  That is pointer to the file.  Other example you have text file with the three lions so the quick brown and so on blank and goodbye.  So you open the file with but again this is redundant.  You can remove it.  Then start counter.  initialize the counter to zero and then insert the loop.  So loop on the file on the content of the file.  So the variable that use in the loop is called the text line.  Anything that handles in the pointer that created in the first line.  So the first iteration it will have the first line and Im increasing the counter by one and then print the value of the counter and the line go meaning the first round the line account that would be one anybody would be the first line then the second one will be blank and third would be goodbye.  Again power is optional.  You may or may not use it and the handle is essential for the process.  Thats another example.  We used in the previous example the counter.  Thats repetition.  You can read the whole file.  So you open the file again.  In this case didnt specify the mean mean the mode the meaning of the mode is R.  Then read the with the statement the file read the entire file into single variable.  And then if bring Lang asking for the length of the content of the variable it will be the number of lines.  And then if want to have the fourth part of the fourth mean the entire variable meaning the first line can use the partitioning method that we saw in the previous class.  Another example.  You have bunch of lines.  So this is a.  Collection of tweets that downloaded few years ago.  And thats an example of the of the user.  So in this case opened the file that saw the file again this one.  So the goal was to counter or to have list of all of the elements starting with an aspect.  So initialize the list of elements with Ashtanga to zero.  Then loop into the file.  split the file to get list.  So again just as reminder am reading the entire string entire line as string.  And then when split split the string into list where the elements are the words.  Because didnt specify anything here.  Meaning the criteria for splitting the variable.  The string is this piece.  If there is space will be two different elements of the string.  So at this point have list.  So the list will contain all the words that you have in each line will line good time.  Then set loop within the list of words and Im asking if the word starts with Ashtanga.  If is starting with the hashtag will append the word to the list of stocks that they created as empty.  When finish this loop will analyze the entire line.  When finish the outer loop will complete analyzing the entire file.  And then will print the first ten.  So in loop could just printed the way it is but it wouldnt look nice.  And thats what you got.  Thats an example of application opening and analyzing content.  We know.  Continue.  That is way to do nothing and go back to the top of the loop.  We can use if in or not in.  Again for selecting portion of the file or Im in favor of the line within the file.  Splitter.  We mentioned that if you have bad Ebola like this one.  So thats what entities are missing.  Its just to the code.  So you split that by exclamation mark meaning the string will be transformed into list where each element is extracted from the original string based on the character exclamation mark.  So you have the first one the first element this would be Hello no exclamation mark because this is the element that is defining the separation.  Its this one.  Then the second will be this piece up to the op called this.  And then the last one.  If you dont specify anything it will be split by space meaning each element will be word keeping in mind that you are keeping all the punctuation that you can have in it.  Because mean unless you remove it before doing it the python will not know what the punctuation can be.  Combining reading skills wi fi and split the.  So you open.  You have this file with name and nationality.  Then you open the file.  You print nationalities.  Then you start the looper into the file and you print the.  mean you take the string you split the string creating list and you take the second element.  So because the elements are separated by comma in split specify comma.  So karma is the character that Im using to split the original string.  And then take the second element that is not number one.  So printing nationalities at the first round is joint American splitting taking America.  And then have space because even if we do not see it after each character after each line you have special character that is new line trailing and she is the is text file with the special character new line.  Im telling whatever is the area code that Im using that you need to go to the next line.  So you are just like eating right up.  So but thats character meaning when you go that next hydration that you will have space.  So if you want to remove it then you need to use another functional strip.  Strip is basically eliminating blanks and special characters left and right.  If you do strip are it will be from the right.  The strip will be from the left.  If you dont say anything.  Just strip will take those characters out both left and right.  So if you do that then you will remove the spaces that you have between the lines.  Writing If look is kind of similar.  So you have the open with the telling side that in this case you are writing file not reading your file.  mean one could be the default.  You cannot not have two defaults.  The default is meaning if you want to write you need to write to add the as parameter.  You read the first line.  You want to add the new line because you want to keep it.  Then if you want separation you would write new line party.  And then the third line and thats what you have.  And then you close it with Python two point clause that was essentially after white writing.  If you didnt have the the closer the actual right statement will never happen with python three is not essential.  Other genera use it.  Um.  Let me skip that and then you have some information on these 3. 6.  If you replace 3. 6 with whatever is the version that you are using you will go there.  If you water on other types of variables.  We will talk about dictionaries and tuples.  So dictionaries are sort of data structure is sort of archaic data structure in Python.  We saw Lisa.  So Lisa again defined by the square brackets.  And inside you have elements that are separated by comma.  Elements can be strings can be other variables of any kind including list.  So you can have list of these.  think we saw an example in the previous class.  You start from zero to the end meaning if you want to get to the third element you will address it as two.  So two will be C.  So the elements are ordered meaning they will keep the order you use to create them unless you change it in sort of explicit way.  Again inside you can have all possible types of elements.  Thats another example.  These are mutable.  Meaning you can change that.  And in this case is string.  You have banana.  You cannot replace values.  think you final three.  You could.  And we mentioned that that you can change from upper to lower.  We saw some of the functions last time in the list.  You can change elements.  In this case replaced the third element that was 26 to 28.  You can get the length of the length of the list using land.  You can create list giving of numbers and giving the range but you can specify the starting the number of steps how you want the numbers to be separated and what is the end.  Or you can just do like in this case four and you will have four elements starting from zero.  There are quite lot of additional functions that are built in in Python.  So we may learn.  You have Max.  mean some that they have the meaning that you can get.  You can split again.  You can split the variables pretty much any time including strings.  We mention that.  We mention little bit more of the split function.  And now we have two bills that the two bills are pretty much similar to this with two main differences.  One they have regular brackets instead of square brackets.  And the second is they are immutable meaning you cannot change the value of one of the elements.  So once you create them they will stay the way they are.  So in this case Im addressing the second element.  That would be if tried to replace that with an with an will get an error.  So and when you want to use tuples so you want to use tuples.  If you want to be sure that value will stay the same across the entire program.  So you do not want accidental change of the content.  Thats why you use tuples.  How many times you are going to use tuples Not many probably.  But just keep in mind that thats an option.  Dictionaries.  As was mentioning before they are sort of data structure so they have key and valuable.  So in this case you have the variable the dictionary population the so dictionaries are in brackets and you have key in this case is USA Italy Japan and you have the number and column separating the key from the value and the number is the value for that key.  So in this case is the population of mean is not exactly updated U. S. A.  380000380.  Now Italy 59 Japan 127.  So if you want to know one element for example Italy you just do population Italy and you will get 59.  So where we go here like in this case do print populations in Japan and you will get you will get 127.  You can get the keys into list.  So population keys should not specify anything.  You have all of them.  You can do the same with the values.  So you can transform dictionary into two lists.  One list will be the list of keys.  One is that list of values.  The dictionaries are immutable and they are not ordered.  Meaning if you have a.  If you have the same dictionary you printed not necessarily.  You have the same order that you used in the infinite wisdom.  The creators of Python they thought that you dont need to keep the order because at the very end that you have key and whatever the element is you will pick it using the key.  So if you do if you create the list and you print in the most likely you will not get the same order that you used to create it.  So if you want to add an element you can do it.  So you do populations name other dictionary in the square brackets the key and the value.  And then when you printed the mean if we go anywhere not necessarily at the end if it was list and you use append that it will go at the end.  In dictionaries you dont have an upper end and there is nothing like pen.  Loops so you can loop into dictionaries.  So.  You can loop by element by keys.  You can retrieve elements using the key.  Thats another exemplar.  was that.  So lets say you have text file like this one.  So we will read that one line at time split each line into words and we want to add one to the value.  mean that its counting the number of times each word is appearing in the text.  So you have one word.  If the word is already in your dictionary you will add one to the counter.  If the word is not in the dictionary you will create the entry for that word.  So.  Keep this in mind because you will use it.  In the inclass assignment.  So you have file you are opening the file.  So again is related to this file.  In re again you dont need to specify you initialize the to empty dictionary and you start reading the file.  So one line at time.  Then what you do is basically strip the line left and right by special characters and blank spaces and then you split it by space.  So you will get.  This line in list where the first element will be in the last element would be the and with all the others.  Then once you have the list you start looping into the list.  So you try if what counter there is dictionary of that particular word meaning you are using that particular word as key in the dictionary.  The first round up.  The dictionary is empty meaning when you try to address that particular element you will get an error because there is no.  Lets say you are in.  In.  There is no in.  In the dictionary.  So you will get an error.  You will go here and you will create the first entry.  So in the first round in that particular file the first line that will be in fill whatever is the end and then the first word will be in.  You will get an error.  When you try to execute this statement you will go into except the new will create new entry.  That will be an element where the key is that particular word in in this case and the value will be one.  When you go to the second word then the second word may be there maybe not.  The certain point that would be awarded there was already there.  And then at that point that you will add one to the counter.  So when you finish board the loops you will have.  dictionary with all the unique words and the number of times that they appear in the text.  And then you create list of the first ten and then you loop it and printed.  And thats what you got.  But in this case we have key and value.  And thats what you have.  Um counting objects.  Again theres something that.  dont want to spend too much time because its kind of similar to the previous one.  Just briefly.  So.  You know is that replacing it with that one Okay.  So thats basically it.  Let me see if you have questions.  Just have one quick question on the homework.  Sure yeah.  For the procedure it says to skip line.  assume that we.  Are we counting the first line in the files as the total line count or are we ignoring it Well there are two ways that you can do that.  One is to use counter that is starting lets say mean that you normally initialize counter to zero.  In this case if you initialize the counter to minus one then at that point the first line will not be counted.  And thats one way the other way.  You can read the out of the loop the first line and then in the loop you will start reading after the first line.  So those are two options that you may have down the road.  We will use different way to read the fine into variables.  So we will talk next week about the.  Data structures and in particular pandas with those structures.  You can just read the keeping the header but in this case you dont have that meaning.  You need to do either one.  So either you use an account that you initialize the account that in different way or youll be out of the loop.  The first line.  Okay.  So if we read or exclude the first line its still correct then right Yeah.  Okay.  Just making sure.  was trying to understand it fully but to avoid any point loss.  Thank you.  Sure.  Sure.  Absolutely.  Okay.  So its uh 730.  830.  Um.  It led us to 15 minutes of inclass exercise.  So let me go.  Let me share the screen.  And let me go here.  So the inclass exercise is two portion one.  Read the file.  That is name the names.  The containing list of names.  Count how many unique names that are in the file and print the results on the screen.  Part two.  You want to print the name that is use the the most in the input file.  Keep in mind what we did.  What we did here.  Wed be pretty much the same.  mean just consider that those prints are supposed to have parentheses and they have not in this example but all the rest would be pretty much the same.  Okay.  So let me.  Publish.  This one right Yep.  Let me publish that in class an exercise.  With the file.  Let me stop sharing.  Create breakout rooms.  So we have three breakout rooms.  Im opening it is 740.  You have about 10 minutes just to go into it.  So dont expect you to finish in 10 minutes but you will have sense of it.  Okay.  All the rooms are open.  Im posing the recording.  Lets resume recording.  So welcome back.  Anyone want to share what you did Again.  You dont have to but there is no judgment and there is no grading or nothing.  Okay.  If not let me.  Go here and let me go to.  Resolutions.  Its pretty much in line with what you saw in one of the slides.  So initialize the counter as Im in dictionaries to zero.  initialize to mean to empty dictionary to zero number or max frequency and the name for the word with the maximum frequency to blank please.  Blank.  Valuable.  think so.  So and then theres the loop again.  There are several different ways to go into fight and so thats another one thats so opening the file and the loop will continue till we reach the end of the file.  So reading line and then in the line that other loop stripping left and right.  Then if the line meaning that particular name is in the dictionary then will add the one to the value and the dictionary meaning into the key so that will add the one to the value of that particular key.  And then Im checking if the value is greater or equal to maximal frequency.  If yes will replace that value with the new value and will add the name as the name with maximum frequency.  Otherwise will initialize the value for that particular key to one.  And then will keep reading.  But when finish will get the entire fine process.  And in those variables the values that you will see in moment.  So theres the value of the dictionary.  So you have the names and the occurrence.  And then used those two variables to get those two numbers.  So those theres 54 is coming out of the number max three and this LE is coming from the name most frequencies.  And its basically.  Okay.  So for its 757.  dont want to keep you for too long.  So.  Next assignment is little bit more complex.  So there are few parts to the assignment.  The whole assignment would be about those two files.  So you have both the sides are related to the combined program and they are from different periods.  So one in January February 2016.  And the other is April May 2016.  So the structure is the same year the duration the day time sort of time and bunch of other information.  So those are the files are relatively big but you dont care much about the length because it will be either ten or 10000.  That million will be different but the number is not going to affect much.  So the first one you will read the first file that is seeded by New York City City by January February 2016.  And you will do some processing.  So before we move on want to drive your attention to one point.  So if you look at in this case thats the this is in classic set say three meaning is this guy here And the file has to be in the same directory.  So when the file is in the same directory dont need to specify the path for the file.  Specifying the path for the file is not what you want.  Because if you change computer meaning dont know you go to from mac to window so different structure that you move the file the program for one rectory to another one and then you need to do the same for the contents.  mean generally speaking strongly encourage you to have files data files and program files in the same directory.  So Im not going to take points off for the time being but down the road may do it.  You dont want to use data structure management libraries like pandas.  Not for now.  You will use in in two classes but not now.  So you will basically go through the file and you will keep the count or number of lines to the count or number of lines with the customer.  But just to be sure you have user type that can be subscriber or customer.  So you want to count the number of customers and the number of subscribers and each one will have separate count.  So N0 and zero or the number of lines and one or the number of customers and two for the number of subscribers.  And you will print the last five lines.  Then after processing you want to calculate the percentage of customers on the totals.  So you have the number of customers who have the total.  You do the you divide the two and you will get by somehow.  Then you will get the percentage.  And then you will print the file as the end zero lines of those and one as user type as customer end to end user type subscriber customer are the of the total.  But two is pretty much the same for the other five.  So you will calculate mean we already use from end zero two and two two and three will be the counter for the number of lines the second one and four for the customer and five for the subscribers.  Same thing.  You calculate the percentage.  So this one was one.  This is two.  Part three.  You want to compare those results So you want to check what is the five that is bigger What is the file with more customers or non subscribers And then you want to write one page or interpretation.  So what is an interpretation Its narrative is plain English.  You have one file that is from winter one that is for spring.  There must be differences.  So are there more customers during the winter than in the spring So look at the results that you extract that you get the mean you get from the analysis meaning at those end zero two and five and use those to create the scoring.  mean to write those few lines.  These one page of interpretation again is narrative describing explaining in plain English the results of your scripts.  Keep in mind that this sort of storytelling will be something that we will use lot in most of the remaining assignments.  We are not into writing code for writing code.  We are on writing code to get insights from the data on the domain that we are analyzing.  We are an engineer in management.  So we want to use the tools to take more informed decision so we can decide okay.  During the winter you have more subscribers and lets do marketing campaign to.  Incentivize non subscribers to user bicycle.  Im assuming that will have an effect in New York with the freezing temperatures anyway.  But mean it just to use the numbers to take decisions.  But you want to have narrative describing what are the findings.  So you want to submit the three parts in mean the initial parts with the analysis of the first one the second with the analysis of the second phyla and then the comparison in one single piece we file with the interpretation in separate doc for PDF files.  And thats basically it.  So let me make sure that everything has been published.  So published that in class.  Solution.  And you have the assignment.  So you should be good to go.  Okay.  Questions Quick question Vanessa.  Yes yes.  Thats four part one.  N0 if N0 equals N1 plus N2 then theres good probability that we did it correctly.  Is that right Yes.  mean keep in mind that it is possible that there are some blanks.  Note some errors in the input or the file.  But assuming theres no blanks assuming theres no blanks then means that there is no blank.  Yes.  Okay.  Got it.  Thank you.  Sure.  Other questions.  All right.  So thank you for staying with me.  Still ahead on six.  See you next week.  If you have questions again send me or you an email and we press that.  SYSTEMS ENGINEERING RESEARCH CENTER Technology Forecast Sponsor DASDSE by Dario Borelli Denisse Martinez clipizzistevens. edu February 2020 aveTE Me Introduction ENGINEERING Technology Forecasting System Future cannot be predicted but reasonable evolutions can be.  We predict the next state of technology given historical evolution environment industries applications Methods explored Based on Linear Algebra dynamic variation of ndimensional distributed representations Based on Graph Theory neural networks for dynamic graphs Dynamic variation of ndimensional ENGINEELING distributed representations RESEARCH CENTER Dynamic variation of meaning is often referred to diachronic variation that is how something like language evolve in time Technologies and market segments are represented by words in papers news and patents over the years and they can leverage on the concept of diachronic variation We use computational and visual analysis of changes in technology related semantic elements over the years Dynamic variation of ndimensional ENGINEEHING distributed representations The current stage of the prototype can predict the neighborhoods where technology can be in the future SYSTEMS Graph neural networks for dynamic graphs ENGINEERING RESEARCH CENTER Capture systems state through time Time Time Time Using the same numerical representation of text we use for the room theory we create graphs where the nodes are the technologies and the edges are their relativenessproximity.  We have numerical representationgraph per each time interval.  All together they are dynamic graph representing the evolution of technologies up to the current time Using predictiveML algorithms we can predict the new interactions and relevance of the nodes meaning the new patterns for technologies ee ee Graph neural networks for dynamic graphs Graph evolution 2009 2018 SYSTEMS What iS next ENGINEERING RESEARCH CENTER Dynamic variation of ndimensional distributed representations 1.  Increase training dataset Increase historic data points for prediction 2.  Increase training of word2vecs 3.  Determine predicted spaces for technologies Graph neural networks for dynamic graphs 1.  Increase training dataset Better representation of the system Network prediction Prediction validation Visualization design for dense graphs of.  Wf Test different networks configurations cee ee aeTEa References ENGINEERING RESEARCH CENTER Aldo Pareja Giacomo Domeniconi Jie Chen Tengfei Ma Toyotaro Suzumura Hiroki Kanezashi Tim Kaler Tao B.  Schardl and Charles E.  Leiserson.  EvolveGCN Evolving Graph Convolutional Networks for Dynamic Graphs.  AAAI 2020.  EvoNet Neural Network for predicting the Evolution of Dynamic Graphs.  ICLR 2020.  Hamilton William L.  Jure Leskovec and Dan Jurafsky.  Diachronic word embeddings reveal statistical laws of semantic change.  arXiv preprint arXiv1605. 09096 2016.  Klingenberg C.  P.  Analyzing fluctuating asymmetry with geometric morphometrics concepts methods and applications.  Symmetry 843934.  2015.  SYSTEMS ENGINEERING RESEARCH CENTER as STEVENS INSTITUTE of TECHNOLOGY THE INNOVATION UNIVERSITY Thank you fis STEVENS lw INSTITUTE of TECHNOLOGY is Extracting Knowledge from data Repel clipizzistevens. edu SSE What is Data Mining What is Data Mining we . . .  The process of discovering meaningful correlations patterns and trends by sifting through large amounts of data stored in repositories.  Data mining employs pattern recognition technologies as well as statistical and mathematical techniques. . .  Gartner Group process used by companies to turn raw data into useful information Investopedia . . the practice of searching through large amounts of computerized data to find useful patterns or trends. . .  MiriamWebster dictionary . . . the analysis step of the Knowledge Discovery and Data Mining process or KDD an interdisciplinary subfield of computer science is the computational process of discovering patterns in large data sets involving methods aft the intersection of artificial intelligence machine learning statistics and database systems.  The overall goal of the data mining orocess Is to extract information from data set and transform if into an Understandable structure for further use. . .  Wikipedia STEVENS INSTITUTE of TECHNOLOGY Why Data Mining now More intense competition Recognition of the value in data sources Availability of quality data The exponential increase in data processing and storage capabilities and decrease in cost STEVENS INSTITUTE of TECHNOLOGY How Data Mining Works le DM extract patterns trom data Pattern mathematical relationshio among data items Types of patterns Association Prediction Cluster segmentation Sequential or time series relationships STEVENS INSTITUTE of TECHNOLOGY of Data Mining Confluence of Multiple Disciplines STEVENS INSTITUTE of TECHNOLOGY Challenges of Data Mining Scalability Dimensionality Complex and Heterogeneous Data Data Quality Data Ownership and Distribution Privacy Preservation Streaming Data STEVENS INSTITUTE of TECHNOLOGY Data Mining vs.  Statistical Analysis Statistical Analysis llsuited for Nominal and Structured Data Types Completely data driven incorporation of domain knowledge not possible Interoretation of results is difficult and daunting Requires expert user guidance Data Mining Large Data sets Efficiency of Algorithms Is important Scalability of Algorithms is important Real World Data Lots of Missing Values Preexisting data not user generated Data not static prone to updates Efficient methods for data retrieval available for use STEVENS INSTITUTE of TECHNOLOGY Data growth The digital tools we are using every day are creating data from everything we do at an unprecedented rate every day 2. 5 quintillion 1018 bytes of data are created and 90 of the data in the world today was created within the past two years.  Data piles up quickly in business applications and compound annual data growth threatens to bury todays application infrastructure.  senior executive at major bank remarked There are only things certain in life death taxes and data growth from Wired Because so much of the population is generating it Big Data can provide potentially useful information for our lives and businesses Mining the Big Data requires combination of tools ability to represent knowledge and domainspecific expertise STEVENS INSTITUTE of TECHNOLOGY The datafication It is happening as result of the digital transformation process that is creating new kind of economy based on the datafication of virtually any aspect of human social political and economic activity as result of the information generated by the digitally connected individuals companies institutions and machines STEVENS INSTITUTE of TECHNOLOGY 10 Why data is relevant Data is the core of any MLAI algorithm It must be supplied in the form that mens aie ng The main function of MLAI algorithms is to unlock the concealed informationknowledge AIML is an actuator of datadriven strategies rooted on data and on the whole process to make it usable from data collection to exploration and preprocessing ee STEVENS INSTITUTE of TECHNOLOGY 11 What to do with Data Science .  STEVENS INSTITUTE of TECHNOLOGY 12 Business Environment STEVENS INSTITUTE of TECHNOLOGY 13 Using Big Data and Social Media we Examples Human Resources management.  Organizations and teams are continuously evolving because of changing market needs mergeacquisition intense competition.  Human capital has to be rearranged based on many factors including internal and external datainformation on the single individuals.  Data such as demographics emails credit card usage web surfing pattern past experiences social behavior these and more all together to create the right mix Energy savinggreen solutions.  We all know we should need more energy and more efficient devices but in reality we need to deal with what we have at least for while.  There are many data we could leverage on the better use the devices and the networksgrids we have.  From regular data we can easily collect such as usage energyhours location to external data such as demographic population profile and user behavior analysis to data collected by adhoc sensors Marketing Sales.  Nothing unheard in this area some of the best examples today in predictive analytics and behavioral analysis are from this vertical.  What we do different is the way we deliver solutions ondemand or inabox as well as the usual friendly traditional ways Transportation.  Think it as the next step from popular logistics solutions.  We focus on all the more data intensive components from soeed optimization for railway transportation to onboard personnel optimization Security.  This is an other relatively common vertical for Business Intelligence solutions from combating terrorism solutions.  We target small and medium business delivering same approach the larger companies have.  Working with B2B2C approach we focus on security as service for consumers JTelecommunication.  Putting together traffic information network Usage Current campaigns location based information social behavior to pinpoint onetoone offers SS LULU STEVENS INSTITUTE of TECHNOLOGY 14 cf Data Mining On What Kind of Data Relational databases Data warehouses Transactional databases Advanced DB and information repositories eObjectoriented and objectrelational databases Spatial databases Timeseries data and temporal data eText databases and multimedia databases Heterogeneous and legacy databases Web SS LULU STEVENS INSTITUTE of TECHNOLOGY 15 Dataset Rows Datdpointsinstancesexamplessamplesrecords Columns Featuresattributesdimensionsindependent variablescovariatespredictors Variables Targetoutcomeresponselabeldependent independent SS LULU STEVENS INSTITUTE of TECHNOLOGY 16 on What is Data Collection of data objects and their attributes An attribute is property or characteristic of an object Examples eye color of person temperature etc.  Attribute is also known as variable field characteristic or feature collection of attributes describe an object Object is also known as record point case sample entity or instance STEVENS INSTITUTE of TECHNOLOGY 17 Attribute Values Attribute values are numbers or symbols assigned to an attribute Distinction between attributes and attribute values Same attribute can be mapped to different attribute values Example weight can be measured in pounds or Kg Different attributes can be mapped fo the same set of values Example Attribute values for ID and age are integers But properties of attribute values can be different ID has no limit but age has maximum and minimum value SS LULU STEVENS INSTITUTE of TECHNOLOGY 18 ry Types of Attributes There are different types of attributes Categorical also called the qualitative type Examples gender eye color genre Numerical can also be qualitative allows for rank order by which data can be sorted Examples rankings e. g.  taste of potato chips on scale from 110 grades height in tall medium short Interval measures the degree of difference between items but not the ratio between them.  interval scale doesnt possesses meaningful unique and non arbitrary zero value Examples calendar dates latitudelongitude Ratio measurement is the estimation of the ratio between magnitude of continuous quantity and unit magnitude of the same kind.  ratio scale possesses meaningful unique and nonarbitrary zero value Examples length time mass SS LULU STEVENS INSTITUTE of TECHNOLOGY 19 on Document Data we Each document becomes term vector each term is component attribute of the vector the value of each component is the number of times the corresponding term occurs in the document STEVENS INSTITUTE of TECHNOLOGY 20 Transaction Data we special type of record data where each record transaction involves set of items.  For example consider grocery store.  The set of products purchased by customer during one shopping trip constitute transaction while the individual products that were purchased are the items TID Items Bread Coke Milk Beer Coke Diaper Milk Beer Bread Diaper Milk Coke Diaper Milk STEVENS INSTITUTE of TECHNOLOGY 21 Graph Data This is graph for the presidential debate Oct.  162012 showing who the most influencers are in the conversation.  NodesVertices are users It reflects the popularity of the users.  For example the big aggregation is around user politifact with 910 retweets with the second largest being EatABrick with 115 southeast of politifact STEVENS INSTITUTE of TECHNOLOGY 22 Data Mining Methodologies we Several non formal methodologies available.  Two more formally defined are SEMMA.  It is list of sequential steps developed by SAS Institute Inc CRISPDM.  Polls conducted in 2002 2004 and 2007 show that it is the leading methodology used by data miners Gregory PiatetskyShapiro WDD Nuggets STEVENS INSTITUTE of TECHNOLOGY 23 Phases in CRISPDM we de facto industry standard for op pets ea data mining Created between 19971999 by DaimlerChrysler SPSS and NCR Acronym stands for Cross Industry Standard Process for Data Mining Consists of phases intended as cyclical process Not all phases are necessary in every analysis STEVENS INSTITUTE of TECHNOLOGY 24 Focus on Data Data Processing Flow Types of Data Quality Problems Ambiguity Uncertainty Erroneous data values Missing Values Duplication etc STEVENS INSTITUTE of TECHNOLOGY 25 Forms of data preprocessing STEVENS INSTITUTE of TECHNOLOGY 26 Sourcing Data copyrightrelevant STEVENS INSTITUTE of TECHNOLOGY 28 What is open data Data freely available to everyone to use Can be republish without restrictions from copyright patents or other mechanisms of control What is open access OA to scientific information OA online access at no charge to the user further distribution and proper archiving to peerreviewed scientific publications to research data Two main OA publishing business models Gold OA costs covered e. g.  by authors immediate OA provided by publisher Green OA deposit of manuscripts immediatedelayed OA provided by author STEVENS INSTITUTE of TECHNOLOGY 29 Open Data Federal Government USA STEVENS INSTITUTE of TECHNOLOGY 31 Mashups Getting and Analyze Data lw from the Web What is Mashup lItisa web page or web application that uses content from more than one source to create single new service displayed in single graphical interface.  For example user could combine the addresses and photographs of their library branches with Google map to create map mashup Commonly associated with web applications that facilitate interactive information sharing interoperability user centered design and collaboration on the WWW Typical characteristics Web is used as participation platform Users can run software applications entirely through Web browser Data and services can be easily combined to create mashups SS LULU STEVENS INSTITUTE of TECHNOLOGY 33 Mashing up content via API ie API stands for pplications rogramming nterface An API interface is used for the exchange and further processing of content and data.  This allows various software and hardware components to connect Housingmaps. com is mashup created of Craigslist and Google Maps The properties described in Craigslist are placed on map STEVENS INSTITUTE of TECHNOLOGY 34 APlIs to get Web Services iw Web Service Is the service provided by server via the API.  Definitions method of communication between two electronic devices over the Web From Wikipedia entry on Web service software system designed to support interoperable machinetomachine interaction over network From W3C definition STEVENS INSTITUTE of TECHNOLOGY 35 What is Web Service we method of communication between two electronic devices over the Web From Wikipedia entry on Web service software system designed to support interoperable machineto machine interaction over network From W3C definition STEVENS INSTITUTE of TECHNOLOGY 36 of Technologies Web Services are possible using Application Program Interfaces APIs way to exchange data between systems APIs are defined by the system providing the service and need to be used to interact with the system APIs use HTTP as the basis XML and JSON for data exchange STEVENS INSTITUTE of TECHNOLOGY 37 tts Twitter Web Services API we Twitter is social networking and microblogging service that enables its users fo send and read messages known as tweets Tweets are textbased posts of up to 140 characters displayed on the authors profile page and delivered fo the authors subscribers who are known as followers Twitter has offered comprehensive set of APIs fo access core Twitter data update timelines status data and user Information User sensitive data Is protected by the HTTP Basic authentication mechanism STEVENS INSTITUTE of TECHNOLOGY 38 Twitter REST API GET example User Timeline Method Description URL Formats HTTP Method Parameters ER Sl3S lure statuses usertimeline Returns the 20 most recent statuses posted from the authenticating user.  Its also possible to request another users timeline via the id parameter.  httpapi. twitter. com1statusesusertimeline. format xml json GET id optional Specifies the ID or screen name of the user for whom to return the user timeline.  since id optional Returns only statuses with an ID greater than that is more recent than the specified ID.  max id optional Returns only statuses with an ID less than that is older than or equal to the specified ID.  STEVENS INSTITUTE of TECHNOLOGY 39 Hello.  mean know that there are several issues.  128 We are we are fixing it.  Sorry.  136 Thank you sir.  can appreciate it.  Im sure.  dont know why.  143 It shows me the homework that is.  Like the one thats there but not the one thats due.  147 Okay.  Okay.  So there must be something in setting up the old courts that is not working fine.  155 But we will fix it.  Thank you.  Sure.  205 Thank you for your patience.  And Im sorry about the inconvenience.  208 Okay.  The 629.  Lets give people another minute or so and then we will start.  219 So in the meantime any particular issue 236 have question about the previous homework.  246 Yeah.  So had difficulty coming up with that to end the loop.  250 So was trying different things but couldnt get it to work.  258 Maybe you could explain.  Yeah.  Do you want to share it 303 Because mean dont have it in front of me.  307 If you have it.  have it on different computer.  312 Unfortunately so.  All right.  316 Uh okay.  you will do the class assignment.  320 will retrieve it and we will discuss by the end of the class.  326 Okay.  All right.  Okay.  330 So its 631.  Today is February the seventh and this is 624.  334 So.  Let me start with sharing the screen.  344 We are already recording.  Let me share the screen.  And let me goo here.  351 So minimize this.  All right.  400 So.  That was the previous week.  404 So module two was software engineering and some coding in Python with the inclass assignment and the exit site zero one.  411 And let me go right away on.  426 The code.  So.  So the assignment was relatively easy.  433 So it was on.  On converting temperature in Celsius to temperature up in Fahrenheit and.  443 use the same loop that we used in previous exercises.  503 So the loop is looper just as we did the previously input with the commenter.  508 What is the temperature in Celsius that you want to convert the type done to exit 519 And then the name of the variable towards celsius temperature.  525 Just to have mnemonic.  Variable.  531 Name of variable.  If this value is done then thanks for using the tool and that breaker would go out of the loop and the program will end.  534 It wouldnt be the same not to have the print statement here but outside of the loop.  546 But again it would be exactly the same.  554 Then Im checking if the number if what the user typed is number if it is false meaning is no the number.  557 Then you go back to the beginning again.  611 Thats not the only way to do it.  We know that there is also the possibility to do in different ways.  615 We will go back and say again just as reminder if is not numeric continue meaning going back.  624 If it is numerical.  Then calculate the temperature in Fahrenheit using the formula and print it.  632 So let me go here for second.  641 So just as reminder there there are two ways to get to test.  646 If number if variable is numeric or not there are many ways but thats one of the ways.  653 Two of the ways so one is using is digital and one is using try.  701 Except let me run this.  707 So if you type number an integer is digit that is working fine.  713 If you type floating point number like 11. 22 then you would get the is now the number meaning that is digit.  720 That is not recognizing the number with decimal values.  733 The.  Right except the is working in different way.  742 Same number 11. 22 and then is number because in this case what its doing is basically trying to do the conversion into floating.  747 If we get an error then it will print the number.  800 Let me run it again.  So if do Q.  807 Theres no number.  If do In the second case it will be the same.  814 So again with try except that Im able to test the also the floating point numbers.  820 So numbers with decimals with the is number is digit.  830 can not.  So in this case use that is digit but is clearly not the best way to do it.  836 But it works in particular if the number is integer otherwise without.  843 So if run it if the number is 37.  852 Then have 98. 6.  859 Pretty much periodically.  It is an approximation and that obviously done.  903 What Okay.  So thats basically the.  912 Uh exercise number one.  921 And let me share again.  925 And let me go back here.  So for today what we are planning will be again revising reviewing the assignment in particular the coding part.  931 Again that was relatively easy code just mean that is the second assignment.  949 So the complexity will grow but we will grow gradually now with big steps.  959 So we will talk about software testing.  We will give some examples.  We will talk about the errors exceptions in Python.  Then we will go back to Python and we will talk about some data structures.  will stop after that for QA.  Then we will start the inclass exercise.  We will discuss the solution and will present the next assignment.  So thats basically the menu for the day.  So.  At this point.  Let me go to the power point and let me start with this one.  Im not going to spend much time on the test driven development.  The main reason is because true test driven development is something that you would do when you have quite complex program so that you would write.  But you need to be aware that generally speaking the problem of testing software is essential.  So there is no software that comes out of the developer right away with no error.  So you can assume that in way you would in either there would be an error.  The point is how to use how you spot it how you determine what the areas where the error is and how to fix it.  So being able to start from the beginning with an approach that that that can give you the possibility to test that all the branches that the logical branches you have in your code is really essential.  So you need to be sure that you define unit of testing per each one of the alternative sets that you have in your code.  In theory you should define the testing strategy before doing the code meaning you define the logical structure of your code.  That is pretty much sort of flowchart of the code.  And then you write the code.  So you define the structure you define how you are going to test it.  You develop the code then you tested the and then you check.  Most of the time this is not what is happening.  Most of the time you do sort of retrofitting.  You already have the code and you want to be sure that you will test all the possible alternatives all the possible branches that are in your code.  Again you want to be sure that testing is an essential part of your development.  When you test the you basically test the four carrots.  So you want to be sure that one there are no formal areas.  And secondly that there are no logical areas.  So let me go briefly into.  The types of that that you can get.  So there are three main types of area.  So one is syntax error.  So we know that in Python you have a.  Collins at the end of the conditional statements like if at the end you are call on while through your column.  And you also know that after call on that you have an indentation.  If you know that if you if equal something the equal something is not single equal sign number is double.  If you miss one of those you will get syntax ever.  Then there are execution errors.  Execution errors is when you do something that is not in line with what Python is allowing.  Like you want you are adding string and number and you will get an error.  So you are breaking the the python rules.  So again execution error is when you have something that is against the python rules.  Example mixing data times.  And then there are the more and is key difficult to detect the error out design add ons meaning the program is not leaving any error or any transfer but is not generating the results that you expect.  So there is something wrong in the logic of the program.  So those types of error are more difficult to detect because mean with the the previous to the interpreter Python will tell you there is this particular type of Arora on the line whatever is the number of the line.  So you go there you check it you fix it.  When is the sign the point Python is not telling you anything because from python standpoint everything is fine but the program is not doing what its supposed to do.  So at that point problem testing is what is really relevant.  You need to really understand that the logical structure of the program.  You need to understand that what are the alternatives that the program should do.  So lets go back here for second.  So in this case for this program that you have so you want to test the mean one of the four think if the program will exit when the user is typing done.  So the branch if done is something that you need to test to see if its working and then if its detecting the done if its doing what its supposed to do when the user is typing done that is axing exiting the program then the second is testing.  If the program is testing for being numerical or the input.  And theres the second test that you need to do so.  And then if its testing is generating the expected the message or result and theres the second test.  And then the loop.  So its looping the proper way meaning that once they have what they have is it going back and asking me for another time pressure So those are the questions that you need to ask to create the testing strategy that you need to have to be sure that you are testing all the branches in the code.  One of the ways that we normally do to be sure that we are checking all the boxes is to put some print statements in the key steps of your process.  So like dont know.  If mean in these cases or in painting something.  So in all the cases is printing something meaning is not necessary.  But if didnt have.  mean that.  If the requirement was only when its done just exit.  And adding printer to say Im passing through this branch is something that you want to happen.  Printing may not be just saying was here but can also be the type of variable or the value of the variable.  That is what expected.  So those kind of temporary pop up print statements are working for the debugging.  Once you fix it you may want either to delete them or to make them comments because you are not totally sure.  Eventually you will change something and you may need to go back to the same point.  The meaning you are pop up print will be useful again.  So at that point you comment the print adding the number sign the in front of it and then once you complete the full debugging you can remove it.  So again three types of errors syntax error execution error.  Those are easier wrote.  They are easy because Python is telling you the type of error.  And when the error occurred the designer roles are more tricky because the interpreter python is not telling anything but the program is not doing what is supposed to do.  At that point you really need to do through debugging.  Questions so far.  All right.  So lets keep going.  And lets go through some other python thinks that we may want to add.  So question.  Yeah go ahead.  Sorry didnt realize it was on hold.  So was looking through the exercise 33 to 36 or something like that from the reading assignment.  And was trying to do the percent deal.  But the percent and then the percent with our homework.  But it didnt work out.  Is it because its not an array by any chance Okay.  Can you share them Because really dont remember.  can tell you can maybe share the book so.  Sure.  Because deleted it because it didnt work.  Okay.  Okay.  Okay.  Okay.  Yeah.  just share what the questions were and then we will review them.  Okay.  think its in the book exercise the the the hard way the prodding the hard way.  believe its an exercise 32.  So if you have it and you you if you can shed the screen.  Otherwise will will check it.  dont.  Okay thats fine I.  If.  All right.  If you can make it little bit bigger would be great.  Okay.  think it is.  Im trying to find it to believe its here.  Yes.  Is this.  got percent.  Ah and this is percent I.  Where is that integer or not integer.  The the value guess.  But tried to do that with my print in the at the very end this says Celsius.  did the same thing.  Lets say the answer is percent.  put and then did the same exact syntax here but percent temperature C.  But it didnt work for me and wasnt sure why.  Yeah.  Oh okay.  So there are couple of issues.  There is one issue and one consideration on that print.  The first issue is because the code that you have is for Python two with Python to you have no parentheses.  So you need to have parentheses meaning is mean the up to the the percentage sign and then whatever it is just before that you need to close the parentheses so the public will start before the quotation sign and then will end after the last the last quotation sign.  Gotcha.  All right.  Ill try to work on it when have.  Yeah.  And then.  Yeah yeah.  And then the second point we generally dont use this way to do the printing with there are two ways of doing it.  The one is print the parentheses and then you have the name of the variables in curly brackets.  And the second is using the percentage sign and the corresponding value after the parentheses in the print.  Its kind of confusing.  dont like it that much.  really like more plain way of printing.  If you stop sharing for second go back to my code and yeah and will just use the code as an example.  But thank you for raising this point and thats very good point.  So.  If you consider this print right here.  So in this case apart from the new line have comment.  have but one value.  have another comment or stronger.  And then another volume.  mean this way in my opinion is very clear and straightforward.  If start using variable mean it is more parametric but its less readable.  So strongly encourage you mean again that the course is not on the esthetic of coding but is more on maybe functionally work.  So really dont care how you do the printing but in my opinion that this way of doing the printing is more readable.  So in Python three dont forget the parentheses at the beginning of the printing and the end and then inside that whatever you print as to be separated by comma.  So you have this first portion that is string and the fix.  The string is not variable.  Then you have comma variable you can or cannot have.  space is up to you again to use this basis because it is more readable.  And then you can have as many variables and strings in your print you do not want to do thinks of that too long because otherwise it will become not readable.  But Im in my opinion that this way is more readable.  What do you think we are now Yeah did.  did exactly what you had.  just wasnt sure.  Yeah why you didnt work but.  Okay that makes sense.  Yeah.  All right.  Okay so let me go back to sharing and let me go here.  So we are going to talk about some other Python related things.  We will go we will review the variable types and how to move across types.  So with Python you have several types of variables.  So we mention strings numbers.  So strings are defined by quotation science and can be single or double.  For Python that is just the same you want to say with either or but mixing and matching doesnt work.  Recently use single up but mean really the same numbers can be inside.  That can be number.  It can be a.  Alphabetical characters or whatever you want.  Numbers can be integers or floating point but.  You can do operations between body of both.  So on the left side the you have strings.  On the right side you have numbers.  You can add the strings variables containing strings like in this case when you add the they will combined attach the one to the other.  Obviously if they are numbers you do the arithmetic operation with that same thing with multiplication you can apply the multiplication to strings and it will be the same string repeated the time each time you attach one to the other.  When you do with number two you have the arithmetic operation.  Again there is no mix and match.  Excuse me because otherwise you will get an execution ever.  So like in this case you have an error.  The good pointer is that python that will tell you the line that when the error record.  You can ask by doing the type of variable that you are working on that seems to be irrelevant.  But sometimes when you do debugging when you when you are doing testing to code that you do an operation you get an error.  The program is pretty long.  You dont know why you have wrong combination of variables because you expect the one variable to be numerical and you are adding number to that variable and you got an error.  Why This variable is not numerical.  You can go back.  And add some print statements to the code the printing the type or the variable before you do the operation.  Just to be sure that you trace the evolution of the values of the variable while you are creating that.  So Typer is useful.  So if in this case is stringer you do typeA for the value for the mean the variable and you will get the in minor bit less than greater than the characters type.  And then the type of variable that that particular string is the particular.  But for this same thing if it was an integer you would get the list floating things like that.  So again type is something spending more time than should but it is important.  We have integers floating points.  We know that you can convert one to the other if the conversion makes sense.  We know that if you try to do conversion of string that has not numbers in it but into integer or floating it you will get an error.  Those are other examples.  So you have.  Operation said that out on the algebraic outside the operations that are.  So you are transforming content and then you doing an arithmetical operation.  In this case you try as we know to do conversion of string into number but the content of the variable its not number and you will get an error.  Again.  Thats another example.  We know how to do the management of errors in this case keeping in mind that when you do try accept that you can specify one particular type of error and have eventually different messages for different types of air.  If you check online in the pilot on the website or in StackOverflow you will get the codes for the different type so that there are several.  User input.  We know how to do it.  We know that you can convert it if its convertible.  We mention that you can do operations with strings.  Now lets talk about lists.  So lists are another formula another type of variable not that are container so they are defined by square brackets.  So there is square back at the beginning one at the end and then you have elements inside of those elements a.  Are separated by commas.  And they can be anything they can.  They can be any type of variable.  They can be numbers.  They can be strings.  They can be other lists.  Meaning you can have list that is nested into another list.  We will talk about that.  Uh.  Lisa our new double meaning.  You can change the content.  You can change the order.  You can add elements.  So lets say that you have this list here.  Like.  Pretty much everything in Python.  We start from zero up to the end.  So the first element is the element zero.  So if you want to recall the first element then you need to point to that element.  So thats the list that we created.  Again the square brackets commas separating the elements and any type of element any type of variable inside.  If you in that mean that is sort of pseudo code that the brackets are missing here.  So example at zero meaning you are pointing to one two three and you would get it.  The example is three.  You are pointing to the fourth element that is fish.  You can change an element.  So in this case and saying example is that three equal tilapia.  So changing from fish to tilapia.  When printed that instead of getting fish would get the new body.  And one more feature that is really useful when you deal with the ball with lists or strings is slicing them so.  We mention that you can point to one particular element.  So if you are saying this leads to a2h3 meaning Im pointing to the fourth element that is the can do three column that meaning is from the fourth element on and you have all this piece of the list so.  can do up to that point the meaning all.  But the fourth element that before the fourth amendment then you will get you can slice piece of it.  So you are saying from three to to 5.  So you have from the fourth element to the fifth element.  mean from the fourth element to the sixth element the excluded.  So you have the any.  You can do backwards.  So you can do minus one meaning the last one you can do minus to call on meaning the last two.  So this lighting is something that you will practice and is pretty useful when you are dealing with managing text in particular.  One thing that is relevant is the use of append and remove append.  That means that you can add the elements to list.  So you have an existing list like what we used before and you want to add the number 42 with append that will add the in the end.  You can remove elements.  So you just call the element you want to remove and you do name on the list remove.  And in parentheses you have the value that you want to remove.  One thing that is sometimes is generating little bit of confusion is the difference between concatenation and appending.  So you have the same lists.  The first is one two three four five six.  You do concatenation so you do plus equal to plus when you print in the you will get the combination of the two lists.  So you have one two three four five six.  If you do append you are upending an element to an existing list.  So the same and you do append b.  When you printed that you had the first three elements and then another element that there is the entire list.  Append is what is normally used.  When you have loop you have loop and you are creating you are generating list adding each iteration an element.  So at that point you are appending just like we did here with 42 you are appending fortitude to the list.  Think about loop or instead of 42 you have an index and you have numbers from.  to whatever and in values.  Each time you will add an element.  At the end of the loop you will have to create list with all the elements.  So append.  Is what we normally use that when we are creating lists and we want to add at each adoration and element.  Another useful thing to know is the existence of in or not in.  So in this case you have at least the but could be string and you are asking if 42 is in the list and you get through.  So in this case is not in the if.  But if you have that in if statement then you can take different actions based on if its true or if its false.  So if you ask 55 in you will get false.  You can do not in that.  And if you do 50 fi not in then the result would be true.  Lists are ordered meaning the way you create them is the way they will stay.  That seems to be obvious but not all the data types in the variable types in python stay order.  You can change the order because again lists are mutable.  So you can.  Either add elements move elements.  You can delete elements.  You can sort the elements.  So all of those is doable.  But if you do nothing of the three the least that will keep the order that you used when you created it.  They can be sorted again.  You can sort them in ascending or descending order.  If that is number it is easy.  If it is string.  It would be alphabetical order.  Pretty much the same is for string.  So when you have three things you can do.  Slicing.  Just like we saw for lists.  So five on meaning.  mean instead of mean from five on you skip the first five but then you do the remaining.  You can pick the fourth element that could be D.  You can.  Do loop within string and then at that point the loop will be on the single character in the string including space because space is character for all intents and purposes.  There are some methods that can be used with the strings upper lower to capitalize either.  All of those are things that can be added to any string to make it little bit different.  So if you have this combination of lower and cubby the letter certainly in the string if you do lower you get low words and so on.  You can also do start with them.  And thats something that sometimes may be useful.  So you want to put into all the courses started with em so you can have list of courses you do loop and then in each loop you have one course and then you start that.  If you ask it and you have and if statement the if the name of the variable start with then do something count it and so on.  Keeping in mind that again is more lettering.  Capital letters in Python are different.  So if you test in this case capital you will get through.  If you do smaller you will get folds.  There are about 33 methods and you can check them online.  Uh.  Again thats another example that can be applied kind of combination.  So you are checking if one string is in.  In the least.  Thats something that can be useful in many case.  You have list that you imported.  You read from file or whatever and you want to see if certain value is there or not.  And then you do different things based on the different options before the results.  Replacer again you can replace elements to both lists and strings and mutable meaning.  You can change them the way you want.  You can do conversions with all the caveats that we mentioned many times when you convert string into list.  The resulting list will be composed by the individual characters that can be letters spaces or any other character in the string.  So in this case when you are making list out of the word cements the resulting list would be mean the individual letters in the name Stephens.  Thats something want to draw your attention to.  So this is list where the first element is number of the second is string.  The third element is list and the fourth is number.  So if you do if you point to the third element so it will be two.  So if you do my list two you will get this list if you want to get the.  The second element of the NRA list.  Then you have you need to have two indexes.  So the first one will point to the inner list and then the second that will point to the element that within the list.  So lists of lists are very common and strongly encourage you to become familiar with those.  Conditional accepts.  Again we can have loops working on the lists.  So you have list of names and then you do loop and each time you will print one.  It is just an example of how to use lists in a.  Loop.  You can apply all the comparison operators.  As we know you can break out of loops using break you can use continue for doing nothing.  Meaning in this case if the and the first element of line that would be the number sign continue meaning you go back you do nothing if its doesnt break.  We know that in this case you are going out of the loop.  Other application of loops.  You have these values and you want to count to do the summation and then you want to bring the count to the summation and the specific part.  So thats another example on how to use loops.  And when you finish when you are out of the loop you can do mean summation of the values divided by the number of values and you have the average.  And then you have links to the.  To the Python website when you can have more details on that.  All right.  Its 718 at this point.  would introduce if there is no question would introduce the inclass assignment and will give you.  About half an hour or 25 minutes for the assignment.  Then we will lets say 20 to 25 minutes.  We would discuss the assignment and will introduce the next exercise and that would be the end of the class.  And obviously if you have questions will be happy to address it.  Okay.  So.  Let me share the screen again.  And let me.  Go here.  So they think class.  Exercise as user for number depending on whether the number is even or the.  You want to print an appropriate message.  Meaning if the number is lets say two then you will print.  The number is odd.  The number Id say is five.  Its its even if it is five the uh the number is uh you want to print the you are asked to print different message if the input number is at four.  So if its for you print something different.  If its not the it just odd or even.  So let me stop sharing and let me create some breakout rooms.  So am creating three breakout rooms with three participants.  Each room.  am opening it so will knew them myself.  will be here all the time anyway.  And.  The rooms will stay open for about 20 minutes.  Then will close the rooms.  will send you message before closing.  And then that we will reconvene.  We will discuss what we had.  And then would talk about the next class.  The next assignment see in about 20 minutes.  Resume the recording.  Oh right.  Welcome back.  All right so anyone wants to share what you did.  Again there is no grading.  There is no judgment.  Its just for sharing and sharing the comments.  Your areas may be useful to someone else.  So.  Youre strongly encouraged to share it.  can share professor during the volunteers Sure please.  Okay.  And so this one.  We had two exercises.  Is that correct Professor Well its one exercise.  So uh lets see what you have.  Okay maybe read something different because was still seeing like all the assignments from like last year.  Yeah.  Yeah.  So maybe read the wrong one.  But anyway so again this program prompted us to enter number one or two to understand exercise one or exercise to exercise one will basically ask the user for number.  Write checks if its hard and then if its not odd or check if its even.  Or multiple four.  Sorry.  If its if its multiple four and its not zero then it will print.  You know the this number is even but also multiple for otherwise in in the case the last case if the user enters zero it would enter uh you know zero is even right So thats the case thats carried here.  And in the second exercise with it prompts user for name you would enter your and it would compute basically the year that you will reach 100 years old including the days until that first day of that 100th year.  And so thats what Exercise two does.  So Ill start with Exercise one right and true one and turn number on like lets do 2. 5.  And as you discussed thats not going to work.  So lets do 20.  So now you get 20 is even and also multiple of four.  Right.  Well lets try to assess case this.  Well start over with this one and our number 200 is even and thats the last which case there.  So thats for exercise one.  Exercise two is an attorney Kevin until your age 30.  And then it says in seven years you will be 100 years old and thats 25530 days away.  So thats the last part and how did.  The last part is use StackOverflow as you recommended to obtain some information about how to obtain the current year.  Years remaining is variable where subtract the user provided age 100 minus that age and then the year at 100 or the current year plus the years remaining and to calculate the days.  So the first day of that 100th year is the date time that now to get the current day and for day two use that time of passing three arguments including the year at that that year that Im talking about hundred years old.  And subtract that right and then assess the days using different days.  So thats how print that result there.  Sounds great.  do have good question professor.  Good.  Is it bad practice to have the numbers like this in variable and by the.  Well mean the names or the variables can be pretty much anything.  Apart from the risks of words and keeping in mind that they should be mnemonic.  So here hundred it is mnemonic.  Its absolutely legitimate.  And mean dont know why would have added an underscore here on this quote hundred but thats me.  mean that is absolutely fine.  The main goal is to have names that will remind you what the content could be.  So in this case that is just fine.  Okay.  Are there any obvious issues you see on these two exercises or.  It looks fine.  No they looks fine.  mean as general consideration mean we are doing exercises in sort of gradual way.  Yeah but more basic way of doing it would be not using functions but just right.  What is the day today What is the object in the code that would be less effective Less sophisticated The more basic.  Im not saying that is the way to do it.  That wouldnt be the way of doing it.  But it would be the way that would expect at this stage of the class.  And that the only consideration mean the way you are doing it is the way youre doing it that you dont want to have data in the code.  Generally speaking you want to have the code the doing only the functional part of the process and the data being outside.  Yeah but mean that at that sort of an early stage of the skills getting process to where you are.  dont care much if you okay in the script but generally speaking thats the way of doing it.  Another approach that generally follow is to have but we didnt do yet.  Handing files is to have parameter thats like the data.  mean they wouldnt want the effort but with any form of parameter in configuration file meaning you read the file with all the data the data will be incorporated in the code and becoming values for variables.  Meaning if you want to change the values you dont need to change the program but you just go into the file with the values and change the values.  So we will go to that in few classes.  So far think his next class when you will do read the right files.  So for the time being what you did was just good.  Okay.  Thank you for feedback for anything.  Thank you.  Any other.  Yeah.  can share.  Please.  So we didnt know about the second son who was not there.  Okay.  So for the first assignment we took pretty simple approach.  So have this variable number and then we pass that number to an eight and divided by two to determine its half number which is this other variable that we made.  And we used this half number that there was there.  Thats why did work anyway.  The fourth thing worked before.  But uh so we said the the actual part of it is down here with the we use integer.  And we said if half number is integer print that its an even number.  And then we said else its an odd number.  And then we have just some other cases up here where we rule out the zero case and the four case that requested so can go ahead and run it.  But so its not the the prettiest uh code.  Okay but.  We She were.  remember we just said all the cases or whatever.  Yeah.  mean its working.  Thats absolutely fine.  couple of considerations.  The first one.  You do loop.  You use way through if there is loop.  So in this case the loop is not use the match.  It could have been used better.  Adding it down when you want to end it instead of breaking the loop.  Each time you reach conclusion.  You may want to have it continue in the testing if done at the very beginning like we did in the previous assignment.  Yeah.  Yeah.  mean it is working again.  Im not teaching.  This time of coding is more functional approach than teaching.  But keep in mind that that that could be good addition.  Yeah sure.  The second point is divided by two is working.  But you can use the function reminder meaning if the remainder of the deviation by two zero then its equal to.  Yeah.  saw that in the previous.  Yeah.  And thats another approach.  But mean both the options are working fine like divided by two because theres more narratively using the basic functions.  And at the stage we are.  If its good to use the basic functions then we will add step by step class by class new elements.  All right.  Thank you.  Okay.  So you can stop sharing.  And will briefly introduce how we shared the screen and would talk for second about the qualities that.  So in this case certainly Im doing the same way through.  So Im asking if.  mean ask him the number.  Baking.  If its done.  If its done breaking then Im checking if its numerical.  If not the meaning.  If there will be an error here will be intercepted by the accept the option will go back ask for another one then and checking if is multiple of four meaning the reminder from the division before it zero then is multiple of four.  And then if its the remainder with the division of two it zero is even.  Otherwise is that all the and we go back.  AbdulMahdi again could add that continue here but its redundant that we go back anyway.  So if ran it up.  It will do dont know.  22.  Its even 11.  Its odd than that is out.  Thats very basic.  So overall want to apologize for the kind of mess that is on campus.  The main reason is because when had the original content there were lot of parts missing.  uploaded the previous version the previous semester but then instead of replacing it kind of added to it.  Meaning you may have multiple versions for the same thing and cleaning up.  So be patient.  My apologies from next class.  This is not going to happen and doing all the cleanup.  So let me go back to the assignments for next week.  strongly encourage you to pay attention to at least the beginning of the description of the assignment.  So the assignment is two parts.  One is on testing and one is on writing the code that they are related to the same problem.  So the testing is not genetic testing but is testing the code that you will write the in part two.  So for the part one you want to design testing.  So to design the testing you will use this template.  So the template has the goal of the program.  And the goal of the program is from the program as loop and all the rest.  So thats the goal of the program.  Then you have the testing strategy meaning what are the logical step so that the program will perform for example done to exit the program and printing the proper statement when the user enters done checking if the price is number another string printing proper statement when the user enter price that is not multiple of five.  So all the alternatives will be here in English.  No no code here no python statements here.  And then for each one of those you will write the data that the user would use to go in each one of the options.  So if you are to print in the proper statement that when the user enters done it will be input done.  Output goodbye input at 12 output price not multiple of 0. 05 something that that.  So again.  Part one is reality two.  Part two is not theoretical question.  So part two is basically write program that will ask the user for number and then a.  The number has to be multiple of five and thats the procedure.  So you prom the user for the price in cents meaning it has to be multiple of 0. 05.  You need to check if the number if the input is numerical if its not negative and if its multiple of five and you will provide different messages for the different roles if the user will enter done then goodbye and stop.  If the user enter price that is actually multiple or five you will print the price and you will repeat the old think.  You will submit the doc or PDF for the testing based on this document and in your programmer as document in canvas.  So will review the submissions for the previous assignment that again there was some confusion on your side on our side.  And apologize for that.  We will fix everything from next class and for the time being and just accept my apologies that.  Okay.  So.  Questions.  So Thomas Im for second.  You have question.  Hello.  Hello everybody.  Its 630 and January 31st the last day of January.  227 And we are here for the second class sell this year.  238 624 So let me just start asking you if you have any question that is something you want to discuss.  243 There was something in the material worth reviewing somehow.  256 So.  Oh things are going.  303 All right.  So.  mean that next time try to be more into questions.  313 So to make it more interactive.  So the whole experience of online is what it is.  324 mean its not like being in person but lets try to make it more more personal somehow.  333 So Im glad that you are switching.  344 have question.  Yeah.  Good.  Really answer right now.  348 So for one of the like when came to to change to one 353 once finally got the software download and everything working when came to change the name.  359 Theres no way to change the name of like like if you see the way submitted it it says homework like p16789 something something or something.  404 And dont have any way to change that.  But was able to change it like changed my homework name.  414 just couldnt change the name of the actual folder.  Yeah.  420 mean but mean the incumbents are own or in your own former.  423 No in my folder and byton.  Okay.  So mean generally speaking what you have on the end is in is in pie chart right 430 Yes.  mean in the pie chart.  Let me share the screen and let me show you.  442 Thats probably easier.  Okay.  454 So thats.  Thats by Sharma.  457 You have Yes.  Yes.  You see all the way to the left Yep.  You see whats on the left.  502 So instead of me being able to name the label the folder m600 507 was able to to label it where it says exercise 00.  lives and able to change that name.  512 But dont know how to change the folder to 624.  518 Yeah.  mean the only way its basically to go here and to go in the folder like in this case that folder is EMC 24.  522 And is this folder here Mm hmm.  And just run the way.  538 Yeah.  You need to change here.  Uh okay.  542 was trying to change it from there and it wasnt.  Yeah no mean Im not even sure if there is rename here but.  546 No no no.  Yeah.  mean the only way would be changing here.  553 And then when you will.  And then Im in the closet.  600 Change it closer the entire program change the name and then open with the new name.  605 And thats.  think everything else is pretty straightforward.  611 Yeah.  Yeah.  mean that is not real file management area.  616 give you some things but is more for displaying what is inside than for doing something active.  624 Okay.  Thank you.  Sure.  All right.  634 Okay.  So.  Uh let me keep sharing actually.  638 Go back and watch it.  647 All right so we are in module two software engineering and some python coding.  652 So.  We had some issues last week with this quiz and 185 Check Your Knowledge.  703 republished it.  Some of you already answered the question and know this as some of you already have 716 knowledge of coding in general and knowledge of coding in Python in particular 728 but some other you do not.  735 So the course up to the midterm is going to be quite basic meaning.  740 cannot leave people behind meaning that will start with the very basic elements of Python and then we will be up from after the midterm.  749 Things will be more engaging for pretty much everybody.  804 In the meantime there will be other portions that are less strictly on Python and more on writing code 809 managing software development projects and things like that.  820 So.  If you didnt do yet please go back to the M1 B5 check your knowledge and do the quiz is very basic.  827 And mean the two most important questions are are you familiar with coding offers 841 Are you familiar with coding in Python disciple All right.  848 So.  During the lecture today we will talk about software engineering.  853 little bit of history.  902 Some example is going to be just an introduction because we are going to have more detailed section on those aspects in few weeks.  904 Then we will continue with the.  By Donna we will do an inclass exercise and then will present.  916 We will discuss the solution of the inclass exercise and will introduce the next homework.  934 All right.  So let me start the fourth.  947 With some slides.  So.  The first group of lights is on developing software.  954 So again that is going to be relatively short.  So software initially was just part of our work so that people were developing and installing the hardware was also the people doing the software.  Then they realized that that there were competencies that should have been developed in different ways.  And then thats the beginning of the.  Jobs of the coders programmers or whatever you want to call them.  Initially that we are from the people who developed the hardware then mathematicians and then develop the in its own discipline.  When already mentioned that when graduated from the University of Rome.  There was no information technology.  It was beginning of AIDS.  There was no information technology.  And graduated as master in math and it was applied math.  And part of the applied math was something close to information technology but was not separate discipline.  And we are talking 1980.  It is not 1880.  So thats just to have timeframe.  When you develop software that is component that is all in terms of course that is the development course.  And there is also component that is on testing and testing.  The software can take big chunk of the overall costs.  Generally speaking you dont have the same people are doing the development and doing the testing because the goal of someone doing the development is basically to make it run and to make the code running.  The goal for people doing the testing is just the opposite.  To find the failure point make the code fail.  Two different mental attitudes to different skills.  But we need the both of them in additional costs.  Its cost of maintenance.  So software is doing certain job.  The job can have all been time.  There could be new routes.  You are in marketing.  There are new campaign.  There is something changing the way the code was originally intended to.  So cost of development the costs of testing and then once the product has been or the solution has been deployed.  The costs of maintenance will stop.  When you design software there are different ways to do it.  The.  Typically when you develop something you do your requirements you do you design the solution you implement the design and then you pass the solution to the user and then the maintenance will stop.  This approach is normally called the waterfall model was the base for most of the socalled legacy systems for quite few time.  Lets say for good 15 years.  Advantages and disadvantages.  So advantages are quite obvious.  You can define the requirements in depth.  You can design the system based on the requirements in the most appropriate way.  You have to allocate the resources in an optimal way.  Thats all in theory.  But then the drawback is that there is no flexibility for change.  Meaning all the beautiful plane that you did may not work because the condition changed because you didnt really understand the flight well what the requirements where for any reason the lack of flexibility is the main reason why the vast majority of the projects didnt went well.  Using this approach 1995.  That was probably the peak of this waterfall approach.  Only 16 could be called the successful.  It was obvious at that point that this approach was not the right approach.  So thats why people started thinking in terms of software engineering so how we can apply methods approaches coming from engineering to the development of software.  Again.  We will talk with more details about that.  But.  Software engineering is pretty much the system engineering applied to software development.  So is the same holistic approach in the same thinking that there is no system living in vacuum.  But you need to consider all the other components that can be related to that.  One of the point of reference in software engineering is the Software Engineering Research Center that is headquartered in the Software Engineering Institute that is headquartered in Carnegie Mellon University.  And they develop the several stages of their methodologies that has been applied for quite long time in developing software.  was partner member of the Software Engineering Institute for few years.  Some basic principles when you develop software.  News.  Open source.  As much as possible it is cost effective.  There are drawbacks that there is no one really standing behind the product because it is open source.  But on the other hand it has the flexibility that you may need in many cases.  Consider you have something that is not working the way you want on the software.  If it is commercial software the only way to do it is submit ticket and wait for the issue to be addressed.  It can be in what it is to release or can never be incorporated in future release because it is considered not strategic by the developer.  So with open source you can change the code yourself to make it like you want.  Use the industry standard.  There are two standards for many of the things that we are doing from interacting with the web interacting with servers exchanging file suites but use that instead of reinventing the wheel.  Third point make the graphical user interface.  In general the user interface separated from the backend system the system with the logic.  So they have different lifestyles.  So the graphic the user interface can change because you have new platform you have new system you have new user but the backend may stay the same or vice versa.  You can change the criteria where you develop you provide the answers but the format will be the same and you are not going to change the user interface.  So generally speaking keep those two aspects separated.  So those are sort of common sense on developing software.  Question so far.  All right.  So lets keep moving.  And lets talk about Python.  So some of the things are well known because we already introduce them last class.  But just want to be sure that they are just clearer and well fixed in your memories.  So like many other languages like all the languages Biden has variable operators functions.  We will talk about functions later on conditionals cooperators loops and all kind of operations.  Um there are some functions that are built in.  There are some types of variables that are built in.  So you have in terms of types of numeric integer floating you have strings lists to build.  So we will go into the details of all of those.  You may have dictionaries.  So all of those are different types for lets say basic different types for Python.  You can assign as we know values to variables.  In this case is mean that is we are in the strengths area.  So in this case is list.  You can have numbers lists.  We will talk about lists shortly but list is basically collection of elements in square brackets where each element is separated by comma.  And the elements can be pretty much anything can be numbers can be strings can be other lists.  And you address the single element by calling them by number.  And Python is starting from zero.  So is the element zero.  Coffee is the element two.  Strings can be both strings and these can be changed meaning you cant replace the values.  We had some examples from the strings.  Naming variables we mention that there are some words that you cannot use to name variables.  Those words are result of the words.  So you have words like and the or from.  So all all of those are or into are reserved words.  You cannot call variable print.  You can call print with capital because up in in python has more letters and capital letters are considered definite.  Again names are case sensitive.  So you can use any one of those with capital letters and there will be no conflict.  But you want to avoid that because it could be confusing at the very end.  You also want to have name.  So.  That we will remind you what is the function that the body of Ebola is having in your program Those are called the mnemonic variables names variable names some meaning the names that are remaining.  Again the the role of that variable within the script.  Comparison.  You have the usual.  There is not much difference from pretty much any other language probably apart from two one that is that equal to the equal in the comparison is two equal signs.  So we use one equals sign to assign by the user to by their both.  So we use two equal signs for the comparison all for the conditional statements.  Another one that may be different that is not equal to that is exclamation marker equal.  In some other languages you has you have combination of less than greater than one after the other.  But think in some versions of Python that works as well.  But what is most commonly used is exclamation mark equal.  In computational theory there is theorem that is called Yeah that is named after the creator of the theorem that is being been theorem saying that every logical operation or process can be represented with the combination of three elements sequences conditionals and loops meaning language to be able to solve any logical problem needs to have those three components in it.  So in Python sequentially it starts from the top going to the bottom from the left going to the right.  So in this case.  If you have program where is equal to is equal to you will get two.  Then you do equals plus two will be four.  So thats the sequence.  Conditional.  We mention that there are operators for comparison.  Those operators are used among other things for the conditional.  So conditional are with the if or if.  So if today equal so double equal sign the October 30th pre into happy birthday John elif means else if.  Meaning if this is not not true then am asking is today June 21st then that if yes print Happy birthday Loreen.  And if not the meaning this is these fail that these fail that you are here else meaning for anything else you print.  Good morning.  Keep in mind that two things.  One you need to have call on that at the end of the conditional statement.  The second that you need to have.  The true case meaning when the conditional statement is through the condition the condition the statement the meaning of the statement that will be executed when the condition is true that has to be indented.  So after call on that you always have an indentation.  Thats one of the most common error at the beginning of coding in Python.  So on the left you have graphical representation flowchart for.  An example of conditionals.  So you have equals five in the room by the you have the FS.  So Im asking if is less than ten.  If yes.  And youre putting smaller then and you go here then Im meaning this is the case for her.  Yes.  But if is no will go here anyway.  So if is yes will print smaller if is greater than 20.  And it would be bigger bigger if is not the either one will bring finish.  So again double equal call on the indentation.  So those are three things that you need to keep in mind.  When you do conditionals.  We already mentioned that loops so loops meaning repaired repeating statements so that can be one single statement or bunch of them.  So in this case initialize the variable with the value five.  Then Im asking is and greater than zero.  If yes it will print an and will subtract one from and well continue printing fill.  It will become negative and meaning not greater than zero.  And then at that point that will go here and will print the finish.  Couple of things.  So one.  We have several ways to represent loops in Pi Donut.  So during the first assignment you experience why that was loop.  The other option that can be why conditioner through then you would exit the if is not true anymore order for for in this case you have list of names.  For anybody any name or variable to say name in the list of names.  Print the name.  So the first round the variable name will have the value of the first element in the list.  That is frank.  So the first round will print Frank.  Then the second round it will point to.  The second one again is loop memory and so on till the end.  What is really important when you do loop You want to be sure that there is no indefinite or infinite loop.  So you need to have if remove this one and this statement an equal.  And minus one he will stay in the loop forever so it will burn your CPU.  So be sure that you have condition that will let the program to leave the.  This is another example of new person in this case that is using Whyalla.  So while countdown at least hundred.  Bring the count down and then you decrease one element from that that countdown.  So initially countdown is 100.  That is not mean initially is at 25.  So you are here.  Yeah.  Less than 100.  Yes.  We printed will be 24 and so on think would be one.  And then it will stop.  So again call on indentation.  So the indentation is basically creating sort of logical block.  So you can have as many statements here.  All right.  So.  You can use in the looper two statements that are particularly useful.  You can use breaker.  We use that in exercise zero and one.  So in this case what we are doing we are generating bunch of numbers and of numbers.  So then we will print the numbers in loop and if the number is five will break.  So it will start with the first number that would be zero.  So range then is generating list of numbers from to 10.  So when the number is equal five it will break.  Breaking mean means getting out of the loop.  In this case.  Its another statement that is continue.  So have range of numbers from one to to with step one.  mean you dont need to memorize all the all of those.  You will use them.  And you will remember then that you start the loop.  Over here.  Im saying if the remainder of the number divided by ten is different from zero then continue.  Meaning dont do anything.  That means that Im looking for numbers that are multiple of ten.  So because the number as reminder at zero if is multiple of that number.  So in this case its ten when have the first nine numbers.  will just continue doing nothing.  When the number will become ten the remainder will be zero zero.  And then will print the number and then the string is multiple and then well continue until the mean the value of 100.  That example.  So.  In this case list of elements.  And theyre that names are the same names that we saw before the looper in this case and saying if name start with then you will printed meaning in the loop.  It will be Mary and Mohammad this one age 20 while age less than 66.  You add one to age.  Then when you go out of death meaning when you are not less than 66 then you will bring the age and retirement.  When we work with Python or similar languages you can easily run all the code you want directly in the Python console.  But then you dont have trace of what happened.  And when you closed your editorial your computer those variables mean the next section next session or Python the previous ones would be deleted.  So thats why we created we added the statements in one single file.  In general use the dot pie as an extension.  Those files that we run executed by the Python interpreter.  So whats wrong in this So in this case you dont have the indentation here.  So thats what is missing in this other case.  And you have.  Numbers.  You have knife.  But unfortunately the if theres one single equal sign none too.  So over here there was the missing the indentation over here the error is the missing second equal sign.  And then you have all the links for.  mean more information on the on the Python website Internet.  So let me stop sharing.  And that is he.  If you have questions those links will have the commands of staff for reference.  Yes.  But mean generally speaking.  Quite honestly rarely go directly into the python.  Her website obviously is the only place with official information about what you are doing but there are different ways to get the information that you may need.  So let me share the screen in second.  For example if do.  dont know transformer.  Right on the list.  Two strings.  mean there are generally million different links you have on campus building to StackOverflow.  Thats generally the way to go.  So if you go to StackOverflow you are going to have all the information you need to check the popularity of the question and the answer just to have an idea on how reliable the answer can be.  So in this case mean thats very basic but common question and thats why you have more than 1000 people upvoted the question and this answer with this in statement is super popular.  So mean you can go to Python and check exactly what the manual is saying but the StackOverflow is probably the easiest way to go.  personally mean called for million reasons.  So just to give you an idea.  One of the things that theyre doing a.  Is managing the scheduling of courses and classes within the School of Systems and Enterprises.  Now we hired someone who will be just on this one but for about two years did it by myself but Im still involved.  One of the issues that we have in comments is mean like all the companies that the data are not very wellstructured.  So when you need that information that piece of information can be all over the places.  So thats why created this script.  The.  Just to give you an idea of how mean in daily life you can use Python.  So in this case download from the system that we use as backend in commenc is called what they.  The list of all the courses that are happening in given semester are at sea events.  And then.  basically clean the file because its giant file with all the courses for all the schools but they need only the courses that are in my programs.  Im IAC as is and way is.  So clean the data add then some features.  What is the program What is the level ground with undergraduate corporate and information like like that.  So when they do something like that mean Im familiar with Python.  So have mean wrote dont know how many probably by the thousand programs but there is always something that you dont remember but youre not sure.  And we tend to be lazy and Im not proud of that.  But these matter of facts.  And instead of going back in my memories and trying to find solution Google it.  So most of the time end up in StackOverflow and use it.  So now Im using also her chart the GP.  Im pretty sure youre familiar with that.  The.  It is very interesting tool.  So it has been trained using pretty much everything that is available in open source including the content on GitHub.  So GitHub is huge repository of code where you can have your own repository with your own code.  Generally if you have space and inside this space you have your different projects.  GitHub is owned by Microsoft but Microsoft is one of the largest investors in open.  And yeah that is the company that created chart to cut it.  Besides using mean everything that you can get from the Internet.  dont know if this is true but this is what they said.  It has also access to everything that is publicly available in GitHub meaning it can really give you way to do the coding.  Im not particularly happy with the result.  So most of the time is missing.  Something is using pseudocode instead of code.  But you think it is called the you try to run.  It is not working but can be helpful.  am writing book on the societal implication of AA and machine learning and Im actually using it as sort of sidekick.  So when have an idea instead of google it use the bot and will give me sort of compiled version of what is available in open source.  But in in education we are all kind of scared of how students can use that because we all know that there is always risk of plagiarism with that.  These tools or tools like that the the risk of plagiarism is even higher.  We are still developing tools able to detect what is coming from Jupiter and what is now her that again you may use it to cheat her.  dont know if this is beneficial for your education.  Most likely not much.  So encourage you to play with it because somehow well be part of our lives.  But before copying and pasting things switch your brain on and read what is inside and be sure that it is doing it in the proper way.  We will run chat group on some of the questions to compare the results and we will apply the same concept that we apply for the copying in general.  So if you are using chat the GP and someone else is using the same.  Probably your code will be similar if not identical.  At that point you will be penalized not for using GP but because someone else did the same and you had the same code.  So it is like doing after the fact because we cannot really intercept the cheating at the very beginning.  So there is no way.  In theory we could create classifier.  So coding is very personal.  So.  We could create classifier analyzing the code and detecting sort of footprint.  So if there is the footprint of GPT three then its cheating but the tool is not ready.  Student University of Princeton created sort of prototype that are the traditional tools 13 that is the most commonly used.  The thing that is the most commonly used to detect plagiarism is developing module on chart.  Gupta.  But mean that this tool has been released by the end of November.  There is nothing that is ready yet.  So but again really wanted to share with you very openly with what what is available if you need help.  Apart from obviously myself and our work to StackOverflow and Google that are always good again dont feel that you are doing something wrong again.  was coding since while but when have even trivial question so that dont remember right away instead of wasting my time googled it and they get the results.  And then now we have chart the JPT that can be an additional help.  So thats the long story probably longer than you want but thats the full story.  So is seven the 17 What we are going to do now will be an inclass exercise.  So let me share the screen.  And let me go.  Be here.  Okay.  So will publish it in moment in in canvas.  But want to introduce it to you first.  So you want to write program that will you will call like changed the UI that kind of mimic conversion from U. S.  dollars to another currency.  So you will ask the user how many U. S.  dollars you want to change.  Lets say the input is hundred.  Enter the name of the currency you want to convert the dollar into lets say is yen.  What is the exchange rate Lets say the user is inputting 114 and the output will be you can exchange the number that you got from the user.  Its 800 U. S.  dollars for the multiplication are between hundred and 814.  So you will use loop that is pretty much similar to what you did the previous exercises.  But to ask for the different input.  And then you will check if the value that has been provided by the user is number of now and you will use is digit as a.  In function that is associated to this to the string.  So whatever is the name daughter is digit the open and close brackets Diawara that is digit the is pretty dumb and is considered number but only if there.  Real numbers meaning no minus sign no decimal point no comma.  If you have one of those characters it will not recognize it as number.  So in this exercise that is obviously not.  mean that defeating the purpose of creating currency conversion tool you will consider only integers for the two numbers that you receive from the user.  And then you will paint blank line whatever is the way you want to paint the blank liner that can be just printing nothing.  Or you can use the special character backslash and telling her new line The meaning is keeping line.  And then you will print her you can exchange or whatever is the number of dollars for whatever is the result whatever currency you are using.  So let me make sure that.  The.  Okay.  So the assignment has been published.  The.  What will do now is to create some breakout rooms for.  So am creating for breakout rooms and you will be assigned automatically to those rooms.  You will have about 20 minutes to do it.  will pause the recording for those 20 minutes and will be here to whatever question you may have.  And then after the 20 minutes will give you warning and will close the room and we will discuss the results.  So you will have the opportunity to present what you did.  If you want will present the possible solutions.  And then we will talk about the assignment for next week.  Okay.  open the room.  Im okay.  So am resuming recording.  So well come back.  Any volunteer just to share what you did.  There is no judgment.  There is no nothing just to share.  Now can share Professor.  So please.  Yeah sure.  Okay.  Let me know when you can see the screen.  Its coming up.  Yep.  Here we go.  Okay let me just stay on somehow.  Yeah.  dont know what the lines are for but when we did is while loop and we first asked the user for input in USD and we used the instruction from the assignment as to check if USD is digit.  If it is digit then we would then proceed to ask the user for currency on the exchange rate and then we re proceed to cast both USD an exchange rate to integer and then we have variable call result.  We did the calculation of exchange rate times USD and then we print the statement your exchange rate is USD US dollars for results.  You can see the output below.  We entered 100 for the currency name.  We entered apples and for the exchange rate we entered 77.  So now the output is then 100 USD 47700 apples.  We also then proceeded to enter random characters and continue the loop again and again with enter US dollars because it was not an integer.  So good good good.  mean the only thing that can say is there is no way to be out of the loop.  So if you remember except size zero we had done with break.  So in this case you dont have this option is that the assignment had the requirement to.  No no no no no but entirely.  Oh youre just making statement.  Okay.  Yeah mean it is working but there is no way out.  Yeah.  So thats the only thing.  It was not requirement.  Okay.  But is generally something that you want to do because otherwise it will run forever.  Yeah.  Take it and call it out.  Okay.  Thank you.  Anyone else who want to share All right.  So let me share the screen and we go to.  Couple options.  So does the basic one.  No.  Thats the basic one.  So the basic one is basic.  mean just what you saw.  So you have the input for the amount in U. S.  dollars.  If done we break.  Then checking if digit if not will print something and will continue.  Then ask you for the currency conversion rate checking.  Same thing if is digit and then calculating the value floating or integer in this case would be the same.  And then printing.  So if run it.  And Id say 11.  have no idea what it is.  And then done.  When its finished.  mean its all good.  Nothing wrong with that.  They only think obviously if we have a.  Here.  Whatever it is.  If the exchange rate lets say its 1. 4.  will give an error.  So and thats basically the way is the Egypt works.  So because the point was not consider number meaning the old think is now the number.  So another way that you have to intercept those airports is using tri except so the initial part is the same.  So asking for the input then the checking instead of using digit and doing tri except tri.  Its basically way to intercept errors.  So meaning Im asking by that to try to do this operation here.  If there is no air ora will continue keeping the.  Except if there is an error.  Meaning.  The amount is not dramatic other than that except the statement that will kick in will bring to growing input and will continue going back and then.  Yes sorry have question in Python version 3. 9 the interpreter.  Can you explain difference between like accept with colon versus accept with explicit value like value error Because it was asking for specific exception it was giving like warning or something of that nature when you just leave accepted by itself without something more after the colon.  Before the colon.  Sure.  mean dont remember.  What is the Python version that Im using Anyway.  So think Im using nine.  But thats not not the point.  Um um.  Well the try.  Except that it can intercept the any kind of error.  Uh you can either leave it open.  So the method that you received that is warning is not something that is blocking the execution.  Um you can mean if you go online you will see what are the code there for the different errors.  So you can probably you can get from the help here.  Yeah.  Yeah.  So you can say okay try this one accept this particular error and then do something.  You can also have more than one exception meaning you can really create logic in there.  So in this case you can say dont know.  mean floating the idea or that you can get it if is not the number.  But when you have statements that are more complex you can have more than one number.  think you want to retrieve value from database.  So at that point the database may not be available that the file may not exist in the written code.  It can be wrong.  So each one will have different the error code.  So you can have different messages for different efforts Yeah.  Go ahead.  Yes.  Sorry.  Would you say that its best practice to be explicit about the exception and provide specific where you want to accept or.  No no no no no.  mean it depends.  If you dont have one particular reason for intercepting one particular errata you dont need to do that.  Keeping in mind that you can have think use that.  Here.  So you can have library.  mean we are not there yet but with Python you can add functions.  So in this case Im out doing libraries doing special things.  This function here is ignoring the warnings because sometimes can be mean in this case and adding it because one library is not fully compatible with another library generating errors.  So because know that there is an error but there is nothing that can do because its just matter of compatibility between libraries.  just use the function that is bypassing the warning messages.  So if the warning method is annoying you can remove it.  But generally speaking really dont see the need to specify the error in the except unless you have good reason.  So in this case quite honestly the only error that could happen there.  mean it could also be misspelled the name of the variable and there could be the variable and not been assigned.  So eventually those are two types of carrots and they can have two different accents.  But mean that you dont need to do that.  Thank you Professor.  hope its not confusing but that there is always more than one answer to most of the questions by the.  Thank you.  So.  All right.  So mean in this case is doing pretty much the same thing.  So if ran it that.  can have dont know 22.  want to convert in euros and lets say 0. 97.  So in this case again no error.  So and then all the rest would be the same.  So again will post both solutions on canvas.  Generally speaking there is the Gita as are quite lot of limitations.  mean if there is floating point number it will never pass.  So the try except its the way to go.  All right.  Okay.  So let me now introduce the next six essays.  So this exercise is in sense easier to.  Then the one you did in class is another conversion.  So you want to convert temperature in Celsius to temperature in Fahrenheit.  As you can imagine being born in Europe.  am more used to censors than Fahrenheit and the conversion is something that either with calculator or just mentally do most of the time.  So thats why Im starting with Celsius to Fahrenheit instead of ISO.  Thats just to give you background so the user will be prompt to input.  Temperature in Celsius for example at 15.  And then the system will do the calculation using the formula the temperature in Celsius multiplied by 1. 8 plus 32.  Im still like sense your sermon.  You may think why you are thinking in that sense.  like the idea of freezing point being zero so its kind of easier to me.  But anyway so you ask for this input you apply the formula and you will put it into the equivalent of this case.  15 degrees Celsius is at 60 Fahrenheit.  So this is the formula and you will print the result with one blank line.  And thats basically it.  So thats pretty much everything.  Let me make sure that you have everything you need to.  am publishing the inclass.  Exercises the to the by.  Publishing the text of the assignment and publishing the slides that use today.  All right.  So thats basically it.  The questions.  All right.  So if you have any question down the road either myself or you we will be happy to help.  If not.  See you next week.  Hey Professor.  Yeah.  Yeah.  Good.  Module modules and canvas is still messed up.  Are you.  Are you aware of that situation Okay which one Well when we look at assignments and everyone chime in if you can.  Its showing with due dates is showing all of the assignments from.  It looks like previous term of last year.  It shows us everything.  Oh.  Okay.  mean in theory they shouldnt be published.  Okay.  really thank you for letting me know.  Yeah.  Okay.  And also in addition did send you two separate emails.  Is your email address la forza at stevens idea Yeah.  Okay.  dont know if you had chance to look at it or maybe you were getting the same types of emails so you just corrected it.  did see the correction to the quiz which you mentioned earlier.  Oh yeah yeah yeah yeah yeah.  mean there was an error and chunk.  Yeah yeah yeah.  Okay.  Yeah thats.  Thats basically all had.  All right.  Yeah.  So how could they Okay.  Thank you you two.  And thank you for letting me know.  Yeah.  Right.  fs STEVENS lw INSTITUTE of TECHNOLOGY Intro to Data Science AlML for Systems and Software Engineering eA clipizzistevens. edu SSE What is Artificial Intelligence Alis the study and design of intelligent agents where an intelligent agent is system that perceives ifs environment and takes actions that maximize its chances of success Al basically puts human intelligence info machine The problem The human mind ts currently not fully understood There is no method of determining when machine is actually intelligent STEVENS INSTITUTE of TECHNOLOGY History of Al STEVENS INSTITUTE of TECHNOLOGY Evaluating Al the Turing test ie Turing test During the Turing test the human questioner asks series of questions to both respondents.  After the specified time the questioner tries to decide which terminal is operated by the human respondent and which terminal is operated by the computer.  The Turing test developed by Alan Turing in 1950 is test of machines ability to exhibit intelligent behavior equivalent to or indistinguishable from that of human SS LULU STEVENS INSTITUTE of TECHNOLOGY Al in its context Data growth The digital tools we are using every day are creating data from everything we do at an unprecedented rate every day 2. 5 quintillion 1018 bytes of data are created and 90 of the data in the world today was created within the past two years The bulk of this flood of data the Big Data is combination of Social Media such as Twitter or Facebook blogs news websites This kind of Big Data is generated by the online population that is growing portion of the total 50 worldwide 74 of Europeans 89 of North Americans Because so much of the population is generating it Big Data can provide potentially useful information for our lives and businesses Mining the Big Data requires combination of tools ability to represent knowledge and domainspecific expertise Exabyte billion gigabytes STEVENS INSTITUTE of TECHNOLOGY Machine Learning and data ie Machine learning is programming computers to optimize performance criterion using example data as past experience Intro to Machine Learning Alpaydin 2010 Machine Learning means learning from Data Machine Learning Is just Data Algorithms but Data Is more important Same steps as Data Science Start with an idea and create the data pipeline Business Understanding Find the necessary data Analyze and validate the data Data Understanding Prepare the data Enrich and transform the data Data Preparation Develop and optimize the ML model with an ML toolengine Modeling Evaluate the results Testing Operationalize the entire process for reuse Deployment STEVENS INSTITUTE of TECHNOLOGY Why Machine Learning No human experts industrialmanufacturing control mass spectrometer analysis drug design astronomic discovery Blackbox human expertise facehandwritingsopeech recognition driving car flying plane Rapidly changing phenomena credit scoring financial modeling diagnosis fraud detection Need for customizationpersonalization personalized news reader moviebook recommendation STEVENS INSTITUTE of TECHNOLOGY Current Al research directions ie Thought processes modeling Knowledge representation and its application Natural language processing Robotics Machine creativity Machine learning STEVENS INSTITUTE of TECHNOLOGY Machine Learning in Software Development Software development itself will increasingly be automated Machine Learning as the next level of abstraction For tasks like face recognition we use ML because we dont know how to write the software and it has been difficult to collect the data.  For other tasks like billing its easy to write program based on few simple business rules Machine learning is already making code more efficient Googles Jeff Dean has reported that 500 lines of TensorFlow code has replaced 500000 lines of code in Google Translate Neural networks can create new programs by combining existing modules.  The system is trained using execution traces from other programs Developer may become teacher curator of training data and an analyst of results Machine learning can be used to generate short programs from training data to optimize small parts of larger programs but not the entire program ML is playing an increasing role in Data management and infrastructure It is difficult to imagine future in which humans no longer need to create software.  But its easy to imagine that human in the loop software development will be big part of the future Machine Learning in Systems Engineering This is 2way road ML can benefit from SE approach and SE will use approaches methods and algorithms from ML to better design systems and to add capabilities to existing systems Modeldriven SE Is traditionally based on classic top down modeling but data driven MLsupported model are emerging and will eventually synergically use the traditional top down ones The datification of our society is making available an unprecedented quantity of data.  While in datascarce environments traditional topdown modeling was the only choice now huge data allows bottomup datadriven approaches When data is huge from different sources all relevant data scienceML approach ts the only way to go Design Machine Learning solution with system view.  This would impact the growing hybrid humanmachine systems segment STEVENS INSTITUTE of TECHNOLOGY 18 Complexsystem Implementations of Al lw Some form of AI in everyday life Cars Selfparking Cruise control Speech recognition Banks Monitoring for fraud ee Complexsystem Implementations of Al Military Miniature robot tank Unmanned underwater vehicles Unmanned aerial vehicles STEVENS INSTITUTE of TECHNOLOGY 20 Hello.  Hello everybody.  Oh there.  141 Oh no.  So its 630 now and we are right on time.  149 All right.  So mean come on campus today and.  157 Lets start so let me start with the screen in second but.  203 Right.  Okay.  215 So Im sharing the screen.  And.  228 All right.  So we are in module five.  236 Uh you did the.  243 The previous assignment.  So for module module five thats basically what we have in the agenda.  247 So we will discuss the previous assignment.  256 We will talk about data in broad sense then we will talk about Python libraries and in particular pandas.  301 Then we will do the usual inclass exercise and then will introduce the next assignment the some comments and that will be the end of the class.  309 All right.  So the previous assignment that was this one was about working on.  322 Who files.  And doing pretty much the same thing comparing them.  333 So lets go to pie chart and lets see an example of the.  339 Luciana quoted.  So it was three parts.  350 The first part was on the CSB file.  354 We wanted to keep it clear this.  359 We want to skip the first line with the header.  403 There are different ways of doing it.  So one way could be to read the and mean the the first line outside of the loop.  408 The second is just initializing the counter to minus one meaning.  422 Then when you will count you will automatically skip the first one.  429 So Im initializing the counter at minus one again not to count the first one to the header.  436 Then initialize list with the subscriber list.  446 mean the counter of this.  Could borrow the counter for the customer and an empty list for the call that started the loop again.  452 Obviously it would have been probably easier using pandas but you didnt know.  506 Officially pandas are up to today.  514 Meaning we are using as files and regular this.  518 So Im appending the ROE meaning the line to the file to the lists.  526 Then Im adding one to the overall counter checking if the in that row there is subscriber.  534 If yes will increase by one the counter subscribers.  545 Same thing for the customers.  And then will continue till the end of the file and then will print it out of the loop.  550 The following are the last five lines of the file.  600 So Im going from to and then going from the end line of content to minus.  606 And so thats the pointer.  And then getting and printing the from the list the pointer 617 mean the elements with you pointed by the pointer that at the very beginning will be the last one.  627 And then because the.  636 mean the point its 1264 thing will be one meaning in the end minus one year minus two and so on.  642 And then maybe add to the three to remove special characters and blank spaces at the beginning.  653 At the end calculated the percentage.  701 use it round with two decimal values.  707 You dont need to do that but it would look nicer.  And then same thing for the subscriber.  713 Print the results.  Part two.  720 Pretty much same thing for the other five.  724 In this case because mean that in the first case was printing the last five lines here in print 730 in the first five lines meaning want to skip the first one because again 738 its the one with the header and dont want to print it and then Im checking if its less than five and then if so 744 will printed the same thing adding one to the counter.  755 So for subscribers and customers and then increasing the overall count.  800 Same thing calculated percentage printing and less to.  806 Part three.  Im comparing the two values.  812 mean the two find the values for the two files.  So the overall number of elements.  816 And the percentage.  If run it.  826 have the last five lines of the file.  833 There are 21 320 21350 rows in the first file.  839 Of those.  Those are user type customer and per subscriber percentage.  848 Stay on file.  First five lines.  Total number distribution percentage.  901 Spring riders are more than winter riders.  910 During the spring.  There are more customers to nonsubscribers than winter.  914 Thats kind of understandable.  So during the winter you have more of the regular clients instead of those that mean just go and take bike.  922 Its winter is cold.  All right.  940 So thats basically it.  Questions 943 Comments.  Did you pretty much did the same.  948 didnt check your submission yet.  So just want to be sure that is pretty much in line with what you did.  956 Im in in this assignment.  The only thing.  So let me share again.  That we are little bit more complex.  We are defined.  mean the fact that you need to keep one line so you need to initialize to either minus one or just read the first line out of the loop then mean that all the rest is pretty much straightforward.  You could have probably done function for dealing with the two sides but we didnt introduce the functions yet that we will do today meaning it wouldnt make sense.  And then even with the function in the first case it was about printing.  The last five lines in the segment was the first five lines meaning the two were different anyway but you could have function to calculate the subscriber and the customer itself but it wouldnt save much in terms of the processing.  All right.  So let me go now to the actual content and let me start just talking 37 slides but we will go relatively fast on that.  So Data what we do in this course is pretty much extracting meaning insights from data.  But what is data mean its kind of generic term.  So lets talk little bit about which kind of data we can deal with.  So it could be structured data like databases data warehouses things like that or can be data that is totally unstructured like the web like other pieces of information music videos images that may not be in the structured.  Databases or data structures.  You may want to use it but thats it.  Most of the time when you have a.  Structure the systems for data you deal with databases.  So databases are large integrated collection of data and they are handled by what is called DB massive database management system that is software that makes our lives easier to interact with the data.  Both the ways.  Writing data.  Retrieving data.  Updating data.  When we work with data there are several layers that we need to consider.  So there is the physical layer meaning one in zero day an hour on your device whatever.  The device user could be hard disk to be remote storage.  But at the very end that what you are going to have will be anyway one zero on device.  Then you have how does one zero hour recorded on the physical device.  So if you consider that you interact with that physical device more than once you may not want to have all the data in one given place but you need to have somehow piece of software that will unlock the doors that one zero belonging to one particular file impositions that are optimizing the space you have on the disk.  You have sort of crossreference the role that for each file will point you or to the system to where physically the data are located.  Then you have conceptual schema of the data what they are presenting because they are representing students.  They are representing courses.  They are representing clients.  Representing whatever.  So those are the logical view of the data that we can have.  And then you have the views of the users.  So if you are in a.  Or the example.  If you are in university you have the view of students the view of administrative personnel the view of the faculty.  Each one will see only portion of the entire data as data base or dataset.  So that again you have different linear from the very physical to the physical schema that is layer provided by the operating system.  Then you have the conceptual schema that is provided by the DB mass and then different views that again are provided by the DB mass that order that software.  The advantages of having DB mass is that you basically do not need to worry too much about the data itself.  So you just mean point to the logical.  Entity and you will get the information.  The master is also doing bunch of other things either letting you extract the data in the aggregation you want or that this aggregation you want is also managing the integrity and the security of the dataset.  But the integrity means you have multiple accesses.  Again concurrent access is an example so you have multiple people accessing the same data but you need to define way to handle those situation.  Typically there is lock on the first one and when the second is trying to access the same data cannot access it.  But this lock is either handled by the DB crash recovery.  What if in the middle of transaction you have power failure and you have no backup you in the power pick up unit.  So at that point typically DBM assets are doing all or nothing.  Meaning either you have your transaction completed or you have nothing.  So is not leaving in the middle.  There are several of those.  The.  Those are some of the examples.  Oracle is the one of the leaders that historically is one of the leaders IBM Microsoft that are solutions that are open source.  MySchool is what the general use even if it is open source but is now owned by Oracle and the community is not very happy with keep using it.  There are other options.  mean the doubt is yes now is open.  So its at the certain point the Oracle can pull the plug and say okay its not available anymore.  Again there are other options.  Anyway Dbmr is three main components.  So storage query process or transaction manager.  So the storage manager is what is really dealing with the physical writing updating.  Deleting the data on your physical device the query processor.  What is it in charge for letting you talk to the data Meaning creating queries optimizing selections of data that you may have.  Transaction manager is what is handling the transactions meaning in error either making sure that concurrent requests will be handled in the proper way.  So those are the SC.  The properties again stressing are pretty much the four characteristics that was mentioning.  Lets go now to the logic.  mean it is sort of stack from the physical data to the very logical lot to the different views.  So we are going up in this stock and we are now on the conceptual level and we are talking about data model.  So the model is primarily three main characteristics that are entity attributes and keys.  The model has been created to meet the 1970s and by Peter Chen.  And again its called entity relationship because entity relationships are the key ingredient of this representation.  So in this chart you have the entities that are in the rectangular shape box.  So there are two entities here shopper and item and then you have relationships that are in the room Boyds.  And in this case you have shopper buys item and then you have attributes so that are this kind of rounded shape boxes where the attributes are the characteristics of the entity.  So shopper buys item item as three attributes type price and sorts.  So theres the basic example.  In real life things can be obviously way much more complicated.  Thinks about large companies may have quite lot of those entity and relationships making the old think kind of complex.  Do you really need to have that In some cases yes.  So in some cases they are required by law for the traceability of the data that you are handling.  The Sarbanes Oxley that was created roughly 15 20 years ago is saying that all the companies that are publicly traded we really need to document processes and data that are related to money handling in broad sense.  So you have that you need to have good representation of the processes and presentation of the data has to be compliant to the requirements.  One of the things that you may want to do with your data is normalization.  So normalization uh instead of giving all the theory lets use an example.  So this table is from we dont needs to go but the concept is still the same in this case is using Microsoft access but can be any read VMs and you have all that you have what is in the order you have with the supplier and with the customer.  So you have three different things that are in the same table.  If the certain point you have customer who changed the address you need to go through all the records all the lines with that customer and change the address.  It would be easier not to have three different tables one for each one of those different objects different entities.  So you have one table for the order one table for the supplier and one table for the customer.  And then you have way with the keys to jump from one to the other and eventually recreate what you have what you had in the previous table.  So thats form of normalization that when you do when you work with the other basis you want to have your data normalized.  There are different stages of normalization but what we need that in this case in this course thats for using this generic way of doing normalization at the school or systems and enterprises.  We dont have records on diplomats is and on as you have at the graduate level and created an undergraduate course for.  They the engineering that is rooted in as well.  But it is the language that is used by relational databases.  But it is again undergraduate think is ISC to 25.  But mean and since we do have courses on the computer science side of the of the Institute.  When you have multiple of those databases each one Fogg used on one of the characteristics of the.  Of your business then you need to have something that will let you have an integrated view.  So those collection of databases are called data warehouses with different logical pieces of the data of your company in that you need then to have something another piece of software that will help you put together the different pieces to have one single view.  So this is the EDL that stands for extract transformer and loader that will take pieces from the different databases and provide an integrated view.  EPL mean is it big business There are companies that are thriving on it.  Um.  We mentioned that one of the features of the beams is their ability to interact with the data to interact with the day that you need to have language to deal with it.  Edgar called the created the relational model and Escuela structured the query language and it is what we use to interact with the relational database.  Its.  Again that we dont have course at the graduate level on actual ISC to 25 is the only court that is spending quite some time not on that but.  As well is language meaning like all the languages like Python.  It has all the structures that you expect in any language.  Most of the time you dont write entire programs in as well.  You do only the portion that is directly related to the.  Interaction with the database.  But you could.  What normally do in my programs when have database in board write the logic in Python and then call that the query.  Just asking one specific value that is the result of the processing that they that they did with Python.  But again its basically up to you where you want to place the logic.  If most on the python side the moth on this other side or all in you have all the possible degrees of where to place the logic.  Um.  would keep those.  Uh again there are several databases.  My Askew and Postgres are two of the most commonly used as open source.  Again using my ask you lot but they are pretty much the same.  Keep in mind that the scale is sort of standard but it is not 100 standard.  Meaning each one of the different VMs is may have special instruction special features that are working on Dave system and on Dave system.  So this is intentional to lock the clients on that particular would be mess but you have good number of common actual statements.  So if you write your ask well in basic format it will run on all the DB masses.  Now.  Not everything is on relational databases because relational database is required required structure.  When you have data that is not structured then relational database may not be what you really need.  So the database that are not relational are called know as well meaning database as well.  Assuming that all the relational are using as well that is pretty much true.  But the reality is that there are more and more unstructured data that would fit poorly on relational databases.  So the main reason for people looking for non relational solutions is because the relational is they have limited flexibility because they have rigid schema that you predefined.  Think about the Excel you need to have the data that are in the format that is defined by your header to mean upload new data.  If you dont have it then it is not going to fit.  Um some companies are using sort of combined solution so you have something for the frontend and something for the backend.  Facebook has relational database for the frontend thats called Cassandra.  They created it and then they made it open source.  And then for the backend they have relational database.  dont know exactly what they have but is relational one meaning information about dont know your characteristics.  So the network of friends you have the about yourself and all the rest is on relational database.  But the content that you provide the pictures dont know.  Details thanks.  Then we go into Cassandra as non structured and then there is software taking from the unstructured and populate or update the structure.  There is no real definition of those known as well.  Generally speaking they are just non.  As you well know the election of generally use MongoDB as not relational database.  use MongoDB because the internal structure is based on JSON.  That is format for file.  So that is pretty common in exchange of information between servers.  Meaning if have if upload lets say tweets from Twitter will receive JSON files and can just dump those JSON files to MongoDB and they will fit right away.  When you work with those relational databases you dont have the same features that you have with the relational meaning.  For example you do not have control of the integrity of the transaction meaning those controls would be up to you.  So you need to take care of the inconsistencies on the integrity of the other transactions and all the other good things that we are in.  The list of the capabilities of relational database is pretty much what you have on the web.  So you get information based on best effort so they can be there or cannot be there.  So its up to your code doing it in the proper way.  MongoDB Again its pretty much to with the relational databases making the transformation from the extraction of data from MongoDB database to relational one.  Pretty straightforward.  And yet it is clear that another element that could be of interest is the MapReduce.  So MapReduce is technique for handling relational data databases where you take the data you map it with its key value.  And then when you want to retrieve you reduce the.  Pretty much you merge and sort the key values players and get the results as.  mean really using the the the differences that you get in this emergence of Hadoop is using the MapReduce approach in uni for loop is not only DMS like but is more distributed resource manager that can be files but can be mean processing resources so so we use it to put together bunch of mac mini that we had from sponsor.  So instead of running them individually we can we connected them with layer.  All of Hadoop managing those resources for sort of parallel processing hub well was supposed to revolve shoot up revolutionize the industry.  Um but if you look at the numbers the number of Hadoop uh systems didnt grow dramatically.  The main reason is because when you need more storage capabilities you go to the cloud.  So you go to Amazon you go to Google you go to to Microsoft.  They do have Hadoop for managing their.  Storage system but you dont see it.  So you may use Hadoop without knowing it but the number of systems is not so big as that.  Initially we dont.  When you work with data one essential step is the preparation.  So you want to be sure that you prepare the data in the proper way.  Data preparation in the entire process of extracting knowledge in broad sense from the data can take up to 70 80 of the total time.  That data preparation is essential because at the very end the quality of the results of your analysis will be meaning the quality of the decisions that you will take based on the analysis.  Its pretty much highly correlated with the quality of data that you provided.  But if you have either not enough data or low quality the analysis cannot be good.  Generally speaking there are three main steps in the preprocessing the data cleaning meaning you need to deal with the missing values you need to deal with the outliers.  So those things or inconsistencies are all part of the cleaning.  Then you need to do data integration.  So the more sources you have the more you know of the domain that you are analyzing.  Markets today are so good in pinpointing our needs because they can put together a.  Pieces of information about us from different sources so they can put together the beats that we visited through different tracking systems.  Facebook is doing lot of it.  Sometimes they have pieces of software in your computer and when you visit the page so that are in their network they basically read those pieces.  So they actually read the cache memory on your computer downloading the entire history of your browsing.  So thats the page that you visited.  But then you have information from the credit cards on your spending patterns and then you have information on dont know easy pass on the the the traveling that you did.  Then you have information from your phone provider and so on.  mean different sources different formats.  But then when you do the integration you could really go into the repeat in my own name with all the characteristics.  And marketers can do that because there are privacy restrictions.  They dont go up to that but they could.  So this is just to say how important is data integration Without data integration you cannot really know enough of someone or some problem because one source will give you only portion of the information doing the integration.  It can be complex because the data may not have the same format.  Format is not just the format one is CSP and one less or something else or one is from database certain type and one another type.  But sometimes that can be in the way the entities are named.  So just stupid simple example.  street can be as Dot Street the old world as the dot media in different ways.  Stephen So can be Stephens conceit of technology can be Stevens to New Jersey and so on.  mean that you need to sort it out.  mean the second part is more on the cleaning but the first one the three is good example.  So thats an easy way.  But sometimes you have even more complex than that.  You may not have the names of the entity then you need to extract the what the entities are from the context where you are.  So those are issues with integration and transformation.  We mentioned the normalization and we also want to aggregate different entities of different attributes that that you have.  So if you have dont know an event that is happening over time and you have the number of records and the duration but then if you do the number of runs in that unit of time you have more of an indication of whats going on.  So thats an example of aggregation of data.  So cleaning the integration transformation those are the three elements that are really important when you do the preprocessing.  So thats basically it.  Let me stop for second on this fourth part that is related to data.  In broad sense questions so far.  All right.  So lets move on and lets go now to functions.  Let me share the screen again and lets talk now about functions.  So we mentioned briefly today about the possibility to kind of put together parts of the code creating an entity that can be used multiple times.  So those are functions.  So functions are different types.  So that are functions that are built in in Python functions that we can import in our code functions that we can create.  So examples of builtin functions are range some land.  So those are building functions in Python.  You can create your own if you create your own.  You use death to define name that is your own name and then in parentheses the parameters that you are passing to the function.  In this case Im passing nothing.  And you have defined.  Hello Hello.  mean like in the conditions.  You had the colon and the indentation and then you have it in this case print high print.  You might not do much more than that though when you call in your program.  Hello.  You will get the high gym.  Then you bring something else.  Then you call again.  And we do again at the same thing.  So basically its way to write once and use multiple times.  So thats the basic reason why you want the functions.  Thats another example.  So you have you define function to calculate the area of triangle and you pass the height and the with the two dimensions and you calculate the area and it is you apply the formula and you retard the value of the area.  So if you pass those two values to the function like this one then you will get the area of three triangle Iguala.  mean you apply the formula then you change the values you use the same function and you will get different value.  So obviously if you use it just once it would it may make much sense to use function.  If you use it multiple times then yes there is reason.  Thats another example.  So square root.  Same thing.  This is little bit more complex.  And then when you want to use it you just call it and pass as an argument parameter to the value that you want the function to use.  Again.  Thats another example.  This is function with some ifs so you will pass to the function the language.  If the language is yes it will print.  Hola.  If else.  If ops is are not French.  Bonjour.  Otherwise is.  Hello.  So if you pass.  If you call greet yen you would get hello.  If you do greet if our is.  Bonjour.  So hes not returning anything.  In this case this function is returning.  Hello mean thats basic stupid function but mean explaining how it works.  So if you.  Hola Greta.  It will retain.  Hello.  And you will have the first one.  Hello Glen.  Hello.  Sending this ceremony one.  You can do what we did here without return.  With the return meaning you can pass up the language and then return either whole bunch of hello and then thats what you have.  So its pretty much the same but structured in different way.  Just as recap.  So you have in this case the function is called Max and you pass law.  So the argument that whatever you want to call it is award that will be passed to the function.  The function will do whatever its supposed to do and then will return as result.  You can pass multiple parameters to function.  The parameter will be separated by comma.  You can have default value for the arguments.  So in this case the function is make sandwich and you have meat cheese.  Thats the default value of cheddar bread.  The default value.  Right.  If you.  And then with those parameters that you print will have sandwich.  Me cheese bread.  So if you pass we go instead of meat and you will have this outcome.  Same thing.  If you change the value you will get the first one.  mean then you will get whatever is the value.  Like in the first example.  If you pass two parameters the second part of the first parameter will go into the argument that with no default and this tag on would go instead of the default if it was third one that will go to the third one.  You can have variable number of arguments.  generally dont use it because it can be little bit confusing.  But you could.  Why and when you use functions so you use functions for sure for sort of an economy of scale.  So you have the square root you call the square root multiple times.  You write it one once and then you call up multiple times.  You can also use the function search to better organize your code having sort of logical elements of what people use to code.  With object oriented approach thats more familiar.  There are other ways to doing it.  We will say with the functions.  Another important element is the difference between local and global variables.  So local variables are variables that are lets say in function and we in the function.  When you go out of the function they will have no value.  So thats an example.  So you have this function up with those values inside the function.  define that as global.  So outside of the function not assign those values.  Then print before calling the function and and then thats what get.  So have one two three four thats what have.  Then pass the 25 and 50 to the function and then print after.  So if go mean when calling Im sorry when Im calling the function go into the function will assign those values.  And then thats what have.  is five is.  Then flip the and meaning instead of 25 and 50 have 1525.  Then stepped out of the function print after because global the value that set for in the function that changed the from to meaning outside of the function.  Now have stay at five but is not global.  So when Im out of the function would go back to the original value and same for the other things.  So local global sometimes can be used.  Lets talk now about the imported functions.  So you import function from libraries.  So in Python there are several thousand libraries that can really make your life easier.  Pretty much you have libraries for anything that you may think about.  No quite so.  But pretty much.  Obviously is not solving your specific problem but is addressing the needs that they got.  million years ago when was starting working in artificial intelligence was in what is called expert systems so rule based systems.  But we also did something that is pretty much in the real mode machine learning.  We did the algorithm some.  There is one algorithm that is decision trees.  We manually created the algorithm in our code.  So that was either Fortran was lisp was ops five and we created our own libraries.  Now import library in my python code.  call the function for the decision tree passing the parameters and then they get the result.  So writing decision tree can be several lines of code now with two lines that import the library and call the function.  And then so thats something that is making lives easier for coders not solving the big problems of the world but its solving our small problems.  So for example you have library that is called math so you import the library and then you bring to the square root.  So security is function part of the library.  So you call it the as the name of the function.  And then you pass the argument and its and you get the result.  There are different ways for doing it.  So the first one is what we.  So you can.  Import to only the function that they need.  And then at that point you dont need to write the math dope as Quixote but just as are keeping in mind that when you import the function you import the your the old function into your code.  Some of the functions are big.  When something is big your code will become big.  Meaning if you also deal with large data you might run out of memory.  So you may want to say importing only what you really need of big libraries.  You can also use the nicknames.  mean in this case doesnt make much sense because you are basically saving one character only.  But if you have libraries with longer name than using three character as nickname may be useful.  But again thats an application.  And those are links.  So lets talk about the mean we mentioned the building functions.  Those are some of the libraries that are very common in Python.  Amoeba is one that is kind of the most commonly used library for plotting for basic.  Graphs so you can have a.  mean you imported with Matlock Lockley.  But again this case being longer P. A.  is kind of useful.  So in this case its sort of arch of parable.  You can do plotline.  You can have parameters.  Call auto market and style of line scatterplot but shop by shot the histogram integrated view so you can have one single metadata.  With subplots you define the different subplots and you have one single view.  Noon pie is another very popular.  common library is the root is the foundation of most of the scientific numerical libraries.  One of the main characteristics is the use of another variable type that is array.  So in canvas you have linker kind of comparing arrays with lists.  They are they look the same but they are different.  The primary arrays are used to deal with that exceeds so think an array as mavericks and then can be one dimension multiple dimensions but pretty much is what you really need if you want to use linear algebra pretty much.  Those are examples.  And thus its probably the most common library in dealing with data not because it is doing lot of hardcore data science but because its creating data structures.  Then you use the data structures for doing something else.  Keeping in mind that is based on known pie meaning embedded in pandas that are all the hearts that you can get from that.  From the nearby.  So lets talk briefly on pandas and then you will do exercises on that and we will probably talk little bit more next class.  So the name is not from the animal but its from Python Data Analysis Library.  Um there are lot of similarities between the general concept of table that can be as well Table Excel spreadsheet and the PANDAS data structures.  There are two types of data structure.  One series.  One is one dimensional data frames two dimensional most of the time we call data frame not no matter what.  So the name series is less used even if one dimensional but it will be more besides pandas.  We the library has been created for one specific company.  It was in finance.  And then the order asked that after few years of use mean the exclusive use by this company to make it the open source and we are all happy that they agreed.  In doing so you can import into pandas pretty much any form of data.  So can be.  This can be.  She has defiance.  It can be fired from database so all of those can be imported into pandas.  Dictionaries are kind of to 1.  But again dictionaries are form of data structure.  So will not do much more than that on the pandas.  You will have the slides.  You will do exercises.  dont want to skip the the inclass exercise because its already 730 and change.  And want to make sure that you will have the opportunity to do it.  All right.  Let me go for second here and share this screen again.  And.  So the inclass exercise has two parts.  So it starts with asking the user to input three numbers.  You want to perform an automatic check on the numbers and you want to use function that you will create to do the checking.  So no each one is number or try except by the function doing for all of them.  Then with those three numbers the first part is calculate the factorial as function for the first number that is being it.  Then the second to you will use to calculate the floating value of the solution in the equation.  The linear equation multiplied by plus equals zero where and are the second and third numbers.  The second and third order of the three numbers meaning is equal to minus divided by eight.  So you want to write your own function for both the factorial and the linear equation.  And you do not want to use it for this particular exercise except in library.  So let me stop sharing and let me make sure that you have it.  Okay.  published the.  The solution on the previous assignment.  And.  Okay.  So.  And publish the inclass exercise.  Let me create the breakout rooms.  Okay.  There are four breakout rooms with two or three participants per room.  Creating and opening the rooms and give you 15 minutes to work on it between 15 and 20 minutes.  And then we will reconvene and we will discuss the solution and then will introduce the next assignment.  It is little bit tricky and so need to explain what to do.  So opening the rooms will pause the recording and will resume it after 1520 minutes.  Meaning in the recording.  So well come back.  Lets give people another 15 seconds.  And so comments.  Get in there.  All right.  So any volunteer.  Anyone want to share what you did Nope.  All right so let me share my solution.  Make sure to screen.  All right.  So again my solution is not the solution but the solution.  So just to be clear as usual obviously had more time to refine it to present in the proper way.  You had up 10 minutes or so.  So thats not possible to be done in 10 minutes for most of us.  But thats the way it is.  So comments over here again comments can be on multiple quotation symbols or single astorga.  This is the function to check if the value is numeric.  Is basically doing is getting the value then is trying floating of the could be into same think floating for the value if there is no error meaning is going here and or with no problem with it.  Why if there is an error will go into the accept and with have down and.  This is the function for the factorial.  So taking the number checking if its zero the factorial zero is one and is returning one if the number is zero.  Otherwise it will return recursively.  The value of the factorization until the end of the loop quoted.  Over here Im defining the function not to calculate the linear equation.  And thats the formula passing list of numbers.  So instead of individual numbers they pass the entire.  So what is this top number So initialize as an endless list of numbers so that the user will provide this.  So we know that there will be three numbers.  So Im counting them up initializing to zero.  And then while counter is less or equal to two will look for asking for new numbers with just telling the user how many numbers he already entered.  For each one Im calling the is numeric function getting the result and either going back to asking again or asking the new one then predicting the factorial.  Just calling the function up passing the first value and then solving the linear equation.  Passing the entire list.  Keeping in mind that the function would take the second and the third values only.  And then printing the solution and the process the mirror at the.  But number lets say its five then 22 66 whatever it is.  So have a.  mean just not is the fact that hes kind of useful tool for the user to know where you are.  So its one out of three two out of three three out of three factorial solution.  They are recreation and the liberals and thats it.  Questions.  All right.  So let me go now to.  The next assignment.  Admin closed this section.  Right.  Share the screen again.  Okay.  The assignment is again on the CD biker bike sharing program in New York City.  And in this case we are going to compare two different finds one from November 2021 and 1st November 2016.  That.  When you compare data from different periods.  So even if they want to represent the same think or they may be different.  So and this is the case.  So let me go to the two files.  So those are the two files that we have.  So this one is the.  Newest one.  This is the oldest one.  So in the older one you have.  Repudiation that is not in the new one.  You have the user type that is either subscriber and customer where subscriber is subscriber customer is someone vocationally like this guy here occasionally getting the bike in the new one.  You dont have subscriber and customer but you have casual or member.  So member subscriber.  Casual is customer.  So again semantically is the same thing but has been represented that in different ways.  So again you have two different files collected from Jersey City one in 2016 one in 2021.  They are pretty much doing the same job but the format is slightly different.  So thats probably the single most complex part of the assignment.  So then mean the things to do are kind of similar to what you did in the previous one.  Uh the indication that and giving you here are not using pandas but you can use pandas at this point.  If you dont use pandas then you use lists.  So each line meaning.  Each one of those.  Lets say this one up would be.  One element of your list and with if you call the entire data set data then would be data want to do because you have to file to read the data to would be the third line that you will read and it will look something like this one.  mean that is not from those files but it will look similar to this one.  So if you want the data you need to go into number two in this case zero.  If it is the fifth entry it will be data for zero meaning you are pointing to the first element or the fifth row.  So that list of lists that is kind of usual thing to do.  But again if you use pandas you can do it in different ways.  So you want to create function called the print details that will loop into the list that will collect the the daily trip duration that again you have in one file.  The actual duration.  And for the other one you dont meaning either you take for both the difference between and in the started or you take that for the second one and the trip duration for the first one is up to you.  So.  You Luper you take that reiteration and then you will.  Create blank line you will print the average daily trip duration for the five most popular starting and ending stations.  The number of members and casual users.  So again that duration is different to five members and casual.  Thats the way user types are called in.  The new one for the old one is different way so you need to create the same language.  Compare that the results from the two files the comparison that should create the elements to evaluate the ridership.  mean how the ridership changed over the two years.  And then you will print the end of the processing.  You will write one two page report based on the data hub over to explain how the ridership changed.  So thats pretty much it.  Again the most there are two complexities.  One is the fact that the two fights are structured in different ways with the same informational content but presented in two different ways.  And the second if you usurp and assert that is the complexity of working with pandas for the first time.  Again you can read into Pan thus.  And if you dont use Pan thus working with the least obvious that can be with some level of complexity.  Okay.  So let me.  Publish everything.  So you have the assignment.  Okay.  would publish it.  Now can publish right away.  published the in class.  Exercise.  And Im publishing all the material and the recording will be available as soon as zoom will allow us.  All right.  So questions.  Any professor whos having trouble accessing the pre prework module for module five the pre class assignment.  think the ungraded email on there will be.  Yeah.  um.  made it available.  Can you check is available now Yeah just do it.  But have to do that.  Yeah.  Yeah.  mean that thats absolutely fine.  mean also considering going into the zero four is not problem at all.  Im sorry if sometimes dont get back to you by the million things but definitely care for your comments and that definitely.  Thats fine.  assume assume that you accidentally deleted it or anything.  Hello.  Hello everybody.  On the weather less.  043 Hoboken less.  So we had.  048 broken main yesterday.  055 So its more than 24 hours without water.  100 So its lot of class.  All right.  104 So lets wait another minute or so less than minute and then with start.  115 Okay.  So we have relatively busy schedule for today so we have an assignment to review.  129 That was not an easy one.  142 would say that there were several things that we are not exactly mainstream compared to the previous assignments at least.  147 And then we will talk about the.  201 So quit engineering in broad sense.  We will talk about the visual intelligence and we will do an inclass exercise.  207 One of you asked me to give more time for the inclass exercise just to have more options to practice.  220 So will do my best to be as fast as possible in the initial part meaning the lights and the lecture and all the rest.  230 So.  Let me start sharing this screen.  244 Welcome everybody.  So Im sharing the screen.  300 would start close this.  305 would start with this.  310 So in the previous assignment there was a.  316 Now.  Its the trauma of the previous assignment that was on.  323 The Sidbi files.  So the main problem with those files was that we had two different files with two different formats.  332 So one had the duration to the other one had not yet all.  351 They have us started and ended up the time.  357 And the other difference was the.  403 Use type that in the old one was the name of the field user type and was subscriber customer while in the new one.  409 Instead of that user type member underscore casual and you have member or casual.  423 The other issue is that there were some characters that are blank and mean that.  430 When you work with the real data things can be messy.  443 So when you work in protected environment all the records are true.  451 But there are no missing values unless theres an exit size or missing values.  457 And we think that there are no strange characters in in the content.  504 mean in this case in the cells and everything is fine.  513 When you work with real world data you get what you get.  519 So if you work with social media for example when people is posting something they character etc.  that they may use may be different.  525 So if they are in one geographical region you have given character etc.  536 Another geographical reason is that region is different character etc.  544 When you put them together and you use the US character etc.  some of those values 549 some of those characters may be recognized for something that you would not want to consider as such like.  557 And then the line and the fine.  605 So those characters that need to be cleaned somehow.  608 So those are some of the issues that you may have when you deal with real world data.  614 So in this case there were some missing values that somebody else that we are not numerical 623 know when they were supposed to be numerical or some other values that we are.  628 Data but may have not been recognized as date with when you read into pandas.  636 So those were the major challenges.  646 So let me go here.  develop the solutions in two different ways.  650 One with Lisa and one with pandas.  702 So we introduce pandas last class.  707 And some of you may be not that familiar with that approach and may want to use lists.  712 So with the lists things are more kind of convoluted.  723 So just as quick comparison so theres the least version any is 129.  731 mean obviously there are comments that are blanks but all in all is under and 29 the pandas version.  738 Same thing with all the comments and all the rest is at 79.  746 So 79 compared to 129.  751 So is big difference.  So.  757 And then unfortunately the way the lists are working when you work with lists be prepared to do loops going into the content.  802 When you work with pandas you may not need the loops because you may have ways to do the calculation on the entire data frame.  815 So with the lists the idea is to read them those files into two lists of lists and then deal with whatever the content is going to be.  829 Because we have been asked to use function and to be named the present details.  847 We want to be sure that they input that this function is going to get there will be the same.  858 Even if the two files have different structure and different content in terms of.  905 mean how to name specific things like member casual or user type.  912 Meaning that before passing the values to the function print details if we need to create one single format for both of them.  920 The print details.  Function.  933 Its relatively straightforward.  So initialize the all the counters that will need.  939 started loop for into the content.  950 That is list of lists with all the records that read from the files with some changes that will show in minute.  956 So you do you start the list you add the duration so that this function is taking duration.  So just want to draw your attention to that is not end and start and end of the trip but duration.  So meaning that calculated the duration before passing the value to the function start sation and station and that member or casual meaning already changed from customer and user whatever was the name into member and casual.  So.  increase the duration by the value in duration for each line.  Then if is member one to the counter of members.  If casual one to the counter of casual.  Otherwise.  Meaning if hes blank or something like that continue.  Meaning doing nothing.  So it is not meant but not casual meaning.  You have blank.  And we know that there are some blanks on that column to continue.  Meaning doing nothing then.  Im checking if the name of the station where the tweet started is already in the dictionary.  If yes will add one to the account.  But we did something similar when we calculated the occurrence.  The frequency of names in one of the inclass exercises is the same approach.  use dictionary to count them.  mean in pandas you dont do that.  You just count using function embedded in pandas.  That is nonparty function.  So.  mean over here.  knew just that we already did few times.  do not want to go back to the same then same thing for the end of the start station and station.  Same thing when finished the lupus.  have all the information for that file and can print that the average daily duration is and all the rest.  Now define structure for the date that is year to month date.  Now what Minutes and seconds.  So you need this case.  You need to define the format for the date.  Opening the first file.  Initializing list that will contain the records will be again list of police.  Then started the loop.  If subscriber or customer.  Start time is going to be.  will take the format that define here to create value with the start time.  Same thing for the end time.  Calculate the difference and then add the to list the time difference and the value for the.  For the state stopping an interstate and ending station.  Else continue meaning there is blank or something.  Uh then um.  Im asking you if subscriber.  So this is basically to eliminate the basis.  The blanks in subscribe for customer can be done in different way.  If subscriber will append.  Member So Im doing the transformation of transcriber to member.  With this statement that same thing if casual would be is customary would be casual and then will append at the end.  will have list of lists with all the records within the first file.  Pretty much the same with the second file but the single file is going to be easier because dont have the this portion replacing the subscriber with member and the customer with casual.  already has those elements so thats why.  Is it shorter Then call the function for the first one call the function for the second one clause in the file not required.  But did it.  And then am printing and processing.  So let me run it.  So thats basically what you have process in the first file average duration most populous start inflation and inflation casual users members.  And then same thing for the second file.  Again.  Thats with the lists.  Without pandas things would be faster with the pandas shorter.  But there are some issues in particular.  Keep in mind that if you are using Max and if you have one of the latest generation of max or the one with the Apple silicon microprocessor you may get errors.  So actually created new directory.  You see thats one Im in the.  This one is the old one and they add to the warnings because otherwise would get notifications of errors that were due to the non compatibility of that version of the version of Python that was using on my old Mac before but with an intel processor on the new Mac with an Apple processor and it didnt work well in some cases blocking the execution of the program.  So strongly encourage you if you have this type of errors go to the site on.  Website and download the version of Python that is not the internal one but the other one.  dont remember how its called but you will check it if you have problems.  Obviously just send me an email and would send you the other way to go.  So with pandas again it will be shorter.  If you look at the function.  So the function is basically just doing small calculation on the time and then printing.  So this case is taking is taking a.  Taken of over generation.  Most popular staff station.  The most popular RN Station.  number of casual users and number of members.  So opening the files and reading the science into pandas data structure.  Initializing list for the values for printing them.  The one that will pass to the PM dictates function.  So what Im doing here Im calculating it again.  Thats not the only way to do it.  When tried to do it on the all data structure got an error that most likely was related to the wrong version of Python.  But decided to change it and work on separate data frames for the different parts that they would need so theyd start.  calculated transformed the value using the pandas to the time specifying the format.  Again could have done different way using just like did for the previous one and variable with the format instead of rewriting it.  So did just two times.  Doesnt change much.  Same thing at the end.  They put one on the stop start time.  Stop time.  Duration.  Its just difference.  do.  You need to use this type because otherwise you will get an error or mean it is not something where you can do calculation upon.  And then added the duration to that data for the search list that will pass to the.  function that most frequent station.  Super easy.  So just from the dataframe that created calculated the name that is according the most one line instead of a.  Its very powerful.  And then added this value to the list that will search for for printing same thing and station user type.  Well in this case dont need to do the conversion.  So for the first one can calculate the number of members as user type.  So as mean from the the call on user type and calculating subscriber.  Meaning no really need to do any conversion calculating as members the records with the subscriber in the same thing customer and then passing it to the list.  Similar thing for the second file.  So same thing.  On the first one Im not even considering the field duration.  could have done in different way but just wanted to have the same approach for the two files.  So.  Duration.  Adding to the list the most frequent same thing that did for the first one in this case cases number of members is name taking different name for what call on it because in the second one have different for the name.  So the first one was user type the second one is member casual instead of looking for subscriber and customer in this case member and casual.  So thats basically it.  At this point.  have in data force all the elements on the first file not the actual elements all defined but all the values that they want to print.  So its slightly different approach from the first one.  The first one was passing the entire file.  So this way is more efficient and will generate the same results.  Then calling the function with the fourth with the second that could have done in different way.  Obviously instead of having two separate.  could have list of lists and doing loop here on the two elements of the list.  But mean it is just two elements and so doesnt make much sense and not saving that much space with it.  So those was where the results from the non pandas version the list version.  This is going to be for.  The new one.  That is exactly the same.  The only difference is that have different format for the duration because wanted to have.  wanted to have Howards minutes and seconds just to have nicer printing.  But mean its basically the same value in different format.  Okay.  Questions have one.  Well yeah.  mean would be surprised if no one had questions.  It was complex.  have real one and then bit of silly one.  Know.  Is there going to be grading on this one Because this gave me this is real run for my money and faster in terms of like difficulty jump from the last couple of homeworks.  Well yes there is there will be grading but it will be kind of generous grading considering that is more complex.  Okay.  And then had another question that was actually homework or is that one kind of in the works It was definitely bit more hefty guess than the other ones in terms of speed but itll take to grade.  But was just wondering.  It should be graded sooner.  mean our T. A.  is grading all the assignments.  We also have greater.  But we have two sections.  a. m.  624.  Okay.  We have this section that is relatively small.  And then we have another section with the 55 C.  So that is running on Wednesdays meaning they may have little bit of issues on their.  Okay.  Thank you so much.  And in particular just to be very honest we had several cases on the previous assignment of cheating in the other class.  And so thats why we are little bit behind.  Just to let you know.  So it took me almost day to go through the entire process.  So we have tool that has been developed by University of Stanford that is comparing.  mean you provide the to the tool all the assignments and they do automatically comparison to with all the combinations at the very end that you have the number that will tell you the level of similarity.  We used that level of similarity as sort of red flag to determine if there could be plagiarism or not.  Once we have the red flag then we go to in that we manually analyze if there was plagiarism or not because mean that is an automatic to learn may work or may not work.  And at the very end that is our responsibility to do something.  Then have spreadsheet for evaluation.  So with the grade for the assignment of the number of people doing the same assignment.  In this case we had the six classes.  So mean its class.  We have the largest cluster with four people.  Theres more.  Laura Theres more or less cluster with two people.  So one of the parameters in my model is the number of people involved in the project.  So you have the the grade that can be hundred or can be not so good can be 80 whatever the number of people in that particular case.  Then the evaluation from the tool and then the if the like.  In that case if there are two parts of the assignment what is the relative weight of the two can probably go and show it to you.  That is probably easier.  No dont.  Okay.  So and at the very end different things.  Okay.  So let me share this.  So thats what we have.  We have in this case there were two parts.  One that was the coda and the other one that was the interpretation.  So you have the score for each one of the two parts the number of students that are involved.  The percentage of similarity from the tool to the revised two because again we do to then is calculating what is the penalty and then the actual score for each one.  Then you have the relative weight.  You have the average.  Because if.  The average Joe dissimilarity is above the similarity that the students have.  Then there is no penalty.  But if the similarity in their submissions is higher than this will kick in.  And then you have this or grade.  So as you can imagine this is taking little bit of time.  So my apologies but really wanted to give you all the insights.  We want to be fair.  So and we want to be clear in the process that we are doing so.  But you can be sure that within couple of days you will be graded.  appreciate the inside scoop.  Thank you.  This year mean things can happen when you have class that is 55 people coming from different cultures.  Sometimes they really think that sharing solutions is something that you are not supposed to do.  So Im generally very clear at the very beginning of the class.  But mean some students may not even be so fortunate.  Thats how.  Other questions.  Yeah.  So got quick question.  Yeah.  Good for the quiz for quiz five.  know its for you know after did it it didnt tell you like which ones you got right which one you got wrong like it just gave you the score.  Didnt show you that the solutions is the one.  Yeah.  dont know why that will check it.  mean its just matter of the box that probably has not been checked.  The one of the questions that they had was on how you call uh the library number.  And was you and is right.  Who asked me that.  Yeah.  had mentioned that in my email yesterday.  Yeah yeah yeah yeah yeah.  So mean when you call function there is not one single way to do it.  In that case there was that one way.  That was great.  That is one of the many ways to do it and all the other that were wrong.  Keep in mind that with by on capital letters sends more letters.  They are different.  So if you have the import non pi with the capital is wrong because there is no library.  No by with the with the capital n.  So.  But again Im sorry if there was no published solution for that.  will definitely check the box and make sure that it would be checked.  Thank you.  Sure.  Sorry about that.  Other questions.  All right.  So.  Yeah.  Yes.  But the for this assignment and Simon finds out were able to resubmit.  Yeah.  Yeah.  Be sure that you are not using the solutions that presented.  Okay.  Because mean it wouldnt be fair.  Of course.  All right.  Thank you.  Okay.  All right.  So let me share the screen.  And let me go now to the.  File for the lecture.  So lets talk about data science and machine learning.  We do offer course that is machine learning for systems and enterprises is course so that created couple of years ago and its running once year in fall and as am6 24 as prerequisite because its python intensive.  mean 624 or equivalent.  So you need to be proficient in Python that would take the courts and is not one of your electives.  But if you are interested we can find way some of your colleagues in the same cohort.  The structure program took it and they liked it.  Um Im also writing book on suicidal impacts of machine learning and some of the things that they would present today are somehow related to the work that Im doing.  What is artificial intelligence So mean we can talk for for days months that the computers do not have intelligence.  So no computer no system that is being created.  Its intelligent in the way we normally use intelligence as an attribute.  But the point is just that we dont really know how to define national intelligence if we cannot define national intelligence.  So we cannot define artificial intelligence the history.  But we have mean test to evaluate the intelligence.  So were talking to me not about that.  So the history of artificial intelligence is starting back several centuries ago just because there is no formal definition in the given the period of time when people realized that was an intelligent behavior or behavior by the machine that was similar to what human was doing then that that was labeled as an artificial intelligence.  Generally speaking artificial intelligence is considered to start with Alan Turing.  So in 1950 Alan Turing was a.  Working during World War Two and decrypting encrypted messages from the Germans.  And it was brilliant mathematician.  And he created the Turing test.  He created this decryptor machine that was considered for example an intelligent one.  Then if you move forward in that lets say in the second half in the 20th century in the 1900s artificial intelligence kind of took little bit of momentum in the late eighties.  was involved in artificial intelligence.  was in RD company within an information technology group and was working on what we are called the time expert systems meaning systems based on rules that the rules that we are representing the expertise of the experts in given field.  So that was in 1986 when they started working on that.  Then we realized that no matter how many roots we can create we will never really have the same level of expertise as human being then.  Obviously there were other conditions so we didnt have enough computing power.  So.  We didnt even have computer with graphical user interface.  So the power of the computer were limited.  We didnt have python with all the libraries meaning all the algorithms.  So we had to write themselves ourselves by hand from scratch.  Meaning mean it was lot of effort.  Now you call library you pass the parameter and you are good to go.  Not at the time.  So the limitations of the hardware resources the limitations of the.  Talk to the interpreters or copilot that we had at the time the limitations of the data we had.  So now everything is digital at that time.  Very little was digital although it was lot of analog meaning how you can do machine learning or data analysis if you dont have the data.  So anyway so then because of those limitations there was what was called the winter of yeah.  So for good 15 years almost 20 years nothing happened.  And then with more data more power and better languages we started again.  So this is just to give you little bit of.  The context and perspective.  So artificial intelligence is not something that was born few years ago but is something that is relatively old.  mentioned the Turing test so the Turing test is working pretty much like that.  You have wall and you have on one side the human being on the other side.  We dont know.  The human being is placing question to whatever it is on the other side of the wall.  If no matter what the questions are the answers are such that the human being cannot define.  If on the other side there is uh human or an artificial entity.  Then they are artificial and it is an artificial entity.  Then the artificial entity passed the Turing test.  Um you will know that we have since on the health of November.  Chuck GP That is a.  On all over the news any is considering artificial intelligence.  So people is using it for million different things.  It is very powerful tool but its pretty much the equivalent of Google with the layer of lets say conversational manager.  So what is doing is taking mountain an ocean of data and then discovering patterns in the data and matching the questions that you have with the partners.  And based on the proximity of your question with the past answer is giving you an answer in conversational way.  So its sort of compile the Google search answer presented in conversational way.  Would it pass the Turing test Well asked Chuck Gupta would you pass the Turing test And the answer was absolutely right.  It depends on who is asking the questions.  Because if am asking questions that are pretty basic may be bold.  So like that they are called the lines the larger language models.  So what to do The NLM may pass it.  But then if the question questioner the human questioner is more advanced it wouldnt pass.  So you may already have grabbed that in different outlets.  But if you search there are interesting examples of failures of charter.  Some are kind of ironic.  Some are funny.  So its kind of interesting.  Anyway what is generally speaking part of automation.  Not everything that is automated has intelligent.  But if.  If.  You have something with artificial intelligence is part of the broader approach to automation.  Robots can be intelligent or not.  If you have robot piling up bulldozer and doing all that we cannot really define it as intelligent.  Within artificial intelligence you may have autonomy or not.  So if you have group that has nothing to do with autonomy.  If you have socalled selfdriving car thats never been there that not happening.  As we know from recent news that is on the line of autonomy.  Drilling down artificial intelligence machine learning data science.  So those are three components that are kind of interconnected.  Not all like the machine learning or better not all the artificial intelligence is machine learning.  Generally speaking there are two schools one that is called symbolic that is based on symbols.  Symbols can be taxonomy.  So taxonomy is structured approach to knowledge.  Consider the taxonomy of the human kingdom of the human or the animal kingdom.  So you have animals.  You have either no mammals no mammals and then you have all the different animals.  So thats an example of taxonomy of classification of domain.  Each domain has its own classification taxonomy and you can use the taxonomy as way to navigate into the semantic meaning the meaning of the documents or the images or whatever elements with the informational content that you want to analyze.  So thats an example that mentioned before the expert system with rules.  Thats another example of symbolic approach.  So thats one way to interpret artificial intelligence.  If you go back in time this approach is based on that.  So in the representation of knowledge there were two different approaches.  One that is based on the concept.  We start with blank slate and then we learn a.  With experience.  So those are the empty seats.  And this is what the machine learning is doing.  This is what it is doing from the data.  All the knowledge is there.  Then there are algorithms that are optimized to get to discover patterns in the data and present the pattern and associate the most appropriate patterns to your request.  Is this representation of knowledge Yes.  Is this representation of knowledge that we use No.  Meaning you cannot really define intelligent system that is based only on given data because it is not able to analyze new data is not able to grow.  It is just doing matching though it discovering pattern and doing matching.  There are many other things that would be happy to discuss with you but dont want to drive the entire class on that.  So one is the empiricist machine learning.  The other one is based on concept that knowledge is something that is embedded in our brain.  So we have pattern.  So we have predefined model that we were already born with it.  So and thats the symbolic approach.  So one but mean that those two schools of thought where mean that they started 2000 years ago or the traditional artificial intelligence or symbolic and the more modern machine learning approach are mapping to to schools of representational knowledge that are 2000 years old obviously.  We can do machine learning today because we have lot of data.  You couldnt do machine learning.  When started working in Artificial Intelligence in 1986 because there were not enough data to do battery recognition or to do any inference on the data.  Data science is working for both.  So when you have data you need to process the data.  What we did for example in the last assignment there was cleaning the data processing the data present in the data.  So thats the real data science.  Not everything in data science as an intersection with machine learning or artificial intelligence but when you do in particular machine learning its kind of difficult to do machine learning without using elements that are typically originally from data science.  In data science you have all the data preparation you have all the algorithms that you normally use in machine learning.  So the intersection is pretty tight.  Again one of the key elements is the availability of data.  Without data you cannot do any machine learning.  So machine learning.  system that is based on machine learning is to make main components one that is the algorithm one that is the data.  Algorithms with no data will generate model of no user data with no model.  So you can do something but its not going to be machine learning system.  So again that machine learning system is as good as the combination of algorithm plus data.  What is more critical is the data.  Keep in mind that on chart GPT they use an algorithm that is mean several are good but the core algorithm is what is called transform.  That is an algorithm created by Google and.  It was used this transformative approach as base for what is called GPP.  That is the first instance of challenged jeep.  So it is based on GP2 GP2.  mean all of those are based on neural networks that are sort of representation of the human brain.  In the brain we have synapses in the neural networks in the artificial neural networks.  So you have the weights that you provide in the different multiplications that you do in the representation in GPT.  Again the GP2 is used and is using half billion of those weights of those parameters.  We are in that GPT 3. 5 with GPT four.  That is due shortly with dont remember how many billion parameters probably 2. 4 billion parameters.  To train those systems to train child GPU that is based again in on GP2.  The course was 1. 5 million and as much energy as the energy required to run 1200.  Thats the number that they had in mind.  But its more than 1000 anyway.  Medium sized cities in the US.  Where Im in.  The energy is poor running.  The computers doing the calculation.  So thats basically the difference between GP and the GP.  So they can only see GPT.  They then building by the way will have tiny fraction of the data meaning is not going to be as smart as the GP GPT even if the algorithms will be the same.  So mean the core algorithm is 300 lines so binary code.  So its that much.  But then you have several billion words collected from all over the Web.  So those are some of the directions.  In robotics is definitely big.  There are several flavors robotics robotics and autonomous robotics or robotics to enhance human characteristics that can be physical or can be mental.  Natural language processing definitely one of that creativity.  dont know about that.  So Gardner is one of the leaders in.  Market analysis and technology is doing those hype cycles where her technologies where you start with the innovation then pretty much everybody is talking about it.  Think about.  So they will reach the peak of expectations.  And then either the technology will die or will become mainstream.  So thats basically the.  Life cycle of technology.  And you would see quite lot of things that we were discussing.  You would see autonomous vehicles cognitive systems and natural language processing.  And then you have different calls for when Gartner believes that doing things is going to happen.  Obviously when you have elements that are more than ten years then who knows mean in in technology something that is so far that they need we dont know what is going to happen.  So if you look at the bottom left the artificial leg in general intelligence meaning something like system passing the Turing test with the examiner that is quite knowledgeable.  Its far far away.  So we say more that then we have said but we have no idea when its going to happen.  Same thing for autonomous vehicles.  We know that Tesla has recalled most of the vehicles with autonomous mean the selfdriving component.  mean there are several complexity issues on there.  But thats another view.  And would keep on that.  Just driving the attention to the chart on the right.  The number of public companies mentioning AA and machine learning in their earnings calls.  So we went from zero to huge number.  Pretty much every one.  We want to be in the AA machine.  So its events.  Each school is of course is on that machine learning because each school wants more students.  And when you have machine learning students would come oh is this something good for the schools Yes it is something good for students.  dont know what mean is generating more confusion than ever.  But thats another.  set of charts.  Look at the bottom.  Right.  So the sentiment on the articles referencing yeah.  So from that skeptical period we are going to the enthusiastic period.  So lot of people is thinking that could do.  Im in.  dont believe in controlling what you do.  do believe that there will be high expectations probably use for what he cannot do.  Generating results that could be disappointing.  Hopefully will not be harmful somehow.  Amazon is using elements of machine learning in software development.  Machine learning can be used both ways can be used in helping develop and developing software that can write code for you.  Im in.  Feel free to use it.  use it for few things but you really need to know how to code to get real benefit.  From what Chad duped he can give you.  By the way not taking clients meaning you cannot say okay redefined created program to redefine and do something based on what is in the field.  You cannot do that because cannot read clients.  So in sense it can be helpful in that way.  But also software development can be helpful to develop better machine learning systems.  You may know DevOps as term meaning all the set of rules and methodologies to better develop software.  When you develop software is not just writing the code but is having the code running in the system.  In the larger system when your piece of code will do his part its pretty much the same thing with machine learning.  You have some code that will run within an environment.  So this set of placing your code the real world is managing the operations of the code and has the equivalent.  So lot is on DevOps for machine learning.  System engineering.  Same thing keeping in mind that when you develop something even if brilliant piece of technology based on machine learning is still portion or something that can be bigger.  So you need to keep the system view of what you are doing with that human so that somehow as to be in the loop.  Just brief example when you when they develop the chart the GPT.  They had not one algorithm but was method.  So you have it.  The first step is collecting this ocean of data.  The second is to have human beings going into these additional data and doing two things.  One eliminating content that is inappropriate.  And unfortunately in the Web there is lot of content that is inappropriate.  So those humans are doing job that is one of the worst jobs that human can do.  Meaning going into the inappropriate content and remove it in five days week or more hours day or more just reading inappropriate content.  So it is not great job.  And the second thing that they are doing up with tagging the.  The area is machine learning with the highest number of humans employed is on net tagging data meaning you have her text images eventually sound new target for what they are that those will be to train the system when the system will read something similar.  So the humans are cleaning tagging portion of the data not the entire mountain.  Then the system will use this first training portion to train larger portion and you humans will give scores to that.  And then you have another element that is based on an algorithm that is called regarding neural network.  That is basically using as score to the proximity to the evaluation of the humans to evaluate the additional data that you may have at that point.  You have relatively large set of data as training subset and then you use that to classify all the rest and target in the proper way.  So thats how the pattern of creation has been done.  Once you have that then you can apply systems for classification as the transform that was mentioning before.  So again it seems to be you have an algorithm with data you apply youre good to go.  No is system and you need to design the system in the appropriate way.  Some applications are so.  Uh selfparking.  Cruise control or speech recognition banks monitoring fraud.  Those are examples of either machine learning or um military just to share with you.  Uh an example was attending um Im working with the D. O. D.  through circulatory system Engineering Research Center.  That we have at the School of Systems and Enterprises.  And we had meeting presenting the research that we as principal investigators did for the day of the.  And there was an invited guests who was talking about the some examples that he collected in book that is called The War None The Army of Man.  And he was he was serving in Afghanistan.  And at the certain point he was close with the ledger with the platoon where mean he was part of and the certain point that girl approached them.  It was nice build.  They offer her some food.  She stayed for bit.  Then she left.  And then from the village they started attacking them.  So the question he had was if instead of us there was an artificial intelligence evaluating the risk that that girl could have been sent to spy on us and then decide to kill the girl.  Well an artificial intelligence that would have done that.  We didnt.  So thats an example of human judgment.  So there are autonomous vehicles.  So some of the drones are both aerial drones or land drones.  They are fully automated but there are quite lot of questions.  So in the US we tend to have more ethical questions even in our warfare.  Some other countries may not.  So we know that there are unmanned vehicles that are on the territory just acting as elements active elements of war.  So would stop here and would briefly go into something completely different.  will go very fast on this.  So will leave you this.  Lights.  So software development.  We know how it was created.  One of the main issues when you develop software is that the specs are being lost in translation.  So you have what the client needs what the contractor understood what the other of the subcontractor.  And then at the very end the delivery may be not exactly either what the client wanted or what the client asked them.  So between what the client is asking what the client it will want and what the contractor is perceiving as need and what the mean all the parts are moving parts and there is quite lot of lost in translation.  So when you develop software there is portion of that is on development the actual development.  Fortunately there is in testing and portion of it is in maintenance.  The sooner you find the harasser the lower the cost of fixing is going to be.  So one of the elements that we generally consider when we develop software is the concept of the software lifecycle.  So the software as a.  beginning and an end.  Some software apps thought of zombies.  They never die.  So we still have COBOL software that is running since few years.  And it is running.  It is running in public administration is running in some banks but generally speaking you have lifecycle and the retirement.  So not always but most of the time that tribally as standard for that.  So one of the traditional ways of developing software is waterfall.  So the waterfall meaning that you start with the requirements based on the requirements you do the design based on the design do decoding.  When you complete the coding you build testing and then you release the software to.  The client the annual start the maintenance.  So unfortunately this approach even if is great for defining the requirements as lack of flexibility for changes making it not very successful actually only 16 in the peak.  This approach was called successful.  So you can add little bit of flexibility with little bit of prototyping and later parameterization but the problem is deeper than that.  So thats basically when software engineering started the.  With the idea of applying elements of engineering to engineering design and development to software and computer science is essential for software engineering that physics is essential for electrical or mechanical engineering.  generally describe software engineering as system.  Engineering applied to computer science is basically considering the complexity of the software development that it is not just developing the components but having the components working in the proper environment.  The The Software Engineering Institute that is currently based within Carnegie Mellon University in Pittsburgh.  was partner member of software engineer initiative to develop the capability maturity model.  That is way to define levels to measure where you are and each level and help you moving up in the levels.  It is very rare that you have software at level four.  Very few if not none either.  Higher than that.  So those are definition of level.  But in order to move from level you need to measure everything.  Meaning you need to have sort of big brother big sister meaning quiet.  Although all that adds to capture score analyze the information when you have very large projector the cost that the overhead may be justified by the size of the project.  When you have smaller projects not so much Agile.  Agile was introduced kind of to keep methodology but with more degrees of flexibility.  The GI Manifesto.  So thats the main characteristics.  We do not offer courses on Agile in broad sense so we do offer courses on Agile for software development.  And we talk about agile development or agile management in our project management course.  Principles.  So pretty much you interact lot.  You have lot of prototyping.  So those are some of the methods.  Scrum is one of the most common.  And.  would stop here because its uh its later than 745 and you have the lights and you can definitely go through them.  strongly encourage you also to go through theres lights and mean they are relatively old but is description of one of the largest failures in software development.  The in this case was by the FBI.  The ritual case file that court said asks that it be huge amount of money generating not much.  So spoiler alert the real reason is the lack of communication and lack of clear responsibilities.  So again its not just matter of how you develop software but how you manage your bank.  And so from the client to the developer the environment the real needs.  So its kind of interesting.  use the original slides that were published in 2005 but didnt change anything because just wanted to give you.  An example of whats going on.  All right.  So in class exercise.  So the in class exercise its about analyzing password.  So the user will impose set of passwords separated by comma.  And you need to check if all those conditions are verified meaning the password is at least one letter between those one number between those some of the capital letters some special characters minimum length of maximum lengths.  And you will take from the user the.  Passwords.  Most likely at least.  And then you look into the list.  You would write function of.  That will take each one of the passwords and do the checks.  And then returning is good.  Is not good.  All right so Im stopping the sharing that Im publishing.  The inclass exercise.  SHUBERT Yes.  Well.  And.  will create the breakout rooms.  Four breakout rooms to three participants creating opening 15 minutes.  All right.  The only minutes.  Then 15 minutes.  Hi.  Sorry my laptop died.  Can you put me back in the room One.  Okay.  Hold on sec.  sprinted to get my charger so can go back there.  Okay.  Thank you.  Sure.  Resuming the recording.  Okay.  So we are all back.  Any one of you want to share either the solution or just the frustration of not having enough time to do it All right.  Okay so let me.  Share the screen and let me do.  Here.  So.  use the the library string.  Uh you can do without.  So lets see both the options.  So in the comment added all the requirements.  Then imported this string.  You would see how this would be used.  And then this is the function validating the password.  So its taking single password then is checking if is either less than six characters or more than 12.  If this is the case it will return an.  Dan is transforming the world into place when you transform stranger into least the elements on the list that will be the characters the single characters.  So one element one character from the origins thing.  Then created list that will use for getting the okay for each one of the tests.  So there are four tests to do as more letters numbers capital letters special characters and order each one.  will eventually change the RN into White.  So the first one am checking if the element has mean need to go little bit down.  So created list for small letters capital letters member numbers.  This can be done using the function three anchor or you can manually create.  So in comments use the manual creation on those lists.  Out of the comments use the function string that it was mentioning before.  So those are the values.  So.  And checking if its more letters.  If is number is numbers if capital letters special characters each one is an okay.  Then well change that and into and then.  If its and then were done the list.  mean if no one of those or those if we generate it.  Yes.  You will get no other otherwise.  Yes.  So when you go down.  You pass the elements.  So its taking the password.  Then there is passenger each one of their passwords into the function and then if it is returning why then is okay.  Otherwise well continue.  Who let me save the cops.  This list here and will use it as an example.  So let me run it.  Back.  And as result.  All right.  So you will find the two more.  Filed by those creeps.  Just play with them.  But they will get back the next class to explain little bit more what they are.  So they are basically to generate reports or to analyze the files for what is called data exploratory analysis.  So one is doing the full exploration.  The other one is focus on the coordination on.  All right.  So.  Next assignment the.  Its going to be.  On COVID 19.  So the file that you will use for your analysis will be What is it Will be like this one.  So you have.  Condition groups specific condition.  code that you would not use the age group.  The number of deaths and the number of mentions.  So this is the file you have.  So based on that the.  You will do.  mean lets keep but one of is just questions.  So you will basically calculate the number of people in the different categories.  So where are categories it would be So you will not read the file.  You will create dictionary or you want to use pandas and feel free to do it.  Population less than 35.  Then you will.  Plot the.  For two elements.  So one bar plot and pie plot similar to this one.  But this one is from different example.  So not the actual graph.  And well show the distribution of deaths by age group meaning you want to calculate.  So create dictionary with the number of deaths for each one of the categories.  You would use function.  So.  You will then generate the chart.  Bar by.  Ukraine their comorbidity with the highest number of deaths with population of less than 35.  Run correlation analysis to determine the relationship between variables.  You will have your script.  And then there will be part one.  That would be just questions.  So what is giant software What is why Waterfall is not great solution to define machine learning.  And some examples.  So thats basically it.  If you have time adjust and eventually you will have the recording considering you will use the correlation.  just want to be sure that you will see it running at least once.  So correlation.  In this case Im using basic pandas functions and my plot labor to.  have the graphical representation of the keyboard and is another graphical library on top of my plot.  So Im reading the NFL Census CSB file.  Calculating the correlation and representing it as graph and eventually save it has point.  If run it.  The fine is relatively big.  You have the correlation.  So you will see that the salary for example.  So the correlation is negative correlation meaning one is decreased is increasing the other is decreasing and vice versa.  Positive one is increasing and the other is decreasing.  So the more blue is the more positive.  So obviously along the main diagonal there is one.  So you have the salary.  That will increase with experience and if the Pro Bowler will be higher.  Thats an example.  And you will have the file that would be generated.  The other one is little bit more powerful even if few lines.  So.  Is generating.  reporter.  So its creating it.  Summarizing the dataset.  Generating the report.  Generating an edge male end is basically something that.  Not sure where this one comes.  Go here for moment.  But.  So theres the excitement that is being generated.  Its mean its amazing that in line to line basically you can generate the entire report with overview description of variables.  Distributional numbers.  Analysis for each one of the variables including the distribution.  To evaluate the skewness.  Then you have.  Interaction correlation pretty much as the other one.  Either as heat map or stable.  Missing values and sample.  So all of this.  With pretty much one library.  And one.  mean theres three things.  And one line.  Two lines.  And then if you want the five three lines.  Okay.  So will post all the content again.  already send an email to the DEA and the grader to make sure that the evaluation will be less strict as the previous one for text size for.  And you will have another couple of days for your submission.  Not that you need to do late submission but you have the option.  aft STEVENS lw INSTITUTE of TECHNOLOGY Text mining in an evolving society clipizzistevens. edu SSE Language How we acquire it B. F.  Skinner Behaviorist theory infants learn language from other human role models through process involving imitation rewards and practice Tt ot J.  Piaget Constructivist theory Language is acquired within the context of the childs broader intellectual development.  Language is not an independent system but part of our general cognitive makeup N.  Chomsky Nativist theory Children are born equipped with an innate template for language and this blueprint aids the child in the task of constructing grammar for their language STEVENS INSTITUTE of TECHNOLOGY ne Language as part of the human evolution STEVENS INSTITUTE of TECHNOLOGY The relevance of the Medium The Medium is the message . . Technological media are staples or natural resources exactly as are coal and cotton and oil Marshall McLuhan 1911 1980 . . .  Tis the medium that shapes and controls the scale and form of human association and action.  The content or uses of such media are as diverse as they are ineffectual in shaping the form of human association STEVENS INSTITUTE of TECHNOLOGY The Printing society Focused on Religion Education Industry Thought Conflict Ideas Community Organization Truth STEVENS INSTITUTE of TECHNOLOGY The Mass Media society le Focused on Leisure time Education Knowledge of the other Politics Global Connections Speed of Life Mean World Effect At an accelerating pace throughout the century the electronic transmission of news and Minimizing Empathy entertainment changed virtually all features of American Life Robert Putnam Bowling Alone.  SS LULU STEVENS INSTITUTE of TECHNOLOGY The Alwayson Internet society Focused on Sharing Cooperation Collective Actions Reduced Privacy Source uncertainty Information overload Living in the cloud ee STEVENS INSTITUTE of TECHNOLOGY Living in the cloud effects the lw overstimulation The average attention span in 2015 seconds The average attention span in 2000 12 seconds The average attention span of gold fish seconds Percent of teens who forget major details of close friends and relatives 25 Percent of people who forget their own birthdays from time to time Average number of times per hour an office worker checks their email inbox 30 Average length watched of single internet video 2. 7 minutes STEVENS INSTITUTE of TECHNOLOGY How we communicate in living in the lw cloud times Percent of page views that last less than seconds 17 Percent of page views that lasted more than 10 minutes Percent of words read on web pages with 111 words or less 49 Percent of words read on an average 593 words web page 28 Users soend only 4. 4 seconds more for each additional 100 words Source Harald Weinreich Hartmut Obendorf Eelco Herder and Matthias Mayer Not Quite the Average An Empirical Study of Web Use in the ACM Transactions on the Web vol.  no.  February 2008.  STEVENS INSTITUTE of TECHNOLOGY Understanding what people say Text lw mining today Communications today are becoming shorter less structured more chopped Some of the media have intrinsic limitations in terms of length but even those with no such limitations tend to be used for short fragmented multi threads or even single message Communications.  This implies less syntactic structure less rhetorical elements Traditional methods to extract knowledge from text are based on the existence of predefined structure that can be in the syntax in writing patterns in preset taxonomiesontologies The lack of structure makes the traditional media either less or not effective anymore STEVENS INSTITUTE of TECHNOLOGY 10 STEVENS ae INSTITUTE of TECHNOLOGY Jy INNOVATION RSIT Mining Social media Using the social structure as proxy for the lacking conversational structure Mining Social media When communications have social component the social structure may act as proxy for the conversational structure STEVENS INSTITUTE of TECHNOLOGY 12 cf Extracting meanings Using combination of semantic and topological analyses we can extract dynamic concept maps from social media streams Conversations are characterized by structural patterns whose properties can be assessed through quantitative metrics tool has based on this approach can be used as backchannel for real life events Conversational patterns can provide dynamic insights on what people say about the event Conversational metrics potentially contain early signals to predict users oreferences and choices STEVENS INSTITUTE of TECHNOLOGY 13 ani ii Focus on Twitter We used message streams from Twitter micro blogs because of Twitter popularity Microblog is the main social medium to share broadcast opinions Wide availability for downloads Intrinsic reduced semantic complexity due to the limited number of characters STEVENS INSTITUTE of TECHNOLOGY 14 Sl Perspective Conversational analysis We use conversational metaphor and assume that in backchanneling applications microblogs stream exhibit some properties of conversations According to the Common Ground theory conversation is form of collective action requiring participants to coordinate on content and on process Brennan Clark 1991 STEVENS INSTITUTE of TECHNOLOGY 15 Mining open texts Extracting the structure cf.  Mining open texts lw When communications have no social component there is no social structure that can act as proxy of the conversational one.  This is the case for novels or larger corpora The distributional semantic approach quantifying and categorizing semantic similarities between linguistic items based on their distributional properties in text can be the basis to induce the missing structure One of the increasingly popular methods to extract topics from text is word2vec that is group of models that are used to produce word embeddings Mikolov Chen Corrado Dean 2013a Word embedding is the collective name for set of language modeling and feature learning techniques in natural language processing where words or phrases from the source are mapped to vectors of real numbers Mikolov Sutskever Chen Corrado Dean 2013b SS LULU STEVENS INSTITUTE of TECHNOLOGY 49 Word2Vec lw Published by Google in 2013 Python implementation in 2014 gensim library Generates distributed vector representations of words word to vec using neural net In those distributed vector representations of words each word Is encoded as vector of floats VCgueen 0. 2 0. 3 . 7 . . .  . 3 VCwoman 0. 1 0. 2 . 6 0. 1 . . .  . 2 length of the vectors dimension of the word representation key concept of word2vec words with similar vectors have similar meaning context STEVENS INSTITUTE of TECHNOLOGY 50 Why this approach is relevant how is structured lw Zellig Harris 1954 oculist and eyedoctor . . .  occur in almost the same environments If Aand have almost identical environments we say that they are synonyms.  Firth 1957 You shall know word by the company it keeps Intuition for algorithm Two words are similar if they have similar word contexts The meaning of word Is vector of numbers Vector models are also called embeddings STEVENS INSTITUTE of TECHNOLOGY 54 ots From words cooccurrence to embeddings lw Word cooccurrence measure how often word occurs with another within given number of words of separation Using cooccurrence we can create wordword co occurrence matrix where rows and columns are the unique words in the source text Each word is represented this way by vector that Is soarse and with most of the values being zero The whole approach Is based only on the actual words proximity STEVENS INSTITUTE of TECHNOLOGY 52 From words cooccurrence to embeddings lw Word2Vec Instead of entire documents Word2vec uses words few positions away from each center word.  The pairs of center wordcontext word are called skipgrams It was bright cold day in April and the clocks were striking Center word red Context words blue Word2vec considers all words as center words and all their context words STEVENS INSTITUTE of TECHNOLOGY 53 From words cooccurrence to embeddings lw predicting the context given word Continuous Bag Of Words predicting the word given its context Distributed Representations of Words and Phrases and their Compositionality Tomas Mikolov Ilva Sutskever Kai Chen Greg Corrado Jeffrey Dean NIPS 2013 STEVENS INSTITUTE of TECHNOLOGY 54 From words cooccurrence to embeddings lw Word2Vec Word2vec optimizes softmax loss for each output word expu pl k1 XPU Vi Where is the output word is the input word.  ranges over context of 35 positions around the Inout word IS Gn Output embedding vector Is AN input embedding vector Word2vec can be implemented with standard ANN toolkits by backpropagating to optimize and Softmax or normalized exponential function is normally used to highlight the largest values SS LULU STEVENS INSTITUTE of TECHNOLOGY 55 ots Using Word2Vec to create network structure lw Data collection and Preprocessing.  Word2vec is steps process training the algorithm and using it Creation of the word tables.  Using PythonGensim we created tables Annbyn matrix with all fhe unique words on both the headers and the values from the word2vec embeddings Areduced dimension matrix by where the words are represented by vector composed by dimensions.  We used 300 and we cut out words occurring less than given number of times depending on the size of the source text STEVENS INSTITUTE of TECHNOLOGY ots Using Word2Vec to create network structure lw Network elements definition Nodes.  The nodes of the network are the words from the above matrix.  Their attributes are their dimensions Relationships.  Two nodes are related if their cosine similarity is above given threshold calculated starting from the average Network representation.  We used combination of Networx pyvis and eventually Gephi GUlbased network analysis tool for fast proof of concepts STEVENS INSTITUTE of TECHNOLOGY 57 Using the network structure lw Just as in the social networkbased case from the network we extracted clusters representing words aggregationstopics.  As in the social network based case for the clustering we used combination of kcore and Lauvain community detection methods.  In order to reduce the noise we focused on larger clusters only. 